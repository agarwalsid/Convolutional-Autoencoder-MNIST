{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Convolutional Autoencoder\n",
    "\n",
    "Compressing and Denoising the MNIST dataset with an autoencoder using convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', validation_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f83965b6c88>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f839f9e8860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = mnist.train.images[2]\n",
    "plt.imshow(img.reshape((28, 28)), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "# Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "\n",
    "conv2 = tf.layers.conv2d(maxpool1, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "\n",
    "conv3 = tf.layers.conv2d(maxpool2, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')\n",
    "\n",
    "\n",
    "# Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "\n",
    "conv4 = tf.layers.conv2d(upsample1, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "\n",
    "conv5 = tf.layers.conv2d(upsample2, 8, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "\n",
    "conv6 = tf.layers.conv2d(upsample3, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding='same', activation=None)\n",
    "\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20... Training loss: 0.7175\n",
      "Epoch: 1/20... Training loss: 0.7037\n",
      "Epoch: 1/20... Training loss: 0.6939\n",
      "Epoch: 1/20... Training loss: 0.6861\n",
      "Epoch: 1/20... Training loss: 0.6791\n",
      "Epoch: 1/20... Training loss: 0.6711\n",
      "Epoch: 1/20... Training loss: 0.6677\n",
      "Epoch: 1/20... Training loss: 0.6544\n",
      "Epoch: 1/20... Training loss: 0.6411\n",
      "Epoch: 1/20... Training loss: 0.6313\n",
      "Epoch: 1/20... Training loss: 0.6163\n",
      "Epoch: 1/20... Training loss: 0.5944\n",
      "Epoch: 1/20... Training loss: 0.5790\n",
      "Epoch: 1/20... Training loss: 0.5581\n",
      "Epoch: 1/20... Training loss: 0.5455\n",
      "Epoch: 1/20... Training loss: 0.5242\n",
      "Epoch: 1/20... Training loss: 0.5313\n",
      "Epoch: 1/20... Training loss: 0.5310\n",
      "Epoch: 1/20... Training loss: 0.5707\n",
      "Epoch: 1/20... Training loss: 0.5340\n",
      "Epoch: 1/20... Training loss: 0.5298\n",
      "Epoch: 1/20... Training loss: 0.5168\n",
      "Epoch: 1/20... Training loss: 0.5185\n",
      "Epoch: 1/20... Training loss: 0.5309\n",
      "Epoch: 1/20... Training loss: 0.5067\n",
      "Epoch: 1/20... Training loss: 0.5098\n",
      "Epoch: 1/20... Training loss: 0.5119\n",
      "Epoch: 1/20... Training loss: 0.5068\n",
      "Epoch: 1/20... Training loss: 0.4943\n",
      "Epoch: 1/20... Training loss: 0.4930\n",
      "Epoch: 1/20... Training loss: 0.5119\n",
      "Epoch: 1/20... Training loss: 0.4885\n",
      "Epoch: 1/20... Training loss: 0.4639\n",
      "Epoch: 1/20... Training loss: 0.4389\n",
      "Epoch: 1/20... Training loss: 0.4480\n",
      "Epoch: 1/20... Training loss: 0.4266\n",
      "Epoch: 1/20... Training loss: 0.4011\n",
      "Epoch: 1/20... Training loss: 0.4039\n",
      "Epoch: 1/20... Training loss: 0.4165\n",
      "Epoch: 1/20... Training loss: 0.4499\n",
      "Epoch: 1/20... Training loss: 0.4163\n",
      "Epoch: 1/20... Training loss: 0.4091\n",
      "Epoch: 1/20... Training loss: 0.4231\n",
      "Epoch: 1/20... Training loss: 0.4013\n",
      "Epoch: 1/20... Training loss: 0.3693\n",
      "Epoch: 1/20... Training loss: 0.3587\n",
      "Epoch: 1/20... Training loss: 0.3566\n",
      "Epoch: 1/20... Training loss: 0.3594\n",
      "Epoch: 1/20... Training loss: 0.3522\n",
      "Epoch: 1/20... Training loss: 0.3379\n",
      "Epoch: 1/20... Training loss: 0.3245\n",
      "Epoch: 1/20... Training loss: 0.3590\n",
      "Epoch: 1/20... Training loss: 0.3275\n",
      "Epoch: 1/20... Training loss: 0.2973\n",
      "Epoch: 1/20... Training loss: 0.3059\n",
      "Epoch: 1/20... Training loss: 0.3026\n",
      "Epoch: 1/20... Training loss: 0.2874\n",
      "Epoch: 1/20... Training loss: 0.2817\n",
      "Epoch: 1/20... Training loss: 0.2717\n",
      "Epoch: 1/20... Training loss: 0.2688\n",
      "Epoch: 1/20... Training loss: 0.2772\n",
      "Epoch: 1/20... Training loss: 0.2752\n",
      "Epoch: 1/20... Training loss: 0.2756\n",
      "Epoch: 1/20... Training loss: 0.2710\n",
      "Epoch: 1/20... Training loss: 0.2602\n",
      "Epoch: 1/20... Training loss: 0.2671\n",
      "Epoch: 1/20... Training loss: 0.2604\n",
      "Epoch: 1/20... Training loss: 0.2641\n",
      "Epoch: 1/20... Training loss: 0.2323\n",
      "Epoch: 1/20... Training loss: 0.2435\n",
      "Epoch: 1/20... Training loss: 0.2579\n",
      "Epoch: 1/20... Training loss: 0.2434\n",
      "Epoch: 1/20... Training loss: 0.2301\n",
      "Epoch: 1/20... Training loss: 0.2296\n",
      "Epoch: 1/20... Training loss: 0.2203\n",
      "Epoch: 1/20... Training loss: 0.2208\n",
      "Epoch: 1/20... Training loss: 0.2167\n",
      "Epoch: 1/20... Training loss: 0.2172\n",
      "Epoch: 1/20... Training loss: 0.2224\n",
      "Epoch: 1/20... Training loss: 0.2115\n",
      "Epoch: 1/20... Training loss: 0.2176\n",
      "Epoch: 1/20... Training loss: 0.2100\n",
      "Epoch: 1/20... Training loss: 0.2119\n",
      "Epoch: 1/20... Training loss: 0.2099\n",
      "Epoch: 1/20... Training loss: 0.2070\n",
      "Epoch: 1/20... Training loss: 0.2138\n",
      "Epoch: 1/20... Training loss: 0.2214\n",
      "Epoch: 1/20... Training loss: 0.2113\n",
      "Epoch: 1/20... Training loss: 0.2017\n",
      "Epoch: 1/20... Training loss: 0.1943\n",
      "Epoch: 1/20... Training loss: 0.1933\n",
      "Epoch: 1/20... Training loss: 0.1948\n",
      "Epoch: 1/20... Training loss: 0.2042\n",
      "Epoch: 1/20... Training loss: 0.2073\n",
      "Epoch: 1/20... Training loss: 0.1997\n",
      "Epoch: 1/20... Training loss: 0.1975\n",
      "Epoch: 1/20... Training loss: 0.2178\n",
      "Epoch: 1/20... Training loss: 0.2037\n",
      "Epoch: 1/20... Training loss: 0.2057\n",
      "Epoch: 1/20... Training loss: 0.2126\n",
      "Epoch: 1/20... Training loss: 0.2068\n",
      "Epoch: 1/20... Training loss: 0.2006\n",
      "Epoch: 1/20... Training loss: 0.1996\n",
      "Epoch: 1/20... Training loss: 0.1937\n",
      "Epoch: 1/20... Training loss: 0.1963\n",
      "Epoch: 1/20... Training loss: 0.1940\n",
      "Epoch: 1/20... Training loss: 0.2079\n",
      "Epoch: 1/20... Training loss: 0.2008\n",
      "Epoch: 1/20... Training loss: 0.1940\n",
      "Epoch: 1/20... Training loss: 0.2003\n",
      "Epoch: 1/20... Training loss: 0.2094\n",
      "Epoch: 1/20... Training loss: 0.1962\n",
      "Epoch: 1/20... Training loss: 0.1917\n",
      "Epoch: 1/20... Training loss: 0.1975\n",
      "Epoch: 1/20... Training loss: 0.1966\n",
      "Epoch: 1/20... Training loss: 0.1981\n",
      "Epoch: 1/20... Training loss: 0.1878\n",
      "Epoch: 1/20... Training loss: 0.1901\n",
      "Epoch: 1/20... Training loss: 0.1978\n",
      "Epoch: 1/20... Training loss: 0.1999\n",
      "Epoch: 1/20... Training loss: 0.1779\n",
      "Epoch: 1/20... Training loss: 0.1839\n",
      "Epoch: 1/20... Training loss: 0.1981\n",
      "Epoch: 1/20... Training loss: 0.1818\n",
      "Epoch: 1/20... Training loss: 0.1727\n",
      "Epoch: 1/20... Training loss: 0.1902\n",
      "Epoch: 1/20... Training loss: 0.1962\n",
      "Epoch: 1/20... Training loss: 0.1836\n",
      "Epoch: 1/20... Training loss: 0.1858\n",
      "Epoch: 1/20... Training loss: 0.1771\n",
      "Epoch: 1/20... Training loss: 0.1815\n",
      "Epoch: 1/20... Training loss: 0.1812\n",
      "Epoch: 1/20... Training loss: 0.1816\n",
      "Epoch: 1/20... Training loss: 0.1858\n",
      "Epoch: 1/20... Training loss: 0.1777\n",
      "Epoch: 1/20... Training loss: 0.1987\n",
      "Epoch: 1/20... Training loss: 0.1935\n",
      "Epoch: 1/20... Training loss: 0.1881\n",
      "Epoch: 1/20... Training loss: 0.1843\n",
      "Epoch: 1/20... Training loss: 0.1889\n",
      "Epoch: 1/20... Training loss: 0.1835\n",
      "Epoch: 1/20... Training loss: 0.1845\n",
      "Epoch: 1/20... Training loss: 0.1819\n",
      "Epoch: 1/20... Training loss: 0.1810\n",
      "Epoch: 1/20... Training loss: 0.1924\n",
      "Epoch: 1/20... Training loss: 0.1919\n",
      "Epoch: 1/20... Training loss: 0.1858\n",
      "Epoch: 1/20... Training loss: 0.1755\n",
      "Epoch: 1/20... Training loss: 0.1759\n",
      "Epoch: 1/20... Training loss: 0.1674\n",
      "Epoch: 1/20... Training loss: 0.1799\n",
      "Epoch: 1/20... Training loss: 0.1808\n",
      "Epoch: 1/20... Training loss: 0.1828\n",
      "Epoch: 1/20... Training loss: 0.1763\n",
      "Epoch: 1/20... Training loss: 0.1718\n",
      "Epoch: 1/20... Training loss: 0.1791\n",
      "Epoch: 1/20... Training loss: 0.1721\n",
      "Epoch: 1/20... Training loss: 0.1783\n",
      "Epoch: 1/20... Training loss: 0.1797\n",
      "Epoch: 1/20... Training loss: 0.1755\n",
      "Epoch: 1/20... Training loss: 0.1795\n",
      "Epoch: 1/20... Training loss: 0.1760\n",
      "Epoch: 1/20... Training loss: 0.1775\n",
      "Epoch: 1/20... Training loss: 0.1865\n",
      "Epoch: 1/20... Training loss: 0.1772\n",
      "Epoch: 1/20... Training loss: 0.1758\n",
      "Epoch: 1/20... Training loss: 0.1794\n",
      "Epoch: 1/20... Training loss: 0.1761\n",
      "Epoch: 1/20... Training loss: 0.1658\n",
      "Epoch: 1/20... Training loss: 0.1672\n",
      "Epoch: 1/20... Training loss: 0.1755\n",
      "Epoch: 1/20... Training loss: 0.1732\n",
      "Epoch: 1/20... Training loss: 0.1801\n",
      "Epoch: 1/20... Training loss: 0.1774\n",
      "Epoch: 1/20... Training loss: 0.1716\n",
      "Epoch: 1/20... Training loss: 0.1768\n",
      "Epoch: 1/20... Training loss: 0.1706\n",
      "Epoch: 1/20... Training loss: 0.1791\n",
      "Epoch: 1/20... Training loss: 0.1785\n",
      "Epoch: 1/20... Training loss: 0.1756\n",
      "Epoch: 1/20... Training loss: 0.1776\n",
      "Epoch: 1/20... Training loss: 0.1859\n",
      "Epoch: 1/20... Training loss: 0.1806\n",
      "Epoch: 1/20... Training loss: 0.1835\n",
      "Epoch: 1/20... Training loss: 0.1748\n",
      "Epoch: 1/20... Training loss: 0.1687\n",
      "Epoch: 1/20... Training loss: 0.1709\n",
      "Epoch: 1/20... Training loss: 0.1757\n",
      "Epoch: 1/20... Training loss: 0.1792\n",
      "Epoch: 1/20... Training loss: 0.1738\n",
      "Epoch: 1/20... Training loss: 0.1707\n",
      "Epoch: 1/20... Training loss: 0.1730\n",
      "Epoch: 1/20... Training loss: 0.1659\n",
      "Epoch: 1/20... Training loss: 0.1793\n",
      "Epoch: 1/20... Training loss: 0.1716\n",
      "Epoch: 1/20... Training loss: 0.1658\n",
      "Epoch: 1/20... Training loss: 0.1687\n",
      "Epoch: 1/20... Training loss: 0.1587\n",
      "Epoch: 1/20... Training loss: 0.1683\n",
      "Epoch: 1/20... Training loss: 0.1752\n",
      "Epoch: 1/20... Training loss: 0.1693\n",
      "Epoch: 1/20... Training loss: 0.1689\n",
      "Epoch: 1/20... Training loss: 0.1737\n",
      "Epoch: 1/20... Training loss: 0.1701\n",
      "Epoch: 1/20... Training loss: 0.1666\n",
      "Epoch: 1/20... Training loss: 0.1695\n",
      "Epoch: 1/20... Training loss: 0.1775\n",
      "Epoch: 1/20... Training loss: 0.1660\n",
      "Epoch: 1/20... Training loss: 0.1614\n",
      "Epoch: 1/20... Training loss: 0.1649\n",
      "Epoch: 1/20... Training loss: 0.1601\n",
      "Epoch: 1/20... Training loss: 0.1686\n",
      "Epoch: 1/20... Training loss: 0.1699\n",
      "Epoch: 1/20... Training loss: 0.1745\n",
      "Epoch: 1/20... Training loss: 0.1684\n",
      "Epoch: 1/20... Training loss: 0.1586\n",
      "Epoch: 1/20... Training loss: 0.1678\n",
      "Epoch: 1/20... Training loss: 0.1727\n",
      "Epoch: 1/20... Training loss: 0.1633\n",
      "Epoch: 1/20... Training loss: 0.1625\n",
      "Epoch: 1/20... Training loss: 0.1749\n",
      "Epoch: 1/20... Training loss: 0.1668\n",
      "Epoch: 1/20... Training loss: 0.1680\n",
      "Epoch: 1/20... Training loss: 0.1655\n",
      "Epoch: 1/20... Training loss: 0.1661\n",
      "Epoch: 1/20... Training loss: 0.1666\n",
      "Epoch: 1/20... Training loss: 0.1751\n",
      "Epoch: 1/20... Training loss: 0.1688\n",
      "Epoch: 1/20... Training loss: 0.1672\n",
      "Epoch: 1/20... Training loss: 0.1697\n",
      "Epoch: 1/20... Training loss: 0.1654\n",
      "Epoch: 1/20... Training loss: 0.1691\n",
      "Epoch: 1/20... Training loss: 0.1668\n",
      "Epoch: 1/20... Training loss: 0.1681\n",
      "Epoch: 1/20... Training loss: 0.1687\n",
      "Epoch: 1/20... Training loss: 0.1609\n",
      "Epoch: 1/20... Training loss: 0.1598\n",
      "Epoch: 1/20... Training loss: 0.1692\n",
      "Epoch: 1/20... Training loss: 0.1706\n",
      "Epoch: 1/20... Training loss: 0.1622\n",
      "Epoch: 1/20... Training loss: 0.1602\n",
      "Epoch: 1/20... Training loss: 0.1631\n",
      "Epoch: 1/20... Training loss: 0.1671\n",
      "Epoch: 1/20... Training loss: 0.1672\n",
      "Epoch: 1/20... Training loss: 0.1605\n",
      "Epoch: 1/20... Training loss: 0.1726\n",
      "Epoch: 1/20... Training loss: 0.1647\n",
      "Epoch: 1/20... Training loss: 0.1686\n",
      "Epoch: 1/20... Training loss: 0.1688\n",
      "Epoch: 1/20... Training loss: 0.1586\n",
      "Epoch: 1/20... Training loss: 0.1575\n",
      "Epoch: 1/20... Training loss: 0.1670\n",
      "Epoch: 1/20... Training loss: 0.1646\n",
      "Epoch: 1/20... Training loss: 0.1628\n",
      "Epoch: 1/20... Training loss: 0.1574\n",
      "Epoch: 1/20... Training loss: 0.1583\n",
      "Epoch: 1/20... Training loss: 0.1631\n",
      "Epoch: 1/20... Training loss: 0.1663\n",
      "Epoch: 1/20... Training loss: 0.1643\n",
      "Epoch: 1/20... Training loss: 0.1652\n",
      "Epoch: 1/20... Training loss: 0.1593\n",
      "Epoch: 1/20... Training loss: 0.1523\n",
      "Epoch: 1/20... Training loss: 0.1645\n",
      "Epoch: 1/20... Training loss: 0.1566\n",
      "Epoch: 1/20... Training loss: 0.1617\n",
      "Epoch: 1/20... Training loss: 0.1620\n",
      "Epoch: 1/20... Training loss: 0.1639\n",
      "Epoch: 1/20... Training loss: 0.1550\n",
      "Epoch: 1/20... Training loss: 0.1595\n",
      "Epoch: 1/20... Training loss: 0.1651\n",
      "Epoch: 1/20... Training loss: 0.1647\n",
      "Epoch: 1/20... Training loss: 0.1566\n",
      "Epoch: 1/20... Training loss: 0.1611\n",
      "Epoch: 1/20... Training loss: 0.1516\n",
      "Epoch: 1/20... Training loss: 0.1581\n",
      "Epoch: 1/20... Training loss: 0.1605\n",
      "Epoch: 1/20... Training loss: 0.1543\n",
      "Epoch: 1/20... Training loss: 0.1582\n",
      "Epoch: 1/20... Training loss: 0.1645\n",
      "Epoch: 1/20... Training loss: 0.1662\n",
      "Epoch: 1/20... Training loss: 0.1573\n",
      "Epoch: 1/20... Training loss: 0.1533\n",
      "Epoch: 1/20... Training loss: 0.1598\n",
      "Epoch: 1/20... Training loss: 0.1567\n",
      "Epoch: 1/20... Training loss: 0.1569\n",
      "Epoch: 1/20... Training loss: 0.1560\n",
      "Epoch: 1/20... Training loss: 0.1642\n",
      "Epoch: 1/20... Training loss: 0.1660\n",
      "Epoch: 1/20... Training loss: 0.1537\n",
      "Epoch: 1/20... Training loss: 0.1594\n",
      "Epoch: 1/20... Training loss: 0.1569\n",
      "Epoch: 1/20... Training loss: 0.1662\n",
      "Epoch: 1/20... Training loss: 0.1597\n",
      "Epoch: 1/20... Training loss: 0.1516\n",
      "Epoch: 1/20... Training loss: 0.1716\n",
      "Epoch: 1/20... Training loss: 0.1587\n",
      "Epoch: 1/20... Training loss: 0.1732\n",
      "Epoch: 1/20... Training loss: 0.1696\n",
      "Epoch: 1/20... Training loss: 0.1577\n",
      "Epoch: 1/20... Training loss: 0.1577\n",
      "Epoch: 2/20... Training loss: 0.1595\n",
      "Epoch: 2/20... Training loss: 0.1573\n",
      "Epoch: 2/20... Training loss: 0.1553\n",
      "Epoch: 2/20... Training loss: 0.1599\n",
      "Epoch: 2/20... Training loss: 0.1570\n",
      "Epoch: 2/20... Training loss: 0.1568\n",
      "Epoch: 2/20... Training loss: 0.1584\n",
      "Epoch: 2/20... Training loss: 0.1510\n",
      "Epoch: 2/20... Training loss: 0.1517\n",
      "Epoch: 2/20... Training loss: 0.1526\n",
      "Epoch: 2/20... Training loss: 0.1559\n",
      "Epoch: 2/20... Training loss: 0.1564\n",
      "Epoch: 2/20... Training loss: 0.1543\n",
      "Epoch: 2/20... Training loss: 0.1556\n",
      "Epoch: 2/20... Training loss: 0.1545\n",
      "Epoch: 2/20... Training loss: 0.1539\n",
      "Epoch: 2/20... Training loss: 0.1591\n",
      "Epoch: 2/20... Training loss: 0.1596\n",
      "Epoch: 2/20... Training loss: 0.1539\n",
      "Epoch: 2/20... Training loss: 0.1538\n",
      "Epoch: 2/20... Training loss: 0.1501\n",
      "Epoch: 2/20... Training loss: 0.1553\n",
      "Epoch: 2/20... Training loss: 0.1558\n",
      "Epoch: 2/20... Training loss: 0.1522\n",
      "Epoch: 2/20... Training loss: 0.1564\n",
      "Epoch: 2/20... Training loss: 0.1548\n",
      "Epoch: 2/20... Training loss: 0.1514\n",
      "Epoch: 2/20... Training loss: 0.1568\n",
      "Epoch: 2/20... Training loss: 0.1533\n",
      "Epoch: 2/20... Training loss: 0.1581\n",
      "Epoch: 2/20... Training loss: 0.1544\n",
      "Epoch: 2/20... Training loss: 0.1532\n",
      "Epoch: 2/20... Training loss: 0.1553\n",
      "Epoch: 2/20... Training loss: 0.1560\n",
      "Epoch: 2/20... Training loss: 0.1511\n",
      "Epoch: 2/20... Training loss: 0.1607\n",
      "Epoch: 2/20... Training loss: 0.1516\n",
      "Epoch: 2/20... Training loss: 0.1540\n",
      "Epoch: 2/20... Training loss: 0.1556\n",
      "Epoch: 2/20... Training loss: 0.1572\n",
      "Epoch: 2/20... Training loss: 0.1562\n",
      "Epoch: 2/20... Training loss: 0.1505\n",
      "Epoch: 2/20... Training loss: 0.1614\n",
      "Epoch: 2/20... Training loss: 0.1572\n",
      "Epoch: 2/20... Training loss: 0.1513\n",
      "Epoch: 2/20... Training loss: 0.1535\n",
      "Epoch: 2/20... Training loss: 0.1515\n",
      "Epoch: 2/20... Training loss: 0.1509\n",
      "Epoch: 2/20... Training loss: 0.1549\n",
      "Epoch: 2/20... Training loss: 0.1495\n",
      "Epoch: 2/20... Training loss: 0.1506\n",
      "Epoch: 2/20... Training loss: 0.1523\n",
      "Epoch: 2/20... Training loss: 0.1519\n",
      "Epoch: 2/20... Training loss: 0.1510\n",
      "Epoch: 2/20... Training loss: 0.1542\n",
      "Epoch: 2/20... Training loss: 0.1532\n",
      "Epoch: 2/20... Training loss: 0.1531\n",
      "Epoch: 2/20... Training loss: 0.1579\n",
      "Epoch: 2/20... Training loss: 0.1542\n",
      "Epoch: 2/20... Training loss: 0.1538\n",
      "Epoch: 2/20... Training loss: 0.1518\n",
      "Epoch: 2/20... Training loss: 0.1473\n",
      "Epoch: 2/20... Training loss: 0.1496\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1530\n",
      "Epoch: 2/20... Training loss: 0.1549\n",
      "Epoch: 2/20... Training loss: 0.1582\n",
      "Epoch: 2/20... Training loss: 0.1480\n",
      "Epoch: 2/20... Training loss: 0.1542\n",
      "Epoch: 2/20... Training loss: 0.1493\n",
      "Epoch: 2/20... Training loss: 0.1556\n",
      "Epoch: 2/20... Training loss: 0.1456\n",
      "Epoch: 2/20... Training loss: 0.1499\n",
      "Epoch: 2/20... Training loss: 0.1525\n",
      "Epoch: 2/20... Training loss: 0.1542\n",
      "Epoch: 2/20... Training loss: 0.1472\n",
      "Epoch: 2/20... Training loss: 0.1523\n",
      "Epoch: 2/20... Training loss: 0.1485\n",
      "Epoch: 2/20... Training loss: 0.1509\n",
      "Epoch: 2/20... Training loss: 0.1534\n",
      "Epoch: 2/20... Training loss: 0.1488\n",
      "Epoch: 2/20... Training loss: 0.1500\n",
      "Epoch: 2/20... Training loss: 0.1504\n",
      "Epoch: 2/20... Training loss: 0.1523\n",
      "Epoch: 2/20... Training loss: 0.1522\n",
      "Epoch: 2/20... Training loss: 0.1506\n",
      "Epoch: 2/20... Training loss: 0.1527\n",
      "Epoch: 2/20... Training loss: 0.1430\n",
      "Epoch: 2/20... Training loss: 0.1497\n",
      "Epoch: 2/20... Training loss: 0.1482\n",
      "Epoch: 2/20... Training loss: 0.1514\n",
      "Epoch: 2/20... Training loss: 0.1514\n",
      "Epoch: 2/20... Training loss: 0.1484\n",
      "Epoch: 2/20... Training loss: 0.1543\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1481\n",
      "Epoch: 2/20... Training loss: 0.1522\n",
      "Epoch: 2/20... Training loss: 0.1498\n",
      "Epoch: 2/20... Training loss: 0.1486\n",
      "Epoch: 2/20... Training loss: 0.1497\n",
      "Epoch: 2/20... Training loss: 0.1498\n",
      "Epoch: 2/20... Training loss: 0.1475\n",
      "Epoch: 2/20... Training loss: 0.1463\n",
      "Epoch: 2/20... Training loss: 0.1486\n",
      "Epoch: 2/20... Training loss: 0.1519\n",
      "Epoch: 2/20... Training loss: 0.1459\n",
      "Epoch: 2/20... Training loss: 0.1521\n",
      "Epoch: 2/20... Training loss: 0.1464\n",
      "Epoch: 2/20... Training loss: 0.1475\n",
      "Epoch: 2/20... Training loss: 0.1502\n",
      "Epoch: 2/20... Training loss: 0.1474\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1495\n",
      "Epoch: 2/20... Training loss: 0.1481\n",
      "Epoch: 2/20... Training loss: 0.1517\n",
      "Epoch: 2/20... Training loss: 0.1472\n",
      "Epoch: 2/20... Training loss: 0.1478\n",
      "Epoch: 2/20... Training loss: 0.1490\n",
      "Epoch: 2/20... Training loss: 0.1434\n",
      "Epoch: 2/20... Training loss: 0.1453\n",
      "Epoch: 2/20... Training loss: 0.1486\n",
      "Epoch: 2/20... Training loss: 0.1487\n",
      "Epoch: 2/20... Training loss: 0.1509\n",
      "Epoch: 2/20... Training loss: 0.1476\n",
      "Epoch: 2/20... Training loss: 0.1466\n",
      "Epoch: 2/20... Training loss: 0.1508\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1466\n",
      "Epoch: 2/20... Training loss: 0.1474\n",
      "Epoch: 2/20... Training loss: 0.1444\n",
      "Epoch: 2/20... Training loss: 0.1475\n",
      "Epoch: 2/20... Training loss: 0.1483\n",
      "Epoch: 2/20... Training loss: 0.1477\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1494\n",
      "Epoch: 2/20... Training loss: 0.1432\n",
      "Epoch: 2/20... Training loss: 0.1504\n",
      "Epoch: 2/20... Training loss: 0.1497\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1469\n",
      "Epoch: 2/20... Training loss: 0.1463\n",
      "Epoch: 2/20... Training loss: 0.1495\n",
      "Epoch: 2/20... Training loss: 0.1443\n",
      "Epoch: 2/20... Training loss: 0.1438\n",
      "Epoch: 2/20... Training loss: 0.1469\n",
      "Epoch: 2/20... Training loss: 0.1500\n",
      "Epoch: 2/20... Training loss: 0.1427\n",
      "Epoch: 2/20... Training loss: 0.1427\n",
      "Epoch: 2/20... Training loss: 0.1463\n",
      "Epoch: 2/20... Training loss: 0.1453\n",
      "Epoch: 2/20... Training loss: 0.1467\n",
      "Epoch: 2/20... Training loss: 0.1489\n",
      "Epoch: 2/20... Training loss: 0.1449\n",
      "Epoch: 2/20... Training loss: 0.1517\n",
      "Epoch: 2/20... Training loss: 0.1418\n",
      "Epoch: 2/20... Training loss: 0.1457\n",
      "Epoch: 2/20... Training loss: 0.1481\n",
      "Epoch: 2/20... Training loss: 0.1426\n",
      "Epoch: 2/20... Training loss: 0.1510\n",
      "Epoch: 2/20... Training loss: 0.1456\n",
      "Epoch: 2/20... Training loss: 0.1425\n",
      "Epoch: 2/20... Training loss: 0.1475\n",
      "Epoch: 2/20... Training loss: 0.1401\n",
      "Epoch: 2/20... Training loss: 0.1412\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1515\n",
      "Epoch: 2/20... Training loss: 0.1414\n",
      "Epoch: 2/20... Training loss: 0.1446\n",
      "Epoch: 2/20... Training loss: 0.1492\n",
      "Epoch: 2/20... Training loss: 0.1481\n",
      "Epoch: 2/20... Training loss: 0.1444\n",
      "Epoch: 2/20... Training loss: 0.1429\n",
      "Epoch: 2/20... Training loss: 0.1449\n",
      "Epoch: 2/20... Training loss: 0.1381\n",
      "Epoch: 2/20... Training loss: 0.1393\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1410\n",
      "Epoch: 2/20... Training loss: 0.1437\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1406\n",
      "Epoch: 2/20... Training loss: 0.1453\n",
      "Epoch: 2/20... Training loss: 0.1419\n",
      "Epoch: 2/20... Training loss: 0.1406\n",
      "Epoch: 2/20... Training loss: 0.1424\n",
      "Epoch: 2/20... Training loss: 0.1409\n",
      "Epoch: 2/20... Training loss: 0.1478\n",
      "Epoch: 2/20... Training loss: 0.1407\n",
      "Epoch: 2/20... Training loss: 0.1412\n",
      "Epoch: 2/20... Training loss: 0.1410\n",
      "Epoch: 2/20... Training loss: 0.1430\n",
      "Epoch: 2/20... Training loss: 0.1435\n",
      "Epoch: 2/20... Training loss: 0.1464\n",
      "Epoch: 2/20... Training loss: 0.1420\n",
      "Epoch: 2/20... Training loss: 0.1445\n",
      "Epoch: 2/20... Training loss: 0.1420\n",
      "Epoch: 2/20... Training loss: 0.1400\n",
      "Epoch: 2/20... Training loss: 0.1396\n",
      "Epoch: 2/20... Training loss: 0.1447\n",
      "Epoch: 2/20... Training loss: 0.1414\n",
      "Epoch: 2/20... Training loss: 0.1463\n",
      "Epoch: 2/20... Training loss: 0.1422\n",
      "Epoch: 2/20... Training loss: 0.1383\n",
      "Epoch: 2/20... Training loss: 0.1461\n",
      "Epoch: 2/20... Training loss: 0.1411\n",
      "Epoch: 2/20... Training loss: 0.1458\n",
      "Epoch: 2/20... Training loss: 0.1487\n",
      "Epoch: 2/20... Training loss: 0.1455\n",
      "Epoch: 2/20... Training loss: 0.1360\n",
      "Epoch: 2/20... Training loss: 0.1410\n",
      "Epoch: 2/20... Training loss: 0.1439\n",
      "Epoch: 2/20... Training loss: 0.1414\n",
      "Epoch: 2/20... Training loss: 0.1430\n",
      "Epoch: 2/20... Training loss: 0.1455\n",
      "Epoch: 2/20... Training loss: 0.1458\n",
      "Epoch: 2/20... Training loss: 0.1393\n",
      "Epoch: 2/20... Training loss: 0.1393\n",
      "Epoch: 2/20... Training loss: 0.1486\n",
      "Epoch: 2/20... Training loss: 0.1400\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1411\n",
      "Epoch: 2/20... Training loss: 0.1451\n",
      "Epoch: 2/20... Training loss: 0.1415\n",
      "Epoch: 2/20... Training loss: 0.1414\n",
      "Epoch: 2/20... Training loss: 0.1428\n",
      "Epoch: 2/20... Training loss: 0.1419\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1462\n",
      "Epoch: 2/20... Training loss: 0.1478\n",
      "Epoch: 2/20... Training loss: 0.1373\n",
      "Epoch: 2/20... Training loss: 0.1408\n",
      "Epoch: 2/20... Training loss: 0.1377\n",
      "Epoch: 2/20... Training loss: 0.1412\n",
      "Epoch: 2/20... Training loss: 0.1443\n",
      "Epoch: 2/20... Training loss: 0.1383\n",
      "Epoch: 2/20... Training loss: 0.1420\n",
      "Epoch: 2/20... Training loss: 0.1369\n",
      "Epoch: 2/20... Training loss: 0.1450\n",
      "Epoch: 2/20... Training loss: 0.1397\n",
      "Epoch: 2/20... Training loss: 0.1452\n",
      "Epoch: 2/20... Training loss: 0.1417\n",
      "Epoch: 2/20... Training loss: 0.1396\n",
      "Epoch: 2/20... Training loss: 0.1395\n",
      "Epoch: 2/20... Training loss: 0.1384\n",
      "Epoch: 2/20... Training loss: 0.1431\n",
      "Epoch: 2/20... Training loss: 0.1355\n",
      "Epoch: 2/20... Training loss: 0.1403\n",
      "Epoch: 2/20... Training loss: 0.1437\n",
      "Epoch: 2/20... Training loss: 0.1349\n",
      "Epoch: 2/20... Training loss: 0.1389\n",
      "Epoch: 2/20... Training loss: 0.1360\n",
      "Epoch: 2/20... Training loss: 0.1418\n",
      "Epoch: 2/20... Training loss: 0.1391\n",
      "Epoch: 2/20... Training loss: 0.1379\n",
      "Epoch: 2/20... Training loss: 0.1426\n",
      "Epoch: 2/20... Training loss: 0.1333\n",
      "Epoch: 2/20... Training loss: 0.1399\n",
      "Epoch: 2/20... Training loss: 0.1392\n",
      "Epoch: 2/20... Training loss: 0.1409\n",
      "Epoch: 2/20... Training loss: 0.1401\n",
      "Epoch: 2/20... Training loss: 0.1412\n",
      "Epoch: 2/20... Training loss: 0.1364\n",
      "Epoch: 2/20... Training loss: 0.1358\n",
      "Epoch: 2/20... Training loss: 0.1449\n",
      "Epoch: 2/20... Training loss: 0.1336\n",
      "Epoch: 2/20... Training loss: 0.1356\n",
      "Epoch: 2/20... Training loss: 0.1435\n",
      "Epoch: 2/20... Training loss: 0.1452\n",
      "Epoch: 2/20... Training loss: 0.1363\n",
      "Epoch: 2/20... Training loss: 0.1362\n",
      "Epoch: 2/20... Training loss: 0.1382\n",
      "Epoch: 2/20... Training loss: 0.1392\n",
      "Epoch: 2/20... Training loss: 0.1387\n",
      "Epoch: 2/20... Training loss: 0.1388\n",
      "Epoch: 2/20... Training loss: 0.1352\n",
      "Epoch: 2/20... Training loss: 0.1428\n",
      "Epoch: 2/20... Training loss: 0.1391\n",
      "Epoch: 2/20... Training loss: 0.1354\n",
      "Epoch: 2/20... Training loss: 0.1333\n",
      "Epoch: 2/20... Training loss: 0.1387\n",
      "Epoch: 2/20... Training loss: 0.1352\n",
      "Epoch: 2/20... Training loss: 0.1413\n",
      "Epoch: 2/20... Training loss: 0.1340\n",
      "Epoch: 2/20... Training loss: 0.1356\n",
      "Epoch: 2/20... Training loss: 0.1391\n",
      "Epoch: 2/20... Training loss: 0.1380\n",
      "Epoch: 2/20... Training loss: 0.1439\n",
      "Epoch: 2/20... Training loss: 0.1373\n",
      "Epoch: 2/20... Training loss: 0.1327\n",
      "Epoch: 2/20... Training loss: 0.1351\n",
      "Epoch: 2/20... Training loss: 0.1380\n",
      "Epoch: 2/20... Training loss: 0.1401\n",
      "Epoch: 2/20... Training loss: 0.1398\n",
      "Epoch: 2/20... Training loss: 0.1387\n",
      "Epoch: 2/20... Training loss: 0.1384\n",
      "Epoch: 2/20... Training loss: 0.1349\n",
      "Epoch: 2/20... Training loss: 0.1286\n",
      "Epoch: 2/20... Training loss: 0.1319\n",
      "Epoch: 2/20... Training loss: 0.1385\n",
      "Epoch: 2/20... Training loss: 0.1374\n",
      "Epoch: 2/20... Training loss: 0.1420\n",
      "Epoch: 3/20... Training loss: 0.1385\n",
      "Epoch: 3/20... Training loss: 0.1412\n",
      "Epoch: 3/20... Training loss: 0.1374\n",
      "Epoch: 3/20... Training loss: 0.1343\n",
      "Epoch: 3/20... Training loss: 0.1431\n",
      "Epoch: 3/20... Training loss: 0.1374\n",
      "Epoch: 3/20... Training loss: 0.1354\n",
      "Epoch: 3/20... Training loss: 0.1325\n",
      "Epoch: 3/20... Training loss: 0.1386\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1352\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1335\n",
      "Epoch: 3/20... Training loss: 0.1343\n",
      "Epoch: 3/20... Training loss: 0.1394\n",
      "Epoch: 3/20... Training loss: 0.1353\n",
      "Epoch: 3/20... Training loss: 0.1337\n",
      "Epoch: 3/20... Training loss: 0.1387\n",
      "Epoch: 3/20... Training loss: 0.1325\n",
      "Epoch: 3/20... Training loss: 0.1363\n",
      "Epoch: 3/20... Training loss: 0.1354\n",
      "Epoch: 3/20... Training loss: 0.1382\n",
      "Epoch: 3/20... Training loss: 0.1376\n",
      "Epoch: 3/20... Training loss: 0.1317\n",
      "Epoch: 3/20... Training loss: 0.1328\n",
      "Epoch: 3/20... Training loss: 0.1282\n",
      "Epoch: 3/20... Training loss: 0.1359\n",
      "Epoch: 3/20... Training loss: 0.1352\n",
      "Epoch: 3/20... Training loss: 0.1352\n",
      "Epoch: 3/20... Training loss: 0.1325\n",
      "Epoch: 3/20... Training loss: 0.1307\n",
      "Epoch: 3/20... Training loss: 0.1312\n",
      "Epoch: 3/20... Training loss: 0.1320\n",
      "Epoch: 3/20... Training loss: 0.1355\n",
      "Epoch: 3/20... Training loss: 0.1349\n",
      "Epoch: 3/20... Training loss: 0.1335\n",
      "Epoch: 3/20... Training loss: 0.1344\n",
      "Epoch: 3/20... Training loss: 0.1376\n",
      "Epoch: 3/20... Training loss: 0.1362\n",
      "Epoch: 3/20... Training loss: 0.1380\n",
      "Epoch: 3/20... Training loss: 0.1370\n",
      "Epoch: 3/20... Training loss: 0.1340\n",
      "Epoch: 3/20... Training loss: 0.1373\n",
      "Epoch: 3/20... Training loss: 0.1313\n",
      "Epoch: 3/20... Training loss: 0.1364\n",
      "Epoch: 3/20... Training loss: 0.1346\n",
      "Epoch: 3/20... Training loss: 0.1321\n",
      "Epoch: 3/20... Training loss: 0.1382\n",
      "Epoch: 3/20... Training loss: 0.1339\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1384\n",
      "Epoch: 3/20... Training loss: 0.1336\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1367\n",
      "Epoch: 3/20... Training loss: 0.1321\n",
      "Epoch: 3/20... Training loss: 0.1278\n",
      "Epoch: 3/20... Training loss: 0.1320\n",
      "Epoch: 3/20... Training loss: 0.1363\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1355\n",
      "Epoch: 3/20... Training loss: 0.1318\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1321\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1364\n",
      "Epoch: 3/20... Training loss: 0.1366\n",
      "Epoch: 3/20... Training loss: 0.1345\n",
      "Epoch: 3/20... Training loss: 0.1371\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1368\n",
      "Epoch: 3/20... Training loss: 0.1338\n",
      "Epoch: 3/20... Training loss: 0.1322\n",
      "Epoch: 3/20... Training loss: 0.1343\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1358\n",
      "Epoch: 3/20... Training loss: 0.1362\n",
      "Epoch: 3/20... Training loss: 0.1360\n",
      "Epoch: 3/20... Training loss: 0.1346\n",
      "Epoch: 3/20... Training loss: 0.1353\n",
      "Epoch: 3/20... Training loss: 0.1325\n",
      "Epoch: 3/20... Training loss: 0.1356\n",
      "Epoch: 3/20... Training loss: 0.1331\n",
      "Epoch: 3/20... Training loss: 0.1364\n",
      "Epoch: 3/20... Training loss: 0.1322\n",
      "Epoch: 3/20... Training loss: 0.1331\n",
      "Epoch: 3/20... Training loss: 0.1350\n",
      "Epoch: 3/20... Training loss: 0.1341\n",
      "Epoch: 3/20... Training loss: 0.1302\n",
      "Epoch: 3/20... Training loss: 0.1332\n",
      "Epoch: 3/20... Training loss: 0.1347\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1306\n",
      "Epoch: 3/20... Training loss: 0.1282\n",
      "Epoch: 3/20... Training loss: 0.1386\n",
      "Epoch: 3/20... Training loss: 0.1282\n",
      "Epoch: 3/20... Training loss: 0.1348\n",
      "Epoch: 3/20... Training loss: 0.1312\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1336\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1326\n",
      "Epoch: 3/20... Training loss: 0.1330\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1284\n",
      "Epoch: 3/20... Training loss: 0.1376\n",
      "Epoch: 3/20... Training loss: 0.1315\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1329\n",
      "Epoch: 3/20... Training loss: 0.1296\n",
      "Epoch: 3/20... Training loss: 0.1330\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1328\n",
      "Epoch: 3/20... Training loss: 0.1349\n",
      "Epoch: 3/20... Training loss: 0.1268\n",
      "Epoch: 3/20... Training loss: 0.1324\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1308\n",
      "Epoch: 3/20... Training loss: 0.1325\n",
      "Epoch: 3/20... Training loss: 0.1335\n",
      "Epoch: 3/20... Training loss: 0.1320\n",
      "Epoch: 3/20... Training loss: 0.1320\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1335\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1287\n",
      "Epoch: 3/20... Training loss: 0.1248\n",
      "Epoch: 3/20... Training loss: 0.1232\n",
      "Epoch: 3/20... Training loss: 0.1307\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1228\n",
      "Epoch: 3/20... Training loss: 0.1280\n",
      "Epoch: 3/20... Training loss: 0.1306\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1345\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1287\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1317\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1262\n",
      "Epoch: 3/20... Training loss: 0.1295\n",
      "Epoch: 3/20... Training loss: 0.1326\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1337\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1295\n",
      "Epoch: 3/20... Training loss: 0.1347\n",
      "Epoch: 3/20... Training loss: 0.1243\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1328\n",
      "Epoch: 3/20... Training loss: 0.1292\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1323\n",
      "Epoch: 3/20... Training loss: 0.1316\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1287\n",
      "Epoch: 3/20... Training loss: 0.1265\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1297\n",
      "Epoch: 3/20... Training loss: 0.1272\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1262\n",
      "Epoch: 3/20... Training loss: 0.1326\n",
      "Epoch: 3/20... Training loss: 0.1307\n",
      "Epoch: 3/20... Training loss: 0.1290\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1340\n",
      "Epoch: 3/20... Training loss: 0.1314\n",
      "Epoch: 3/20... Training loss: 0.1284\n",
      "Epoch: 3/20... Training loss: 0.1308\n",
      "Epoch: 3/20... Training loss: 0.1317\n",
      "Epoch: 3/20... Training loss: 0.1287\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1304\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1254\n",
      "Epoch: 3/20... Training loss: 0.1340\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1307\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1293\n",
      "Epoch: 3/20... Training loss: 0.1302\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1247\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1337\n",
      "Epoch: 3/20... Training loss: 0.1242\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1294\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1238\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1302\n",
      "Epoch: 3/20... Training loss: 0.1306\n",
      "Epoch: 3/20... Training loss: 0.1263\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1330\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1309\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1281\n",
      "Epoch: 3/20... Training loss: 0.1265\n",
      "Epoch: 3/20... Training loss: 0.1227\n",
      "Epoch: 3/20... Training loss: 0.1290\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1218\n",
      "Epoch: 3/20... Training loss: 0.1266\n",
      "Epoch: 3/20... Training loss: 0.1278\n",
      "Epoch: 3/20... Training loss: 0.1308\n",
      "Epoch: 3/20... Training loss: 0.1290\n",
      "Epoch: 3/20... Training loss: 0.1315\n",
      "Epoch: 3/20... Training loss: 0.1320\n",
      "Epoch: 3/20... Training loss: 0.1285\n",
      "Epoch: 3/20... Training loss: 0.1279\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1269\n",
      "Epoch: 3/20... Training loss: 0.1336\n",
      "Epoch: 3/20... Training loss: 0.1292\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1258\n",
      "Epoch: 3/20... Training loss: 0.1340\n",
      "Epoch: 3/20... Training loss: 0.1251\n",
      "Epoch: 3/20... Training loss: 0.1262\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1261\n",
      "Epoch: 3/20... Training loss: 0.1291\n",
      "Epoch: 3/20... Training loss: 0.1303\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1305\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1240\n",
      "Epoch: 3/20... Training loss: 0.1301\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1276\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1247\n",
      "Epoch: 3/20... Training loss: 0.1277\n",
      "Epoch: 3/20... Training loss: 0.1298\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1294\n",
      "Epoch: 3/20... Training loss: 0.1278\n",
      "Epoch: 3/20... Training loss: 0.1264\n",
      "Epoch: 3/20... Training loss: 0.1246\n",
      "Epoch: 3/20... Training loss: 0.1283\n",
      "Epoch: 3/20... Training loss: 0.1247\n",
      "Epoch: 3/20... Training loss: 0.1252\n",
      "Epoch: 3/20... Training loss: 0.1271\n",
      "Epoch: 3/20... Training loss: 0.1246\n",
      "Epoch: 3/20... Training loss: 0.1247\n",
      "Epoch: 3/20... Training loss: 0.1319\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1311\n",
      "Epoch: 3/20... Training loss: 0.1293\n",
      "Epoch: 3/20... Training loss: 0.1277\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1244\n",
      "Epoch: 3/20... Training loss: 0.1279\n",
      "Epoch: 3/20... Training loss: 0.1288\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 3/20... Training loss: 0.1218\n",
      "Epoch: 3/20... Training loss: 0.1241\n",
      "Epoch: 3/20... Training loss: 0.1293\n",
      "Epoch: 3/20... Training loss: 0.1257\n",
      "Epoch: 3/20... Training loss: 0.1286\n",
      "Epoch: 3/20... Training loss: 0.1280\n",
      "Epoch: 3/20... Training loss: 0.1315\n",
      "Epoch: 3/20... Training loss: 0.1235\n",
      "Epoch: 3/20... Training loss: 0.1259\n",
      "Epoch: 3/20... Training loss: 0.1300\n",
      "Epoch: 3/20... Training loss: 0.1267\n",
      "Epoch: 3/20... Training loss: 0.1226\n",
      "Epoch: 3/20... Training loss: 0.1274\n",
      "Epoch: 3/20... Training loss: 0.1253\n",
      "Epoch: 3/20... Training loss: 0.1257\n",
      "Epoch: 3/20... Training loss: 0.1289\n",
      "Epoch: 3/20... Training loss: 0.1254\n",
      "Epoch: 3/20... Training loss: 0.1299\n",
      "Epoch: 3/20... Training loss: 0.1233\n",
      "Epoch: 3/20... Training loss: 0.1266\n",
      "Epoch: 3/20... Training loss: 0.1270\n",
      "Epoch: 4/20... Training loss: 0.1293\n",
      "Epoch: 4/20... Training loss: 0.1293\n",
      "Epoch: 4/20... Training loss: 0.1274\n",
      "Epoch: 4/20... Training loss: 0.1267\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1241\n",
      "Epoch: 4/20... Training loss: 0.1257\n",
      "Epoch: 4/20... Training loss: 0.1300\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1279\n",
      "Epoch: 4/20... Training loss: 0.1279\n",
      "Epoch: 4/20... Training loss: 0.1318\n",
      "Epoch: 4/20... Training loss: 0.1287\n",
      "Epoch: 4/20... Training loss: 0.1266\n",
      "Epoch: 4/20... Training loss: 0.1259\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1266\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1293\n",
      "Epoch: 4/20... Training loss: 0.1265\n",
      "Epoch: 4/20... Training loss: 0.1241\n",
      "Epoch: 4/20... Training loss: 0.1282\n",
      "Epoch: 4/20... Training loss: 0.1306\n",
      "Epoch: 4/20... Training loss: 0.1275\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1263\n",
      "Epoch: 4/20... Training loss: 0.1264\n",
      "Epoch: 4/20... Training loss: 0.1271\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1250\n",
      "Epoch: 4/20... Training loss: 0.1288\n",
      "Epoch: 4/20... Training loss: 0.1265\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1248\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1255\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1261\n",
      "Epoch: 4/20... Training loss: 0.1275\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1259\n",
      "Epoch: 4/20... Training loss: 0.1278\n",
      "Epoch: 4/20... Training loss: 0.1248\n",
      "Epoch: 4/20... Training loss: 0.1268\n",
      "Epoch: 4/20... Training loss: 0.1207\n",
      "Epoch: 4/20... Training loss: 0.1268\n",
      "Epoch: 4/20... Training loss: 0.1245\n",
      "Epoch: 4/20... Training loss: 0.1231\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1243\n",
      "Epoch: 4/20... Training loss: 0.1231\n",
      "Epoch: 4/20... Training loss: 0.1233\n",
      "Epoch: 4/20... Training loss: 0.1257\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1253\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1256\n",
      "Epoch: 4/20... Training loss: 0.1250\n",
      "Epoch: 4/20... Training loss: 0.1228\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1266\n",
      "Epoch: 4/20... Training loss: 0.1263\n",
      "Epoch: 4/20... Training loss: 0.1225\n",
      "Epoch: 4/20... Training loss: 0.1276\n",
      "Epoch: 4/20... Training loss: 0.1233\n",
      "Epoch: 4/20... Training loss: 0.1277\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1242\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1220\n",
      "Epoch: 4/20... Training loss: 0.1276\n",
      "Epoch: 4/20... Training loss: 0.1247\n",
      "Epoch: 4/20... Training loss: 0.1220\n",
      "Epoch: 4/20... Training loss: 0.1257\n",
      "Epoch: 4/20... Training loss: 0.1244\n",
      "Epoch: 4/20... Training loss: 0.1249\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1228\n",
      "Epoch: 4/20... Training loss: 0.1271\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1258\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1185\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1274\n",
      "Epoch: 4/20... Training loss: 0.1247\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1241\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1255\n",
      "Epoch: 4/20... Training loss: 0.1277\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1252\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1212\n",
      "Epoch: 4/20... Training loss: 0.1288\n",
      "Epoch: 4/20... Training loss: 0.1230\n",
      "Epoch: 4/20... Training loss: 0.1269\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1265\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1254\n",
      "Epoch: 4/20... Training loss: 0.1258\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1231\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1228\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1253\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1262\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1172\n",
      "Epoch: 4/20... Training loss: 0.1225\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1241\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1271\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1200\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1237\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1262\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1249\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1207\n",
      "Epoch: 4/20... Training loss: 0.1208\n",
      "Epoch: 4/20... Training loss: 0.1244\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1230\n",
      "Epoch: 4/20... Training loss: 0.1230\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1183\n",
      "Epoch: 4/20... Training loss: 0.1259\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1220\n",
      "Epoch: 4/20... Training loss: 0.1253\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1229\n",
      "Epoch: 4/20... Training loss: 0.1228\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1247\n",
      "Epoch: 4/20... Training loss: 0.1159\n",
      "Epoch: 4/20... Training loss: 0.1239\n",
      "Epoch: 4/20... Training loss: 0.1142\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1259\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1213\n",
      "Epoch: 4/20... Training loss: 0.1189\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1265\n",
      "Epoch: 4/20... Training loss: 0.1208\n",
      "Epoch: 4/20... Training loss: 0.1198\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1170\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1223\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1188\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1206\n",
      "Epoch: 4/20... Training loss: 0.1230\n",
      "Epoch: 4/20... Training loss: 0.1274\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1233\n",
      "Epoch: 4/20... Training loss: 0.1220\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1228\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1238\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1186\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1240\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1224\n",
      "Epoch: 4/20... Training loss: 0.1198\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1220\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1163\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1197\n",
      "Epoch: 4/20... Training loss: 0.1174\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1200\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1168\n",
      "Epoch: 4/20... Training loss: 0.1227\n",
      "Epoch: 4/20... Training loss: 0.1231\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1214\n",
      "Epoch: 4/20... Training loss: 0.1228\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1234\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1161\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1226\n",
      "Epoch: 4/20... Training loss: 0.1154\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1222\n",
      "Epoch: 4/20... Training loss: 0.1159\n",
      "Epoch: 4/20... Training loss: 0.1199\n",
      "Epoch: 4/20... Training loss: 0.1187\n",
      "Epoch: 4/20... Training loss: 0.1228\n",
      "Epoch: 4/20... Training loss: 0.1209\n",
      "Epoch: 4/20... Training loss: 0.1157\n",
      "Epoch: 4/20... Training loss: 0.1182\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1185\n",
      "Epoch: 4/20... Training loss: 0.1249\n",
      "Epoch: 4/20... Training loss: 0.1215\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1235\n",
      "Epoch: 4/20... Training loss: 0.1203\n",
      "Epoch: 4/20... Training loss: 0.1169\n",
      "Epoch: 4/20... Training loss: 0.1221\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1217\n",
      "Epoch: 4/20... Training loss: 0.1191\n",
      "Epoch: 4/20... Training loss: 0.1184\n",
      "Epoch: 4/20... Training loss: 0.1264\n",
      "Epoch: 4/20... Training loss: 0.1180\n",
      "Epoch: 4/20... Training loss: 0.1247\n",
      "Epoch: 4/20... Training loss: 0.1196\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1202\n",
      "Epoch: 4/20... Training loss: 0.1211\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1156\n",
      "Epoch: 4/20... Training loss: 0.1248\n",
      "Epoch: 4/20... Training loss: 0.1232\n",
      "Epoch: 4/20... Training loss: 0.1198\n",
      "Epoch: 4/20... Training loss: 0.1236\n",
      "Epoch: 4/20... Training loss: 0.1210\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1169\n",
      "Epoch: 4/20... Training loss: 0.1200\n",
      "Epoch: 4/20... Training loss: 0.1179\n",
      "Epoch: 4/20... Training loss: 0.1190\n",
      "Epoch: 4/20... Training loss: 0.1205\n",
      "Epoch: 4/20... Training loss: 0.1195\n",
      "Epoch: 4/20... Training loss: 0.1216\n",
      "Epoch: 4/20... Training loss: 0.1241\n",
      "Epoch: 4/20... Training loss: 0.1204\n",
      "Epoch: 4/20... Training loss: 0.1194\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1218\n",
      "Epoch: 4/20... Training loss: 0.1219\n",
      "Epoch: 4/20... Training loss: 0.1201\n",
      "Epoch: 4/20... Training loss: 0.1173\n",
      "Epoch: 4/20... Training loss: 0.1193\n",
      "Epoch: 4/20... Training loss: 0.1213\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1162\n",
      "Epoch: 5/20... Training loss: 0.1179\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1186\n",
      "Epoch: 5/20... Training loss: 0.1227\n",
      "Epoch: 5/20... Training loss: 0.1206\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1229\n",
      "Epoch: 5/20... Training loss: 0.1202\n",
      "Epoch: 5/20... Training loss: 0.1178\n",
      "Epoch: 5/20... Training loss: 0.1240\n",
      "Epoch: 5/20... Training loss: 0.1226\n",
      "Epoch: 5/20... Training loss: 0.1198\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1253\n",
      "Epoch: 5/20... Training loss: 0.1219\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1203\n",
      "Epoch: 5/20... Training loss: 0.1244\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1236\n",
      "Epoch: 5/20... Training loss: 0.1203\n",
      "Epoch: 5/20... Training loss: 0.1169\n",
      "Epoch: 5/20... Training loss: 0.1244\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1256\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1220\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1191\n",
      "Epoch: 5/20... Training loss: 0.1226\n",
      "Epoch: 5/20... Training loss: 0.1211\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1231\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1208\n",
      "Epoch: 5/20... Training loss: 0.1233\n",
      "Epoch: 5/20... Training loss: 0.1208\n",
      "Epoch: 5/20... Training loss: 0.1228\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1242\n",
      "Epoch: 5/20... Training loss: 0.1192\n",
      "Epoch: 5/20... Training loss: 0.1214\n",
      "Epoch: 5/20... Training loss: 0.1214\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1216\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1207\n",
      "Epoch: 5/20... Training loss: 0.1221\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1223\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1207\n",
      "Epoch: 5/20... Training loss: 0.1172\n",
      "Epoch: 5/20... Training loss: 0.1203\n",
      "Epoch: 5/20... Training loss: 0.1186\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1146\n",
      "Epoch: 5/20... Training loss: 0.1197\n",
      "Epoch: 5/20... Training loss: 0.1200\n",
      "Epoch: 5/20... Training loss: 0.1212\n",
      "Epoch: 5/20... Training loss: 0.1194\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1197\n",
      "Epoch: 5/20... Training loss: 0.1196\n",
      "Epoch: 5/20... Training loss: 0.1202\n",
      "Epoch: 5/20... Training loss: 0.1191\n",
      "Epoch: 5/20... Training loss: 0.1221\n",
      "Epoch: 5/20... Training loss: 0.1206\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1167\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1146\n",
      "Epoch: 5/20... Training loss: 0.1197\n",
      "Epoch: 5/20... Training loss: 0.1212\n",
      "Epoch: 5/20... Training loss: 0.1118\n",
      "Epoch: 5/20... Training loss: 0.1187\n",
      "Epoch: 5/20... Training loss: 0.1206\n",
      "Epoch: 5/20... Training loss: 0.1181\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1166\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1208\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1192\n",
      "Epoch: 5/20... Training loss: 0.1194\n",
      "Epoch: 5/20... Training loss: 0.1167\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1193\n",
      "Epoch: 5/20... Training loss: 0.1220\n",
      "Epoch: 5/20... Training loss: 0.1210\n",
      "Epoch: 5/20... Training loss: 0.1176\n",
      "Epoch: 5/20... Training loss: 0.1190\n",
      "Epoch: 5/20... Training loss: 0.1216\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1188\n",
      "Epoch: 5/20... Training loss: 0.1186\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1246\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1205\n",
      "Epoch: 5/20... Training loss: 0.1190\n",
      "Epoch: 5/20... Training loss: 0.1129\n",
      "Epoch: 5/20... Training loss: 0.1195\n",
      "Epoch: 5/20... Training loss: 0.1169\n",
      "Epoch: 5/20... Training loss: 0.1187\n",
      "Epoch: 5/20... Training loss: 0.1208\n",
      "Epoch: 5/20... Training loss: 0.1207\n",
      "Epoch: 5/20... Training loss: 0.1208\n",
      "Epoch: 5/20... Training loss: 0.1187\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1206\n",
      "Epoch: 5/20... Training loss: 0.1162\n",
      "Epoch: 5/20... Training loss: 0.1205\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1204\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1179\n",
      "Epoch: 5/20... Training loss: 0.1191\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1188\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1206\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1111\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1166\n",
      "Epoch: 5/20... Training loss: 0.1190\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1123\n",
      "Epoch: 5/20... Training loss: 0.1172\n",
      "Epoch: 5/20... Training loss: 0.1210\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1161\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1162\n",
      "Epoch: 5/20... Training loss: 0.1178\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1193\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1208\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1203\n",
      "Epoch: 5/20... Training loss: 0.1121\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1144\n",
      "Epoch: 5/20... Training loss: 0.1192\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1104\n",
      "Epoch: 5/20... Training loss: 0.1183\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1175\n",
      "Epoch: 5/20... Training loss: 0.1219\n",
      "Epoch: 5/20... Training loss: 0.1236\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1187\n",
      "Epoch: 5/20... Training loss: 0.1197\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1168\n",
      "Epoch: 5/20... Training loss: 0.1196\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1114\n",
      "Epoch: 5/20... Training loss: 0.1179\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1152\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1177\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1132\n",
      "Epoch: 5/20... Training loss: 0.1196\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1207\n",
      "Epoch: 5/20... Training loss: 0.1127\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1143\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1178\n",
      "Epoch: 5/20... Training loss: 0.1164\n",
      "Epoch: 5/20... Training loss: 0.1223\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1196\n",
      "Epoch: 5/20... Training loss: 0.1150\n",
      "Epoch: 5/20... Training loss: 0.1187\n",
      "Epoch: 5/20... Training loss: 0.1176\n",
      "Epoch: 5/20... Training loss: 0.1166\n",
      "Epoch: 5/20... Training loss: 0.1151\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1120\n",
      "Epoch: 5/20... Training loss: 0.1147\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1180\n",
      "Epoch: 5/20... Training loss: 0.1187\n",
      "Epoch: 5/20... Training loss: 0.1137\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1170\n",
      "Epoch: 5/20... Training loss: 0.1194\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1189\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1185\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1139\n",
      "Epoch: 5/20... Training loss: 0.1141\n",
      "Epoch: 5/20... Training loss: 0.1154\n",
      "Epoch: 5/20... Training loss: 0.1188\n",
      "Epoch: 5/20... Training loss: 0.1152\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1167\n",
      "Epoch: 5/20... Training loss: 0.1159\n",
      "Epoch: 5/20... Training loss: 0.1163\n",
      "Epoch: 5/20... Training loss: 0.1109\n",
      "Epoch: 5/20... Training loss: 0.1199\n",
      "Epoch: 5/20... Training loss: 0.1223\n",
      "Epoch: 5/20... Training loss: 0.1172\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1175\n",
      "Epoch: 5/20... Training loss: 0.1173\n",
      "Epoch: 5/20... Training loss: 0.1152\n",
      "Epoch: 5/20... Training loss: 0.1203\n",
      "Epoch: 5/20... Training loss: 0.1133\n",
      "Epoch: 5/20... Training loss: 0.1187\n",
      "Epoch: 5/20... Training loss: 0.1194\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1142\n",
      "Epoch: 5/20... Training loss: 0.1251\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1160\n",
      "Epoch: 5/20... Training loss: 0.1197\n",
      "Epoch: 5/20... Training loss: 0.1127\n",
      "Epoch: 5/20... Training loss: 0.1170\n",
      "Epoch: 5/20... Training loss: 0.1134\n",
      "Epoch: 5/20... Training loss: 0.1174\n",
      "Epoch: 5/20... Training loss: 0.1179\n",
      "Epoch: 5/20... Training loss: 0.1153\n",
      "Epoch: 5/20... Training loss: 0.1165\n",
      "Epoch: 5/20... Training loss: 0.1172\n",
      "Epoch: 5/20... Training loss: 0.1186\n",
      "Epoch: 5/20... Training loss: 0.1149\n",
      "Epoch: 5/20... Training loss: 0.1168\n",
      "Epoch: 5/20... Training loss: 0.1169\n",
      "Epoch: 5/20... Training loss: 0.1145\n",
      "Epoch: 5/20... Training loss: 0.1171\n",
      "Epoch: 5/20... Training loss: 0.1155\n",
      "Epoch: 5/20... Training loss: 0.1157\n",
      "Epoch: 5/20... Training loss: 0.1181\n",
      "Epoch: 5/20... Training loss: 0.1123\n",
      "Epoch: 5/20... Training loss: 0.1186\n",
      "Epoch: 5/20... Training loss: 0.1156\n",
      "Epoch: 5/20... Training loss: 0.1184\n",
      "Epoch: 5/20... Training loss: 0.1197\n",
      "Epoch: 5/20... Training loss: 0.1130\n",
      "Epoch: 5/20... Training loss: 0.1110\n",
      "Epoch: 5/20... Training loss: 0.1179\n",
      "Epoch: 5/20... Training loss: 0.1169\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 5/20... Training loss: 0.1129\n",
      "Epoch: 5/20... Training loss: 0.1138\n",
      "Epoch: 5/20... Training loss: 0.1148\n",
      "Epoch: 5/20... Training loss: 0.1187\n",
      "Epoch: 5/20... Training loss: 0.1192\n",
      "Epoch: 5/20... Training loss: 0.1123\n",
      "Epoch: 5/20... Training loss: 0.1140\n",
      "Epoch: 5/20... Training loss: 0.1158\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1128\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1154\n",
      "Epoch: 6/20... Training loss: 0.1148\n",
      "Epoch: 6/20... Training loss: 0.1166\n",
      "Epoch: 6/20... Training loss: 0.1136\n",
      "Epoch: 6/20... Training loss: 0.1121\n",
      "Epoch: 6/20... Training loss: 0.1178\n",
      "Epoch: 6/20... Training loss: 0.1124\n",
      "Epoch: 6/20... Training loss: 0.1156\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1196\n",
      "Epoch: 6/20... Training loss: 0.1165\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1161\n",
      "Epoch: 6/20... Training loss: 0.1181\n",
      "Epoch: 6/20... Training loss: 0.1181\n",
      "Epoch: 6/20... Training loss: 0.1097\n",
      "Epoch: 6/20... Training loss: 0.1180\n",
      "Epoch: 6/20... Training loss: 0.1148\n",
      "Epoch: 6/20... Training loss: 0.1164\n",
      "Epoch: 6/20... Training loss: 0.1166\n",
      "Epoch: 6/20... Training loss: 0.1155\n",
      "Epoch: 6/20... Training loss: 0.1178\n",
      "Epoch: 6/20... Training loss: 0.1172\n",
      "Epoch: 6/20... Training loss: 0.1163\n",
      "Epoch: 6/20... Training loss: 0.1158\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1173\n",
      "Epoch: 6/20... Training loss: 0.1202\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1102\n",
      "Epoch: 6/20... Training loss: 0.1164\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1154\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1204\n",
      "Epoch: 6/20... Training loss: 0.1163\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1148\n",
      "Epoch: 6/20... Training loss: 0.1093\n",
      "Epoch: 6/20... Training loss: 0.1121\n",
      "Epoch: 6/20... Training loss: 0.1181\n",
      "Epoch: 6/20... Training loss: 0.1173\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1165\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1182\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1122\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1185\n",
      "Epoch: 6/20... Training loss: 0.1114\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1202\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1169\n",
      "Epoch: 6/20... Training loss: 0.1162\n",
      "Epoch: 6/20... Training loss: 0.1154\n",
      "Epoch: 6/20... Training loss: 0.1109\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1183\n",
      "Epoch: 6/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1118\n",
      "Epoch: 6/20... Training loss: 0.1134\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1152\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1114\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1168\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1164\n",
      "Epoch: 6/20... Training loss: 0.1184\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1203\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1156\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1165\n",
      "Epoch: 6/20... Training loss: 0.1156\n",
      "Epoch: 6/20... Training loss: 0.1153\n",
      "Epoch: 6/20... Training loss: 0.1118\n",
      "Epoch: 6/20... Training loss: 0.1192\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1167\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1162\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1199\n",
      "Epoch: 6/20... Training loss: 0.1210\n",
      "Epoch: 6/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1198\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1173\n",
      "Epoch: 6/20... Training loss: 0.1158\n",
      "Epoch: 6/20... Training loss: 0.1152\n",
      "Epoch: 6/20... Training loss: 0.1153\n",
      "Epoch: 6/20... Training loss: 0.1090\n",
      "Epoch: 6/20... Training loss: 0.1175\n",
      "Epoch: 6/20... Training loss: 0.1152\n",
      "Epoch: 6/20... Training loss: 0.1190\n",
      "Epoch: 6/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1148\n",
      "Epoch: 6/20... Training loss: 0.1175\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1175\n",
      "Epoch: 6/20... Training loss: 0.1110\n",
      "Epoch: 6/20... Training loss: 0.1180\n",
      "Epoch: 6/20... Training loss: 0.1179\n",
      "Epoch: 6/20... Training loss: 0.1115\n",
      "Epoch: 6/20... Training loss: 0.1154\n",
      "Epoch: 6/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1176\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1083\n",
      "Epoch: 6/20... Training loss: 0.1163\n",
      "Epoch: 6/20... Training loss: 0.1154\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1161\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1105\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1172\n",
      "Epoch: 6/20... Training loss: 0.1093\n",
      "Epoch: 6/20... Training loss: 0.1206\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1131\n",
      "Epoch: 6/20... Training loss: 0.1113\n",
      "Epoch: 6/20... Training loss: 0.1124\n",
      "Epoch: 6/20... Training loss: 0.1160\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1102\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1128\n",
      "Epoch: 6/20... Training loss: 0.1184\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1105\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1094\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1101\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1112\n",
      "Epoch: 6/20... Training loss: 0.1126\n",
      "Epoch: 6/20... Training loss: 0.1116\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1155\n",
      "Epoch: 6/20... Training loss: 0.1111\n",
      "Epoch: 6/20... Training loss: 0.1131\n",
      "Epoch: 6/20... Training loss: 0.1148\n",
      "Epoch: 6/20... Training loss: 0.1150\n",
      "Epoch: 6/20... Training loss: 0.1099\n",
      "Epoch: 6/20... Training loss: 0.1153\n",
      "Epoch: 6/20... Training loss: 0.1098\n",
      "Epoch: 6/20... Training loss: 0.1130\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1099\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1116\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1142\n",
      "Epoch: 6/20... Training loss: 0.1063\n",
      "Epoch: 6/20... Training loss: 0.1173\n",
      "Epoch: 6/20... Training loss: 0.1116\n",
      "Epoch: 6/20... Training loss: 0.1144\n",
      "Epoch: 6/20... Training loss: 0.1121\n",
      "Epoch: 6/20... Training loss: 0.1177\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1159\n",
      "Epoch: 6/20... Training loss: 0.1148\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1169\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1115\n",
      "Epoch: 6/20... Training loss: 0.1166\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1168\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1115\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1149\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1112\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1090\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1170\n",
      "Epoch: 6/20... Training loss: 0.1136\n",
      "Epoch: 6/20... Training loss: 0.1155\n",
      "Epoch: 6/20... Training loss: 0.1139\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1155\n",
      "Epoch: 6/20... Training loss: 0.1106\n",
      "Epoch: 6/20... Training loss: 0.1098\n",
      "Epoch: 6/20... Training loss: 0.1114\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1120\n",
      "Epoch: 6/20... Training loss: 0.1108\n",
      "Epoch: 6/20... Training loss: 0.1088\n",
      "Epoch: 6/20... Training loss: 0.1122\n",
      "Epoch: 6/20... Training loss: 0.1107\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1153\n",
      "Epoch: 6/20... Training loss: 0.1100\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1156\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1109\n",
      "Epoch: 6/20... Training loss: 0.1122\n",
      "Epoch: 6/20... Training loss: 0.1127\n",
      "Epoch: 6/20... Training loss: 0.1076\n",
      "Epoch: 6/20... Training loss: 0.1159\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1151\n",
      "Epoch: 6/20... Training loss: 0.1158\n",
      "Epoch: 6/20... Training loss: 0.1122\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1167\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1090\n",
      "Epoch: 6/20... Training loss: 0.1087\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 6/20... Training loss: 0.1122\n",
      "Epoch: 6/20... Training loss: 0.1145\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1146\n",
      "Epoch: 6/20... Training loss: 0.1133\n",
      "Epoch: 6/20... Training loss: 0.1137\n",
      "Epoch: 6/20... Training loss: 0.1122\n",
      "Epoch: 6/20... Training loss: 0.1085\n",
      "Epoch: 6/20... Training loss: 0.1135\n",
      "Epoch: 6/20... Training loss: 0.1125\n",
      "Epoch: 6/20... Training loss: 0.1143\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1164\n",
      "Epoch: 6/20... Training loss: 0.1129\n",
      "Epoch: 6/20... Training loss: 0.1118\n",
      "Epoch: 6/20... Training loss: 0.1179\n",
      "Epoch: 6/20... Training loss: 0.1138\n",
      "Epoch: 6/20... Training loss: 0.1102\n",
      "Epoch: 6/20... Training loss: 0.1140\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1157\n",
      "Epoch: 6/20... Training loss: 0.1101\n",
      "Epoch: 6/20... Training loss: 0.1119\n",
      "Epoch: 6/20... Training loss: 0.1155\n",
      "Epoch: 6/20... Training loss: 0.1117\n",
      "Epoch: 6/20... Training loss: 0.1147\n",
      "Epoch: 6/20... Training loss: 0.1156\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1132\n",
      "Epoch: 6/20... Training loss: 0.1123\n",
      "Epoch: 6/20... Training loss: 0.1102\n",
      "Epoch: 6/20... Training loss: 0.1096\n",
      "Epoch: 6/20... Training loss: 0.1155\n",
      "Epoch: 6/20... Training loss: 0.1158\n",
      "Epoch: 6/20... Training loss: 0.1141\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1159\n",
      "Epoch: 7/20... Training loss: 0.1147\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1141\n",
      "Epoch: 7/20... Training loss: 0.1130\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1120\n",
      "Epoch: 7/20... Training loss: 0.1112\n",
      "Epoch: 7/20... Training loss: 0.1161\n",
      "Epoch: 7/20... Training loss: 0.1135\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1108\n",
      "Epoch: 7/20... Training loss: 0.1135\n",
      "Epoch: 7/20... Training loss: 0.1157\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1099\n",
      "Epoch: 7/20... Training loss: 0.1121\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1162\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1182\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1115\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1130\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1138\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1155\n",
      "Epoch: 7/20... Training loss: 0.1121\n",
      "Epoch: 7/20... Training loss: 0.1101\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1081\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1162\n",
      "Epoch: 7/20... Training loss: 0.1080\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1128\n",
      "Epoch: 7/20... Training loss: 0.1130\n",
      "Epoch: 7/20... Training loss: 0.1106\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1144\n",
      "Epoch: 7/20... Training loss: 0.1108\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1158\n",
      "Epoch: 7/20... Training loss: 0.1112\n",
      "Epoch: 7/20... Training loss: 0.1146\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1106\n",
      "Epoch: 7/20... Training loss: 0.1155\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1102\n",
      "Epoch: 7/20... Training loss: 0.1103\n",
      "Epoch: 7/20... Training loss: 0.1150\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1120\n",
      "Epoch: 7/20... Training loss: 0.1134\n",
      "Epoch: 7/20... Training loss: 0.1144\n",
      "Epoch: 7/20... Training loss: 0.1105\n",
      "Epoch: 7/20... Training loss: 0.1163\n",
      "Epoch: 7/20... Training loss: 0.1096\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1088\n",
      "Epoch: 7/20... Training loss: 0.1203\n",
      "Epoch: 7/20... Training loss: 0.1068\n",
      "Epoch: 7/20... Training loss: 0.1073\n",
      "Epoch: 7/20... Training loss: 0.1172\n",
      "Epoch: 7/20... Training loss: 0.1194\n",
      "Epoch: 7/20... Training loss: 0.1108\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1128\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1096\n",
      "Epoch: 7/20... Training loss: 0.1169\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1106\n",
      "Epoch: 7/20... Training loss: 0.1125\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1146\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1134\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1070\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1082\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1101\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1108\n",
      "Epoch: 7/20... Training loss: 0.1091\n",
      "Epoch: 7/20... Training loss: 0.1111\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1076\n",
      "Epoch: 7/20... Training loss: 0.1126\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1154\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1069\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1114\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1099\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1092\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1136\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1136\n",
      "Epoch: 7/20... Training loss: 0.1154\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1128\n",
      "Epoch: 7/20... Training loss: 0.1160\n",
      "Epoch: 7/20... Training loss: 0.1149\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1116\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1131\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1176\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1106\n",
      "Epoch: 7/20... Training loss: 0.1084\n",
      "Epoch: 7/20... Training loss: 0.1115\n",
      "Epoch: 7/20... Training loss: 0.1121\n",
      "Epoch: 7/20... Training loss: 0.1144\n",
      "Epoch: 7/20... Training loss: 0.1134\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1089\n",
      "Epoch: 7/20... Training loss: 0.1124\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1163\n",
      "Epoch: 7/20... Training loss: 0.1155\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1099\n",
      "Epoch: 7/20... Training loss: 0.1171\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1078\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1122\n",
      "Epoch: 7/20... Training loss: 0.1088\n",
      "Epoch: 7/20... Training loss: 0.1132\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1106\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1116\n",
      "Epoch: 7/20... Training loss: 0.1091\n",
      "Epoch: 7/20... Training loss: 0.1128\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1111\n",
      "Epoch: 7/20... Training loss: 0.1091\n",
      "Epoch: 7/20... Training loss: 0.1152\n",
      "Epoch: 7/20... Training loss: 0.1089\n",
      "Epoch: 7/20... Training loss: 0.1088\n",
      "Epoch: 7/20... Training loss: 0.1143\n",
      "Epoch: 7/20... Training loss: 0.1153\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1120\n",
      "Epoch: 7/20... Training loss: 0.1137\n",
      "Epoch: 7/20... Training loss: 0.1131\n",
      "Epoch: 7/20... Training loss: 0.1115\n",
      "Epoch: 7/20... Training loss: 0.1043\n",
      "Epoch: 7/20... Training loss: 0.1085\n",
      "Epoch: 7/20... Training loss: 0.1092\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1120\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1104\n",
      "Epoch: 7/20... Training loss: 0.1113\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1156\n",
      "Epoch: 7/20... Training loss: 0.1101\n",
      "Epoch: 7/20... Training loss: 0.1114\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1128\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1184\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1114\n",
      "Epoch: 7/20... Training loss: 0.1146\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1112\n",
      "Epoch: 7/20... Training loss: 0.1123\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1144\n",
      "Epoch: 7/20... Training loss: 0.1063\n",
      "Epoch: 7/20... Training loss: 0.1126\n",
      "Epoch: 7/20... Training loss: 0.1135\n",
      "Epoch: 7/20... Training loss: 0.1130\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1151\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1129\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1146\n",
      "Epoch: 7/20... Training loss: 0.1183\n",
      "Epoch: 7/20... Training loss: 0.1086\n",
      "Epoch: 7/20... Training loss: 0.1126\n",
      "Epoch: 7/20... Training loss: 0.1082\n",
      "Epoch: 7/20... Training loss: 0.1118\n",
      "Epoch: 7/20... Training loss: 0.1117\n",
      "Epoch: 7/20... Training loss: 0.1108\n",
      "Epoch: 7/20... Training loss: 0.1091\n",
      "Epoch: 7/20... Training loss: 0.1081\n",
      "Epoch: 7/20... Training loss: 0.1134\n",
      "Epoch: 7/20... Training loss: 0.1120\n",
      "Epoch: 7/20... Training loss: 0.1078\n",
      "Epoch: 7/20... Training loss: 0.1092\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1166\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1102\n",
      "Epoch: 7/20... Training loss: 0.1133\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1072\n",
      "Epoch: 7/20... Training loss: 0.1093\n",
      "Epoch: 7/20... Training loss: 0.1121\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1125\n",
      "Epoch: 7/20... Training loss: 0.1137\n",
      "Epoch: 7/20... Training loss: 0.1131\n",
      "Epoch: 7/20... Training loss: 0.1127\n",
      "Epoch: 7/20... Training loss: 0.1082\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1102\n",
      "Epoch: 7/20... Training loss: 0.1109\n",
      "Epoch: 7/20... Training loss: 0.1151\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1119\n",
      "Epoch: 7/20... Training loss: 0.1164\n",
      "Epoch: 7/20... Training loss: 0.1081\n",
      "Epoch: 7/20... Training loss: 0.1090\n",
      "Epoch: 7/20... Training loss: 0.1098\n",
      "Epoch: 7/20... Training loss: 0.1107\n",
      "Epoch: 7/20... Training loss: 0.1103\n",
      "Epoch: 7/20... Training loss: 0.1110\n",
      "Epoch: 7/20... Training loss: 0.1111\n",
      "Epoch: 7/20... Training loss: 0.1061\n",
      "Epoch: 7/20... Training loss: 0.1152\n",
      "Epoch: 7/20... Training loss: 0.1140\n",
      "Epoch: 7/20... Training loss: 0.1105\n",
      "Epoch: 7/20... Training loss: 0.1100\n",
      "Epoch: 7/20... Training loss: 0.1087\n",
      "Epoch: 7/20... Training loss: 0.1137\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1079\n",
      "Epoch: 7/20... Training loss: 0.1097\n",
      "Epoch: 7/20... Training loss: 0.1126\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1076\n",
      "Epoch: 7/20... Training loss: 0.1094\n",
      "Epoch: 7/20... Training loss: 0.1139\n",
      "Epoch: 7/20... Training loss: 0.1096\n",
      "Epoch: 7/20... Training loss: 0.1126\n",
      "Epoch: 7/20... Training loss: 0.1077\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1088\n",
      "Epoch: 7/20... Training loss: 0.1095\n",
      "Epoch: 7/20... Training loss: 0.1126\n",
      "Epoch: 7/20... Training loss: 0.1085\n",
      "Epoch: 7/20... Training loss: 0.1106\n",
      "Epoch: 7/20... Training loss: 0.1142\n",
      "Epoch: 7/20... Training loss: 0.1106\n",
      "Epoch: 7/20... Training loss: 0.1053\n",
      "Epoch: 8/20... Training loss: 0.1111\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1185\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1109\n",
      "Epoch: 8/20... Training loss: 0.1134\n",
      "Epoch: 8/20... Training loss: 0.1096\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1069\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1127\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1147\n",
      "Epoch: 8/20... Training loss: 0.1077\n",
      "Epoch: 8/20... Training loss: 0.1160\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1149\n",
      "Epoch: 8/20... Training loss: 0.1117\n",
      "Epoch: 8/20... Training loss: 0.1067\n",
      "Epoch: 8/20... Training loss: 0.1135\n",
      "Epoch: 8/20... Training loss: 0.1137\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1096\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1107\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1051\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1109\n",
      "Epoch: 8/20... Training loss: 0.1149\n",
      "Epoch: 8/20... Training loss: 0.1123\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1058\n",
      "Epoch: 8/20... Training loss: 0.1138\n",
      "Epoch: 8/20... Training loss: 0.1111\n",
      "Epoch: 8/20... Training loss: 0.1116\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1130\n",
      "Epoch: 8/20... Training loss: 0.1085\n",
      "Epoch: 8/20... Training loss: 0.1065\n",
      "Epoch: 8/20... Training loss: 0.1142\n",
      "Epoch: 8/20... Training loss: 0.1106\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1151\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1065\n",
      "Epoch: 8/20... Training loss: 0.1128\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1106\n",
      "Epoch: 8/20... Training loss: 0.1135\n",
      "Epoch: 8/20... Training loss: 0.1086\n",
      "Epoch: 8/20... Training loss: 0.1079\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1126\n",
      "Epoch: 8/20... Training loss: 0.1157\n",
      "Epoch: 8/20... Training loss: 0.1103\n",
      "Epoch: 8/20... Training loss: 0.1123\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1090\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1119\n",
      "Epoch: 8/20... Training loss: 0.1109\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1133\n",
      "Epoch: 8/20... Training loss: 0.1135\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1109\n",
      "Epoch: 8/20... Training loss: 0.1107\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1116\n",
      "Epoch: 8/20... Training loss: 0.1064\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1087\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1055\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1132\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1133\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1107\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1109\n",
      "Epoch: 8/20... Training loss: 0.1115\n",
      "Epoch: 8/20... Training loss: 0.1124\n",
      "Epoch: 8/20... Training loss: 0.1156\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1105\n",
      "Epoch: 8/20... Training loss: 0.1086\n",
      "Epoch: 8/20... Training loss: 0.1123\n",
      "Epoch: 8/20... Training loss: 0.1118\n",
      "Epoch: 8/20... Training loss: 0.1072\n",
      "Epoch: 8/20... Training loss: 0.1090\n",
      "Epoch: 8/20... Training loss: 0.1111\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1111\n",
      "Epoch: 8/20... Training loss: 0.1133\n",
      "Epoch: 8/20... Training loss: 0.1116\n",
      "Epoch: 8/20... Training loss: 0.1108\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1107\n",
      "Epoch: 8/20... Training loss: 0.1106\n",
      "Epoch: 8/20... Training loss: 0.1074\n",
      "Epoch: 8/20... Training loss: 0.1132\n",
      "Epoch: 8/20... Training loss: 0.1069\n",
      "Epoch: 8/20... Training loss: 0.1129\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1136\n",
      "Epoch: 8/20... Training loss: 0.1087\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1091\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1090\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1103\n",
      "Epoch: 8/20... Training loss: 0.1080\n",
      "Epoch: 8/20... Training loss: 0.1138\n",
      "Epoch: 8/20... Training loss: 0.1108\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1083\n",
      "Epoch: 8/20... Training loss: 0.1090\n",
      "Epoch: 8/20... Training loss: 0.1103\n",
      "Epoch: 8/20... Training loss: 0.1134\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1153\n",
      "Epoch: 8/20... Training loss: 0.1079\n",
      "Epoch: 8/20... Training loss: 0.1037\n",
      "Epoch: 8/20... Training loss: 0.1127\n",
      "Epoch: 8/20... Training loss: 0.1103\n",
      "Epoch: 8/20... Training loss: 0.1129\n",
      "Epoch: 8/20... Training loss: 0.1069\n",
      "Epoch: 8/20... Training loss: 0.1107\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1045\n",
      "Epoch: 8/20... Training loss: 0.1085\n",
      "Epoch: 8/20... Training loss: 0.1091\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1080\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1057\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1112\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1112\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1086\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1074\n",
      "Epoch: 8/20... Training loss: 0.1131\n",
      "Epoch: 8/20... Training loss: 0.1085\n",
      "Epoch: 8/20... Training loss: 0.1074\n",
      "Epoch: 8/20... Training loss: 0.1054\n",
      "Epoch: 8/20... Training loss: 0.1078\n",
      "Epoch: 8/20... Training loss: 0.1111\n",
      "Epoch: 8/20... Training loss: 0.1096\n",
      "Epoch: 8/20... Training loss: 0.1067\n",
      "Epoch: 8/20... Training loss: 0.1075\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1091\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1083\n",
      "Epoch: 8/20... Training loss: 0.1107\n",
      "Epoch: 8/20... Training loss: 0.1129\n",
      "Epoch: 8/20... Training loss: 0.1073\n",
      "Epoch: 8/20... Training loss: 0.1109\n",
      "Epoch: 8/20... Training loss: 0.1077\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1077\n",
      "Epoch: 8/20... Training loss: 0.1146\n",
      "Epoch: 8/20... Training loss: 0.1059\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1105\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1054\n",
      "Epoch: 8/20... Training loss: 0.1119\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1135\n",
      "Epoch: 8/20... Training loss: 0.1068\n",
      "Epoch: 8/20... Training loss: 0.1042\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1062\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1100\n",
      "Epoch: 8/20... Training loss: 0.1121\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1082\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1051\n",
      "Epoch: 8/20... Training loss: 0.1089\n",
      "Epoch: 8/20... Training loss: 0.1086\n",
      "Epoch: 8/20... Training loss: 0.1032\n",
      "Epoch: 8/20... Training loss: 0.1066\n",
      "Epoch: 8/20... Training loss: 0.1059\n",
      "Epoch: 8/20... Training loss: 0.1093\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1069\n",
      "Epoch: 8/20... Training loss: 0.1102\n",
      "Epoch: 8/20... Training loss: 0.1125\n",
      "Epoch: 8/20... Training loss: 0.1049\n",
      "Epoch: 8/20... Training loss: 0.1049\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1062\n",
      "Epoch: 8/20... Training loss: 0.1095\n",
      "Epoch: 8/20... Training loss: 0.1050\n",
      "Epoch: 8/20... Training loss: 0.1092\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1131\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1043\n",
      "Epoch: 8/20... Training loss: 0.1112\n",
      "Epoch: 8/20... Training loss: 0.1043\n",
      "Epoch: 8/20... Training loss: 0.1141\n",
      "Epoch: 8/20... Training loss: 0.1106\n",
      "Epoch: 8/20... Training loss: 0.1129\n",
      "Epoch: 8/20... Training loss: 0.1076\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1085\n",
      "Epoch: 8/20... Training loss: 0.1026\n",
      "Epoch: 8/20... Training loss: 0.1074\n",
      "Epoch: 8/20... Training loss: 0.1058\n",
      "Epoch: 8/20... Training loss: 0.1073\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1098\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1047\n",
      "Epoch: 8/20... Training loss: 0.1063\n",
      "Epoch: 8/20... Training loss: 0.1051\n",
      "Epoch: 8/20... Training loss: 0.1094\n",
      "Epoch: 8/20... Training loss: 0.1085\n",
      "Epoch: 8/20... Training loss: 0.1151\n",
      "Epoch: 8/20... Training loss: 0.1081\n",
      "Epoch: 8/20... Training loss: 0.1115\n",
      "Epoch: 8/20... Training loss: 0.1091\n",
      "Epoch: 8/20... Training loss: 0.1079\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1109\n",
      "Epoch: 8/20... Training loss: 0.1114\n",
      "Epoch: 8/20... Training loss: 0.1058\n",
      "Epoch: 8/20... Training loss: 0.1113\n",
      "Epoch: 8/20... Training loss: 0.1154\n",
      "Epoch: 8/20... Training loss: 0.1127\n",
      "Epoch: 8/20... Training loss: 0.1088\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 8/20... Training loss: 0.1067\n",
      "Epoch: 8/20... Training loss: 0.1108\n",
      "Epoch: 8/20... Training loss: 0.1120\n",
      "Epoch: 8/20... Training loss: 0.1055\n",
      "Epoch: 8/20... Training loss: 0.1110\n",
      "Epoch: 8/20... Training loss: 0.1080\n",
      "Epoch: 8/20... Training loss: 0.1138\n",
      "Epoch: 8/20... Training loss: 0.1129\n",
      "Epoch: 8/20... Training loss: 0.1073\n",
      "Epoch: 8/20... Training loss: 0.1084\n",
      "Epoch: 8/20... Training loss: 0.1097\n",
      "Epoch: 8/20... Training loss: 0.1071\n",
      "Epoch: 8/20... Training loss: 0.1135\n",
      "Epoch: 8/20... Training loss: 0.1101\n",
      "Epoch: 8/20... Training loss: 0.1099\n",
      "Epoch: 9/20... Training loss: 0.1154\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1121\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1109\n",
      "Epoch: 9/20... Training loss: 0.1119\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1096\n",
      "Epoch: 9/20... Training loss: 0.1134\n",
      "Epoch: 9/20... Training loss: 0.1115\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1099\n",
      "Epoch: 9/20... Training loss: 0.1127\n",
      "Epoch: 9/20... Training loss: 0.1048\n",
      "Epoch: 9/20... Training loss: 0.1112\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1135\n",
      "Epoch: 9/20... Training loss: 0.1058\n",
      "Epoch: 9/20... Training loss: 0.1126\n",
      "Epoch: 9/20... Training loss: 0.1086\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1084\n",
      "Epoch: 9/20... Training loss: 0.1107\n",
      "Epoch: 9/20... Training loss: 0.1094\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1119\n",
      "Epoch: 9/20... Training loss: 0.1080\n",
      "Epoch: 9/20... Training loss: 0.1045\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1131\n",
      "Epoch: 9/20... Training loss: 0.1084\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1071\n",
      "Epoch: 9/20... Training loss: 0.1111\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1086\n",
      "Epoch: 9/20... Training loss: 0.1098\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1098\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1114\n",
      "Epoch: 9/20... Training loss: 0.1130\n",
      "Epoch: 9/20... Training loss: 0.1026\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1031\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1121\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1130\n",
      "Epoch: 9/20... Training loss: 0.1057\n",
      "Epoch: 9/20... Training loss: 0.1057\n",
      "Epoch: 9/20... Training loss: 0.1053\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1065\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1062\n",
      "Epoch: 9/20... Training loss: 0.1102\n",
      "Epoch: 9/20... Training loss: 0.1045\n",
      "Epoch: 9/20... Training loss: 0.1114\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1099\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1051\n",
      "Epoch: 9/20... Training loss: 0.1045\n",
      "Epoch: 9/20... Training loss: 0.1061\n",
      "Epoch: 9/20... Training loss: 0.1042\n",
      "Epoch: 9/20... Training loss: 0.1123\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1080\n",
      "Epoch: 9/20... Training loss: 0.1143\n",
      "Epoch: 9/20... Training loss: 0.1074\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1091\n",
      "Epoch: 9/20... Training loss: 0.1098\n",
      "Epoch: 9/20... Training loss: 0.1104\n",
      "Epoch: 9/20... Training loss: 0.1122\n",
      "Epoch: 9/20... Training loss: 0.1069\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1051\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1092\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1067\n",
      "Epoch: 9/20... Training loss: 0.1104\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1070\n",
      "Epoch: 9/20... Training loss: 0.1058\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1061\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1067\n",
      "Epoch: 9/20... Training loss: 0.1049\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1048\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1058\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1051\n",
      "Epoch: 9/20... Training loss: 0.1086\n",
      "Epoch: 9/20... Training loss: 0.1112\n",
      "Epoch: 9/20... Training loss: 0.1071\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1118\n",
      "Epoch: 9/20... Training loss: 0.1052\n",
      "Epoch: 9/20... Training loss: 0.1107\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1105\n",
      "Epoch: 9/20... Training loss: 0.1156\n",
      "Epoch: 9/20... Training loss: 0.1046\n",
      "Epoch: 9/20... Training loss: 0.1069\n",
      "Epoch: 9/20... Training loss: 0.1054\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1054\n",
      "Epoch: 9/20... Training loss: 0.1065\n",
      "Epoch: 9/20... Training loss: 0.1071\n",
      "Epoch: 9/20... Training loss: 0.1055\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1110\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1061\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1042\n",
      "Epoch: 9/20... Training loss: 0.1096\n",
      "Epoch: 9/20... Training loss: 0.1043\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1055\n",
      "Epoch: 9/20... Training loss: 0.1065\n",
      "Epoch: 9/20... Training loss: 0.1120\n",
      "Epoch: 9/20... Training loss: 0.1110\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1127\n",
      "Epoch: 9/20... Training loss: 0.1072\n",
      "Epoch: 9/20... Training loss: 0.1058\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1061\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1090\n",
      "Epoch: 9/20... Training loss: 0.1094\n",
      "Epoch: 9/20... Training loss: 0.1072\n",
      "Epoch: 9/20... Training loss: 0.1070\n",
      "Epoch: 9/20... Training loss: 0.1127\n",
      "Epoch: 9/20... Training loss: 0.1060\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1128\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1070\n",
      "Epoch: 9/20... Training loss: 0.1061\n",
      "Epoch: 9/20... Training loss: 0.1099\n",
      "Epoch: 9/20... Training loss: 0.1094\n",
      "Epoch: 9/20... Training loss: 0.1049\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1041\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1115\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1085\n",
      "Epoch: 9/20... Training loss: 0.1071\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1081\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1097\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1096\n",
      "Epoch: 9/20... Training loss: 0.1058\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1059\n",
      "Epoch: 9/20... Training loss: 0.1049\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1092\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1091\n",
      "Epoch: 9/20... Training loss: 0.1103\n",
      "Epoch: 9/20... Training loss: 0.1069\n",
      "Epoch: 9/20... Training loss: 0.1096\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1110\n",
      "Epoch: 9/20... Training loss: 0.1129\n",
      "Epoch: 9/20... Training loss: 0.1084\n",
      "Epoch: 9/20... Training loss: 0.1069\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1075\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1078\n",
      "Epoch: 9/20... Training loss: 0.1024\n",
      "Epoch: 9/20... Training loss: 0.1095\n",
      "Epoch: 9/20... Training loss: 0.1117\n",
      "Epoch: 9/20... Training loss: 0.1101\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1095\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1113\n",
      "Epoch: 9/20... Training loss: 0.1037\n",
      "Epoch: 9/20... Training loss: 0.1037\n",
      "Epoch: 9/20... Training loss: 0.1048\n",
      "Epoch: 9/20... Training loss: 0.1095\n",
      "Epoch: 9/20... Training loss: 0.1085\n",
      "Epoch: 9/20... Training loss: 0.1031\n",
      "Epoch: 9/20... Training loss: 0.1138\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1067\n",
      "Epoch: 9/20... Training loss: 0.1101\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1062\n",
      "Epoch: 9/20... Training loss: 0.1124\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1087\n",
      "Epoch: 9/20... Training loss: 0.1104\n",
      "Epoch: 9/20... Training loss: 0.1047\n",
      "Epoch: 9/20... Training loss: 0.1117\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 9/20... Training loss: 0.1109\n",
      "Epoch: 9/20... Training loss: 0.1076\n",
      "Epoch: 9/20... Training loss: 0.1064\n",
      "Epoch: 9/20... Training loss: 0.1079\n",
      "Epoch: 9/20... Training loss: 0.1056\n",
      "Epoch: 9/20... Training loss: 0.1066\n",
      "Epoch: 9/20... Training loss: 0.1115\n",
      "Epoch: 9/20... Training loss: 0.1053\n",
      "Epoch: 9/20... Training loss: 0.1054\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1091\n",
      "Epoch: 9/20... Training loss: 0.1140\n",
      "Epoch: 9/20... Training loss: 0.1068\n",
      "Epoch: 9/20... Training loss: 0.1129\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1096\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1088\n",
      "Epoch: 9/20... Training loss: 0.1045\n",
      "Epoch: 9/20... Training loss: 0.1069\n",
      "Epoch: 9/20... Training loss: 0.1060\n",
      "Epoch: 9/20... Training loss: 0.1090\n",
      "Epoch: 9/20... Training loss: 0.1077\n",
      "Epoch: 9/20... Training loss: 0.1100\n",
      "Epoch: 9/20... Training loss: 0.1048\n",
      "Epoch: 9/20... Training loss: 0.1073\n",
      "Epoch: 9/20... Training loss: 0.1108\n",
      "Epoch: 9/20... Training loss: 0.1128\n",
      "Epoch: 9/20... Training loss: 0.1083\n",
      "Epoch: 9/20... Training loss: 0.1096\n",
      "Epoch: 9/20... Training loss: 0.1030\n",
      "Epoch: 9/20... Training loss: 0.1106\n",
      "Epoch: 9/20... Training loss: 0.1093\n",
      "Epoch: 9/20... Training loss: 0.1053\n",
      "Epoch: 9/20... Training loss: 0.1138\n",
      "Epoch: 9/20... Training loss: 0.1063\n",
      "Epoch: 9/20... Training loss: 0.1080\n",
      "Epoch: 9/20... Training loss: 0.1095\n",
      "Epoch: 9/20... Training loss: 0.1085\n",
      "Epoch: 9/20... Training loss: 0.1096\n",
      "Epoch: 9/20... Training loss: 0.1089\n",
      "Epoch: 9/20... Training loss: 0.1082\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1039\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1129\n",
      "Epoch: 10/20... Training loss: 0.1073\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1053\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1038\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1113\n",
      "Epoch: 10/20... Training loss: 0.1130\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.1098\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1092\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.1082\n",
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 10/20... Training loss: 0.1123\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1092\n",
      "Epoch: 10/20... Training loss: 0.1060\n",
      "Epoch: 10/20... Training loss: 0.1109\n",
      "Epoch: 10/20... Training loss: 0.1096\n",
      "Epoch: 10/20... Training loss: 0.1044\n",
      "Epoch: 10/20... Training loss: 0.1053\n",
      "Epoch: 10/20... Training loss: 0.1095\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1034\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1099\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1075\n",
      "Epoch: 10/20... Training loss: 0.1030\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1099\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1070\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 10/20... Training loss: 0.1066\n",
      "Epoch: 10/20... Training loss: 0.1067\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1089\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1127\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1034\n",
      "Epoch: 10/20... Training loss: 0.1034\n",
      "Epoch: 10/20... Training loss: 0.1154\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1073\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1105\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1111\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1064\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1086\n",
      "Epoch: 10/20... Training loss: 0.1016\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1108\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1100\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1058\n",
      "Epoch: 10/20... Training loss: 0.1079\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1046\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.1071\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1102\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1067\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1084\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1109\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1079\n",
      "Epoch: 10/20... Training loss: 0.1038\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1058\n",
      "Epoch: 10/20... Training loss: 0.1070\n",
      "Epoch: 10/20... Training loss: 0.1082\n",
      "Epoch: 10/20... Training loss: 0.1055\n",
      "Epoch: 10/20... Training loss: 0.1065\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1097\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1086\n",
      "Epoch: 10/20... Training loss: 0.1042\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1028\n",
      "Epoch: 10/20... Training loss: 0.1066\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1015\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1036\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1089\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1104\n",
      "Epoch: 10/20... Training loss: 0.1123\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1079\n",
      "Epoch: 10/20... Training loss: 0.1057\n",
      "Epoch: 10/20... Training loss: 0.1075\n",
      "Epoch: 10/20... Training loss: 0.1055\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1055\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1066\n",
      "Epoch: 10/20... Training loss: 0.1108\n",
      "Epoch: 10/20... Training loss: 0.1115\n",
      "Epoch: 10/20... Training loss: 0.1105\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1089\n",
      "Epoch: 10/20... Training loss: 0.1075\n",
      "Epoch: 10/20... Training loss: 0.1060\n",
      "Epoch: 10/20... Training loss: 0.1056\n",
      "Epoch: 10/20... Training loss: 0.1100\n",
      "Epoch: 10/20... Training loss: 0.1032\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 10/20... Training loss: 0.1045\n",
      "Epoch: 10/20... Training loss: 0.1076\n",
      "Epoch: 10/20... Training loss: 0.1048\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1041\n",
      "Epoch: 10/20... Training loss: 0.1109\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1031\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1074\n",
      "Epoch: 10/20... Training loss: 0.1032\n",
      "Epoch: 10/20... Training loss: 0.1101\n",
      "Epoch: 10/20... Training loss: 0.1091\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1067\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1097\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1099\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1116\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1096\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1103\n",
      "Epoch: 10/20... Training loss: 0.1086\n",
      "Epoch: 10/20... Training loss: 0.1094\n",
      "Epoch: 10/20... Training loss: 0.1072\n",
      "Epoch: 10/20... Training loss: 0.1079\n",
      "Epoch: 10/20... Training loss: 0.1064\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1035\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1070\n",
      "Epoch: 10/20... Training loss: 0.1067\n",
      "Epoch: 10/20... Training loss: 0.1040\n",
      "Epoch: 10/20... Training loss: 0.1098\n",
      "Epoch: 10/20... Training loss: 0.1056\n",
      "Epoch: 10/20... Training loss: 0.1079\n",
      "Epoch: 10/20... Training loss: 0.1057\n",
      "Epoch: 10/20... Training loss: 0.1094\n",
      "Epoch: 10/20... Training loss: 0.1067\n",
      "Epoch: 10/20... Training loss: 0.1050\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1081\n",
      "Epoch: 10/20... Training loss: 0.1095\n",
      "Epoch: 10/20... Training loss: 0.1093\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1133\n",
      "Epoch: 10/20... Training loss: 0.1053\n",
      "Epoch: 10/20... Training loss: 0.1089\n",
      "Epoch: 10/20... Training loss: 0.1101\n",
      "Epoch: 10/20... Training loss: 0.1088\n",
      "Epoch: 10/20... Training loss: 0.1087\n",
      "Epoch: 10/20... Training loss: 0.1110\n",
      "Epoch: 10/20... Training loss: 0.1058\n",
      "Epoch: 10/20... Training loss: 0.1045\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.1086\n",
      "Epoch: 10/20... Training loss: 0.1117\n",
      "Epoch: 10/20... Training loss: 0.1056\n",
      "Epoch: 10/20... Training loss: 0.1063\n",
      "Epoch: 10/20... Training loss: 0.1064\n",
      "Epoch: 10/20... Training loss: 0.1002\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1058\n",
      "Epoch: 10/20... Training loss: 0.1075\n",
      "Epoch: 10/20... Training loss: 0.1011\n",
      "Epoch: 10/20... Training loss: 0.1014\n",
      "Epoch: 10/20... Training loss: 0.1065\n",
      "Epoch: 10/20... Training loss: 0.1031\n",
      "Epoch: 10/20... Training loss: 0.1031\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1029\n",
      "Epoch: 10/20... Training loss: 0.1102\n",
      "Epoch: 10/20... Training loss: 0.1071\n",
      "Epoch: 10/20... Training loss: 0.1058\n",
      "Epoch: 10/20... Training loss: 0.1107\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1090\n",
      "Epoch: 10/20... Training loss: 0.1035\n",
      "Epoch: 10/20... Training loss: 0.1065\n",
      "Epoch: 10/20... Training loss: 0.1002\n",
      "Epoch: 10/20... Training loss: 0.1059\n",
      "Epoch: 10/20... Training loss: 0.1083\n",
      "Epoch: 10/20... Training loss: 0.1029\n",
      "Epoch: 10/20... Training loss: 0.1036\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.1080\n",
      "Epoch: 10/20... Training loss: 0.1051\n",
      "Epoch: 10/20... Training loss: 0.1099\n",
      "Epoch: 10/20... Training loss: 0.1052\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1057\n",
      "Epoch: 10/20... Training loss: 0.1055\n",
      "Epoch: 10/20... Training loss: 0.1075\n",
      "Epoch: 10/20... Training loss: 0.1062\n",
      "Epoch: 10/20... Training loss: 0.1027\n",
      "Epoch: 10/20... Training loss: 0.1047\n",
      "Epoch: 10/20... Training loss: 0.1052\n",
      "Epoch: 10/20... Training loss: 0.1125\n",
      "Epoch: 10/20... Training loss: 0.1021\n",
      "Epoch: 10/20... Training loss: 0.1054\n",
      "Epoch: 10/20... Training loss: 0.1069\n",
      "Epoch: 10/20... Training loss: 0.1100\n",
      "Epoch: 10/20... Training loss: 0.1078\n",
      "Epoch: 10/20... Training loss: 0.1039\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1052\n",
      "Epoch: 10/20... Training loss: 0.1068\n",
      "Epoch: 10/20... Training loss: 0.1031\n",
      "Epoch: 10/20... Training loss: 0.1049\n",
      "Epoch: 10/20... Training loss: 0.1085\n",
      "Epoch: 10/20... Training loss: 0.1076\n",
      "Epoch: 10/20... Training loss: 0.1064\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1077\n",
      "Epoch: 10/20... Training loss: 0.1079\n",
      "Epoch: 10/20... Training loss: 0.1043\n",
      "Epoch: 10/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1069\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1040\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1071\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1059\n",
      "Epoch: 11/20... Training loss: 0.1104\n",
      "Epoch: 11/20... Training loss: 0.1106\n",
      "Epoch: 11/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1027\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1102\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1090\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1052\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1023\n",
      "Epoch: 11/20... Training loss: 0.1082\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1100\n",
      "Epoch: 11/20... Training loss: 0.1116\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1125\n",
      "Epoch: 11/20... Training loss: 0.1047\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1082\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.1093\n",
      "Epoch: 11/20... Training loss: 0.1071\n",
      "Epoch: 11/20... Training loss: 0.1083\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1024\n",
      "Epoch: 11/20... Training loss: 0.1084\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1076\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1089\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.1035\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1106\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1087\n",
      "Epoch: 11/20... Training loss: 0.1015\n",
      "Epoch: 11/20... Training loss: 0.1033\n",
      "Epoch: 11/20... Training loss: 0.1076\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1043\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1035\n",
      "Epoch: 11/20... Training loss: 0.1082\n",
      "Epoch: 11/20... Training loss: 0.1099\n",
      "Epoch: 11/20... Training loss: 0.1069\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1063\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1101\n",
      "Epoch: 11/20... Training loss: 0.1044\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1075\n",
      "Epoch: 11/20... Training loss: 0.1087\n",
      "Epoch: 11/20... Training loss: 0.1075\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1033\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.1018\n",
      "Epoch: 11/20... Training loss: 0.1035\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1043\n",
      "Epoch: 11/20... Training loss: 0.1045\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.1100\n",
      "Epoch: 11/20... Training loss: 0.1036\n",
      "Epoch: 11/20... Training loss: 0.1097\n",
      "Epoch: 11/20... Training loss: 0.1044\n",
      "Epoch: 11/20... Training loss: 0.1071\n",
      "Epoch: 11/20... Training loss: 0.1043\n",
      "Epoch: 11/20... Training loss: 0.1077\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1047\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1059\n",
      "Epoch: 11/20... Training loss: 0.1020\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1088\n",
      "Epoch: 11/20... Training loss: 0.1100\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.1074\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1049\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1063\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1069\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1094\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1047\n",
      "Epoch: 11/20... Training loss: 0.1052\n",
      "Epoch: 11/20... Training loss: 0.1089\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1073\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1087\n",
      "Epoch: 11/20... Training loss: 0.1024\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1011\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1042\n",
      "Epoch: 11/20... Training loss: 0.1088\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1031\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1077\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1042\n",
      "Epoch: 11/20... Training loss: 0.1047\n",
      "Epoch: 11/20... Training loss: 0.1048\n",
      "Epoch: 11/20... Training loss: 0.1093\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1048\n",
      "Epoch: 11/20... Training loss: 0.1077\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1031\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1045\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1061\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1090\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1088\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1052\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1047\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1081\n",
      "Epoch: 11/20... Training loss: 0.1065\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1069\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1102\n",
      "Epoch: 11/20... Training loss: 0.1050\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1014\n",
      "Epoch: 11/20... Training loss: 0.1077\n",
      "Epoch: 11/20... Training loss: 0.1084\n",
      "Epoch: 11/20... Training loss: 0.1097\n",
      "Epoch: 11/20... Training loss: 0.1086\n",
      "Epoch: 11/20... Training loss: 0.1095\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1085\n",
      "Epoch: 11/20... Training loss: 0.1036\n",
      "Epoch: 11/20... Training loss: 0.1110\n",
      "Epoch: 11/20... Training loss: 0.1045\n",
      "Epoch: 11/20... Training loss: 0.1065\n",
      "Epoch: 11/20... Training loss: 0.1033\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.1090\n",
      "Epoch: 11/20... Training loss: 0.1072\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.0983\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1045\n",
      "Epoch: 11/20... Training loss: 0.1093\n",
      "Epoch: 11/20... Training loss: 0.1031\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1024\n",
      "Epoch: 11/20... Training loss: 0.1074\n",
      "Epoch: 11/20... Training loss: 0.1031\n",
      "Epoch: 11/20... Training loss: 0.1063\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1022\n",
      "Epoch: 11/20... Training loss: 0.1060\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1013\n",
      "Epoch: 11/20... Training loss: 0.1080\n",
      "Epoch: 11/20... Training loss: 0.1055\n",
      "Epoch: 11/20... Training loss: 0.1048\n",
      "Epoch: 11/20... Training loss: 0.1088\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1066\n",
      "Epoch: 11/20... Training loss: 0.1068\n",
      "Epoch: 11/20... Training loss: 0.1026\n",
      "Epoch: 11/20... Training loss: 0.1068\n",
      "Epoch: 11/20... Training loss: 0.1064\n",
      "Epoch: 11/20... Training loss: 0.1031\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1035\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1071\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1087\n",
      "Epoch: 11/20... Training loss: 0.1062\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1058\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1087\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1071\n",
      "Epoch: 11/20... Training loss: 0.1054\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1024\n",
      "Epoch: 11/20... Training loss: 0.1056\n",
      "Epoch: 11/20... Training loss: 0.1055\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1070\n",
      "Epoch: 11/20... Training loss: 0.1091\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1112\n",
      "Epoch: 11/20... Training loss: 0.1029\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1019\n",
      "Epoch: 11/20... Training loss: 0.1001\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1030\n",
      "Epoch: 11/20... Training loss: 0.1032\n",
      "Epoch: 11/20... Training loss: 0.1024\n",
      "Epoch: 11/20... Training loss: 0.1048\n",
      "Epoch: 11/20... Training loss: 0.1075\n",
      "Epoch: 11/20... Training loss: 0.1046\n",
      "Epoch: 11/20... Training loss: 0.1089\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1078\n",
      "Epoch: 11/20... Training loss: 0.1037\n",
      "Epoch: 11/20... Training loss: 0.1053\n",
      "Epoch: 11/20... Training loss: 0.1033\n",
      "Epoch: 11/20... Training loss: 0.1079\n",
      "Epoch: 11/20... Training loss: 0.1006\n",
      "Epoch: 11/20... Training loss: 0.1034\n",
      "Epoch: 11/20... Training loss: 0.1102\n",
      "Epoch: 11/20... Training loss: 0.1041\n",
      "Epoch: 11/20... Training loss: 0.1067\n",
      "Epoch: 11/20... Training loss: 0.1092\n",
      "Epoch: 11/20... Training loss: 0.1031\n",
      "Epoch: 11/20... Training loss: 0.1043\n",
      "Epoch: 11/20... Training loss: 0.1090\n",
      "Epoch: 11/20... Training loss: 0.1057\n",
      "Epoch: 11/20... Training loss: 0.1039\n",
      "Epoch: 11/20... Training loss: 0.1097\n",
      "Epoch: 11/20... Training loss: 0.1051\n",
      "Epoch: 11/20... Training loss: 0.1077\n",
      "Epoch: 11/20... Training loss: 0.1099\n",
      "Epoch: 11/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1059\n",
      "Epoch: 12/20... Training loss: 0.1018\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1030\n",
      "Epoch: 12/20... Training loss: 0.1085\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1084\n",
      "Epoch: 12/20... Training loss: 0.1019\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1076\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1102\n",
      "Epoch: 12/20... Training loss: 0.1030\n",
      "Epoch: 12/20... Training loss: 0.1064\n",
      "Epoch: 12/20... Training loss: 0.1040\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1015\n",
      "Epoch: 12/20... Training loss: 0.1076\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1074\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1061\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1067\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1084\n",
      "Epoch: 12/20... Training loss: 0.1014\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1032\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1027\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1006\n",
      "Epoch: 12/20... Training loss: 0.1044\n",
      "Epoch: 12/20... Training loss: 0.1069\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1064\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1059\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1061\n",
      "Epoch: 12/20... Training loss: 0.1065\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1087\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1049\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1081\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1059\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1033\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1085\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1064\n",
      "Epoch: 12/20... Training loss: 0.1065\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1041\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1001\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1091\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1052\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1009\n",
      "Epoch: 12/20... Training loss: 0.1079\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1069\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1093\n",
      "Epoch: 12/20... Training loss: 0.1092\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1065\n",
      "Epoch: 12/20... Training loss: 0.0982\n",
      "Epoch: 12/20... Training loss: 0.1067\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1061\n",
      "Epoch: 12/20... Training loss: 0.1073\n",
      "Epoch: 12/20... Training loss: 0.1088\n",
      "Epoch: 12/20... Training loss: 0.1102\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1075\n",
      "Epoch: 12/20... Training loss: 0.1032\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1028\n",
      "Epoch: 12/20... Training loss: 0.1011\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1101\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1012\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1087\n",
      "Epoch: 12/20... Training loss: 0.1033\n",
      "Epoch: 12/20... Training loss: 0.1069\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1087\n",
      "Epoch: 12/20... Training loss: 0.1032\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1083\n",
      "Epoch: 12/20... Training loss: 0.1073\n",
      "Epoch: 12/20... Training loss: 0.1073\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1044\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1049\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1082\n",
      "Epoch: 12/20... Training loss: 0.1079\n",
      "Epoch: 12/20... Training loss: 0.1090\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1083\n",
      "Epoch: 12/20... Training loss: 0.1090\n",
      "Epoch: 12/20... Training loss: 0.1074\n",
      "Epoch: 12/20... Training loss: 0.1032\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1034\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.1044\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1074\n",
      "Epoch: 12/20... Training loss: 0.1057\n",
      "Epoch: 12/20... Training loss: 0.1022\n",
      "Epoch: 12/20... Training loss: 0.1073\n",
      "Epoch: 12/20... Training loss: 0.1039\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1081\n",
      "Epoch: 12/20... Training loss: 0.1096\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1037\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.1103\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1039\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1076\n",
      "Epoch: 12/20... Training loss: 0.1049\n",
      "Epoch: 12/20... Training loss: 0.1079\n",
      "Epoch: 12/20... Training loss: 0.1023\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.1053\n",
      "Epoch: 12/20... Training loss: 0.1069\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1057\n",
      "Epoch: 12/20... Training loss: 0.1028\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1099\n",
      "Epoch: 12/20... Training loss: 0.1041\n",
      "Epoch: 12/20... Training loss: 0.1030\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1099\n",
      "Epoch: 12/20... Training loss: 0.1069\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1035\n",
      "Epoch: 12/20... Training loss: 0.1053\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1087\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1024\n",
      "Epoch: 12/20... Training loss: 0.1036\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1075\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1022\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1040\n",
      "Epoch: 12/20... Training loss: 0.1002\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1040\n",
      "Epoch: 12/20... Training loss: 0.1041\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1019\n",
      "Epoch: 12/20... Training loss: 0.1033\n",
      "Epoch: 12/20... Training loss: 0.1027\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1041\n",
      "Epoch: 12/20... Training loss: 0.1002\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1079\n",
      "Epoch: 12/20... Training loss: 0.1029\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1075\n",
      "Epoch: 12/20... Training loss: 0.1022\n",
      "Epoch: 12/20... Training loss: 0.0995\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1031\n",
      "Epoch: 12/20... Training loss: 0.1018\n",
      "Epoch: 12/20... Training loss: 0.1040\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1050\n",
      "Epoch: 12/20... Training loss: 0.1054\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1042\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1038\n",
      "Epoch: 12/20... Training loss: 0.1005\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.0996\n",
      "Epoch: 12/20... Training loss: 0.1041\n",
      "Epoch: 12/20... Training loss: 0.1020\n",
      "Epoch: 12/20... Training loss: 0.1057\n",
      "Epoch: 12/20... Training loss: 0.1022\n",
      "Epoch: 12/20... Training loss: 0.1056\n",
      "Epoch: 12/20... Training loss: 0.1037\n",
      "Epoch: 12/20... Training loss: 0.1005\n",
      "Epoch: 12/20... Training loss: 0.1063\n",
      "Epoch: 12/20... Training loss: 0.1034\n",
      "Epoch: 12/20... Training loss: 0.1057\n",
      "Epoch: 12/20... Training loss: 0.1030\n",
      "Epoch: 12/20... Training loss: 0.1037\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1001\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1046\n",
      "Epoch: 12/20... Training loss: 0.0989\n",
      "Epoch: 12/20... Training loss: 0.1060\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1034\n",
      "Epoch: 12/20... Training loss: 0.1011\n",
      "Epoch: 12/20... Training loss: 0.1093\n",
      "Epoch: 12/20... Training loss: 0.1066\n",
      "Epoch: 12/20... Training loss: 0.1043\n",
      "Epoch: 12/20... Training loss: 0.1041\n",
      "Epoch: 12/20... Training loss: 0.1045\n",
      "Epoch: 12/20... Training loss: 0.1078\n",
      "Epoch: 12/20... Training loss: 0.1048\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1049\n",
      "Epoch: 12/20... Training loss: 0.1087\n",
      "Epoch: 12/20... Training loss: 0.1072\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1086\n",
      "Epoch: 12/20... Training loss: 0.1076\n",
      "Epoch: 12/20... Training loss: 0.1082\n",
      "Epoch: 12/20... Training loss: 0.1026\n",
      "Epoch: 12/20... Training loss: 0.1051\n",
      "Epoch: 12/20... Training loss: 0.1014\n",
      "Epoch: 12/20... Training loss: 0.1058\n",
      "Epoch: 12/20... Training loss: 0.1075\n",
      "Epoch: 12/20... Training loss: 0.1040\n",
      "Epoch: 12/20... Training loss: 0.1053\n",
      "Epoch: 12/20... Training loss: 0.1025\n",
      "Epoch: 12/20... Training loss: 0.1011\n",
      "Epoch: 12/20... Training loss: 0.1041\n",
      "Epoch: 12/20... Training loss: 0.1065\n",
      "Epoch: 12/20... Training loss: 0.1018\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1021\n",
      "Epoch: 12/20... Training loss: 0.1014\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 12/20... Training loss: 0.1044\n",
      "Epoch: 12/20... Training loss: 0.1067\n",
      "Epoch: 12/20... Training loss: 0.1071\n",
      "Epoch: 12/20... Training loss: 0.1029\n",
      "Epoch: 12/20... Training loss: 0.1065\n",
      "Epoch: 12/20... Training loss: 0.1077\n",
      "Epoch: 12/20... Training loss: 0.1080\n",
      "Epoch: 12/20... Training loss: 0.1068\n",
      "Epoch: 12/20... Training loss: 0.1070\n",
      "Epoch: 12/20... Training loss: 0.1006\n",
      "Epoch: 12/20... Training loss: 0.1047\n",
      "Epoch: 12/20... Training loss: 0.1044\n",
      "Epoch: 12/20... Training loss: 0.1062\n",
      "Epoch: 12/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1061\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1063\n",
      "Epoch: 13/20... Training loss: 0.1060\n",
      "Epoch: 13/20... Training loss: 0.1067\n",
      "Epoch: 13/20... Training loss: 0.1094\n",
      "Epoch: 13/20... Training loss: 0.1054\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1011\n",
      "Epoch: 13/20... Training loss: 0.1038\n",
      "Epoch: 13/20... Training loss: 0.1078\n",
      "Epoch: 13/20... Training loss: 0.1092\n",
      "Epoch: 13/20... Training loss: 0.1007\n",
      "Epoch: 13/20... Training loss: 0.1074\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1060\n",
      "Epoch: 13/20... Training loss: 0.1004\n",
      "Epoch: 13/20... Training loss: 0.1073\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1009\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1065\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1102\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1070\n",
      "Epoch: 13/20... Training loss: 0.1022\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1069\n",
      "Epoch: 13/20... Training loss: 0.1049\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1049\n",
      "Epoch: 13/20... Training loss: 0.1054\n",
      "Epoch: 13/20... Training loss: 0.1078\n",
      "Epoch: 13/20... Training loss: 0.1071\n",
      "Epoch: 13/20... Training loss: 0.0997\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1050\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1010\n",
      "Epoch: 13/20... Training loss: 0.1016\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1042\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1046\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1049\n",
      "Epoch: 13/20... Training loss: 0.1061\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1070\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1078\n",
      "Epoch: 13/20... Training loss: 0.1090\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1015\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1063\n",
      "Epoch: 13/20... Training loss: 0.1009\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1003\n",
      "Epoch: 13/20... Training loss: 0.1047\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1018\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1064\n",
      "Epoch: 13/20... Training loss: 0.1061\n",
      "Epoch: 13/20... Training loss: 0.1074\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1061\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.0996\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.1077\n",
      "Epoch: 13/20... Training loss: 0.0997\n",
      "Epoch: 13/20... Training loss: 0.1054\n",
      "Epoch: 13/20... Training loss: 0.1060\n",
      "Epoch: 13/20... Training loss: 0.1051\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.1045\n",
      "Epoch: 13/20... Training loss: 0.1073\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1096\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1079\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1012\n",
      "Epoch: 13/20... Training loss: 0.1047\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1058\n",
      "Epoch: 13/20... Training loss: 0.1045\n",
      "Epoch: 13/20... Training loss: 0.1004\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1006\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1040\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1047\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1060\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1016\n",
      "Epoch: 13/20... Training loss: 0.1056\n",
      "Epoch: 13/20... Training loss: 0.0995\n",
      "Epoch: 13/20... Training loss: 0.1009\n",
      "Epoch: 13/20... Training loss: 0.1050\n",
      "Epoch: 13/20... Training loss: 0.1013\n",
      "Epoch: 13/20... Training loss: 0.0992\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1030\n",
      "Epoch: 13/20... Training loss: 0.1034\n",
      "Epoch: 13/20... Training loss: 0.1016\n",
      "Epoch: 13/20... Training loss: 0.1063\n",
      "Epoch: 13/20... Training loss: 0.1082\n",
      "Epoch: 13/20... Training loss: 0.1064\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.1082\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1073\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1032\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.1073\n",
      "Epoch: 13/20... Training loss: 0.1016\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.1059\n",
      "Epoch: 13/20... Training loss: 0.1069\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1050\n",
      "Epoch: 13/20... Training loss: 0.1065\n",
      "Epoch: 13/20... Training loss: 0.1026\n",
      "Epoch: 13/20... Training loss: 0.1020\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1042\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.0988\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1071\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1005\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1000\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1017\n",
      "Epoch: 13/20... Training loss: 0.1066\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1031\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1048\n",
      "Epoch: 13/20... Training loss: 0.1034\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.1069\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1080\n",
      "Epoch: 13/20... Training loss: 0.1022\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1041\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.1019\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1043\n",
      "Epoch: 13/20... Training loss: 0.1054\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1045\n",
      "Epoch: 13/20... Training loss: 0.1044\n",
      "Epoch: 13/20... Training loss: 0.1068\n",
      "Epoch: 13/20... Training loss: 0.1065\n",
      "Epoch: 13/20... Training loss: 0.1021\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.0963\n",
      "Epoch: 13/20... Training loss: 0.1027\n",
      "Epoch: 13/20... Training loss: 0.1046\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1028\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1054\n",
      "Epoch: 13/20... Training loss: 0.1000\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1051\n",
      "Epoch: 13/20... Training loss: 0.1062\n",
      "Epoch: 13/20... Training loss: 0.1073\n",
      "Epoch: 13/20... Training loss: 0.1033\n",
      "Epoch: 13/20... Training loss: 0.1080\n",
      "Epoch: 13/20... Training loss: 0.1038\n",
      "Epoch: 13/20... Training loss: 0.1025\n",
      "Epoch: 13/20... Training loss: 0.1070\n",
      "Epoch: 13/20... Training loss: 0.1076\n",
      "Epoch: 13/20... Training loss: 0.1012\n",
      "Epoch: 13/20... Training loss: 0.1006\n",
      "Epoch: 13/20... Training loss: 0.1052\n",
      "Epoch: 13/20... Training loss: 0.1024\n",
      "Epoch: 13/20... Training loss: 0.1039\n",
      "Epoch: 13/20... Training loss: 0.1045\n",
      "Epoch: 13/20... Training loss: 0.1067\n",
      "Epoch: 13/20... Training loss: 0.1055\n",
      "Epoch: 13/20... Training loss: 0.1030\n",
      "Epoch: 13/20... Training loss: 0.1072\n",
      "Epoch: 13/20... Training loss: 0.1036\n",
      "Epoch: 13/20... Training loss: 0.1034\n",
      "Epoch: 13/20... Training loss: 0.1082\n",
      "Epoch: 13/20... Training loss: 0.1047\n",
      "Epoch: 13/20... Training loss: 0.1049\n",
      "Epoch: 13/20... Training loss: 0.1029\n",
      "Epoch: 13/20... Training loss: 0.1011\n",
      "Epoch: 13/20... Training loss: 0.1049\n",
      "Epoch: 13/20... Training loss: 0.1053\n",
      "Epoch: 13/20... Training loss: 0.1030\n",
      "Epoch: 13/20... Training loss: 0.1037\n",
      "Epoch: 13/20... Training loss: 0.1090\n",
      "Epoch: 13/20... Training loss: 0.1071\n",
      "Epoch: 13/20... Training loss: 0.1035\n",
      "Epoch: 13/20... Training loss: 0.1094\n",
      "Epoch: 13/20... Training loss: 0.1023\n",
      "Epoch: 13/20... Training loss: 0.1057\n",
      "Epoch: 13/20... Training loss: 0.1085\n",
      "Epoch: 13/20... Training loss: 0.1018\n",
      "Epoch: 13/20... Training loss: 0.1014\n",
      "Epoch: 13/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1062\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1075\n",
      "Epoch: 14/20... Training loss: 0.1085\n",
      "Epoch: 14/20... Training loss: 0.1073\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1001\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1046\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.1027\n",
      "Epoch: 14/20... Training loss: 0.1002\n",
      "Epoch: 14/20... Training loss: 0.1074\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1061\n",
      "Epoch: 14/20... Training loss: 0.1050\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1080\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1083\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1024\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.0986\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.1056\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1071\n",
      "Epoch: 14/20... Training loss: 0.1012\n",
      "Epoch: 14/20... Training loss: 0.1070\n",
      "Epoch: 14/20... Training loss: 0.1058\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1046\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1072\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1057\n",
      "Epoch: 14/20... Training loss: 0.1060\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1060\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.1069\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1057\n",
      "Epoch: 14/20... Training loss: 0.0985\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.0971\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1055\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.0986\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1074\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1006\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.1090\n",
      "Epoch: 14/20... Training loss: 0.1060\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.0996\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1001\n",
      "Epoch: 14/20... Training loss: 0.1027\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1046\n",
      "Epoch: 14/20... Training loss: 0.1061\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1054\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1094\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1023\n",
      "Epoch: 14/20... Training loss: 0.1046\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1001\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.0977\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1064\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.1060\n",
      "Epoch: 14/20... Training loss: 0.1070\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.0990\n",
      "Epoch: 14/20... Training loss: 0.1008\n",
      "Epoch: 14/20... Training loss: 0.1020\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 14/20... Training loss: 0.1039\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.1008\n",
      "Epoch: 14/20... Training loss: 0.1001\n",
      "Epoch: 14/20... Training loss: 0.1020\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 14/20... Training loss: 0.1068\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1056\n",
      "Epoch: 14/20... Training loss: 0.1025\n",
      "Epoch: 14/20... Training loss: 0.1054\n",
      "Epoch: 14/20... Training loss: 0.1039\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1079\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.0996\n",
      "Epoch: 14/20... Training loss: 0.0992\n",
      "Epoch: 14/20... Training loss: 0.1046\n",
      "Epoch: 14/20... Training loss: 0.1056\n",
      "Epoch: 14/20... Training loss: 0.0985\n",
      "Epoch: 14/20... Training loss: 0.1009\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.1068\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1044\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1039\n",
      "Epoch: 14/20... Training loss: 0.0990\n",
      "Epoch: 14/20... Training loss: 0.1044\n",
      "Epoch: 14/20... Training loss: 0.1072\n",
      "Epoch: 14/20... Training loss: 0.1055\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1055\n",
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1007\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1025\n",
      "Epoch: 14/20... Training loss: 0.1046\n",
      "Epoch: 14/20... Training loss: 0.1045\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1025\n",
      "Epoch: 14/20... Training loss: 0.1047\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1066\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.1077\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.1042\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.1044\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1037\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.1068\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1072\n",
      "Epoch: 14/20... Training loss: 0.1030\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1051\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.0995\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.1015\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1031\n",
      "Epoch: 14/20... Training loss: 0.1012\n",
      "Epoch: 14/20... Training loss: 0.1035\n",
      "Epoch: 14/20... Training loss: 0.1036\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1049\n",
      "Epoch: 14/20... Training loss: 0.1013\n",
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.0990\n",
      "Epoch: 14/20... Training loss: 0.0999\n",
      "Epoch: 14/20... Training loss: 0.1008\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.0994\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1044\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1038\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1066\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1057\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1029\n",
      "Epoch: 14/20... Training loss: 0.1020\n",
      "Epoch: 14/20... Training loss: 0.1078\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.1077\n",
      "Epoch: 14/20... Training loss: 0.0985\n",
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1060\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.1058\n",
      "Epoch: 14/20... Training loss: 0.1012\n",
      "Epoch: 14/20... Training loss: 0.1039\n",
      "Epoch: 14/20... Training loss: 0.1017\n",
      "Epoch: 14/20... Training loss: 0.1021\n",
      "Epoch: 14/20... Training loss: 0.1048\n",
      "Epoch: 14/20... Training loss: 0.1014\n",
      "Epoch: 14/20... Training loss: 0.0982\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.1041\n",
      "Epoch: 14/20... Training loss: 0.1033\n",
      "Epoch: 14/20... Training loss: 0.1022\n",
      "Epoch: 14/20... Training loss: 0.1040\n",
      "Epoch: 14/20... Training loss: 0.1005\n",
      "Epoch: 14/20... Training loss: 0.1050\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1032\n",
      "Epoch: 14/20... Training loss: 0.1004\n",
      "Epoch: 14/20... Training loss: 0.1016\n",
      "Epoch: 14/20... Training loss: 0.1034\n",
      "Epoch: 14/20... Training loss: 0.1085\n",
      "Epoch: 14/20... Training loss: 0.1018\n",
      "Epoch: 14/20... Training loss: 0.1052\n",
      "Epoch: 14/20... Training loss: 0.1053\n",
      "Epoch: 14/20... Training loss: 0.1011\n",
      "Epoch: 14/20... Training loss: 0.1070\n",
      "Epoch: 14/20... Training loss: 0.1063\n",
      "Epoch: 14/20... Training loss: 0.1019\n",
      "Epoch: 14/20... Training loss: 0.0998\n",
      "Epoch: 14/20... Training loss: 0.1062\n",
      "Epoch: 14/20... Training loss: 0.1010\n",
      "Epoch: 14/20... Training loss: 0.1039\n",
      "Epoch: 14/20... Training loss: 0.1026\n",
      "Epoch: 14/20... Training loss: 0.1028\n",
      "Epoch: 14/20... Training loss: 0.1059\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.1066\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1046\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1052\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1082\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.1065\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1048\n",
      "Epoch: 15/20... Training loss: 0.1074\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1034\n",
      "Epoch: 15/20... Training loss: 0.0987\n",
      "Epoch: 15/20... Training loss: 0.1055\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1074\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1062\n",
      "Epoch: 15/20... Training loss: 0.1096\n",
      "Epoch: 15/20... Training loss: 0.1068\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.1061\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1047\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1081\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1060\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1043\n",
      "Epoch: 15/20... Training loss: 0.1058\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1078\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1057\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.0991\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1056\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.1054\n",
      "Epoch: 15/20... Training loss: 0.1048\n",
      "Epoch: 15/20... Training loss: 0.1072\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1063\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1075\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.0965\n",
      "Epoch: 15/20... Training loss: 0.1069\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1043\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1072\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1081\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1034\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.1070\n",
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.0979\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1016\n",
      "Epoch: 15/20... Training loss: 0.1014\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1064\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.1042\n",
      "Epoch: 15/20... Training loss: 0.1014\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1063\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1061\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1047\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1043\n",
      "Epoch: 15/20... Training loss: 0.1059\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1060\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1014\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1033\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1037\n",
      "Epoch: 15/20... Training loss: 0.1010\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1029\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1062\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.0995\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1018\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1053\n",
      "Epoch: 15/20... Training loss: 0.1043\n",
      "Epoch: 15/20... Training loss: 0.0984\n",
      "Epoch: 15/20... Training loss: 0.1033\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1028\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.1064\n",
      "Epoch: 15/20... Training loss: 0.0999\n",
      "Epoch: 15/20... Training loss: 0.1006\n",
      "Epoch: 15/20... Training loss: 0.1055\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1031\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.0994\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1050\n",
      "Epoch: 15/20... Training loss: 0.1005\n",
      "Epoch: 15/20... Training loss: 0.1009\n",
      "Epoch: 15/20... Training loss: 0.0992\n",
      "Epoch: 15/20... Training loss: 0.1052\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1008\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.1059\n",
      "Epoch: 15/20... Training loss: 0.1040\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.0993\n",
      "Epoch: 15/20... Training loss: 0.1007\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1014\n",
      "Epoch: 15/20... Training loss: 0.1000\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.0996\n",
      "Epoch: 15/20... Training loss: 0.1014\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1071\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.1036\n",
      "Epoch: 15/20... Training loss: 0.0998\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.1004\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1029\n",
      "Epoch: 15/20... Training loss: 0.1034\n",
      "Epoch: 15/20... Training loss: 0.1047\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.1046\n",
      "Epoch: 15/20... Training loss: 0.1006\n",
      "Epoch: 15/20... Training loss: 0.1047\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1002\n",
      "Epoch: 15/20... Training loss: 0.1003\n",
      "Epoch: 15/20... Training loss: 0.1034\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.1059\n",
      "Epoch: 15/20... Training loss: 0.1025\n",
      "Epoch: 15/20... Training loss: 0.1006\n",
      "Epoch: 15/20... Training loss: 0.1069\n",
      "Epoch: 15/20... Training loss: 0.0996\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1014\n",
      "Epoch: 15/20... Training loss: 0.1023\n",
      "Epoch: 15/20... Training loss: 0.1021\n",
      "Epoch: 15/20... Training loss: 0.1006\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.1035\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1044\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.0990\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.1049\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1030\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1011\n",
      "Epoch: 15/20... Training loss: 0.1017\n",
      "Epoch: 15/20... Training loss: 0.1001\n",
      "Epoch: 15/20... Training loss: 0.1038\n",
      "Epoch: 15/20... Training loss: 0.1024\n",
      "Epoch: 15/20... Training loss: 0.1043\n",
      "Epoch: 15/20... Training loss: 0.1032\n",
      "Epoch: 15/20... Training loss: 0.1039\n",
      "Epoch: 15/20... Training loss: 0.1020\n",
      "Epoch: 15/20... Training loss: 0.1076\n",
      "Epoch: 15/20... Training loss: 0.0996\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.0995\n",
      "Epoch: 15/20... Training loss: 0.1026\n",
      "Epoch: 15/20... Training loss: 0.1041\n",
      "Epoch: 15/20... Training loss: 0.1045\n",
      "Epoch: 15/20... Training loss: 0.1048\n",
      "Epoch: 15/20... Training loss: 0.1051\n",
      "Epoch: 15/20... Training loss: 0.1047\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1029\n",
      "Epoch: 15/20... Training loss: 0.1048\n",
      "Epoch: 15/20... Training loss: 0.1027\n",
      "Epoch: 15/20... Training loss: 0.0986\n",
      "Epoch: 15/20... Training loss: 0.1012\n",
      "Epoch: 15/20... Training loss: 0.1022\n",
      "Epoch: 15/20... Training loss: 0.1019\n",
      "Epoch: 15/20... Training loss: 0.1015\n",
      "Epoch: 15/20... Training loss: 0.0997\n",
      "Epoch: 15/20... Training loss: 0.1046\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1069\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1066\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.0991\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.0995\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1041\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.0978\n",
      "Epoch: 16/20... Training loss: 0.1071\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1056\n",
      "Epoch: 16/20... Training loss: 0.1037\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.1054\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.0981\n",
      "Epoch: 16/20... Training loss: 0.1019\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1047\n",
      "Epoch: 16/20... Training loss: 0.1068\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.1048\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.1045\n",
      "Epoch: 16/20... Training loss: 0.1019\n",
      "Epoch: 16/20... Training loss: 0.1043\n",
      "Epoch: 16/20... Training loss: 0.1057\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.1087\n",
      "Epoch: 16/20... Training loss: 0.0986\n",
      "Epoch: 16/20... Training loss: 0.1068\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1017\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.1001\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1017\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.1045\n",
      "Epoch: 16/20... Training loss: 0.1043\n",
      "Epoch: 16/20... Training loss: 0.1040\n",
      "Epoch: 16/20... Training loss: 0.1004\n",
      "Epoch: 16/20... Training loss: 0.1008\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.1082\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1044\n",
      "Epoch: 16/20... Training loss: 0.0954\n",
      "Epoch: 16/20... Training loss: 0.0990\n",
      "Epoch: 16/20... Training loss: 0.1009\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.1009\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.1059\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.1043\n",
      "Epoch: 16/20... Training loss: 0.1037\n",
      "Epoch: 16/20... Training loss: 0.1057\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1064\n",
      "Epoch: 16/20... Training loss: 0.0979\n",
      "Epoch: 16/20... Training loss: 0.1008\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.1063\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1001\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1008\n",
      "Epoch: 16/20... Training loss: 0.1055\n",
      "Epoch: 16/20... Training loss: 0.1078\n",
      "Epoch: 16/20... Training loss: 0.1057\n",
      "Epoch: 16/20... Training loss: 0.1037\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.1011\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.1036\n",
      "Epoch: 16/20... Training loss: 0.0963\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.0994\n",
      "Epoch: 16/20... Training loss: 0.0971\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.1056\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.1014\n",
      "Epoch: 16/20... Training loss: 0.1019\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.1072\n",
      "Epoch: 16/20... Training loss: 0.1043\n",
      "Epoch: 16/20... Training loss: 0.1060\n",
      "Epoch: 16/20... Training loss: 0.1011\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1021\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.1054\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.0984\n",
      "Epoch: 16/20... Training loss: 0.1002\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1004\n",
      "Epoch: 16/20... Training loss: 0.1021\n",
      "Epoch: 16/20... Training loss: 0.1017\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1040\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1042\n",
      "Epoch: 16/20... Training loss: 0.1052\n",
      "Epoch: 16/20... Training loss: 0.0991\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1027\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.1027\n",
      "Epoch: 16/20... Training loss: 0.1023\n",
      "Epoch: 16/20... Training loss: 0.1008\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.1045\n",
      "Epoch: 16/20... Training loss: 0.1058\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.1033\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.1037\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.1004\n",
      "Epoch: 16/20... Training loss: 0.1070\n",
      "Epoch: 16/20... Training loss: 0.1029\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.0985\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.1070\n",
      "Epoch: 16/20... Training loss: 0.1047\n",
      "Epoch: 16/20... Training loss: 0.1043\n",
      "Epoch: 16/20... Training loss: 0.1060\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.1026\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1004\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.0992\n",
      "Epoch: 16/20... Training loss: 0.1031\n",
      "Epoch: 16/20... Training loss: 0.1040\n",
      "Epoch: 16/20... Training loss: 0.1046\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1000\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1028\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1052\n",
      "Epoch: 16/20... Training loss: 0.1034\n",
      "Epoch: 16/20... Training loss: 0.1069\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.0992\n",
      "Epoch: 16/20... Training loss: 0.0991\n",
      "Epoch: 16/20... Training loss: 0.1008\n",
      "Epoch: 16/20... Training loss: 0.1042\n",
      "Epoch: 16/20... Training loss: 0.1043\n",
      "Epoch: 16/20... Training loss: 0.1011\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1042\n",
      "Epoch: 16/20... Training loss: 0.1073\n",
      "Epoch: 16/20... Training loss: 0.0971\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.0969\n",
      "Epoch: 16/20... Training loss: 0.0996\n",
      "Epoch: 16/20... Training loss: 0.1010\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.0996\n",
      "Epoch: 16/20... Training loss: 0.1006\n",
      "Epoch: 16/20... Training loss: 0.0989\n",
      "Epoch: 16/20... Training loss: 0.1051\n",
      "Epoch: 16/20... Training loss: 0.1037\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.1050\n",
      "Epoch: 16/20... Training loss: 0.1008\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.0999\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1015\n",
      "Epoch: 16/20... Training loss: 0.1044\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.1027\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1011\n",
      "Epoch: 16/20... Training loss: 0.0997\n",
      "Epoch: 16/20... Training loss: 0.1069\n",
      "Epoch: 16/20... Training loss: 0.1022\n",
      "Epoch: 16/20... Training loss: 0.1045\n",
      "Epoch: 16/20... Training loss: 0.1008\n",
      "Epoch: 16/20... Training loss: 0.1020\n",
      "Epoch: 16/20... Training loss: 0.1058\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.0996\n",
      "Epoch: 16/20... Training loss: 0.1057\n",
      "Epoch: 16/20... Training loss: 0.1007\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.0998\n",
      "Epoch: 16/20... Training loss: 0.1057\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.0993\n",
      "Epoch: 16/20... Training loss: 0.1030\n",
      "Epoch: 16/20... Training loss: 0.1050\n",
      "Epoch: 16/20... Training loss: 0.0982\n",
      "Epoch: 16/20... Training loss: 0.1003\n",
      "Epoch: 16/20... Training loss: 0.1056\n",
      "Epoch: 16/20... Training loss: 0.1035\n",
      "Epoch: 16/20... Training loss: 0.1047\n",
      "Epoch: 16/20... Training loss: 0.1012\n",
      "Epoch: 16/20... Training loss: 0.1044\n",
      "Epoch: 16/20... Training loss: 0.1016\n",
      "Epoch: 16/20... Training loss: 0.0977\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1032\n",
      "Epoch: 16/20... Training loss: 0.0967\n",
      "Epoch: 16/20... Training loss: 0.1027\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1005\n",
      "Epoch: 16/20... Training loss: 0.1025\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.1027\n",
      "Epoch: 16/20... Training loss: 0.1038\n",
      "Epoch: 16/20... Training loss: 0.1033\n",
      "Epoch: 16/20... Training loss: 0.1046\n",
      "Epoch: 16/20... Training loss: 0.1018\n",
      "Epoch: 16/20... Training loss: 0.1024\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.0987\n",
      "Epoch: 16/20... Training loss: 0.0981\n",
      "Epoch: 16/20... Training loss: 0.1013\n",
      "Epoch: 16/20... Training loss: 0.1040\n",
      "Epoch: 16/20... Training loss: 0.1047\n",
      "Epoch: 16/20... Training loss: 0.1040\n",
      "Epoch: 16/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.0984\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.0973\n",
      "Epoch: 17/20... Training loss: 0.1029\n",
      "Epoch: 17/20... Training loss: 0.1039\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.0978\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.1078\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1063\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.1070\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.0973\n",
      "Epoch: 17/20... Training loss: 0.1029\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1033\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1055\n",
      "Epoch: 17/20... Training loss: 0.1052\n",
      "Epoch: 17/20... Training loss: 0.1043\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.0975\n",
      "Epoch: 17/20... Training loss: 0.1035\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.1050\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.1049\n",
      "Epoch: 17/20... Training loss: 0.1040\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.1047\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.0989\n",
      "Epoch: 17/20... Training loss: 0.1029\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.1045\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.0991\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.1028\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1047\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1069\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.0982\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.1034\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.1007\n",
      "Epoch: 17/20... Training loss: 0.0979\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1029\n",
      "Epoch: 17/20... Training loss: 0.1035\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1041\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.1028\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.0978\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.1032\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.1043\n",
      "Epoch: 17/20... Training loss: 0.1032\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1037\n",
      "Epoch: 17/20... Training loss: 0.1052\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.1040\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.1057\n",
      "Epoch: 17/20... Training loss: 0.1064\n",
      "Epoch: 17/20... Training loss: 0.1051\n",
      "Epoch: 17/20... Training loss: 0.0979\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1037\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.1023\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1025\n",
      "Epoch: 17/20... Training loss: 0.1032\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.0979\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.1064\n",
      "Epoch: 17/20... Training loss: 0.1049\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.1049\n",
      "Epoch: 17/20... Training loss: 0.0971\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.1043\n",
      "Epoch: 17/20... Training loss: 0.0996\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.1045\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.0992\n",
      "Epoch: 17/20... Training loss: 0.1023\n",
      "Epoch: 17/20... Training loss: 0.1028\n",
      "Epoch: 17/20... Training loss: 0.0989\n",
      "Epoch: 17/20... Training loss: 0.0995\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.1035\n",
      "Epoch: 17/20... Training loss: 0.1058\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.1038\n",
      "Epoch: 17/20... Training loss: 0.1039\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1034\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.0989\n",
      "Epoch: 17/20... Training loss: 0.1060\n",
      "Epoch: 17/20... Training loss: 0.1039\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.1004\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.0998\n",
      "Epoch: 17/20... Training loss: 0.1032\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.1021\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1042\n",
      "Epoch: 17/20... Training loss: 0.1050\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1037\n",
      "Epoch: 17/20... Training loss: 0.0986\n",
      "Epoch: 17/20... Training loss: 0.1033\n",
      "Epoch: 17/20... Training loss: 0.0959\n",
      "Epoch: 17/20... Training loss: 0.1015\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.1027\n",
      "Epoch: 17/20... Training loss: 0.0981\n",
      "Epoch: 17/20... Training loss: 0.1028\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1012\n",
      "Epoch: 17/20... Training loss: 0.1022\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.1059\n",
      "Epoch: 17/20... Training loss: 0.1048\n",
      "Epoch: 17/20... Training loss: 0.1031\n",
      "Epoch: 17/20... Training loss: 0.1005\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.1040\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.0985\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1001\n",
      "Epoch: 17/20... Training loss: 0.1026\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.0990\n",
      "Epoch: 17/20... Training loss: 0.0976\n",
      "Epoch: 17/20... Training loss: 0.1008\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1044\n",
      "Epoch: 17/20... Training loss: 0.0994\n",
      "Epoch: 17/20... Training loss: 0.1039\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.1032\n",
      "Epoch: 17/20... Training loss: 0.0993\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1003\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.0989\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.1030\n",
      "Epoch: 17/20... Training loss: 0.1016\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.1006\n",
      "Epoch: 17/20... Training loss: 0.1027\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1014\n",
      "Epoch: 17/20... Training loss: 0.1010\n",
      "Epoch: 17/20... Training loss: 0.1036\n",
      "Epoch: 17/20... Training loss: 0.1063\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.1064\n",
      "Epoch: 17/20... Training loss: 0.1034\n",
      "Epoch: 17/20... Training loss: 0.1029\n",
      "Epoch: 17/20... Training loss: 0.0977\n",
      "Epoch: 17/20... Training loss: 0.1023\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.1023\n",
      "Epoch: 17/20... Training loss: 0.1032\n",
      "Epoch: 17/20... Training loss: 0.1000\n",
      "Epoch: 17/20... Training loss: 0.1023\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.1043\n",
      "Epoch: 17/20... Training loss: 0.1018\n",
      "Epoch: 17/20... Training loss: 0.0997\n",
      "Epoch: 17/20... Training loss: 0.0978\n",
      "Epoch: 17/20... Training loss: 0.1002\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.1009\n",
      "Epoch: 17/20... Training loss: 0.1020\n",
      "Epoch: 17/20... Training loss: 0.0988\n",
      "Epoch: 17/20... Training loss: 0.1017\n",
      "Epoch: 17/20... Training loss: 0.1019\n",
      "Epoch: 17/20... Training loss: 0.1024\n",
      "Epoch: 17/20... Training loss: 0.0999\n",
      "Epoch: 17/20... Training loss: 0.1013\n",
      "Epoch: 17/20... Training loss: 0.1033\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 17/20... Training loss: 0.1034\n",
      "Epoch: 17/20... Training loss: 0.1011\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1068\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.0984\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.1011\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.1041\n",
      "Epoch: 18/20... Training loss: 0.1031\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.1027\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1052\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1022\n",
      "Epoch: 18/20... Training loss: 0.1007\n",
      "Epoch: 18/20... Training loss: 0.1038\n",
      "Epoch: 18/20... Training loss: 0.0983\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.1043\n",
      "Epoch: 18/20... Training loss: 0.1011\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.0981\n",
      "Epoch: 18/20... Training loss: 0.0971\n",
      "Epoch: 18/20... Training loss: 0.1044\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1065\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1046\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.1038\n",
      "Epoch: 18/20... Training loss: 0.1029\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1046\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.1011\n",
      "Epoch: 18/20... Training loss: 0.0985\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.1022\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.1030\n",
      "Epoch: 18/20... Training loss: 0.1046\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1024\n",
      "Epoch: 18/20... Training loss: 0.1050\n",
      "Epoch: 18/20... Training loss: 0.1044\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.1016\n",
      "Epoch: 18/20... Training loss: 0.0985\n",
      "Epoch: 18/20... Training loss: 0.1023\n",
      "Epoch: 18/20... Training loss: 0.0980\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1023\n",
      "Epoch: 18/20... Training loss: 0.1000\n",
      "Epoch: 18/20... Training loss: 0.1027\n",
      "Epoch: 18/20... Training loss: 0.0985\n",
      "Epoch: 18/20... Training loss: 0.1031\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.1056\n",
      "Epoch: 18/20... Training loss: 0.1003\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1030\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1035\n",
      "Epoch: 18/20... Training loss: 0.1007\n",
      "Epoch: 18/20... Training loss: 0.0961\n",
      "Epoch: 18/20... Training loss: 0.0990\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1037\n",
      "Epoch: 18/20... Training loss: 0.1022\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1031\n",
      "Epoch: 18/20... Training loss: 0.0974\n",
      "Epoch: 18/20... Training loss: 0.1013\n",
      "Epoch: 18/20... Training loss: 0.1023\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.1022\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.1050\n",
      "Epoch: 18/20... Training loss: 0.1011\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1052\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1046\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.0956\n",
      "Epoch: 18/20... Training loss: 0.1013\n",
      "Epoch: 18/20... Training loss: 0.1046\n",
      "Epoch: 18/20... Training loss: 0.0951\n",
      "Epoch: 18/20... Training loss: 0.0987\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1039\n",
      "Epoch: 18/20... Training loss: 0.0981\n",
      "Epoch: 18/20... Training loss: 0.0979\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.0970\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1016\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1068\n",
      "Epoch: 18/20... Training loss: 0.1057\n",
      "Epoch: 18/20... Training loss: 0.1040\n",
      "Epoch: 18/20... Training loss: 0.0986\n",
      "Epoch: 18/20... Training loss: 0.0994\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.0973\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1013\n",
      "Epoch: 18/20... Training loss: 0.1024\n",
      "Epoch: 18/20... Training loss: 0.0982\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.1016\n",
      "Epoch: 18/20... Training loss: 0.0997\n",
      "Epoch: 18/20... Training loss: 0.1039\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.1016\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.1040\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.0970\n",
      "Epoch: 18/20... Training loss: 0.0969\n",
      "Epoch: 18/20... Training loss: 0.1033\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1008\n",
      "Epoch: 18/20... Training loss: 0.1003\n",
      "Epoch: 18/20... Training loss: 0.1007\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1022\n",
      "Epoch: 18/20... Training loss: 0.0989\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.1038\n",
      "Epoch: 18/20... Training loss: 0.0990\n",
      "Epoch: 18/20... Training loss: 0.1007\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.0986\n",
      "Epoch: 18/20... Training loss: 0.1013\n",
      "Epoch: 18/20... Training loss: 0.1013\n",
      "Epoch: 18/20... Training loss: 0.0981\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.1003\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.1043\n",
      "Epoch: 18/20... Training loss: 0.1019\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.1013\n",
      "Epoch: 18/20... Training loss: 0.1025\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1010\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.1007\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 18/20... Training loss: 0.1027\n",
      "Epoch: 18/20... Training loss: 0.0992\n",
      "Epoch: 18/20... Training loss: 0.1018\n",
      "Epoch: 18/20... Training loss: 0.0968\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.0960\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.1036\n",
      "Epoch: 18/20... Training loss: 0.0989\n",
      "Epoch: 18/20... Training loss: 0.1040\n",
      "Epoch: 18/20... Training loss: 0.0995\n",
      "Epoch: 18/20... Training loss: 0.1047\n",
      "Epoch: 18/20... Training loss: 0.0981\n",
      "Epoch: 18/20... Training loss: 0.1002\n",
      "Epoch: 18/20... Training loss: 0.0993\n",
      "Epoch: 18/20... Training loss: 0.0986\n",
      "Epoch: 18/20... Training loss: 0.0986\n",
      "Epoch: 18/20... Training loss: 0.1032\n",
      "Epoch: 18/20... Training loss: 0.1007\n",
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.0985\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.1038\n",
      "Epoch: 18/20... Training loss: 0.0999\n",
      "Epoch: 18/20... Training loss: 0.1012\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.1065\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.0990\n",
      "Epoch: 18/20... Training loss: 0.1029\n",
      "Epoch: 18/20... Training loss: 0.0939\n",
      "Epoch: 18/20... Training loss: 0.1015\n",
      "Epoch: 18/20... Training loss: 0.1051\n",
      "Epoch: 18/20... Training loss: 0.1006\n",
      "Epoch: 18/20... Training loss: 0.0998\n",
      "Epoch: 18/20... Training loss: 0.1034\n",
      "Epoch: 18/20... Training loss: 0.0996\n",
      "Epoch: 18/20... Training loss: 0.1026\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.0967\n",
      "Epoch: 18/20... Training loss: 0.1014\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.1005\n",
      "Epoch: 18/20... Training loss: 0.1028\n",
      "Epoch: 18/20... Training loss: 0.1038\n",
      "Epoch: 18/20... Training loss: 0.1047\n",
      "Epoch: 18/20... Training loss: 0.1009\n",
      "Epoch: 18/20... Training loss: 0.0977\n",
      "Epoch: 18/20... Training loss: 0.1020\n",
      "Epoch: 18/20... Training loss: 0.1042\n",
      "Epoch: 18/20... Training loss: 0.0947\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.0954\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.1011\n",
      "Epoch: 18/20... Training loss: 0.1013\n",
      "Epoch: 18/20... Training loss: 0.1017\n",
      "Epoch: 18/20... Training loss: 0.1029\n",
      "Epoch: 18/20... Training loss: 0.1052\n",
      "Epoch: 18/20... Training loss: 0.0991\n",
      "Epoch: 18/20... Training loss: 0.1021\n",
      "Epoch: 18/20... Training loss: 0.1001\n",
      "Epoch: 18/20... Training loss: 0.0985\n",
      "Epoch: 18/20... Training loss: 0.0988\n",
      "Epoch: 18/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.0975\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.1038\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.1046\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.1006\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.0982\n",
      "Epoch: 19/20... Training loss: 0.1046\n",
      "Epoch: 19/20... Training loss: 0.0994\n",
      "Epoch: 19/20... Training loss: 0.1048\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.1058\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.1048\n",
      "Epoch: 19/20... Training loss: 0.1034\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.0989\n",
      "Epoch: 19/20... Training loss: 0.1049\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.1038\n",
      "Epoch: 19/20... Training loss: 0.1016\n",
      "Epoch: 19/20... Training loss: 0.1032\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.1037\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.1024\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1031\n",
      "Epoch: 19/20... Training loss: 0.0967\n",
      "Epoch: 19/20... Training loss: 0.1043\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1007\n",
      "Epoch: 19/20... Training loss: 0.1026\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.1023\n",
      "Epoch: 19/20... Training loss: 0.1039\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.1060\n",
      "Epoch: 19/20... Training loss: 0.1043\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 19/20... Training loss: 0.0982\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1033\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.1033\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.1037\n",
      "Epoch: 19/20... Training loss: 0.1020\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1027\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.1016\n",
      "Epoch: 19/20... Training loss: 0.0979\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.1031\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.1026\n",
      "Epoch: 19/20... Training loss: 0.1055\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1040\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.1055\n",
      "Epoch: 19/20... Training loss: 0.1041\n",
      "Epoch: 19/20... Training loss: 0.1007\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.1020\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.1040\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.1041\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0958\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1027\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.1026\n",
      "Epoch: 19/20... Training loss: 0.1008\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1006\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1032\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.0994\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1033\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.1001\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.0984\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1046\n",
      "Epoch: 19/20... Training loss: 0.0962\n",
      "Epoch: 19/20... Training loss: 0.1027\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.1054\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.1016\n",
      "Epoch: 19/20... Training loss: 0.1049\n",
      "Epoch: 19/20... Training loss: 0.1076\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1075\n",
      "Epoch: 19/20... Training loss: 0.1041\n",
      "Epoch: 19/20... Training loss: 0.0983\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.1036\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.1048\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.0976\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.1049\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0984\n",
      "Epoch: 19/20... Training loss: 0.0992\n",
      "Epoch: 19/20... Training loss: 0.1022\n",
      "Epoch: 19/20... Training loss: 0.1023\n",
      "Epoch: 19/20... Training loss: 0.1052\n",
      "Epoch: 19/20... Training loss: 0.1007\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1017\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.1006\n",
      "Epoch: 19/20... Training loss: 0.1057\n",
      "Epoch: 19/20... Training loss: 0.1040\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.0989\n",
      "Epoch: 19/20... Training loss: 0.1015\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.0969\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.1039\n",
      "Epoch: 19/20... Training loss: 0.1023\n",
      "Epoch: 19/20... Training loss: 0.0990\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.1029\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.0985\n",
      "Epoch: 19/20... Training loss: 0.1010\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1017\n",
      "Epoch: 19/20... Training loss: 0.1019\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.1039\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.0944\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.0980\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.0989\n",
      "Epoch: 19/20... Training loss: 0.1022\n",
      "Epoch: 19/20... Training loss: 0.1043\n",
      "Epoch: 19/20... Training loss: 0.1023\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.1018\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.1034\n",
      "Epoch: 19/20... Training loss: 0.1016\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.1030\n",
      "Epoch: 19/20... Training loss: 0.1033\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1038\n",
      "Epoch: 19/20... Training loss: 0.1022\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.1046\n",
      "Epoch: 19/20... Training loss: 0.1053\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.0989\n",
      "Epoch: 19/20... Training loss: 0.1027\n",
      "Epoch: 19/20... Training loss: 0.0973\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1011\n",
      "Epoch: 19/20... Training loss: 0.0989\n",
      "Epoch: 19/20... Training loss: 0.1046\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.0976\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.1007\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.0977\n",
      "Epoch: 19/20... Training loss: 0.1008\n",
      "Epoch: 19/20... Training loss: 0.1014\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.0987\n",
      "Epoch: 19/20... Training loss: 0.1028\n",
      "Epoch: 19/20... Training loss: 0.1021\n",
      "Epoch: 19/20... Training loss: 0.1009\n",
      "Epoch: 19/20... Training loss: 0.1038\n",
      "Epoch: 19/20... Training loss: 0.1025\n",
      "Epoch: 19/20... Training loss: 0.0995\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.0986\n",
      "Epoch: 19/20... Training loss: 0.1013\n",
      "Epoch: 19/20... Training loss: 0.1034\n",
      "Epoch: 19/20... Training loss: 0.1012\n",
      "Epoch: 19/20... Training loss: 0.0981\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.0992\n",
      "Epoch: 19/20... Training loss: 0.1005\n",
      "Epoch: 19/20... Training loss: 0.1027\n",
      "Epoch: 19/20... Training loss: 0.1020\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.0997\n",
      "Epoch: 19/20... Training loss: 0.0988\n",
      "Epoch: 19/20... Training loss: 0.0998\n",
      "Epoch: 19/20... Training loss: 0.1004\n",
      "Epoch: 19/20... Training loss: 0.1024\n",
      "Epoch: 19/20... Training loss: 0.1022\n",
      "Epoch: 19/20... Training loss: 0.1020\n",
      "Epoch: 19/20... Training loss: 0.0967\n",
      "Epoch: 19/20... Training loss: 0.1007\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 19/20... Training loss: 0.0966\n",
      "Epoch: 19/20... Training loss: 0.1034\n",
      "Epoch: 19/20... Training loss: 0.0967\n",
      "Epoch: 19/20... Training loss: 0.0960\n",
      "Epoch: 19/20... Training loss: 0.0970\n",
      "Epoch: 19/20... Training loss: 0.0974\n",
      "Epoch: 19/20... Training loss: 0.1002\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.1000\n",
      "Epoch: 19/20... Training loss: 0.1003\n",
      "Epoch: 19/20... Training loss: 0.0991\n",
      "Epoch: 19/20... Training loss: 0.0971\n",
      "Epoch: 19/20... Training loss: 0.0996\n",
      "Epoch: 19/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.0979\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.1033\n",
      "Epoch: 20/20... Training loss: 0.1052\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.0961\n",
      "Epoch: 20/20... Training loss: 0.0969\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1019\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.1003\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.1034\n",
      "Epoch: 20/20... Training loss: 0.0954\n",
      "Epoch: 20/20... Training loss: 0.1046\n",
      "Epoch: 20/20... Training loss: 0.1057\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0997\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1024\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.1038\n",
      "Epoch: 20/20... Training loss: 0.1048\n",
      "Epoch: 20/20... Training loss: 0.1056\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.1021\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.1018\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.1018\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.1036\n",
      "Epoch: 20/20... Training loss: 0.1064\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.1019\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.1032\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.1000\n",
      "Epoch: 20/20... Training loss: 0.0943\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.1035\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.1068\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.1029\n",
      "Epoch: 20/20... Training loss: 0.1029\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.0997\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.1065\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.1015\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.0966\n",
      "Epoch: 20/20... Training loss: 0.1065\n",
      "Epoch: 20/20... Training loss: 0.1047\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.1084\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.0997\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.0997\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.1031\n",
      "Epoch: 20/20... Training loss: 0.1019\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.1047\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.1014\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.1003\n",
      "Epoch: 20/20... Training loss: 0.1035\n",
      "Epoch: 20/20... Training loss: 0.1047\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.1035\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1022\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.1020\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.1029\n",
      "Epoch: 20/20... Training loss: 0.1029\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.1027\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.0963\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.1003\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.1024\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.1023\n",
      "Epoch: 20/20... Training loss: 0.1000\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.1019\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.1033\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.1020\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0974\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.1003\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.0983\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.1000\n",
      "Epoch: 20/20... Training loss: 0.0989\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.1009\n",
      "Epoch: 20/20... Training loss: 0.0979\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.0970\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.0994\n",
      "Epoch: 20/20... Training loss: 0.0965\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.0986\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.0941\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.1048\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.1018\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1039\n",
      "Epoch: 20/20... Training loss: 0.1004\n",
      "Epoch: 20/20... Training loss: 0.1011\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.0995\n",
      "Epoch: 20/20... Training loss: 0.0980\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.1000\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1027\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.1018\n",
      "Epoch: 20/20... Training loss: 0.1019\n",
      "Epoch: 20/20... Training loss: 0.1056\n",
      "Epoch: 20/20... Training loss: 0.1045\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.0990\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.0973\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.1001\n",
      "Epoch: 20/20... Training loss: 0.1025\n",
      "Epoch: 20/20... Training loss: 0.0975\n",
      "Epoch: 20/20... Training loss: 0.1017\n",
      "Epoch: 20/20... Training loss: 0.0968\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.0992\n",
      "Epoch: 20/20... Training loss: 0.1015\n",
      "Epoch: 20/20... Training loss: 0.1028\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.1034\n",
      "Epoch: 20/20... Training loss: 0.0984\n",
      "Epoch: 20/20... Training loss: 0.1020\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.0980\n",
      "Epoch: 20/20... Training loss: 0.1015\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.1034\n",
      "Epoch: 20/20... Training loss: 0.1003\n",
      "Epoch: 20/20... Training loss: 0.0988\n",
      "Epoch: 20/20... Training loss: 0.1051\n",
      "Epoch: 20/20... Training loss: 0.1008\n",
      "Epoch: 20/20... Training loss: 0.1010\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.1027\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1026\n",
      "Epoch: 20/20... Training loss: 0.1003\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.1023\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.0978\n",
      "Epoch: 20/20... Training loss: 0.1013\n",
      "Epoch: 20/20... Training loss: 0.0987\n",
      "Epoch: 20/20... Training loss: 0.1002\n",
      "Epoch: 20/20... Training loss: 0.0981\n",
      "Epoch: 20/20... Training loss: 0.1031\n",
      "Epoch: 20/20... Training loss: 0.0982\n",
      "Epoch: 20/20... Training loss: 0.0972\n",
      "Epoch: 20/20... Training loss: 0.0993\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.0985\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.1006\n",
      "Epoch: 20/20... Training loss: 0.1016\n",
      "Epoch: 20/20... Training loss: 0.0976\n",
      "Epoch: 20/20... Training loss: 0.0998\n",
      "Epoch: 20/20... Training loss: 0.0996\n",
      "Epoch: 20/20... Training loss: 0.0971\n",
      "Epoch: 20/20... Training loss: 0.0991\n",
      "Epoch: 20/20... Training loss: 0.0977\n",
      "Epoch: 20/20... Training loss: 0.1020\n",
      "Epoch: 20/20... Training loss: 0.1007\n",
      "Epoch: 20/20... Training loss: 0.1005\n",
      "Epoch: 20/20... Training loss: 0.1012\n",
      "Epoch: 20/20... Training loss: 0.0967\n",
      "Epoch: 20/20... Training loss: 0.0999\n",
      "Epoch: 20/20... Training loss: 0.1019\n",
      "Epoch: 20/20... Training loss: 0.0992\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 200\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAEsCAYAAAAvofT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n7KL7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f83965a7dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: in_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([in_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "inputs_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='inputs')\n",
    "targets_ = tf.placeholder(tf.float32, (None, 28, 28, 1), name='targets')\n",
    "\n",
    "### Encoder\n",
    "conv1 = tf.layers.conv2d(inputs_, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "maxpool1 = tf.layers.max_pooling2d(conv1, (2,2), (2,2), padding='same')\n",
    "\n",
    "conv2 = tf.layers.conv2d(maxpool1, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "maxpool2 = tf.layers.max_pooling2d(conv2, (2,2), (2,2), padding='same')\n",
    "\n",
    "conv3 = tf.layers.conv2d(maxpool2, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "encoded = tf.layers.max_pooling2d(conv3, (2,2), (2,2), padding='same')\n",
    "\n",
    "\n",
    "### Decoder\n",
    "upsample1 = tf.image.resize_nearest_neighbor(encoded, (7,7))\n",
    "\n",
    "conv4 = tf.layers.conv2d(upsample1, 16, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "upsample2 = tf.image.resize_nearest_neighbor(conv4, (14,14))\n",
    "\n",
    "conv5 = tf.layers.conv2d(upsample2, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "upsample3 = tf.image.resize_nearest_neighbor(conv5, (28,28))\n",
    "\n",
    "conv6 = tf.layers.conv2d(upsample3, 32, (3,3), padding='same', activation=tf.nn.relu)\n",
    "\n",
    "logits = tf.layers.conv2d(conv6, 1, (3,3), padding='same', activation=None)\n",
    "\n",
    "decoded = tf.nn.sigmoid(logits, name='decoded')\n",
    "\n",
    "loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=targets_, logits=logits)\n",
    "cost = tf.reduce_mean(loss)\n",
    "opt = tf.train.AdamOptimizer(0.001).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/100... Training loss: 0.7070\n",
      "Epoch: 1/100... Training loss: 0.6916\n",
      "Epoch: 1/100... Training loss: 0.6808\n",
      "Epoch: 1/100... Training loss: 0.6652\n",
      "Epoch: 1/100... Training loss: 0.6448\n",
      "Epoch: 1/100... Training loss: 0.6135\n",
      "Epoch: 1/100... Training loss: 0.5756\n",
      "Epoch: 1/100... Training loss: 0.5373\n",
      "Epoch: 1/100... Training loss: 0.4969\n",
      "Epoch: 1/100... Training loss: 0.4903\n",
      "Epoch: 1/100... Training loss: 0.5216\n",
      "Epoch: 1/100... Training loss: 0.5246\n",
      "Epoch: 1/100... Training loss: 0.5069\n",
      "Epoch: 1/100... Training loss: 0.4915\n",
      "Epoch: 1/100... Training loss: 0.4751\n",
      "Epoch: 1/100... Training loss: 0.4709\n",
      "Epoch: 1/100... Training loss: 0.4757\n",
      "Epoch: 1/100... Training loss: 0.4644\n",
      "Epoch: 1/100... Training loss: 0.4638\n",
      "Epoch: 1/100... Training loss: 0.4564\n",
      "Epoch: 1/100... Training loss: 0.4444\n",
      "Epoch: 1/100... Training loss: 0.4443\n",
      "Epoch: 1/100... Training loss: 0.4360\n",
      "Epoch: 1/100... Training loss: 0.4358\n",
      "Epoch: 1/100... Training loss: 0.4107\n",
      "Epoch: 1/100... Training loss: 0.4101\n",
      "Epoch: 1/100... Training loss: 0.3933\n",
      "Epoch: 1/100... Training loss: 0.3852\n",
      "Epoch: 1/100... Training loss: 0.3717\n",
      "Epoch: 1/100... Training loss: 0.3563\n",
      "Epoch: 1/100... Training loss: 0.3465\n",
      "Epoch: 1/100... Training loss: 0.3421\n",
      "Epoch: 1/100... Training loss: 0.3322\n",
      "Epoch: 1/100... Training loss: 0.3246\n",
      "Epoch: 1/100... Training loss: 0.3130\n",
      "Epoch: 1/100... Training loss: 0.3078\n",
      "Epoch: 1/100... Training loss: 0.3101\n",
      "Epoch: 1/100... Training loss: 0.3030\n",
      "Epoch: 1/100... Training loss: 0.2903\n",
      "Epoch: 1/100... Training loss: 0.3006\n",
      "Epoch: 1/100... Training loss: 0.2865\n",
      "Epoch: 1/100... Training loss: 0.2828\n",
      "Epoch: 1/100... Training loss: 0.2912\n",
      "Epoch: 1/100... Training loss: 0.2814\n",
      "Epoch: 1/100... Training loss: 0.2746\n",
      "Epoch: 1/100... Training loss: 0.2701\n",
      "Epoch: 1/100... Training loss: 0.2665\n",
      "Epoch: 1/100... Training loss: 0.2747\n",
      "Epoch: 1/100... Training loss: 0.2705\n",
      "Epoch: 1/100... Training loss: 0.2726\n",
      "Epoch: 1/100... Training loss: 0.2672\n",
      "Epoch: 1/100... Training loss: 0.2579\n",
      "Epoch: 1/100... Training loss: 0.2625\n",
      "Epoch: 1/100... Training loss: 0.2612\n",
      "Epoch: 1/100... Training loss: 0.2695\n",
      "Epoch: 1/100... Training loss: 0.2511\n",
      "Epoch: 1/100... Training loss: 0.2667\n",
      "Epoch: 1/100... Training loss: 0.2521\n",
      "Epoch: 1/100... Training loss: 0.2638\n",
      "Epoch: 1/100... Training loss: 0.2531\n",
      "Epoch: 1/100... Training loss: 0.2516\n",
      "Epoch: 1/100... Training loss: 0.2560\n",
      "Epoch: 1/100... Training loss: 0.2542\n",
      "Epoch: 1/100... Training loss: 0.2524\n",
      "Epoch: 1/100... Training loss: 0.2470\n",
      "Epoch: 1/100... Training loss: 0.2498\n",
      "Epoch: 1/100... Training loss: 0.2454\n",
      "Epoch: 1/100... Training loss: 0.2465\n",
      "Epoch: 1/100... Training loss: 0.2467\n",
      "Epoch: 1/100... Training loss: 0.2387\n",
      "Epoch: 1/100... Training loss: 0.2463\n",
      "Epoch: 1/100... Training loss: 0.2408\n",
      "Epoch: 1/100... Training loss: 0.2472\n",
      "Epoch: 1/100... Training loss: 0.2439\n",
      "Epoch: 1/100... Training loss: 0.2364\n",
      "Epoch: 1/100... Training loss: 0.2496\n",
      "Epoch: 1/100... Training loss: 0.2444\n",
      "Epoch: 1/100... Training loss: 0.2438\n",
      "Epoch: 1/100... Training loss: 0.2372\n",
      "Epoch: 1/100... Training loss: 0.2369\n",
      "Epoch: 1/100... Training loss: 0.2308\n",
      "Epoch: 1/100... Training loss: 0.2395\n",
      "Epoch: 1/100... Training loss: 0.2333\n",
      "Epoch: 1/100... Training loss: 0.2364\n",
      "Epoch: 1/100... Training loss: 0.2339\n",
      "Epoch: 1/100... Training loss: 0.2326\n",
      "Epoch: 1/100... Training loss: 0.2333\n",
      "Epoch: 1/100... Training loss: 0.2266\n",
      "Epoch: 1/100... Training loss: 0.2272\n",
      "Epoch: 1/100... Training loss: 0.2317\n",
      "Epoch: 1/100... Training loss: 0.2268\n",
      "Epoch: 1/100... Training loss: 0.2356\n",
      "Epoch: 1/100... Training loss: 0.2234\n",
      "Epoch: 1/100... Training loss: 0.2324\n",
      "Epoch: 1/100... Training loss: 0.2289\n",
      "Epoch: 1/100... Training loss: 0.2271\n",
      "Epoch: 1/100... Training loss: 0.2308\n",
      "Epoch: 1/100... Training loss: 0.2243\n",
      "Epoch: 1/100... Training loss: 0.2264\n",
      "Epoch: 1/100... Training loss: 0.2241\n",
      "Epoch: 1/100... Training loss: 0.2214\n",
      "Epoch: 1/100... Training loss: 0.2262\n",
      "Epoch: 1/100... Training loss: 0.2245\n",
      "Epoch: 1/100... Training loss: 0.2265\n",
      "Epoch: 1/100... Training loss: 0.2208\n",
      "Epoch: 1/100... Training loss: 0.2302\n",
      "Epoch: 1/100... Training loss: 0.2256\n",
      "Epoch: 1/100... Training loss: 0.2273\n",
      "Epoch: 1/100... Training loss: 0.2243\n",
      "Epoch: 1/100... Training loss: 0.2264\n",
      "Epoch: 1/100... Training loss: 0.2240\n",
      "Epoch: 1/100... Training loss: 0.2242\n",
      "Epoch: 1/100... Training loss: 0.2186\n",
      "Epoch: 1/100... Training loss: 0.2226\n",
      "Epoch: 1/100... Training loss: 0.2224\n",
      "Epoch: 1/100... Training loss: 0.2231\n",
      "Epoch: 1/100... Training loss: 0.2161\n",
      "Epoch: 1/100... Training loss: 0.2184\n",
      "Epoch: 1/100... Training loss: 0.2185\n",
      "Epoch: 1/100... Training loss: 0.2228\n",
      "Epoch: 1/100... Training loss: 0.2240\n",
      "Epoch: 1/100... Training loss: 0.2224\n",
      "Epoch: 1/100... Training loss: 0.2206\n",
      "Epoch: 1/100... Training loss: 0.2152\n",
      "Epoch: 1/100... Training loss: 0.2227\n",
      "Epoch: 1/100... Training loss: 0.2151\n",
      "Epoch: 1/100... Training loss: 0.2167\n",
      "Epoch: 1/100... Training loss: 0.2191\n",
      "Epoch: 1/100... Training loss: 0.2190\n",
      "Epoch: 1/100... Training loss: 0.2234\n",
      "Epoch: 1/100... Training loss: 0.2107\n",
      "Epoch: 1/100... Training loss: 0.2185\n",
      "Epoch: 1/100... Training loss: 0.2146\n",
      "Epoch: 1/100... Training loss: 0.2153\n",
      "Epoch: 1/100... Training loss: 0.2088\n",
      "Epoch: 1/100... Training loss: 0.2164\n",
      "Epoch: 1/100... Training loss: 0.2119\n",
      "Epoch: 1/100... Training loss: 0.2153\n",
      "Epoch: 1/100... Training loss: 0.2169\n",
      "Epoch: 1/100... Training loss: 0.2112\n",
      "Epoch: 1/100... Training loss: 0.2094\n",
      "Epoch: 1/100... Training loss: 0.2124\n",
      "Epoch: 1/100... Training loss: 0.2100\n",
      "Epoch: 1/100... Training loss: 0.2126\n",
      "Epoch: 1/100... Training loss: 0.2082\n",
      "Epoch: 1/100... Training loss: 0.2153\n",
      "Epoch: 1/100... Training loss: 0.2129\n",
      "Epoch: 1/100... Training loss: 0.2101\n",
      "Epoch: 1/100... Training loss: 0.2086\n",
      "Epoch: 1/100... Training loss: 0.2122\n",
      "Epoch: 1/100... Training loss: 0.2148\n",
      "Epoch: 1/100... Training loss: 0.2131\n",
      "Epoch: 1/100... Training loss: 0.2073\n",
      "Epoch: 1/100... Training loss: 0.2071\n",
      "Epoch: 1/100... Training loss: 0.2070\n",
      "Epoch: 1/100... Training loss: 0.2119\n",
      "Epoch: 1/100... Training loss: 0.2073\n",
      "Epoch: 1/100... Training loss: 0.2080\n",
      "Epoch: 1/100... Training loss: 0.2110\n",
      "Epoch: 1/100... Training loss: 0.2114\n",
      "Epoch: 1/100... Training loss: 0.2119\n",
      "Epoch: 1/100... Training loss: 0.2049\n",
      "Epoch: 1/100... Training loss: 0.2123\n",
      "Epoch: 1/100... Training loss: 0.2089\n",
      "Epoch: 1/100... Training loss: 0.2055\n",
      "Epoch: 1/100... Training loss: 0.2078\n",
      "Epoch: 1/100... Training loss: 0.2092\n",
      "Epoch: 1/100... Training loss: 0.2054\n",
      "Epoch: 1/100... Training loss: 0.2118\n",
      "Epoch: 1/100... Training loss: 0.2069\n",
      "Epoch: 1/100... Training loss: 0.2056\n",
      "Epoch: 1/100... Training loss: 0.1996\n",
      "Epoch: 1/100... Training loss: 0.2038\n",
      "Epoch: 1/100... Training loss: 0.2030\n",
      "Epoch: 1/100... Training loss: 0.1988\n",
      "Epoch: 1/100... Training loss: 0.2060\n",
      "Epoch: 1/100... Training loss: 0.2013\n",
      "Epoch: 1/100... Training loss: 0.2050\n",
      "Epoch: 1/100... Training loss: 0.1973\n",
      "Epoch: 1/100... Training loss: 0.1998\n",
      "Epoch: 1/100... Training loss: 0.2033\n",
      "Epoch: 1/100... Training loss: 0.2040\n",
      "Epoch: 1/100... Training loss: 0.2030\n",
      "Epoch: 1/100... Training loss: 0.1970\n",
      "Epoch: 1/100... Training loss: 0.2021\n",
      "Epoch: 1/100... Training loss: 0.2022\n",
      "Epoch: 1/100... Training loss: 0.2059\n",
      "Epoch: 1/100... Training loss: 0.2008\n",
      "Epoch: 1/100... Training loss: 0.2033\n",
      "Epoch: 1/100... Training loss: 0.2004\n",
      "Epoch: 1/100... Training loss: 0.1968\n",
      "Epoch: 1/100... Training loss: 0.1941\n",
      "Epoch: 1/100... Training loss: 0.2007\n",
      "Epoch: 1/100... Training loss: 0.1996\n",
      "Epoch: 1/100... Training loss: 0.1993\n",
      "Epoch: 1/100... Training loss: 0.1932\n",
      "Epoch: 1/100... Training loss: 0.1983\n",
      "Epoch: 1/100... Training loss: 0.1986\n",
      "Epoch: 1/100... Training loss: 0.1966\n",
      "Epoch: 1/100... Training loss: 0.1938\n",
      "Epoch: 1/100... Training loss: 0.1945\n",
      "Epoch: 1/100... Training loss: 0.1979\n",
      "Epoch: 1/100... Training loss: 0.1983\n",
      "Epoch: 1/100... Training loss: 0.1948\n",
      "Epoch: 1/100... Training loss: 0.1949\n",
      "Epoch: 1/100... Training loss: 0.1942\n",
      "Epoch: 1/100... Training loss: 0.1958\n",
      "Epoch: 1/100... Training loss: 0.1892\n",
      "Epoch: 1/100... Training loss: 0.1914\n",
      "Epoch: 1/100... Training loss: 0.1899\n",
      "Epoch: 1/100... Training loss: 0.1918\n",
      "Epoch: 1/100... Training loss: 0.1993\n",
      "Epoch: 1/100... Training loss: 0.1938\n",
      "Epoch: 1/100... Training loss: 0.1954\n",
      "Epoch: 1/100... Training loss: 0.1930\n",
      "Epoch: 1/100... Training loss: 0.1956\n",
      "Epoch: 1/100... Training loss: 0.1912\n",
      "Epoch: 1/100... Training loss: 0.1884\n",
      "Epoch: 1/100... Training loss: 0.1909\n",
      "Epoch: 1/100... Training loss: 0.1968\n",
      "Epoch: 1/100... Training loss: 0.1888\n",
      "Epoch: 1/100... Training loss: 0.1913\n",
      "Epoch: 1/100... Training loss: 0.1938\n",
      "Epoch: 1/100... Training loss: 0.1945\n",
      "Epoch: 1/100... Training loss: 0.1874\n",
      "Epoch: 1/100... Training loss: 0.1998\n",
      "Epoch: 1/100... Training loss: 0.1899\n",
      "Epoch: 1/100... Training loss: 0.1924\n",
      "Epoch: 1/100... Training loss: 0.1891\n",
      "Epoch: 1/100... Training loss: 0.1892\n",
      "Epoch: 1/100... Training loss: 0.1855\n",
      "Epoch: 1/100... Training loss: 0.1920\n",
      "Epoch: 1/100... Training loss: 0.1931\n",
      "Epoch: 1/100... Training loss: 0.1909\n",
      "Epoch: 1/100... Training loss: 0.1934\n",
      "Epoch: 1/100... Training loss: 0.1974\n",
      "Epoch: 1/100... Training loss: 0.1859\n",
      "Epoch: 1/100... Training loss: 0.1920\n",
      "Epoch: 1/100... Training loss: 0.1898\n",
      "Epoch: 1/100... Training loss: 0.1879\n",
      "Epoch: 1/100... Training loss: 0.1872\n",
      "Epoch: 1/100... Training loss: 0.1897\n",
      "Epoch: 1/100... Training loss: 0.1814\n",
      "Epoch: 1/100... Training loss: 0.1941\n",
      "Epoch: 1/100... Training loss: 0.1937\n",
      "Epoch: 1/100... Training loss: 0.1852\n",
      "Epoch: 1/100... Training loss: 0.1923\n",
      "Epoch: 1/100... Training loss: 0.1878\n",
      "Epoch: 1/100... Training loss: 0.1880\n",
      "Epoch: 1/100... Training loss: 0.1925\n",
      "Epoch: 1/100... Training loss: 0.1809\n",
      "Epoch: 1/100... Training loss: 0.1894\n",
      "Epoch: 1/100... Training loss: 0.1901\n",
      "Epoch: 1/100... Training loss: 0.1910\n",
      "Epoch: 1/100... Training loss: 0.1871\n",
      "Epoch: 1/100... Training loss: 0.1880\n",
      "Epoch: 1/100... Training loss: 0.1868\n",
      "Epoch: 1/100... Training loss: 0.1838\n",
      "Epoch: 1/100... Training loss: 0.1771\n",
      "Epoch: 1/100... Training loss: 0.1897\n",
      "Epoch: 1/100... Training loss: 0.1847\n",
      "Epoch: 1/100... Training loss: 0.1821\n",
      "Epoch: 1/100... Training loss: 0.1815\n",
      "Epoch: 1/100... Training loss: 0.1868\n",
      "Epoch: 1/100... Training loss: 0.1874\n",
      "Epoch: 1/100... Training loss: 0.1854\n",
      "Epoch: 1/100... Training loss: 0.1804\n",
      "Epoch: 1/100... Training loss: 0.1853\n",
      "Epoch: 1/100... Training loss: 0.1757\n",
      "Epoch: 1/100... Training loss: 0.1841\n",
      "Epoch: 1/100... Training loss: 0.1820\n",
      "Epoch: 1/100... Training loss: 0.1861\n",
      "Epoch: 1/100... Training loss: 0.1844\n",
      "Epoch: 1/100... Training loss: 0.1810\n",
      "Epoch: 1/100... Training loss: 0.1780\n",
      "Epoch: 1/100... Training loss: 0.1800\n",
      "Epoch: 1/100... Training loss: 0.1867\n",
      "Epoch: 1/100... Training loss: 0.1847\n",
      "Epoch: 1/100... Training loss: 0.1759\n",
      "Epoch: 1/100... Training loss: 0.1848\n",
      "Epoch: 1/100... Training loss: 0.1831\n",
      "Epoch: 1/100... Training loss: 0.1802\n",
      "Epoch: 1/100... Training loss: 0.1806\n",
      "Epoch: 1/100... Training loss: 0.1776\n",
      "Epoch: 1/100... Training loss: 0.1798\n",
      "Epoch: 1/100... Training loss: 0.1829\n",
      "Epoch: 1/100... Training loss: 0.1812\n",
      "Epoch: 1/100... Training loss: 0.1778\n",
      "Epoch: 1/100... Training loss: 0.1796\n",
      "Epoch: 1/100... Training loss: 0.1741\n",
      "Epoch: 1/100... Training loss: 0.1780\n",
      "Epoch: 1/100... Training loss: 0.1806\n",
      "Epoch: 1/100... Training loss: 0.1729\n",
      "Epoch: 1/100... Training loss: 0.1765\n",
      "Epoch: 1/100... Training loss: 0.1777\n",
      "Epoch: 1/100... Training loss: 0.1806\n",
      "Epoch: 1/100... Training loss: 0.1801\n",
      "Epoch: 1/100... Training loss: 0.1831\n",
      "Epoch: 1/100... Training loss: 0.1811\n",
      "Epoch: 1/100... Training loss: 0.1758\n",
      "Epoch: 2/100... Training loss: 0.1773\n",
      "Epoch: 2/100... Training loss: 0.1822\n",
      "Epoch: 2/100... Training loss: 0.1749\n",
      "Epoch: 2/100... Training loss: 0.1739\n",
      "Epoch: 2/100... Training loss: 0.1805\n",
      "Epoch: 2/100... Training loss: 0.1758\n",
      "Epoch: 2/100... Training loss: 0.1766\n",
      "Epoch: 2/100... Training loss: 0.1756\n",
      "Epoch: 2/100... Training loss: 0.1743\n",
      "Epoch: 2/100... Training loss: 0.1803\n",
      "Epoch: 2/100... Training loss: 0.1742\n",
      "Epoch: 2/100... Training loss: 0.1786\n",
      "Epoch: 2/100... Training loss: 0.1801\n",
      "Epoch: 2/100... Training loss: 0.1810\n",
      "Epoch: 2/100... Training loss: 0.1765\n",
      "Epoch: 2/100... Training loss: 0.1745\n",
      "Epoch: 2/100... Training loss: 0.1805\n",
      "Epoch: 2/100... Training loss: 0.1752\n",
      "Epoch: 2/100... Training loss: 0.1777\n",
      "Epoch: 2/100... Training loss: 0.1793\n",
      "Epoch: 2/100... Training loss: 0.1739\n",
      "Epoch: 2/100... Training loss: 0.1741\n",
      "Epoch: 2/100... Training loss: 0.1737\n",
      "Epoch: 2/100... Training loss: 0.1756\n",
      "Epoch: 2/100... Training loss: 0.1721\n",
      "Epoch: 2/100... Training loss: 0.1719\n",
      "Epoch: 2/100... Training loss: 0.1735\n",
      "Epoch: 2/100... Training loss: 0.1772\n",
      "Epoch: 2/100... Training loss: 0.1737\n",
      "Epoch: 2/100... Training loss: 0.1744\n",
      "Epoch: 2/100... Training loss: 0.1740\n",
      "Epoch: 2/100... Training loss: 0.1745\n",
      "Epoch: 2/100... Training loss: 0.1696\n",
      "Epoch: 2/100... Training loss: 0.1718\n",
      "Epoch: 2/100... Training loss: 0.1760\n",
      "Epoch: 2/100... Training loss: 0.1764\n",
      "Epoch: 2/100... Training loss: 0.1732\n",
      "Epoch: 2/100... Training loss: 0.1707\n",
      "Epoch: 2/100... Training loss: 0.1741\n",
      "Epoch: 2/100... Training loss: 0.1788\n",
      "Epoch: 2/100... Training loss: 0.1724\n",
      "Epoch: 2/100... Training loss: 0.1686\n",
      "Epoch: 2/100... Training loss: 0.1660\n",
      "Epoch: 2/100... Training loss: 0.1721\n",
      "Epoch: 2/100... Training loss: 0.1725\n",
      "Epoch: 2/100... Training loss: 0.1704\n",
      "Epoch: 2/100... Training loss: 0.1729\n",
      "Epoch: 2/100... Training loss: 0.1708\n",
      "Epoch: 2/100... Training loss: 0.1737\n",
      "Epoch: 2/100... Training loss: 0.1688\n",
      "Epoch: 2/100... Training loss: 0.1718\n",
      "Epoch: 2/100... Training loss: 0.1717\n",
      "Epoch: 2/100... Training loss: 0.1691\n",
      "Epoch: 2/100... Training loss: 0.1719\n",
      "Epoch: 2/100... Training loss: 0.1701\n",
      "Epoch: 2/100... Training loss: 0.1660\n",
      "Epoch: 2/100... Training loss: 0.1725\n",
      "Epoch: 2/100... Training loss: 0.1696\n",
      "Epoch: 2/100... Training loss: 0.1659\n",
      "Epoch: 2/100... Training loss: 0.1720\n",
      "Epoch: 2/100... Training loss: 0.1740\n",
      "Epoch: 2/100... Training loss: 0.1740\n",
      "Epoch: 2/100... Training loss: 0.1714\n",
      "Epoch: 2/100... Training loss: 0.1718\n",
      "Epoch: 2/100... Training loss: 0.1687\n",
      "Epoch: 2/100... Training loss: 0.1688\n",
      "Epoch: 2/100... Training loss: 0.1727\n",
      "Epoch: 2/100... Training loss: 0.1717\n",
      "Epoch: 2/100... Training loss: 0.1712\n",
      "Epoch: 2/100... Training loss: 0.1690\n",
      "Epoch: 2/100... Training loss: 0.1791\n",
      "Epoch: 2/100... Training loss: 0.1688\n",
      "Epoch: 2/100... Training loss: 0.1676\n",
      "Epoch: 2/100... Training loss: 0.1697\n",
      "Epoch: 2/100... Training loss: 0.1692\n",
      "Epoch: 2/100... Training loss: 0.1723\n",
      "Epoch: 2/100... Training loss: 0.1725\n",
      "Epoch: 2/100... Training loss: 0.1730\n",
      "Epoch: 2/100... Training loss: 0.1668\n",
      "Epoch: 2/100... Training loss: 0.1711\n",
      "Epoch: 2/100... Training loss: 0.1713\n",
      "Epoch: 2/100... Training loss: 0.1673\n",
      "Epoch: 2/100... Training loss: 0.1711\n",
      "Epoch: 2/100... Training loss: 0.1701\n",
      "Epoch: 2/100... Training loss: 0.1686\n",
      "Epoch: 2/100... Training loss: 0.1714\n",
      "Epoch: 2/100... Training loss: 0.1665\n",
      "Epoch: 2/100... Training loss: 0.1727\n",
      "Epoch: 2/100... Training loss: 0.1709\n",
      "Epoch: 2/100... Training loss: 0.1691\n",
      "Epoch: 2/100... Training loss: 0.1656\n",
      "Epoch: 2/100... Training loss: 0.1656\n",
      "Epoch: 2/100... Training loss: 0.1718\n",
      "Epoch: 2/100... Training loss: 0.1672\n",
      "Epoch: 2/100... Training loss: 0.1651\n",
      "Epoch: 2/100... Training loss: 0.1651\n",
      "Epoch: 2/100... Training loss: 0.1712\n",
      "Epoch: 2/100... Training loss: 0.1662\n",
      "Epoch: 2/100... Training loss: 0.1676\n",
      "Epoch: 2/100... Training loss: 0.1665\n",
      "Epoch: 2/100... Training loss: 0.1704\n",
      "Epoch: 2/100... Training loss: 0.1634\n",
      "Epoch: 2/100... Training loss: 0.1643\n",
      "Epoch: 2/100... Training loss: 0.1677\n",
      "Epoch: 2/100... Training loss: 0.1700\n",
      "Epoch: 2/100... Training loss: 0.1647\n",
      "Epoch: 2/100... Training loss: 0.1641\n",
      "Epoch: 2/100... Training loss: 0.1678\n",
      "Epoch: 2/100... Training loss: 0.1659\n",
      "Epoch: 2/100... Training loss: 0.1653\n",
      "Epoch: 2/100... Training loss: 0.1611\n",
      "Epoch: 2/100... Training loss: 0.1630\n",
      "Epoch: 2/100... Training loss: 0.1626\n",
      "Epoch: 2/100... Training loss: 0.1681\n",
      "Epoch: 2/100... Training loss: 0.1695\n",
      "Epoch: 2/100... Training loss: 0.1708\n",
      "Epoch: 2/100... Training loss: 0.1701\n",
      "Epoch: 2/100... Training loss: 0.1627\n",
      "Epoch: 2/100... Training loss: 0.1645\n",
      "Epoch: 2/100... Training loss: 0.1724\n",
      "Epoch: 2/100... Training loss: 0.1617\n",
      "Epoch: 2/100... Training loss: 0.1619\n",
      "Epoch: 2/100... Training loss: 0.1644\n",
      "Epoch: 2/100... Training loss: 0.1681\n",
      "Epoch: 2/100... Training loss: 0.1626\n",
      "Epoch: 2/100... Training loss: 0.1636\n",
      "Epoch: 2/100... Training loss: 0.1637\n",
      "Epoch: 2/100... Training loss: 0.1664\n",
      "Epoch: 2/100... Training loss: 0.1660\n",
      "Epoch: 2/100... Training loss: 0.1661\n",
      "Epoch: 2/100... Training loss: 0.1659\n",
      "Epoch: 2/100... Training loss: 0.1703\n",
      "Epoch: 2/100... Training loss: 0.1651\n",
      "Epoch: 2/100... Training loss: 0.1616\n",
      "Epoch: 2/100... Training loss: 0.1574\n",
      "Epoch: 2/100... Training loss: 0.1639\n",
      "Epoch: 2/100... Training loss: 0.1582\n",
      "Epoch: 2/100... Training loss: 0.1571\n",
      "Epoch: 2/100... Training loss: 0.1681\n",
      "Epoch: 2/100... Training loss: 0.1627\n",
      "Epoch: 2/100... Training loss: 0.1662\n",
      "Epoch: 2/100... Training loss: 0.1634\n",
      "Epoch: 2/100... Training loss: 0.1612\n",
      "Epoch: 2/100... Training loss: 0.1611\n",
      "Epoch: 2/100... Training loss: 0.1595\n",
      "Epoch: 2/100... Training loss: 0.1652\n",
      "Epoch: 2/100... Training loss: 0.1571\n",
      "Epoch: 2/100... Training loss: 0.1617\n",
      "Epoch: 2/100... Training loss: 0.1642\n",
      "Epoch: 2/100... Training loss: 0.1638\n",
      "Epoch: 2/100... Training loss: 0.1618\n",
      "Epoch: 2/100... Training loss: 0.1612\n",
      "Epoch: 2/100... Training loss: 0.1620\n",
      "Epoch: 2/100... Training loss: 0.1641\n",
      "Epoch: 2/100... Training loss: 0.1595\n",
      "Epoch: 2/100... Training loss: 0.1523\n",
      "Epoch: 2/100... Training loss: 0.1693\n",
      "Epoch: 2/100... Training loss: 0.1610\n",
      "Epoch: 2/100... Training loss: 0.1595\n",
      "Epoch: 2/100... Training loss: 0.1607\n",
      "Epoch: 2/100... Training loss: 0.1626\n",
      "Epoch: 2/100... Training loss: 0.1623\n",
      "Epoch: 2/100... Training loss: 0.1595\n",
      "Epoch: 2/100... Training loss: 0.1577\n",
      "Epoch: 2/100... Training loss: 0.1629\n",
      "Epoch: 2/100... Training loss: 0.1621\n",
      "Epoch: 2/100... Training loss: 0.1606\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1614\n",
      "Epoch: 2/100... Training loss: 0.1644\n",
      "Epoch: 2/100... Training loss: 0.1660\n",
      "Epoch: 2/100... Training loss: 0.1632\n",
      "Epoch: 2/100... Training loss: 0.1650\n",
      "Epoch: 2/100... Training loss: 0.1572\n",
      "Epoch: 2/100... Training loss: 0.1665\n",
      "Epoch: 2/100... Training loss: 0.1621\n",
      "Epoch: 2/100... Training loss: 0.1649\n",
      "Epoch: 2/100... Training loss: 0.1525\n",
      "Epoch: 2/100... Training loss: 0.1577\n",
      "Epoch: 2/100... Training loss: 0.1621\n",
      "Epoch: 2/100... Training loss: 0.1644\n",
      "Epoch: 2/100... Training loss: 0.1624\n",
      "Epoch: 2/100... Training loss: 0.1628\n",
      "Epoch: 2/100... Training loss: 0.1579\n",
      "Epoch: 2/100... Training loss: 0.1540\n",
      "Epoch: 2/100... Training loss: 0.1611\n",
      "Epoch: 2/100... Training loss: 0.1620\n",
      "Epoch: 2/100... Training loss: 0.1574\n",
      "Epoch: 2/100... Training loss: 0.1614\n",
      "Epoch: 2/100... Training loss: 0.1594\n",
      "Epoch: 2/100... Training loss: 0.1567\n",
      "Epoch: 2/100... Training loss: 0.1597\n",
      "Epoch: 2/100... Training loss: 0.1557\n",
      "Epoch: 2/100... Training loss: 0.1618\n",
      "Epoch: 2/100... Training loss: 0.1619\n",
      "Epoch: 2/100... Training loss: 0.1636\n",
      "Epoch: 2/100... Training loss: 0.1621\n",
      "Epoch: 2/100... Training loss: 0.1601\n",
      "Epoch: 2/100... Training loss: 0.1625\n",
      "Epoch: 2/100... Training loss: 0.1604\n",
      "Epoch: 2/100... Training loss: 0.1598\n",
      "Epoch: 2/100... Training loss: 0.1616\n",
      "Epoch: 2/100... Training loss: 0.1561\n",
      "Epoch: 2/100... Training loss: 0.1610\n",
      "Epoch: 2/100... Training loss: 0.1618\n",
      "Epoch: 2/100... Training loss: 0.1582\n",
      "Epoch: 2/100... Training loss: 0.1557\n",
      "Epoch: 2/100... Training loss: 0.1568\n",
      "Epoch: 2/100... Training loss: 0.1653\n",
      "Epoch: 2/100... Training loss: 0.1579\n",
      "Epoch: 2/100... Training loss: 0.1579\n",
      "Epoch: 2/100... Training loss: 0.1579\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1576\n",
      "Epoch: 2/100... Training loss: 0.1605\n",
      "Epoch: 2/100... Training loss: 0.1643\n",
      "Epoch: 2/100... Training loss: 0.1624\n",
      "Epoch: 2/100... Training loss: 0.1570\n",
      "Epoch: 2/100... Training loss: 0.1613\n",
      "Epoch: 2/100... Training loss: 0.1570\n",
      "Epoch: 2/100... Training loss: 0.1603\n",
      "Epoch: 2/100... Training loss: 0.1565\n",
      "Epoch: 2/100... Training loss: 0.1558\n",
      "Epoch: 2/100... Training loss: 0.1562\n",
      "Epoch: 2/100... Training loss: 0.1569\n",
      "Epoch: 2/100... Training loss: 0.1594\n",
      "Epoch: 2/100... Training loss: 0.1594\n",
      "Epoch: 2/100... Training loss: 0.1595\n",
      "Epoch: 2/100... Training loss: 0.1588\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1605\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1552\n",
      "Epoch: 2/100... Training loss: 0.1576\n",
      "Epoch: 2/100... Training loss: 0.1553\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1598\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1619\n",
      "Epoch: 2/100... Training loss: 0.1574\n",
      "Epoch: 2/100... Training loss: 0.1550\n",
      "Epoch: 2/100... Training loss: 0.1490\n",
      "Epoch: 2/100... Training loss: 0.1587\n",
      "Epoch: 2/100... Training loss: 0.1530\n",
      "Epoch: 2/100... Training loss: 0.1536\n",
      "Epoch: 2/100... Training loss: 0.1522\n",
      "Epoch: 2/100... Training loss: 0.1535\n",
      "Epoch: 2/100... Training loss: 0.1576\n",
      "Epoch: 2/100... Training loss: 0.1581\n",
      "Epoch: 2/100... Training loss: 0.1567\n",
      "Epoch: 2/100... Training loss: 0.1482\n",
      "Epoch: 2/100... Training loss: 0.1569\n",
      "Epoch: 2/100... Training loss: 0.1567\n",
      "Epoch: 2/100... Training loss: 0.1568\n",
      "Epoch: 2/100... Training loss: 0.1545\n",
      "Epoch: 2/100... Training loss: 0.1567\n",
      "Epoch: 2/100... Training loss: 0.1542\n",
      "Epoch: 2/100... Training loss: 0.1550\n",
      "Epoch: 2/100... Training loss: 0.1552\n",
      "Epoch: 2/100... Training loss: 0.1499\n",
      "Epoch: 2/100... Training loss: 0.1563\n",
      "Epoch: 2/100... Training loss: 0.1532\n",
      "Epoch: 2/100... Training loss: 0.1545\n",
      "Epoch: 2/100... Training loss: 0.1568\n",
      "Epoch: 2/100... Training loss: 0.1543\n",
      "Epoch: 2/100... Training loss: 0.1504\n",
      "Epoch: 2/100... Training loss: 0.1557\n",
      "Epoch: 2/100... Training loss: 0.1560\n",
      "Epoch: 2/100... Training loss: 0.1578\n",
      "Epoch: 2/100... Training loss: 0.1541\n",
      "Epoch: 2/100... Training loss: 0.1564\n",
      "Epoch: 2/100... Training loss: 0.1509\n",
      "Epoch: 2/100... Training loss: 0.1473\n",
      "Epoch: 2/100... Training loss: 0.1570\n",
      "Epoch: 2/100... Training loss: 0.1535\n",
      "Epoch: 2/100... Training loss: 0.1520\n",
      "Epoch: 2/100... Training loss: 0.1508\n",
      "Epoch: 2/100... Training loss: 0.1575\n",
      "Epoch: 2/100... Training loss: 0.1531\n",
      "Epoch: 2/100... Training loss: 0.1497\n",
      "Epoch: 2/100... Training loss: 0.1555\n",
      "Epoch: 2/100... Training loss: 0.1557\n",
      "Epoch: 2/100... Training loss: 0.1540\n",
      "Epoch: 2/100... Training loss: 0.1519\n",
      "Epoch: 2/100... Training loss: 0.1541\n",
      "Epoch: 2/100... Training loss: 0.1546\n",
      "Epoch: 2/100... Training loss: 0.1562\n",
      "Epoch: 2/100... Training loss: 0.1537\n",
      "Epoch: 2/100... Training loss: 0.1514\n",
      "Epoch: 2/100... Training loss: 0.1556\n",
      "Epoch: 2/100... Training loss: 0.1485\n",
      "Epoch: 2/100... Training loss: 0.1482\n",
      "Epoch: 2/100... Training loss: 0.1638\n",
      "Epoch: 2/100... Training loss: 0.1488\n",
      "Epoch: 2/100... Training loss: 0.1479\n",
      "Epoch: 2/100... Training loss: 0.1564\n",
      "Epoch: 2/100... Training loss: 0.1594\n",
      "Epoch: 2/100... Training loss: 0.1599\n",
      "Epoch: 2/100... Training loss: 0.1507\n",
      "Epoch: 2/100... Training loss: 0.1609\n",
      "Epoch: 3/100... Training loss: 0.1540\n",
      "Epoch: 3/100... Training loss: 0.1586\n",
      "Epoch: 3/100... Training loss: 0.1554\n",
      "Epoch: 3/100... Training loss: 0.1526\n",
      "Epoch: 3/100... Training loss: 0.1530\n",
      "Epoch: 3/100... Training loss: 0.1559\n",
      "Epoch: 3/100... Training loss: 0.1548\n",
      "Epoch: 3/100... Training loss: 0.1525\n",
      "Epoch: 3/100... Training loss: 0.1561\n",
      "Epoch: 3/100... Training loss: 0.1494\n",
      "Epoch: 3/100... Training loss: 0.1530\n",
      "Epoch: 3/100... Training loss: 0.1496\n",
      "Epoch: 3/100... Training loss: 0.1550\n",
      "Epoch: 3/100... Training loss: 0.1504\n",
      "Epoch: 3/100... Training loss: 0.1544\n",
      "Epoch: 3/100... Training loss: 0.1558\n",
      "Epoch: 3/100... Training loss: 0.1497\n",
      "Epoch: 3/100... Training loss: 0.1515\n",
      "Epoch: 3/100... Training loss: 0.1518\n",
      "Epoch: 3/100... Training loss: 0.1486\n",
      "Epoch: 3/100... Training loss: 0.1562\n",
      "Epoch: 3/100... Training loss: 0.1546\n",
      "Epoch: 3/100... Training loss: 0.1504\n",
      "Epoch: 3/100... Training loss: 0.1491\n",
      "Epoch: 3/100... Training loss: 0.1518\n",
      "Epoch: 3/100... Training loss: 0.1570\n",
      "Epoch: 3/100... Training loss: 0.1496\n",
      "Epoch: 3/100... Training loss: 0.1539\n",
      "Epoch: 3/100... Training loss: 0.1506\n",
      "Epoch: 3/100... Training loss: 0.1500\n",
      "Epoch: 3/100... Training loss: 0.1506\n",
      "Epoch: 3/100... Training loss: 0.1532\n",
      "Epoch: 3/100... Training loss: 0.1478\n",
      "Epoch: 3/100... Training loss: 0.1507\n",
      "Epoch: 3/100... Training loss: 0.1550\n",
      "Epoch: 3/100... Training loss: 0.1514\n",
      "Epoch: 3/100... Training loss: 0.1500\n",
      "Epoch: 3/100... Training loss: 0.1472\n",
      "Epoch: 3/100... Training loss: 0.1509\n",
      "Epoch: 3/100... Training loss: 0.1465\n",
      "Epoch: 3/100... Training loss: 0.1516\n",
      "Epoch: 3/100... Training loss: 0.1487\n",
      "Epoch: 3/100... Training loss: 0.1512\n",
      "Epoch: 3/100... Training loss: 0.1483\n",
      "Epoch: 3/100... Training loss: 0.1517\n",
      "Epoch: 3/100... Training loss: 0.1512\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1472\n",
      "Epoch: 3/100... Training loss: 0.1490\n",
      "Epoch: 3/100... Training loss: 0.1532\n",
      "Epoch: 3/100... Training loss: 0.1458\n",
      "Epoch: 3/100... Training loss: 0.1496\n",
      "Epoch: 3/100... Training loss: 0.1498\n",
      "Epoch: 3/100... Training loss: 0.1471\n",
      "Epoch: 3/100... Training loss: 0.1513\n",
      "Epoch: 3/100... Training loss: 0.1488\n",
      "Epoch: 3/100... Training loss: 0.1530\n",
      "Epoch: 3/100... Training loss: 0.1466\n",
      "Epoch: 3/100... Training loss: 0.1483\n",
      "Epoch: 3/100... Training loss: 0.1512\n",
      "Epoch: 3/100... Training loss: 0.1518\n",
      "Epoch: 3/100... Training loss: 0.1487\n",
      "Epoch: 3/100... Training loss: 0.1514\n",
      "Epoch: 3/100... Training loss: 0.1506\n",
      "Epoch: 3/100... Training loss: 0.1537\n",
      "Epoch: 3/100... Training loss: 0.1515\n",
      "Epoch: 3/100... Training loss: 0.1384\n",
      "Epoch: 3/100... Training loss: 0.1528\n",
      "Epoch: 3/100... Training loss: 0.1511\n",
      "Epoch: 3/100... Training loss: 0.1510\n",
      "Epoch: 3/100... Training loss: 0.1530\n",
      "Epoch: 3/100... Training loss: 0.1525\n",
      "Epoch: 3/100... Training loss: 0.1497\n",
      "Epoch: 3/100... Training loss: 0.1521\n",
      "Epoch: 3/100... Training loss: 0.1507\n",
      "Epoch: 3/100... Training loss: 0.1501\n",
      "Epoch: 3/100... Training loss: 0.1531\n",
      "Epoch: 3/100... Training loss: 0.1485\n",
      "Epoch: 3/100... Training loss: 0.1478\n",
      "Epoch: 3/100... Training loss: 0.1495\n",
      "Epoch: 3/100... Training loss: 0.1460\n",
      "Epoch: 3/100... Training loss: 0.1542\n",
      "Epoch: 3/100... Training loss: 0.1489\n",
      "Epoch: 3/100... Training loss: 0.1461\n",
      "Epoch: 3/100... Training loss: 0.1476\n",
      "Epoch: 3/100... Training loss: 0.1513\n",
      "Epoch: 3/100... Training loss: 0.1459\n",
      "Epoch: 3/100... Training loss: 0.1468\n",
      "Epoch: 3/100... Training loss: 0.1491\n",
      "Epoch: 3/100... Training loss: 0.1558\n",
      "Epoch: 3/100... Training loss: 0.1482\n",
      "Epoch: 3/100... Training loss: 0.1472\n",
      "Epoch: 3/100... Training loss: 0.1525\n",
      "Epoch: 3/100... Training loss: 0.1515\n",
      "Epoch: 3/100... Training loss: 0.1514\n",
      "Epoch: 3/100... Training loss: 0.1467\n",
      "Epoch: 3/100... Training loss: 0.1482\n",
      "Epoch: 3/100... Training loss: 0.1445\n",
      "Epoch: 3/100... Training loss: 0.1473\n",
      "Epoch: 3/100... Training loss: 0.1456\n",
      "Epoch: 3/100... Training loss: 0.1533\n",
      "Epoch: 3/100... Training loss: 0.1504\n",
      "Epoch: 3/100... Training loss: 0.1452\n",
      "Epoch: 3/100... Training loss: 0.1478\n",
      "Epoch: 3/100... Training loss: 0.1485\n",
      "Epoch: 3/100... Training loss: 0.1474\n",
      "Epoch: 3/100... Training loss: 0.1480\n",
      "Epoch: 3/100... Training loss: 0.1503\n",
      "Epoch: 3/100... Training loss: 0.1496\n",
      "Epoch: 3/100... Training loss: 0.1446\n",
      "Epoch: 3/100... Training loss: 0.1488\n",
      "Epoch: 3/100... Training loss: 0.1493\n",
      "Epoch: 3/100... Training loss: 0.1469\n",
      "Epoch: 3/100... Training loss: 0.1492\n",
      "Epoch: 3/100... Training loss: 0.1498\n",
      "Epoch: 3/100... Training loss: 0.1460\n",
      "Epoch: 3/100... Training loss: 0.1525\n",
      "Epoch: 3/100... Training loss: 0.1466\n",
      "Epoch: 3/100... Training loss: 0.1470\n",
      "Epoch: 3/100... Training loss: 0.1463\n",
      "Epoch: 3/100... Training loss: 0.1454\n",
      "Epoch: 3/100... Training loss: 0.1453\n",
      "Epoch: 3/100... Training loss: 0.1445\n",
      "Epoch: 3/100... Training loss: 0.1506\n",
      "Epoch: 3/100... Training loss: 0.1490\n",
      "Epoch: 3/100... Training loss: 0.1489\n",
      "Epoch: 3/100... Training loss: 0.1451\n",
      "Epoch: 3/100... Training loss: 0.1504\n",
      "Epoch: 3/100... Training loss: 0.1461\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1479\n",
      "Epoch: 3/100... Training loss: 0.1445\n",
      "Epoch: 3/100... Training loss: 0.1493\n",
      "Epoch: 3/100... Training loss: 0.1485\n",
      "Epoch: 3/100... Training loss: 0.1434\n",
      "Epoch: 3/100... Training loss: 0.1430\n",
      "Epoch: 3/100... Training loss: 0.1463\n",
      "Epoch: 3/100... Training loss: 0.1478\n",
      "Epoch: 3/100... Training loss: 0.1431\n",
      "Epoch: 3/100... Training loss: 0.1476\n",
      "Epoch: 3/100... Training loss: 0.1430\n",
      "Epoch: 3/100... Training loss: 0.1422\n",
      "Epoch: 3/100... Training loss: 0.1466\n",
      "Epoch: 3/100... Training loss: 0.1482\n",
      "Epoch: 3/100... Training loss: 0.1469\n",
      "Epoch: 3/100... Training loss: 0.1491\n",
      "Epoch: 3/100... Training loss: 0.1445\n",
      "Epoch: 3/100... Training loss: 0.1504\n",
      "Epoch: 3/100... Training loss: 0.1509\n",
      "Epoch: 3/100... Training loss: 0.1512\n",
      "Epoch: 3/100... Training loss: 0.1506\n",
      "Epoch: 3/100... Training loss: 0.1454\n",
      "Epoch: 3/100... Training loss: 0.1441\n",
      "Epoch: 3/100... Training loss: 0.1530\n",
      "Epoch: 3/100... Training loss: 0.1463\n",
      "Epoch: 3/100... Training loss: 0.1453\n",
      "Epoch: 3/100... Training loss: 0.1442\n",
      "Epoch: 3/100... Training loss: 0.1473\n",
      "Epoch: 3/100... Training loss: 0.1453\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1455\n",
      "Epoch: 3/100... Training loss: 0.1462\n",
      "Epoch: 3/100... Training loss: 0.1441\n",
      "Epoch: 3/100... Training loss: 0.1475\n",
      "Epoch: 3/100... Training loss: 0.1478\n",
      "Epoch: 3/100... Training loss: 0.1481\n",
      "Epoch: 3/100... Training loss: 0.1435\n",
      "Epoch: 3/100... Training loss: 0.1436\n",
      "Epoch: 3/100... Training loss: 0.1457\n",
      "Epoch: 3/100... Training loss: 0.1469\n",
      "Epoch: 3/100... Training loss: 0.1481\n",
      "Epoch: 3/100... Training loss: 0.1452\n",
      "Epoch: 3/100... Training loss: 0.1491\n",
      "Epoch: 3/100... Training loss: 0.1474\n",
      "Epoch: 3/100... Training loss: 0.1448\n",
      "Epoch: 3/100... Training loss: 0.1433\n",
      "Epoch: 3/100... Training loss: 0.1516\n",
      "Epoch: 3/100... Training loss: 0.1467\n",
      "Epoch: 3/100... Training loss: 0.1450\n",
      "Epoch: 3/100... Training loss: 0.1489\n",
      "Epoch: 3/100... Training loss: 0.1435\n",
      "Epoch: 3/100... Training loss: 0.1461\n",
      "Epoch: 3/100... Training loss: 0.1455\n",
      "Epoch: 3/100... Training loss: 0.1467\n",
      "Epoch: 3/100... Training loss: 0.1437\n",
      "Epoch: 3/100... Training loss: 0.1454\n",
      "Epoch: 3/100... Training loss: 0.1461\n",
      "Epoch: 3/100... Training loss: 0.1429\n",
      "Epoch: 3/100... Training loss: 0.1441\n",
      "Epoch: 3/100... Training loss: 0.1426\n",
      "Epoch: 3/100... Training loss: 0.1459\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1455\n",
      "Epoch: 3/100... Training loss: 0.1473\n",
      "Epoch: 3/100... Training loss: 0.1427\n",
      "Epoch: 3/100... Training loss: 0.1428\n",
      "Epoch: 3/100... Training loss: 0.1481\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1481\n",
      "Epoch: 3/100... Training loss: 0.1441\n",
      "Epoch: 3/100... Training loss: 0.1432\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1457\n",
      "Epoch: 3/100... Training loss: 0.1447\n",
      "Epoch: 3/100... Training loss: 0.1452\n",
      "Epoch: 3/100... Training loss: 0.1436\n",
      "Epoch: 3/100... Training loss: 0.1373\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 3/100... Training loss: 0.1512\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1487\n",
      "Epoch: 3/100... Training loss: 0.1458\n",
      "Epoch: 3/100... Training loss: 0.1438\n",
      "Epoch: 3/100... Training loss: 0.1461\n",
      "Epoch: 3/100... Training loss: 0.1471\n",
      "Epoch: 3/100... Training loss: 0.1434\n",
      "Epoch: 3/100... Training loss: 0.1447\n",
      "Epoch: 3/100... Training loss: 0.1433\n",
      "Epoch: 3/100... Training loss: 0.1427\n",
      "Epoch: 3/100... Training loss: 0.1411\n",
      "Epoch: 3/100... Training loss: 0.1429\n",
      "Epoch: 3/100... Training loss: 0.1465\n",
      "Epoch: 3/100... Training loss: 0.1480\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1458\n",
      "Epoch: 3/100... Training loss: 0.1448\n",
      "Epoch: 3/100... Training loss: 0.1466\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1471\n",
      "Epoch: 3/100... Training loss: 0.1442\n",
      "Epoch: 3/100... Training loss: 0.1474\n",
      "Epoch: 3/100... Training loss: 0.1429\n",
      "Epoch: 3/100... Training loss: 0.1413\n",
      "Epoch: 3/100... Training loss: 0.1439\n",
      "Epoch: 3/100... Training loss: 0.1383\n",
      "Epoch: 3/100... Training loss: 0.1474\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1404\n",
      "Epoch: 3/100... Training loss: 0.1429\n",
      "Epoch: 3/100... Training loss: 0.1434\n",
      "Epoch: 3/100... Training loss: 0.1441\n",
      "Epoch: 3/100... Training loss: 0.1405\n",
      "Epoch: 3/100... Training loss: 0.1441\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1451\n",
      "Epoch: 3/100... Training loss: 0.1457\n",
      "Epoch: 3/100... Training loss: 0.1448\n",
      "Epoch: 3/100... Training loss: 0.1397\n",
      "Epoch: 3/100... Training loss: 0.1398\n",
      "Epoch: 3/100... Training loss: 0.1447\n",
      "Epoch: 3/100... Training loss: 0.1401\n",
      "Epoch: 3/100... Training loss: 0.1395\n",
      "Epoch: 3/100... Training loss: 0.1410\n",
      "Epoch: 3/100... Training loss: 0.1451\n",
      "Epoch: 3/100... Training loss: 0.1421\n",
      "Epoch: 3/100... Training loss: 0.1366\n",
      "Epoch: 3/100... Training loss: 0.1502\n",
      "Epoch: 3/100... Training loss: 0.1348\n",
      "Epoch: 3/100... Training loss: 0.1452\n",
      "Epoch: 3/100... Training loss: 0.1452\n",
      "Epoch: 3/100... Training loss: 0.1505\n",
      "Epoch: 3/100... Training loss: 0.1417\n",
      "Epoch: 3/100... Training loss: 0.1453\n",
      "Epoch: 3/100... Training loss: 0.1458\n",
      "Epoch: 3/100... Training loss: 0.1438\n",
      "Epoch: 3/100... Training loss: 0.1423\n",
      "Epoch: 3/100... Training loss: 0.1384\n",
      "Epoch: 3/100... Training loss: 0.1435\n",
      "Epoch: 3/100... Training loss: 0.1479\n",
      "Epoch: 3/100... Training loss: 0.1495\n",
      "Epoch: 3/100... Training loss: 0.1436\n",
      "Epoch: 3/100... Training loss: 0.1398\n",
      "Epoch: 3/100... Training loss: 0.1412\n",
      "Epoch: 3/100... Training loss: 0.1402\n",
      "Epoch: 3/100... Training loss: 0.1476\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1396\n",
      "Epoch: 3/100... Training loss: 0.1416\n",
      "Epoch: 3/100... Training loss: 0.1471\n",
      "Epoch: 3/100... Training loss: 0.1463\n",
      "Epoch: 3/100... Training loss: 0.1436\n",
      "Epoch: 3/100... Training loss: 0.1488\n",
      "Epoch: 3/100... Training loss: 0.1435\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 3/100... Training loss: 0.1499\n",
      "Epoch: 3/100... Training loss: 0.1468\n",
      "Epoch: 3/100... Training loss: 0.1451\n",
      "Epoch: 3/100... Training loss: 0.1386\n",
      "Epoch: 3/100... Training loss: 0.1423\n",
      "Epoch: 3/100... Training loss: 0.1464\n",
      "Epoch: 3/100... Training loss: 0.1369\n",
      "Epoch: 3/100... Training loss: 0.1389\n",
      "Epoch: 3/100... Training loss: 0.1424\n",
      "Epoch: 3/100... Training loss: 0.1448\n",
      "Epoch: 3/100... Training loss: 0.1432\n",
      "Epoch: 3/100... Training loss: 0.1450\n",
      "Epoch: 3/100... Training loss: 0.1420\n",
      "Epoch: 3/100... Training loss: 0.1453\n",
      "Epoch: 3/100... Training loss: 0.1414\n",
      "Epoch: 3/100... Training loss: 0.1425\n",
      "Epoch: 4/100... Training loss: 0.1407\n",
      "Epoch: 4/100... Training loss: 0.1402\n",
      "Epoch: 4/100... Training loss: 0.1416\n",
      "Epoch: 4/100... Training loss: 0.1398\n",
      "Epoch: 4/100... Training loss: 0.1365\n",
      "Epoch: 4/100... Training loss: 0.1441\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1418\n",
      "Epoch: 4/100... Training loss: 0.1430\n",
      "Epoch: 4/100... Training loss: 0.1397\n",
      "Epoch: 4/100... Training loss: 0.1441\n",
      "Epoch: 4/100... Training loss: 0.1416\n",
      "Epoch: 4/100... Training loss: 0.1407\n",
      "Epoch: 4/100... Training loss: 0.1433\n",
      "Epoch: 4/100... Training loss: 0.1413\n",
      "Epoch: 4/100... Training loss: 0.1440\n",
      "Epoch: 4/100... Training loss: 0.1379\n",
      "Epoch: 4/100... Training loss: 0.1464\n",
      "Epoch: 4/100... Training loss: 0.1388\n",
      "Epoch: 4/100... Training loss: 0.1426\n",
      "Epoch: 4/100... Training loss: 0.1388\n",
      "Epoch: 4/100... Training loss: 0.1407\n",
      "Epoch: 4/100... Training loss: 0.1388\n",
      "Epoch: 4/100... Training loss: 0.1384\n",
      "Epoch: 4/100... Training loss: 0.1418\n",
      "Epoch: 4/100... Training loss: 0.1450\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1388\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1425\n",
      "Epoch: 4/100... Training loss: 0.1384\n",
      "Epoch: 4/100... Training loss: 0.1453\n",
      "Epoch: 4/100... Training loss: 0.1395\n",
      "Epoch: 4/100... Training loss: 0.1395\n",
      "Epoch: 4/100... Training loss: 0.1439\n",
      "Epoch: 4/100... Training loss: 0.1408\n",
      "Epoch: 4/100... Training loss: 0.1361\n",
      "Epoch: 4/100... Training loss: 0.1448\n",
      "Epoch: 4/100... Training loss: 0.1418\n",
      "Epoch: 4/100... Training loss: 0.1395\n",
      "Epoch: 4/100... Training loss: 0.1360\n",
      "Epoch: 4/100... Training loss: 0.1441\n",
      "Epoch: 4/100... Training loss: 0.1407\n",
      "Epoch: 4/100... Training loss: 0.1464\n",
      "Epoch: 4/100... Training loss: 0.1425\n",
      "Epoch: 4/100... Training loss: 0.1424\n",
      "Epoch: 4/100... Training loss: 0.1356\n",
      "Epoch: 4/100... Training loss: 0.1399\n",
      "Epoch: 4/100... Training loss: 0.1419\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1458\n",
      "Epoch: 4/100... Training loss: 0.1427\n",
      "Epoch: 4/100... Training loss: 0.1424\n",
      "Epoch: 4/100... Training loss: 0.1414\n",
      "Epoch: 4/100... Training loss: 0.1422\n",
      "Epoch: 4/100... Training loss: 0.1416\n",
      "Epoch: 4/100... Training loss: 0.1462\n",
      "Epoch: 4/100... Training loss: 0.1405\n",
      "Epoch: 4/100... Training loss: 0.1396\n",
      "Epoch: 4/100... Training loss: 0.1390\n",
      "Epoch: 4/100... Training loss: 0.1411\n",
      "Epoch: 4/100... Training loss: 0.1383\n",
      "Epoch: 4/100... Training loss: 0.1422\n",
      "Epoch: 4/100... Training loss: 0.1444\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1395\n",
      "Epoch: 4/100... Training loss: 0.1492\n",
      "Epoch: 4/100... Training loss: 0.1416\n",
      "Epoch: 4/100... Training loss: 0.1364\n",
      "Epoch: 4/100... Training loss: 0.1400\n",
      "Epoch: 4/100... Training loss: 0.1359\n",
      "Epoch: 4/100... Training loss: 0.1405\n",
      "Epoch: 4/100... Training loss: 0.1392\n",
      "Epoch: 4/100... Training loss: 0.1392\n",
      "Epoch: 4/100... Training loss: 0.1486\n",
      "Epoch: 4/100... Training loss: 0.1438\n",
      "Epoch: 4/100... Training loss: 0.1360\n",
      "Epoch: 4/100... Training loss: 0.1428\n",
      "Epoch: 4/100... Training loss: 0.1391\n",
      "Epoch: 4/100... Training loss: 0.1431\n",
      "Epoch: 4/100... Training loss: 0.1378\n",
      "Epoch: 4/100... Training loss: 0.1414\n",
      "Epoch: 4/100... Training loss: 0.1372\n",
      "Epoch: 4/100... Training loss: 0.1420\n",
      "Epoch: 4/100... Training loss: 0.1432\n",
      "Epoch: 4/100... Training loss: 0.1413\n",
      "Epoch: 4/100... Training loss: 0.1367\n",
      "Epoch: 4/100... Training loss: 0.1430\n",
      "Epoch: 4/100... Training loss: 0.1380\n",
      "Epoch: 4/100... Training loss: 0.1399\n",
      "Epoch: 4/100... Training loss: 0.1414\n",
      "Epoch: 4/100... Training loss: 0.1373\n",
      "Epoch: 4/100... Training loss: 0.1405\n",
      "Epoch: 4/100... Training loss: 0.1448\n",
      "Epoch: 4/100... Training loss: 0.1414\n",
      "Epoch: 4/100... Training loss: 0.1455\n",
      "Epoch: 4/100... Training loss: 0.1387\n",
      "Epoch: 4/100... Training loss: 0.1399\n",
      "Epoch: 4/100... Training loss: 0.1446\n",
      "Epoch: 4/100... Training loss: 0.1408\n",
      "Epoch: 4/100... Training loss: 0.1425\n",
      "Epoch: 4/100... Training loss: 0.1397\n",
      "Epoch: 4/100... Training loss: 0.1385\n",
      "Epoch: 4/100... Training loss: 0.1393\n",
      "Epoch: 4/100... Training loss: 0.1376\n",
      "Epoch: 4/100... Training loss: 0.1394\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1413\n",
      "Epoch: 4/100... Training loss: 0.1356\n",
      "Epoch: 4/100... Training loss: 0.1399\n",
      "Epoch: 4/100... Training loss: 0.1377\n",
      "Epoch: 4/100... Training loss: 0.1390\n",
      "Epoch: 4/100... Training loss: 0.1404\n",
      "Epoch: 4/100... Training loss: 0.1412\n",
      "Epoch: 4/100... Training loss: 0.1365\n",
      "Epoch: 4/100... Training loss: 0.1419\n",
      "Epoch: 4/100... Training loss: 0.1403\n",
      "Epoch: 4/100... Training loss: 0.1379\n",
      "Epoch: 4/100... Training loss: 0.1386\n",
      "Epoch: 4/100... Training loss: 0.1404\n",
      "Epoch: 4/100... Training loss: 0.1403\n",
      "Epoch: 4/100... Training loss: 0.1427\n",
      "Epoch: 4/100... Training loss: 0.1392\n",
      "Epoch: 4/100... Training loss: 0.1367\n",
      "Epoch: 4/100... Training loss: 0.1417\n",
      "Epoch: 4/100... Training loss: 0.1400\n",
      "Epoch: 4/100... Training loss: 0.1395\n",
      "Epoch: 4/100... Training loss: 0.1444\n",
      "Epoch: 4/100... Training loss: 0.1373\n",
      "Epoch: 4/100... Training loss: 0.1374\n",
      "Epoch: 4/100... Training loss: 0.1435\n",
      "Epoch: 4/100... Training loss: 0.1351\n",
      "Epoch: 4/100... Training loss: 0.1414\n",
      "Epoch: 4/100... Training loss: 0.1398\n",
      "Epoch: 4/100... Training loss: 0.1376\n",
      "Epoch: 4/100... Training loss: 0.1405\n",
      "Epoch: 4/100... Training loss: 0.1472\n",
      "Epoch: 4/100... Training loss: 0.1405\n",
      "Epoch: 4/100... Training loss: 0.1364\n",
      "Epoch: 4/100... Training loss: 0.1370\n",
      "Epoch: 4/100... Training loss: 0.1368\n",
      "Epoch: 4/100... Training loss: 0.1367\n",
      "Epoch: 4/100... Training loss: 0.1384\n",
      "Epoch: 4/100... Training loss: 0.1435\n",
      "Epoch: 4/100... Training loss: 0.1372\n",
      "Epoch: 4/100... Training loss: 0.1405\n",
      "Epoch: 4/100... Training loss: 0.1357\n",
      "Epoch: 4/100... Training loss: 0.1330\n",
      "Epoch: 4/100... Training loss: 0.1374\n",
      "Epoch: 4/100... Training loss: 0.1428\n",
      "Epoch: 4/100... Training loss: 0.1351\n",
      "Epoch: 4/100... Training loss: 0.1357\n",
      "Epoch: 4/100... Training loss: 0.1413\n",
      "Epoch: 4/100... Training loss: 0.1407\n",
      "Epoch: 4/100... Training loss: 0.1408\n",
      "Epoch: 4/100... Training loss: 0.1369\n",
      "Epoch: 4/100... Training loss: 0.1402\n",
      "Epoch: 4/100... Training loss: 0.1378\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1390\n",
      "Epoch: 4/100... Training loss: 0.1380\n",
      "Epoch: 4/100... Training loss: 0.1376\n",
      "Epoch: 4/100... Training loss: 0.1410\n",
      "Epoch: 4/100... Training loss: 0.1366\n",
      "Epoch: 4/100... Training loss: 0.1393\n",
      "Epoch: 4/100... Training loss: 0.1319\n",
      "Epoch: 4/100... Training loss: 0.1433\n",
      "Epoch: 4/100... Training loss: 0.1394\n",
      "Epoch: 4/100... Training loss: 0.1411\n",
      "Epoch: 4/100... Training loss: 0.1356\n",
      "Epoch: 4/100... Training loss: 0.1342\n",
      "Epoch: 4/100... Training loss: 0.1364\n",
      "Epoch: 4/100... Training loss: 0.1362\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1390\n",
      "Epoch: 4/100... Training loss: 0.1346\n",
      "Epoch: 4/100... Training loss: 0.1356\n",
      "Epoch: 4/100... Training loss: 0.1400\n",
      "Epoch: 4/100... Training loss: 0.1397\n",
      "Epoch: 4/100... Training loss: 0.1351\n",
      "Epoch: 4/100... Training loss: 0.1411\n",
      "Epoch: 4/100... Training loss: 0.1374\n",
      "Epoch: 4/100... Training loss: 0.1396\n",
      "Epoch: 4/100... Training loss: 0.1356\n",
      "Epoch: 4/100... Training loss: 0.1425\n",
      "Epoch: 4/100... Training loss: 0.1390\n",
      "Epoch: 4/100... Training loss: 0.1360\n",
      "Epoch: 4/100... Training loss: 0.1323\n",
      "Epoch: 4/100... Training loss: 0.1357\n",
      "Epoch: 4/100... Training loss: 0.1399\n",
      "Epoch: 4/100... Training loss: 0.1359\n",
      "Epoch: 4/100... Training loss: 0.1404\n",
      "Epoch: 4/100... Training loss: 0.1292\n",
      "Epoch: 4/100... Training loss: 0.1400\n",
      "Epoch: 4/100... Training loss: 0.1366\n",
      "Epoch: 4/100... Training loss: 0.1327\n",
      "Epoch: 4/100... Training loss: 0.1382\n",
      "Epoch: 4/100... Training loss: 0.1386\n",
      "Epoch: 4/100... Training loss: 0.1360\n",
      "Epoch: 4/100... Training loss: 0.1408\n",
      "Epoch: 4/100... Training loss: 0.1378\n",
      "Epoch: 4/100... Training loss: 0.1378\n",
      "Epoch: 4/100... Training loss: 0.1390\n",
      "Epoch: 4/100... Training loss: 0.1343\n",
      "Epoch: 4/100... Training loss: 0.1357\n",
      "Epoch: 4/100... Training loss: 0.1392\n",
      "Epoch: 4/100... Training loss: 0.1308\n",
      "Epoch: 4/100... Training loss: 0.1383\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1422\n",
      "Epoch: 4/100... Training loss: 0.1340\n",
      "Epoch: 4/100... Training loss: 0.1362\n",
      "Epoch: 4/100... Training loss: 0.1345\n",
      "Epoch: 4/100... Training loss: 0.1367\n",
      "Epoch: 4/100... Training loss: 0.1399\n",
      "Epoch: 4/100... Training loss: 0.1339\n",
      "Epoch: 4/100... Training loss: 0.1358\n",
      "Epoch: 4/100... Training loss: 0.1397\n",
      "Epoch: 4/100... Training loss: 0.1410\n",
      "Epoch: 4/100... Training loss: 0.1403\n",
      "Epoch: 4/100... Training loss: 0.1328\n",
      "Epoch: 4/100... Training loss: 0.1390\n",
      "Epoch: 4/100... Training loss: 0.1310\n",
      "Epoch: 4/100... Training loss: 0.1368\n",
      "Epoch: 4/100... Training loss: 0.1400\n",
      "Epoch: 4/100... Training loss: 0.1387\n",
      "Epoch: 4/100... Training loss: 0.1349\n",
      "Epoch: 4/100... Training loss: 0.1349\n",
      "Epoch: 4/100... Training loss: 0.1403\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1359\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1392\n",
      "Epoch: 4/100... Training loss: 0.1332\n",
      "Epoch: 4/100... Training loss: 0.1344\n",
      "Epoch: 4/100... Training loss: 0.1385\n",
      "Epoch: 4/100... Training loss: 0.1402\n",
      "Epoch: 4/100... Training loss: 0.1411\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1315\n",
      "Epoch: 4/100... Training loss: 0.1399\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1382\n",
      "Epoch: 4/100... Training loss: 0.1335\n",
      "Epoch: 4/100... Training loss: 0.1369\n",
      "Epoch: 4/100... Training loss: 0.1394\n",
      "Epoch: 4/100... Training loss: 0.1396\n",
      "Epoch: 4/100... Training loss: 0.1327\n",
      "Epoch: 4/100... Training loss: 0.1366\n",
      "Epoch: 4/100... Training loss: 0.1425\n",
      "Epoch: 4/100... Training loss: 0.1365\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1353\n",
      "Epoch: 4/100... Training loss: 0.1372\n",
      "Epoch: 4/100... Training loss: 0.1400\n",
      "Epoch: 4/100... Training loss: 0.1377\n",
      "Epoch: 4/100... Training loss: 0.1378\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1371\n",
      "Epoch: 4/100... Training loss: 0.1398\n",
      "Epoch: 4/100... Training loss: 0.1334\n",
      "Epoch: 4/100... Training loss: 0.1377\n",
      "Epoch: 4/100... Training loss: 0.1380\n",
      "Epoch: 4/100... Training loss: 0.1389\n",
      "Epoch: 4/100... Training loss: 0.1381\n",
      "Epoch: 4/100... Training loss: 0.1340\n",
      "Epoch: 4/100... Training loss: 0.1348\n",
      "Epoch: 4/100... Training loss: 0.1325\n",
      "Epoch: 4/100... Training loss: 0.1437\n",
      "Epoch: 4/100... Training loss: 0.1380\n",
      "Epoch: 4/100... Training loss: 0.1338\n",
      "Epoch: 4/100... Training loss: 0.1395\n",
      "Epoch: 4/100... Training loss: 0.1338\n",
      "Epoch: 4/100... Training loss: 0.1386\n",
      "Epoch: 4/100... Training loss: 0.1364\n",
      "Epoch: 4/100... Training loss: 0.1346\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1331\n",
      "Epoch: 4/100... Training loss: 0.1333\n",
      "Epoch: 4/100... Training loss: 0.1392\n",
      "Epoch: 4/100... Training loss: 0.1371\n",
      "Epoch: 4/100... Training loss: 0.1363\n",
      "Epoch: 4/100... Training loss: 0.1358\n",
      "Epoch: 4/100... Training loss: 0.1355\n",
      "Epoch: 4/100... Training loss: 0.1314\n",
      "Epoch: 4/100... Training loss: 0.1384\n",
      "Epoch: 4/100... Training loss: 0.1362\n",
      "Epoch: 4/100... Training loss: 0.1368\n",
      "Epoch: 4/100... Training loss: 0.1341\n",
      "Epoch: 4/100... Training loss: 0.1397\n",
      "Epoch: 4/100... Training loss: 0.1367\n",
      "Epoch: 4/100... Training loss: 0.1317\n",
      "Epoch: 4/100... Training loss: 0.1382\n",
      "Epoch: 4/100... Training loss: 0.1407\n",
      "Epoch: 4/100... Training loss: 0.1381\n",
      "Epoch: 4/100... Training loss: 0.1365\n",
      "Epoch: 4/100... Training loss: 0.1347\n",
      "Epoch: 4/100... Training loss: 0.1390\n",
      "Epoch: 4/100... Training loss: 0.1321\n",
      "Epoch: 5/100... Training loss: 0.1370\n",
      "Epoch: 5/100... Training loss: 0.1354\n",
      "Epoch: 5/100... Training loss: 0.1374\n",
      "Epoch: 5/100... Training loss: 0.1333\n",
      "Epoch: 5/100... Training loss: 0.1351\n",
      "Epoch: 5/100... Training loss: 0.1324\n",
      "Epoch: 5/100... Training loss: 0.1352\n",
      "Epoch: 5/100... Training loss: 0.1374\n",
      "Epoch: 5/100... Training loss: 0.1319\n",
      "Epoch: 5/100... Training loss: 0.1340\n",
      "Epoch: 5/100... Training loss: 0.1399\n",
      "Epoch: 5/100... Training loss: 0.1340\n",
      "Epoch: 5/100... Training loss: 0.1361\n",
      "Epoch: 5/100... Training loss: 0.1352\n",
      "Epoch: 5/100... Training loss: 0.1374\n",
      "Epoch: 5/100... Training loss: 0.1362\n",
      "Epoch: 5/100... Training loss: 0.1351\n",
      "Epoch: 5/100... Training loss: 0.1372\n",
      "Epoch: 5/100... Training loss: 0.1368\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1357\n",
      "Epoch: 5/100... Training loss: 0.1334\n",
      "Epoch: 5/100... Training loss: 0.1337\n",
      "Epoch: 5/100... Training loss: 0.1342\n",
      "Epoch: 5/100... Training loss: 0.1365\n",
      "Epoch: 5/100... Training loss: 0.1387\n",
      "Epoch: 5/100... Training loss: 0.1302\n",
      "Epoch: 5/100... Training loss: 0.1338\n",
      "Epoch: 5/100... Training loss: 0.1335\n",
      "Epoch: 5/100... Training loss: 0.1328\n",
      "Epoch: 5/100... Training loss: 0.1353\n",
      "Epoch: 5/100... Training loss: 0.1364\n",
      "Epoch: 5/100... Training loss: 0.1343\n",
      "Epoch: 5/100... Training loss: 0.1337\n",
      "Epoch: 5/100... Training loss: 0.1342\n",
      "Epoch: 5/100... Training loss: 0.1337\n",
      "Epoch: 5/100... Training loss: 0.1384\n",
      "Epoch: 5/100... Training loss: 0.1349\n",
      "Epoch: 5/100... Training loss: 0.1331\n",
      "Epoch: 5/100... Training loss: 0.1343\n",
      "Epoch: 5/100... Training loss: 0.1305\n",
      "Epoch: 5/100... Training loss: 0.1392\n",
      "Epoch: 5/100... Training loss: 0.1365\n",
      "Epoch: 5/100... Training loss: 0.1350\n",
      "Epoch: 5/100... Training loss: 0.1376\n",
      "Epoch: 5/100... Training loss: 0.1392\n",
      "Epoch: 5/100... Training loss: 0.1313\n",
      "Epoch: 5/100... Training loss: 0.1324\n",
      "Epoch: 5/100... Training loss: 0.1376\n",
      "Epoch: 5/100... Training loss: 0.1318\n",
      "Epoch: 5/100... Training loss: 0.1334\n",
      "Epoch: 5/100... Training loss: 0.1365\n",
      "Epoch: 5/100... Training loss: 0.1394\n",
      "Epoch: 5/100... Training loss: 0.1373\n",
      "Epoch: 5/100... Training loss: 0.1332\n",
      "Epoch: 5/100... Training loss: 0.1309\n",
      "Epoch: 5/100... Training loss: 0.1361\n",
      "Epoch: 5/100... Training loss: 0.1363\n",
      "Epoch: 5/100... Training loss: 0.1338\n",
      "Epoch: 5/100... Training loss: 0.1337\n",
      "Epoch: 5/100... Training loss: 0.1378\n",
      "Epoch: 5/100... Training loss: 0.1344\n",
      "Epoch: 5/100... Training loss: 0.1307\n",
      "Epoch: 5/100... Training loss: 0.1339\n",
      "Epoch: 5/100... Training loss: 0.1357\n",
      "Epoch: 5/100... Training loss: 0.1347\n",
      "Epoch: 5/100... Training loss: 0.1340\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1360\n",
      "Epoch: 5/100... Training loss: 0.1287\n",
      "Epoch: 5/100... Training loss: 0.1327\n",
      "Epoch: 5/100... Training loss: 0.1328\n",
      "Epoch: 5/100... Training loss: 0.1342\n",
      "Epoch: 5/100... Training loss: 0.1320\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1316\n",
      "Epoch: 5/100... Training loss: 0.1303\n",
      "Epoch: 5/100... Training loss: 0.1343\n",
      "Epoch: 5/100... Training loss: 0.1323\n",
      "Epoch: 5/100... Training loss: 0.1390\n",
      "Epoch: 5/100... Training loss: 0.1358\n",
      "Epoch: 5/100... Training loss: 0.1377\n",
      "Epoch: 5/100... Training loss: 0.1347\n",
      "Epoch: 5/100... Training loss: 0.1349\n",
      "Epoch: 5/100... Training loss: 0.1348\n",
      "Epoch: 5/100... Training loss: 0.1292\n",
      "Epoch: 5/100... Training loss: 0.1346\n",
      "Epoch: 5/100... Training loss: 0.1360\n",
      "Epoch: 5/100... Training loss: 0.1327\n",
      "Epoch: 5/100... Training loss: 0.1330\n",
      "Epoch: 5/100... Training loss: 0.1357\n",
      "Epoch: 5/100... Training loss: 0.1346\n",
      "Epoch: 5/100... Training loss: 0.1336\n",
      "Epoch: 5/100... Training loss: 0.1323\n",
      "Epoch: 5/100... Training loss: 0.1333\n",
      "Epoch: 5/100... Training loss: 0.1335\n",
      "Epoch: 5/100... Training loss: 0.1331\n",
      "Epoch: 5/100... Training loss: 0.1314\n",
      "Epoch: 5/100... Training loss: 0.1362\n",
      "Epoch: 5/100... Training loss: 0.1328\n",
      "Epoch: 5/100... Training loss: 0.1380\n",
      "Epoch: 5/100... Training loss: 0.1287\n",
      "Epoch: 5/100... Training loss: 0.1357\n",
      "Epoch: 5/100... Training loss: 0.1341\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1341\n",
      "Epoch: 5/100... Training loss: 0.1346\n",
      "Epoch: 5/100... Training loss: 0.1339\n",
      "Epoch: 5/100... Training loss: 0.1354\n",
      "Epoch: 5/100... Training loss: 0.1324\n",
      "Epoch: 5/100... Training loss: 0.1346\n",
      "Epoch: 5/100... Training loss: 0.1353\n",
      "Epoch: 5/100... Training loss: 0.1349\n",
      "Epoch: 5/100... Training loss: 0.1335\n",
      "Epoch: 5/100... Training loss: 0.1323\n",
      "Epoch: 5/100... Training loss: 0.1322\n",
      "Epoch: 5/100... Training loss: 0.1349\n",
      "Epoch: 5/100... Training loss: 0.1375\n",
      "Epoch: 5/100... Training loss: 0.1325\n",
      "Epoch: 5/100... Training loss: 0.1349\n",
      "Epoch: 5/100... Training loss: 0.1314\n",
      "Epoch: 5/100... Training loss: 0.1347\n",
      "Epoch: 5/100... Training loss: 0.1354\n",
      "Epoch: 5/100... Training loss: 0.1330\n",
      "Epoch: 5/100... Training loss: 0.1329\n",
      "Epoch: 5/100... Training loss: 0.1287\n",
      "Epoch: 5/100... Training loss: 0.1300\n",
      "Epoch: 5/100... Training loss: 0.1318\n",
      "Epoch: 5/100... Training loss: 0.1325\n",
      "Epoch: 5/100... Training loss: 0.1378\n",
      "Epoch: 5/100... Training loss: 0.1345\n",
      "Epoch: 5/100... Training loss: 0.1336\n",
      "Epoch: 5/100... Training loss: 0.1344\n",
      "Epoch: 5/100... Training loss: 0.1361\n",
      "Epoch: 5/100... Training loss: 0.1310\n",
      "Epoch: 5/100... Training loss: 0.1288\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1330\n",
      "Epoch: 5/100... Training loss: 0.1319\n",
      "Epoch: 5/100... Training loss: 0.1349\n",
      "Epoch: 5/100... Training loss: 0.1368\n",
      "Epoch: 5/100... Training loss: 0.1292\n",
      "Epoch: 5/100... Training loss: 0.1389\n",
      "Epoch: 5/100... Training loss: 0.1332\n",
      "Epoch: 5/100... Training loss: 0.1296\n",
      "Epoch: 5/100... Training loss: 0.1310\n",
      "Epoch: 5/100... Training loss: 0.1281\n",
      "Epoch: 5/100... Training loss: 0.1285\n",
      "Epoch: 5/100... Training loss: 0.1328\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1374\n",
      "Epoch: 5/100... Training loss: 0.1323\n",
      "Epoch: 5/100... Training loss: 0.1303\n",
      "Epoch: 5/100... Training loss: 0.1309\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1289\n",
      "Epoch: 5/100... Training loss: 0.1320\n",
      "Epoch: 5/100... Training loss: 0.1274\n",
      "Epoch: 5/100... Training loss: 0.1318\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1312\n",
      "Epoch: 5/100... Training loss: 0.1343\n",
      "Epoch: 5/100... Training loss: 0.1331\n",
      "Epoch: 5/100... Training loss: 0.1291\n",
      "Epoch: 5/100... Training loss: 0.1319\n",
      "Epoch: 5/100... Training loss: 0.1312\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1307\n",
      "Epoch: 5/100... Training loss: 0.1320\n",
      "Epoch: 5/100... Training loss: 0.1316\n",
      "Epoch: 5/100... Training loss: 0.1341\n",
      "Epoch: 5/100... Training loss: 0.1343\n",
      "Epoch: 5/100... Training loss: 0.1272\n",
      "Epoch: 5/100... Training loss: 0.1334\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1278\n",
      "Epoch: 5/100... Training loss: 0.1328\n",
      "Epoch: 5/100... Training loss: 0.1349\n",
      "Epoch: 5/100... Training loss: 0.1305\n",
      "Epoch: 5/100... Training loss: 0.1310\n",
      "Epoch: 5/100... Training loss: 0.1343\n",
      "Epoch: 5/100... Training loss: 0.1367\n",
      "Epoch: 5/100... Training loss: 0.1319\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1263\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1372\n",
      "Epoch: 5/100... Training loss: 0.1358\n",
      "Epoch: 5/100... Training loss: 0.1305\n",
      "Epoch: 5/100... Training loss: 0.1330\n",
      "Epoch: 5/100... Training loss: 0.1374\n",
      "Epoch: 5/100... Training loss: 0.1309\n",
      "Epoch: 5/100... Training loss: 0.1241\n",
      "Epoch: 5/100... Training loss: 0.1338\n",
      "Epoch: 5/100... Training loss: 0.1323\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1326\n",
      "Epoch: 5/100... Training loss: 0.1300\n",
      "Epoch: 5/100... Training loss: 0.1354\n",
      "Epoch: 5/100... Training loss: 0.1293\n",
      "Epoch: 5/100... Training loss: 0.1323\n",
      "Epoch: 5/100... Training loss: 0.1342\n",
      "Epoch: 5/100... Training loss: 0.1284\n",
      "Epoch: 5/100... Training loss: 0.1353\n",
      "Epoch: 5/100... Training loss: 0.1321\n",
      "Epoch: 5/100... Training loss: 0.1365\n",
      "Epoch: 5/100... Training loss: 0.1322\n",
      "Epoch: 5/100... Training loss: 0.1297\n",
      "Epoch: 5/100... Training loss: 0.1361\n",
      "Epoch: 5/100... Training loss: 0.1321\n",
      "Epoch: 5/100... Training loss: 0.1353\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1345\n",
      "Epoch: 5/100... Training loss: 0.1377\n",
      "Epoch: 5/100... Training loss: 0.1336\n",
      "Epoch: 5/100... Training loss: 0.1310\n",
      "Epoch: 5/100... Training loss: 0.1316\n",
      "Epoch: 5/100... Training loss: 0.1275\n",
      "Epoch: 5/100... Training loss: 0.1322\n",
      "Epoch: 5/100... Training loss: 0.1335\n",
      "Epoch: 5/100... Training loss: 0.1320\n",
      "Epoch: 5/100... Training loss: 0.1279\n",
      "Epoch: 5/100... Training loss: 0.1307\n",
      "Epoch: 5/100... Training loss: 0.1320\n",
      "Epoch: 5/100... Training loss: 0.1355\n",
      "Epoch: 5/100... Training loss: 0.1342\n",
      "Epoch: 5/100... Training loss: 0.1288\n",
      "Epoch: 5/100... Training loss: 0.1293\n",
      "Epoch: 5/100... Training loss: 0.1298\n",
      "Epoch: 5/100... Training loss: 0.1283\n",
      "Epoch: 5/100... Training loss: 0.1313\n",
      "Epoch: 5/100... Training loss: 0.1314\n",
      "Epoch: 5/100... Training loss: 0.1312\n",
      "Epoch: 5/100... Training loss: 0.1299\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1343\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1334\n",
      "Epoch: 5/100... Training loss: 0.1367\n",
      "Epoch: 5/100... Training loss: 0.1312\n",
      "Epoch: 5/100... Training loss: 0.1318\n",
      "Epoch: 5/100... Training loss: 0.1335\n",
      "Epoch: 5/100... Training loss: 0.1302\n",
      "Epoch: 5/100... Training loss: 0.1325\n",
      "Epoch: 5/100... Training loss: 0.1267\n",
      "Epoch: 5/100... Training loss: 0.1316\n",
      "Epoch: 5/100... Training loss: 0.1320\n",
      "Epoch: 5/100... Training loss: 0.1247\n",
      "Epoch: 5/100... Training loss: 0.1295\n",
      "Epoch: 5/100... Training loss: 0.1318\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1309\n",
      "Epoch: 5/100... Training loss: 0.1315\n",
      "Epoch: 5/100... Training loss: 0.1307\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1339\n",
      "Epoch: 5/100... Training loss: 0.1329\n",
      "Epoch: 5/100... Training loss: 0.1320\n",
      "Epoch: 5/100... Training loss: 0.1335\n",
      "Epoch: 5/100... Training loss: 0.1234\n",
      "Epoch: 5/100... Training loss: 0.1287\n",
      "Epoch: 5/100... Training loss: 0.1334\n",
      "Epoch: 5/100... Training loss: 0.1293\n",
      "Epoch: 5/100... Training loss: 0.1297\n",
      "Epoch: 5/100... Training loss: 0.1335\n",
      "Epoch: 5/100... Training loss: 0.1222\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1292\n",
      "Epoch: 5/100... Training loss: 0.1317\n",
      "Epoch: 5/100... Training loss: 0.1304\n",
      "Epoch: 5/100... Training loss: 0.1276\n",
      "Epoch: 5/100... Training loss: 0.1268\n",
      "Epoch: 5/100... Training loss: 0.1308\n",
      "Epoch: 5/100... Training loss: 0.1337\n",
      "Epoch: 5/100... Training loss: 0.1340\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1309\n",
      "Epoch: 5/100... Training loss: 0.1285\n",
      "Epoch: 5/100... Training loss: 0.1304\n",
      "Epoch: 5/100... Training loss: 0.1320\n",
      "Epoch: 5/100... Training loss: 0.1309\n",
      "Epoch: 5/100... Training loss: 0.1318\n",
      "Epoch: 5/100... Training loss: 0.1299\n",
      "Epoch: 5/100... Training loss: 0.1290\n",
      "Epoch: 5/100... Training loss: 0.1340\n",
      "Epoch: 5/100... Training loss: 0.1289\n",
      "Epoch: 5/100... Training loss: 0.1260\n",
      "Epoch: 5/100... Training loss: 0.1277\n",
      "Epoch: 5/100... Training loss: 0.1329\n",
      "Epoch: 5/100... Training loss: 0.1280\n",
      "Epoch: 5/100... Training loss: 0.1325\n",
      "Epoch: 5/100... Training loss: 0.1311\n",
      "Epoch: 5/100... Training loss: 0.1322\n",
      "Epoch: 5/100... Training loss: 0.1306\n",
      "Epoch: 5/100... Training loss: 0.1324\n",
      "Epoch: 5/100... Training loss: 0.1294\n",
      "Epoch: 5/100... Training loss: 0.1324\n",
      "Epoch: 5/100... Training loss: 0.1330\n",
      "Epoch: 6/100... Training loss: 0.1325\n",
      "Epoch: 6/100... Training loss: 0.1331\n",
      "Epoch: 6/100... Training loss: 0.1322\n",
      "Epoch: 6/100... Training loss: 0.1366\n",
      "Epoch: 6/100... Training loss: 0.1309\n",
      "Epoch: 6/100... Training loss: 0.1312\n",
      "Epoch: 6/100... Training loss: 0.1326\n",
      "Epoch: 6/100... Training loss: 0.1345\n",
      "Epoch: 6/100... Training loss: 0.1297\n",
      "Epoch: 6/100... Training loss: 0.1258\n",
      "Epoch: 6/100... Training loss: 0.1270\n",
      "Epoch: 6/100... Training loss: 0.1316\n",
      "Epoch: 6/100... Training loss: 0.1310\n",
      "Epoch: 6/100... Training loss: 0.1341\n",
      "Epoch: 6/100... Training loss: 0.1279\n",
      "Epoch: 6/100... Training loss: 0.1324\n",
      "Epoch: 6/100... Training loss: 0.1327\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1303\n",
      "Epoch: 6/100... Training loss: 0.1316\n",
      "Epoch: 6/100... Training loss: 0.1298\n",
      "Epoch: 6/100... Training loss: 0.1275\n",
      "Epoch: 6/100... Training loss: 0.1320\n",
      "Epoch: 6/100... Training loss: 0.1311\n",
      "Epoch: 6/100... Training loss: 0.1290\n",
      "Epoch: 6/100... Training loss: 0.1306\n",
      "Epoch: 6/100... Training loss: 0.1349\n",
      "Epoch: 6/100... Training loss: 0.1276\n",
      "Epoch: 6/100... Training loss: 0.1314\n",
      "Epoch: 6/100... Training loss: 0.1359\n",
      "Epoch: 6/100... Training loss: 0.1337\n",
      "Epoch: 6/100... Training loss: 0.1295\n",
      "Epoch: 6/100... Training loss: 0.1401\n",
      "Epoch: 6/100... Training loss: 0.1341\n",
      "Epoch: 6/100... Training loss: 0.1318\n",
      "Epoch: 6/100... Training loss: 0.1323\n",
      "Epoch: 6/100... Training loss: 0.1338\n",
      "Epoch: 6/100... Training loss: 0.1302\n",
      "Epoch: 6/100... Training loss: 0.1270\n",
      "Epoch: 6/100... Training loss: 0.1260\n",
      "Epoch: 6/100... Training loss: 0.1245\n",
      "Epoch: 6/100... Training loss: 0.1355\n",
      "Epoch: 6/100... Training loss: 0.1302\n",
      "Epoch: 6/100... Training loss: 0.1334\n",
      "Epoch: 6/100... Training loss: 0.1324\n",
      "Epoch: 6/100... Training loss: 0.1293\n",
      "Epoch: 6/100... Training loss: 0.1294\n",
      "Epoch: 6/100... Training loss: 0.1277\n",
      "Epoch: 6/100... Training loss: 0.1304\n",
      "Epoch: 6/100... Training loss: 0.1271\n",
      "Epoch: 6/100... Training loss: 0.1305\n",
      "Epoch: 6/100... Training loss: 0.1314\n",
      "Epoch: 6/100... Training loss: 0.1292\n",
      "Epoch: 6/100... Training loss: 0.1269\n",
      "Epoch: 6/100... Training loss: 0.1309\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1308\n",
      "Epoch: 6/100... Training loss: 0.1307\n",
      "Epoch: 6/100... Training loss: 0.1342\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1283\n",
      "Epoch: 6/100... Training loss: 0.1308\n",
      "Epoch: 6/100... Training loss: 0.1306\n",
      "Epoch: 6/100... Training loss: 0.1293\n",
      "Epoch: 6/100... Training loss: 0.1313\n",
      "Epoch: 6/100... Training loss: 0.1310\n",
      "Epoch: 6/100... Training loss: 0.1217\n",
      "Epoch: 6/100... Training loss: 0.1358\n",
      "Epoch: 6/100... Training loss: 0.1274\n",
      "Epoch: 6/100... Training loss: 0.1274\n",
      "Epoch: 6/100... Training loss: 0.1299\n",
      "Epoch: 6/100... Training loss: 0.1323\n",
      "Epoch: 6/100... Training loss: 0.1328\n",
      "Epoch: 6/100... Training loss: 0.1275\n",
      "Epoch: 6/100... Training loss: 0.1301\n",
      "Epoch: 6/100... Training loss: 0.1314\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1298\n",
      "Epoch: 6/100... Training loss: 0.1302\n",
      "Epoch: 6/100... Training loss: 0.1266\n",
      "Epoch: 6/100... Training loss: 0.1302\n",
      "Epoch: 6/100... Training loss: 0.1311\n",
      "Epoch: 6/100... Training loss: 0.1315\n",
      "Epoch: 6/100... Training loss: 0.1269\n",
      "Epoch: 6/100... Training loss: 0.1266\n",
      "Epoch: 6/100... Training loss: 0.1342\n",
      "Epoch: 6/100... Training loss: 0.1314\n",
      "Epoch: 6/100... Training loss: 0.1291\n",
      "Epoch: 6/100... Training loss: 0.1291\n",
      "Epoch: 6/100... Training loss: 0.1303\n",
      "Epoch: 6/100... Training loss: 0.1305\n",
      "Epoch: 6/100... Training loss: 0.1359\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1318\n",
      "Epoch: 6/100... Training loss: 0.1276\n",
      "Epoch: 6/100... Training loss: 0.1284\n",
      "Epoch: 6/100... Training loss: 0.1305\n",
      "Epoch: 6/100... Training loss: 0.1280\n",
      "Epoch: 6/100... Training loss: 0.1267\n",
      "Epoch: 6/100... Training loss: 0.1295\n",
      "Epoch: 6/100... Training loss: 0.1290\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1327\n",
      "Epoch: 6/100... Training loss: 0.1267\n",
      "Epoch: 6/100... Training loss: 0.1340\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1329\n",
      "Epoch: 6/100... Training loss: 0.1334\n",
      "Epoch: 6/100... Training loss: 0.1293\n",
      "Epoch: 6/100... Training loss: 0.1279\n",
      "Epoch: 6/100... Training loss: 0.1294\n",
      "Epoch: 6/100... Training loss: 0.1292\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1282\n",
      "Epoch: 6/100... Training loss: 0.1292\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1266\n",
      "Epoch: 6/100... Training loss: 0.1310\n",
      "Epoch: 6/100... Training loss: 0.1272\n",
      "Epoch: 6/100... Training loss: 0.1301\n",
      "Epoch: 6/100... Training loss: 0.1256\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1291\n",
      "Epoch: 6/100... Training loss: 0.1260\n",
      "Epoch: 6/100... Training loss: 0.1314\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1301\n",
      "Epoch: 6/100... Training loss: 0.1273\n",
      "Epoch: 6/100... Training loss: 0.1292\n",
      "Epoch: 6/100... Training loss: 0.1283\n",
      "Epoch: 6/100... Training loss: 0.1298\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1247\n",
      "Epoch: 6/100... Training loss: 0.1279\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1297\n",
      "Epoch: 6/100... Training loss: 0.1333\n",
      "Epoch: 6/100... Training loss: 0.1337\n",
      "Epoch: 6/100... Training loss: 0.1331\n",
      "Epoch: 6/100... Training loss: 0.1298\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1274\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1259\n",
      "Epoch: 6/100... Training loss: 0.1266\n",
      "Epoch: 6/100... Training loss: 0.1278\n",
      "Epoch: 6/100... Training loss: 0.1307\n",
      "Epoch: 6/100... Training loss: 0.1274\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1284\n",
      "Epoch: 6/100... Training loss: 0.1292\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1246\n",
      "Epoch: 6/100... Training loss: 0.1316\n",
      "Epoch: 6/100... Training loss: 0.1273\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1326\n",
      "Epoch: 6/100... Training loss: 0.1317\n",
      "Epoch: 6/100... Training loss: 0.1314\n",
      "Epoch: 6/100... Training loss: 0.1327\n",
      "Epoch: 6/100... Training loss: 0.1283\n",
      "Epoch: 6/100... Training loss: 0.1296\n",
      "Epoch: 6/100... Training loss: 0.1227\n",
      "Epoch: 6/100... Training loss: 0.1278\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1289\n",
      "Epoch: 6/100... Training loss: 0.1273\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1304\n",
      "Epoch: 6/100... Training loss: 0.1281\n",
      "Epoch: 6/100... Training loss: 0.1276\n",
      "Epoch: 6/100... Training loss: 0.1279\n",
      "Epoch: 6/100... Training loss: 0.1233\n",
      "Epoch: 6/100... Training loss: 0.1275\n",
      "Epoch: 6/100... Training loss: 0.1288\n",
      "Epoch: 6/100... Training loss: 0.1187\n",
      "Epoch: 6/100... Training loss: 0.1286\n",
      "Epoch: 6/100... Training loss: 0.1304\n",
      "Epoch: 6/100... Training loss: 0.1261\n",
      "Epoch: 6/100... Training loss: 0.1292\n",
      "Epoch: 6/100... Training loss: 0.1274\n",
      "Epoch: 6/100... Training loss: 0.1294\n",
      "Epoch: 6/100... Training loss: 0.1278\n",
      "Epoch: 6/100... Training loss: 0.1259\n",
      "Epoch: 6/100... Training loss: 0.1277\n",
      "Epoch: 6/100... Training loss: 0.1294\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1286\n",
      "Epoch: 6/100... Training loss: 0.1273\n",
      "Epoch: 6/100... Training loss: 0.1267\n",
      "Epoch: 6/100... Training loss: 0.1251\n",
      "Epoch: 6/100... Training loss: 0.1258\n",
      "Epoch: 6/100... Training loss: 0.1298\n",
      "Epoch: 6/100... Training loss: 0.1292\n",
      "Epoch: 6/100... Training loss: 0.1279\n",
      "Epoch: 6/100... Training loss: 0.1309\n",
      "Epoch: 6/100... Training loss: 0.1267\n",
      "Epoch: 6/100... Training loss: 0.1267\n",
      "Epoch: 6/100... Training loss: 0.1251\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1324\n",
      "Epoch: 6/100... Training loss: 0.1273\n",
      "Epoch: 6/100... Training loss: 0.1286\n",
      "Epoch: 6/100... Training loss: 0.1308\n",
      "Epoch: 6/100... Training loss: 0.1286\n",
      "Epoch: 6/100... Training loss: 0.1282\n",
      "Epoch: 6/100... Training loss: 0.1316\n",
      "Epoch: 6/100... Training loss: 0.1261\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1328\n",
      "Epoch: 6/100... Training loss: 0.1281\n",
      "Epoch: 6/100... Training loss: 0.1301\n",
      "Epoch: 6/100... Training loss: 0.1234\n",
      "Epoch: 6/100... Training loss: 0.1290\n",
      "Epoch: 6/100... Training loss: 0.1268\n",
      "Epoch: 6/100... Training loss: 0.1287\n",
      "Epoch: 6/100... Training loss: 0.1301\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1276\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1326\n",
      "Epoch: 6/100... Training loss: 0.1254\n",
      "Epoch: 6/100... Training loss: 0.1254\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1282\n",
      "Epoch: 6/100... Training loss: 0.1260\n",
      "Epoch: 6/100... Training loss: 0.1311\n",
      "Epoch: 6/100... Training loss: 0.1264\n",
      "Epoch: 6/100... Training loss: 0.1304\n",
      "Epoch: 6/100... Training loss: 0.1288\n",
      "Epoch: 6/100... Training loss: 0.1281\n",
      "Epoch: 6/100... Training loss: 0.1330\n",
      "Epoch: 6/100... Training loss: 0.1285\n",
      "Epoch: 6/100... Training loss: 0.1279\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1245\n",
      "Epoch: 6/100... Training loss: 0.1270\n",
      "Epoch: 6/100... Training loss: 0.1282\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1276\n",
      "Epoch: 6/100... Training loss: 0.1272\n",
      "Epoch: 6/100... Training loss: 0.1261\n",
      "Epoch: 6/100... Training loss: 0.1298\n",
      "Epoch: 6/100... Training loss: 0.1274\n",
      "Epoch: 6/100... Training loss: 0.1308\n",
      "Epoch: 6/100... Training loss: 0.1286\n",
      "Epoch: 6/100... Training loss: 0.1274\n",
      "Epoch: 6/100... Training loss: 0.1303\n",
      "Epoch: 6/100... Training loss: 0.1270\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1235\n",
      "Epoch: 6/100... Training loss: 0.1284\n",
      "Epoch: 6/100... Training loss: 0.1314\n",
      "Epoch: 6/100... Training loss: 0.1280\n",
      "Epoch: 6/100... Training loss: 0.1263\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1282\n",
      "Epoch: 6/100... Training loss: 0.1254\n",
      "Epoch: 6/100... Training loss: 0.1296\n",
      "Epoch: 6/100... Training loss: 0.1244\n",
      "Epoch: 6/100... Training loss: 0.1266\n",
      "Epoch: 6/100... Training loss: 0.1259\n",
      "Epoch: 6/100... Training loss: 0.1277\n",
      "Epoch: 6/100... Training loss: 0.1286\n",
      "Epoch: 6/100... Training loss: 0.1247\n",
      "Epoch: 6/100... Training loss: 0.1273\n",
      "Epoch: 6/100... Training loss: 0.1261\n",
      "Epoch: 6/100... Training loss: 0.1271\n",
      "Epoch: 6/100... Training loss: 0.1295\n",
      "Epoch: 6/100... Training loss: 0.1295\n",
      "Epoch: 6/100... Training loss: 0.1283\n",
      "Epoch: 6/100... Training loss: 0.1260\n",
      "Epoch: 6/100... Training loss: 0.1266\n",
      "Epoch: 6/100... Training loss: 0.1257\n",
      "Epoch: 6/100... Training loss: 0.1318\n",
      "Epoch: 6/100... Training loss: 0.1255\n",
      "Epoch: 6/100... Training loss: 0.1228\n",
      "Epoch: 6/100... Training loss: 0.1222\n",
      "Epoch: 6/100... Training loss: 0.1281\n",
      "Epoch: 6/100... Training loss: 0.1248\n",
      "Epoch: 6/100... Training loss: 0.1236\n",
      "Epoch: 6/100... Training loss: 0.1270\n",
      "Epoch: 6/100... Training loss: 0.1252\n",
      "Epoch: 6/100... Training loss: 0.1265\n",
      "Epoch: 6/100... Training loss: 0.1262\n",
      "Epoch: 6/100... Training loss: 0.1242\n",
      "Epoch: 6/100... Training loss: 0.1249\n",
      "Epoch: 6/100... Training loss: 0.1232\n",
      "Epoch: 6/100... Training loss: 0.1253\n",
      "Epoch: 6/100... Training loss: 0.1241\n",
      "Epoch: 6/100... Training loss: 0.1269\n",
      "Epoch: 6/100... Training loss: 0.1278\n",
      "Epoch: 7/100... Training loss: 0.1295\n",
      "Epoch: 7/100... Training loss: 0.1257\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1266\n",
      "Epoch: 7/100... Training loss: 0.1286\n",
      "Epoch: 7/100... Training loss: 0.1264\n",
      "Epoch: 7/100... Training loss: 0.1242\n",
      "Epoch: 7/100... Training loss: 0.1265\n",
      "Epoch: 7/100... Training loss: 0.1251\n",
      "Epoch: 7/100... Training loss: 0.1271\n",
      "Epoch: 7/100... Training loss: 0.1267\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1286\n",
      "Epoch: 7/100... Training loss: 0.1280\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1287\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1281\n",
      "Epoch: 7/100... Training loss: 0.1309\n",
      "Epoch: 7/100... Training loss: 0.1267\n",
      "Epoch: 7/100... Training loss: 0.1259\n",
      "Epoch: 7/100... Training loss: 0.1276\n",
      "Epoch: 7/100... Training loss: 0.1256\n",
      "Epoch: 7/100... Training loss: 0.1259\n",
      "Epoch: 7/100... Training loss: 0.1302\n",
      "Epoch: 7/100... Training loss: 0.1271\n",
      "Epoch: 7/100... Training loss: 0.1241\n",
      "Epoch: 7/100... Training loss: 0.1300\n",
      "Epoch: 7/100... Training loss: 0.1286\n",
      "Epoch: 7/100... Training loss: 0.1264\n",
      "Epoch: 7/100... Training loss: 0.1278\n",
      "Epoch: 7/100... Training loss: 0.1323\n",
      "Epoch: 7/100... Training loss: 0.1256\n",
      "Epoch: 7/100... Training loss: 0.1254\n",
      "Epoch: 7/100... Training loss: 0.1258\n",
      "Epoch: 7/100... Training loss: 0.1277\n",
      "Epoch: 7/100... Training loss: 0.1296\n",
      "Epoch: 7/100... Training loss: 0.1295\n",
      "Epoch: 7/100... Training loss: 0.1263\n",
      "Epoch: 7/100... Training loss: 0.1300\n",
      "Epoch: 7/100... Training loss: 0.1261\n",
      "Epoch: 7/100... Training loss: 0.1284\n",
      "Epoch: 7/100... Training loss: 0.1247\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1250\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1261\n",
      "Epoch: 7/100... Training loss: 0.1252\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1222\n",
      "Epoch: 7/100... Training loss: 0.1285\n",
      "Epoch: 7/100... Training loss: 0.1267\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1288\n",
      "Epoch: 7/100... Training loss: 0.1245\n",
      "Epoch: 7/100... Training loss: 0.1285\n",
      "Epoch: 7/100... Training loss: 0.1247\n",
      "Epoch: 7/100... Training loss: 0.1268\n",
      "Epoch: 7/100... Training loss: 0.1270\n",
      "Epoch: 7/100... Training loss: 0.1314\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1220\n",
      "Epoch: 7/100... Training loss: 0.1248\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1255\n",
      "Epoch: 7/100... Training loss: 0.1248\n",
      "Epoch: 7/100... Training loss: 0.1237\n",
      "Epoch: 7/100... Training loss: 0.1254\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1252\n",
      "Epoch: 7/100... Training loss: 0.1279\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1282\n",
      "Epoch: 7/100... Training loss: 0.1269\n",
      "Epoch: 7/100... Training loss: 0.1243\n",
      "Epoch: 7/100... Training loss: 0.1290\n",
      "Epoch: 7/100... Training loss: 0.1302\n",
      "Epoch: 7/100... Training loss: 0.1280\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1259\n",
      "Epoch: 7/100... Training loss: 0.1276\n",
      "Epoch: 7/100... Training loss: 0.1264\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1247\n",
      "Epoch: 7/100... Training loss: 0.1260\n",
      "Epoch: 7/100... Training loss: 0.1275\n",
      "Epoch: 7/100... Training loss: 0.1271\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1282\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1277\n",
      "Epoch: 7/100... Training loss: 0.1230\n",
      "Epoch: 7/100... Training loss: 0.1279\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1294\n",
      "Epoch: 7/100... Training loss: 0.1241\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1280\n",
      "Epoch: 7/100... Training loss: 0.1267\n",
      "Epoch: 7/100... Training loss: 0.1297\n",
      "Epoch: 7/100... Training loss: 0.1263\n",
      "Epoch: 7/100... Training loss: 0.1270\n",
      "Epoch: 7/100... Training loss: 0.1266\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1251\n",
      "Epoch: 7/100... Training loss: 0.1307\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1278\n",
      "Epoch: 7/100... Training loss: 0.1278\n",
      "Epoch: 7/100... Training loss: 0.1253\n",
      "Epoch: 7/100... Training loss: 0.1245\n",
      "Epoch: 7/100... Training loss: 0.1247\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1268\n",
      "Epoch: 7/100... Training loss: 0.1252\n",
      "Epoch: 7/100... Training loss: 0.1288\n",
      "Epoch: 7/100... Training loss: 0.1237\n",
      "Epoch: 7/100... Training loss: 0.1250\n",
      "Epoch: 7/100... Training loss: 0.1242\n",
      "Epoch: 7/100... Training loss: 0.1209\n",
      "Epoch: 7/100... Training loss: 0.1216\n",
      "Epoch: 7/100... Training loss: 0.1256\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1237\n",
      "Epoch: 7/100... Training loss: 0.1248\n",
      "Epoch: 7/100... Training loss: 0.1266\n",
      "Epoch: 7/100... Training loss: 0.1253\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1289\n",
      "Epoch: 7/100... Training loss: 0.1260\n",
      "Epoch: 7/100... Training loss: 0.1290\n",
      "Epoch: 7/100... Training loss: 0.1264\n",
      "Epoch: 7/100... Training loss: 0.1312\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1273\n",
      "Epoch: 7/100... Training loss: 0.1279\n",
      "Epoch: 7/100... Training loss: 0.1252\n",
      "Epoch: 7/100... Training loss: 0.1280\n",
      "Epoch: 7/100... Training loss: 0.1281\n",
      "Epoch: 7/100... Training loss: 0.1272\n",
      "Epoch: 7/100... Training loss: 0.1227\n",
      "Epoch: 7/100... Training loss: 0.1280\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1264\n",
      "Epoch: 7/100... Training loss: 0.1223\n",
      "Epoch: 7/100... Training loss: 0.1275\n",
      "Epoch: 7/100... Training loss: 0.1275\n",
      "Epoch: 7/100... Training loss: 0.1237\n",
      "Epoch: 7/100... Training loss: 0.1288\n",
      "Epoch: 7/100... Training loss: 0.1201\n",
      "Epoch: 7/100... Training loss: 0.1275\n",
      "Epoch: 7/100... Training loss: 0.1269\n",
      "Epoch: 7/100... Training loss: 0.1291\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 7/100... Training loss: 0.1277\n",
      "Epoch: 7/100... Training loss: 0.1261\n",
      "Epoch: 7/100... Training loss: 0.1254\n",
      "Epoch: 7/100... Training loss: 0.1219\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1247\n",
      "Epoch: 7/100... Training loss: 0.1280\n",
      "Epoch: 7/100... Training loss: 0.1261\n",
      "Epoch: 7/100... Training loss: 0.1242\n",
      "Epoch: 7/100... Training loss: 0.1248\n",
      "Epoch: 7/100... Training loss: 0.1281\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1270\n",
      "Epoch: 7/100... Training loss: 0.1292\n",
      "Epoch: 7/100... Training loss: 0.1280\n",
      "Epoch: 7/100... Training loss: 0.1244\n",
      "Epoch: 7/100... Training loss: 0.1263\n",
      "Epoch: 7/100... Training loss: 0.1258\n",
      "Epoch: 7/100... Training loss: 0.1258\n",
      "Epoch: 7/100... Training loss: 0.1276\n",
      "Epoch: 7/100... Training loss: 0.1175\n",
      "Epoch: 7/100... Training loss: 0.1231\n",
      "Epoch: 7/100... Training loss: 0.1275\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1243\n",
      "Epoch: 7/100... Training loss: 0.1245\n",
      "Epoch: 7/100... Training loss: 0.1275\n",
      "Epoch: 7/100... Training loss: 0.1255\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1218\n",
      "Epoch: 7/100... Training loss: 0.1251\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1248\n",
      "Epoch: 7/100... Training loss: 0.1276\n",
      "Epoch: 7/100... Training loss: 0.1259\n",
      "Epoch: 7/100... Training loss: 0.1259\n",
      "Epoch: 7/100... Training loss: 0.1250\n",
      "Epoch: 7/100... Training loss: 0.1214\n",
      "Epoch: 7/100... Training loss: 0.1255\n",
      "Epoch: 7/100... Training loss: 0.1250\n",
      "Epoch: 7/100... Training loss: 0.1200\n",
      "Epoch: 7/100... Training loss: 0.1251\n",
      "Epoch: 7/100... Training loss: 0.1273\n",
      "Epoch: 7/100... Training loss: 0.1270\n",
      "Epoch: 7/100... Training loss: 0.1236\n",
      "Epoch: 7/100... Training loss: 0.1257\n",
      "Epoch: 7/100... Training loss: 0.1250\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1233\n",
      "Epoch: 7/100... Training loss: 0.1165\n",
      "Epoch: 7/100... Training loss: 0.1249\n",
      "Epoch: 7/100... Training loss: 0.1240\n",
      "Epoch: 7/100... Training loss: 0.1300\n",
      "Epoch: 7/100... Training loss: 0.1279\n",
      "Epoch: 7/100... Training loss: 0.1263\n",
      "Epoch: 7/100... Training loss: 0.1242\n",
      "Epoch: 7/100... Training loss: 0.1204\n",
      "Epoch: 7/100... Training loss: 0.1286\n",
      "Epoch: 7/100... Training loss: 0.1255\n",
      "Epoch: 7/100... Training loss: 0.1265\n",
      "Epoch: 7/100... Training loss: 0.1266\n",
      "Epoch: 7/100... Training loss: 0.1226\n",
      "Epoch: 7/100... Training loss: 0.1245\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1254\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1298\n",
      "Epoch: 7/100... Training loss: 0.1287\n",
      "Epoch: 7/100... Training loss: 0.1196\n",
      "Epoch: 7/100... Training loss: 0.1234\n",
      "Epoch: 7/100... Training loss: 0.1273\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1266\n",
      "Epoch: 7/100... Training loss: 0.1182\n",
      "Epoch: 7/100... Training loss: 0.1246\n",
      "Epoch: 7/100... Training loss: 0.1270\n",
      "Epoch: 7/100... Training loss: 0.1263\n",
      "Epoch: 7/100... Training loss: 0.1248\n",
      "Epoch: 7/100... Training loss: 0.1237\n",
      "Epoch: 7/100... Training loss: 0.1268\n",
      "Epoch: 7/100... Training loss: 0.1232\n",
      "Epoch: 7/100... Training loss: 0.1224\n",
      "Epoch: 7/100... Training loss: 0.1271\n",
      "Epoch: 7/100... Training loss: 0.1238\n",
      "Epoch: 7/100... Training loss: 0.1293\n",
      "Epoch: 7/100... Training loss: 0.1254\n",
      "Epoch: 7/100... Training loss: 0.1254\n",
      "Epoch: 7/100... Training loss: 0.1198\n",
      "Epoch: 7/100... Training loss: 0.1244\n",
      "Epoch: 7/100... Training loss: 0.1238\n",
      "Epoch: 7/100... Training loss: 0.1206\n",
      "Epoch: 7/100... Training loss: 0.1299\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1248\n",
      "Epoch: 7/100... Training loss: 0.1236\n",
      "Epoch: 7/100... Training loss: 0.1260\n",
      "Epoch: 7/100... Training loss: 0.1267\n",
      "Epoch: 7/100... Training loss: 0.1245\n",
      "Epoch: 7/100... Training loss: 0.1211\n",
      "Epoch: 7/100... Training loss: 0.1231\n",
      "Epoch: 7/100... Training loss: 0.1208\n",
      "Epoch: 7/100... Training loss: 0.1253\n",
      "Epoch: 7/100... Training loss: 0.1256\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1284\n",
      "Epoch: 7/100... Training loss: 0.1217\n",
      "Epoch: 7/100... Training loss: 0.1241\n",
      "Epoch: 7/100... Training loss: 0.1260\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1250\n",
      "Epoch: 7/100... Training loss: 0.1258\n",
      "Epoch: 7/100... Training loss: 0.1218\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1301\n",
      "Epoch: 7/100... Training loss: 0.1193\n",
      "Epoch: 7/100... Training loss: 0.1264\n",
      "Epoch: 7/100... Training loss: 0.1246\n",
      "Epoch: 7/100... Training loss: 0.1239\n",
      "Epoch: 7/100... Training loss: 0.1262\n",
      "Epoch: 7/100... Training loss: 0.1261\n",
      "Epoch: 7/100... Training loss: 0.1244\n",
      "Epoch: 7/100... Training loss: 0.1223\n",
      "Epoch: 7/100... Training loss: 0.1243\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1207\n",
      "Epoch: 7/100... Training loss: 0.1212\n",
      "Epoch: 7/100... Training loss: 0.1267\n",
      "Epoch: 7/100... Training loss: 0.1248\n",
      "Epoch: 7/100... Training loss: 0.1258\n",
      "Epoch: 7/100... Training loss: 0.1235\n",
      "Epoch: 7/100... Training loss: 0.1225\n",
      "Epoch: 7/100... Training loss: 0.1266\n",
      "Epoch: 7/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1263\n",
      "Epoch: 8/100... Training loss: 0.1233\n",
      "Epoch: 8/100... Training loss: 0.1221\n",
      "Epoch: 8/100... Training loss: 0.1275\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1304\n",
      "Epoch: 8/100... Training loss: 0.1245\n",
      "Epoch: 8/100... Training loss: 0.1257\n",
      "Epoch: 8/100... Training loss: 0.1257\n",
      "Epoch: 8/100... Training loss: 0.1260\n",
      "Epoch: 8/100... Training loss: 0.1253\n",
      "Epoch: 8/100... Training loss: 0.1288\n",
      "Epoch: 8/100... Training loss: 0.1260\n",
      "Epoch: 8/100... Training loss: 0.1272\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1263\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1259\n",
      "Epoch: 8/100... Training loss: 0.1219\n",
      "Epoch: 8/100... Training loss: 0.1263\n",
      "Epoch: 8/100... Training loss: 0.1231\n",
      "Epoch: 8/100... Training loss: 0.1247\n",
      "Epoch: 8/100... Training loss: 0.1215\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1258\n",
      "Epoch: 8/100... Training loss: 0.1241\n",
      "Epoch: 8/100... Training loss: 0.1237\n",
      "Epoch: 8/100... Training loss: 0.1272\n",
      "Epoch: 8/100... Training loss: 0.1244\n",
      "Epoch: 8/100... Training loss: 0.1261\n",
      "Epoch: 8/100... Training loss: 0.1284\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1265\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1239\n",
      "Epoch: 8/100... Training loss: 0.1232\n",
      "Epoch: 8/100... Training loss: 0.1302\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1216\n",
      "Epoch: 8/100... Training loss: 0.1222\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1270\n",
      "Epoch: 8/100... Training loss: 0.1210\n",
      "Epoch: 8/100... Training loss: 0.1264\n",
      "Epoch: 8/100... Training loss: 0.1254\n",
      "Epoch: 8/100... Training loss: 0.1235\n",
      "Epoch: 8/100... Training loss: 0.1213\n",
      "Epoch: 8/100... Training loss: 0.1241\n",
      "Epoch: 8/100... Training loss: 0.1220\n",
      "Epoch: 8/100... Training loss: 0.1219\n",
      "Epoch: 8/100... Training loss: 0.1223\n",
      "Epoch: 8/100... Training loss: 0.1223\n",
      "Epoch: 8/100... Training loss: 0.1256\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1247\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1220\n",
      "Epoch: 8/100... Training loss: 0.1230\n",
      "Epoch: 8/100... Training loss: 0.1234\n",
      "Epoch: 8/100... Training loss: 0.1260\n",
      "Epoch: 8/100... Training loss: 0.1237\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1301\n",
      "Epoch: 8/100... Training loss: 0.1219\n",
      "Epoch: 8/100... Training loss: 0.1262\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1239\n",
      "Epoch: 8/100... Training loss: 0.1253\n",
      "Epoch: 8/100... Training loss: 0.1228\n",
      "Epoch: 8/100... Training loss: 0.1223\n",
      "Epoch: 8/100... Training loss: 0.1266\n",
      "Epoch: 8/100... Training loss: 0.1297\n",
      "Epoch: 8/100... Training loss: 0.1254\n",
      "Epoch: 8/100... Training loss: 0.1196\n",
      "Epoch: 8/100... Training loss: 0.1237\n",
      "Epoch: 8/100... Training loss: 0.1239\n",
      "Epoch: 8/100... Training loss: 0.1254\n",
      "Epoch: 8/100... Training loss: 0.1257\n",
      "Epoch: 8/100... Training loss: 0.1226\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1244\n",
      "Epoch: 8/100... Training loss: 0.1253\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1249\n",
      "Epoch: 8/100... Training loss: 0.1234\n",
      "Epoch: 8/100... Training loss: 0.1242\n",
      "Epoch: 8/100... Training loss: 0.1246\n",
      "Epoch: 8/100... Training loss: 0.1263\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1268\n",
      "Epoch: 8/100... Training loss: 0.1263\n",
      "Epoch: 8/100... Training loss: 0.1280\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1210\n",
      "Epoch: 8/100... Training loss: 0.1236\n",
      "Epoch: 8/100... Training loss: 0.1240\n",
      "Epoch: 8/100... Training loss: 0.1259\n",
      "Epoch: 8/100... Training loss: 0.1244\n",
      "Epoch: 8/100... Training loss: 0.1170\n",
      "Epoch: 8/100... Training loss: 0.1285\n",
      "Epoch: 8/100... Training loss: 0.1238\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1213\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1231\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1243\n",
      "Epoch: 8/100... Training loss: 0.1248\n",
      "Epoch: 8/100... Training loss: 0.1218\n",
      "Epoch: 8/100... Training loss: 0.1237\n",
      "Epoch: 8/100... Training loss: 0.1230\n",
      "Epoch: 8/100... Training loss: 0.1250\n",
      "Epoch: 8/100... Training loss: 0.1237\n",
      "Epoch: 8/100... Training loss: 0.1187\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1231\n",
      "Epoch: 8/100... Training loss: 0.1243\n",
      "Epoch: 8/100... Training loss: 0.1228\n",
      "Epoch: 8/100... Training loss: 0.1226\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1260\n",
      "Epoch: 8/100... Training loss: 0.1251\n",
      "Epoch: 8/100... Training loss: 0.1178\n",
      "Epoch: 8/100... Training loss: 0.1214\n",
      "Epoch: 8/100... Training loss: 0.1237\n",
      "Epoch: 8/100... Training loss: 0.1251\n",
      "Epoch: 8/100... Training loss: 0.1235\n",
      "Epoch: 8/100... Training loss: 0.1237\n",
      "Epoch: 8/100... Training loss: 0.1241\n",
      "Epoch: 8/100... Training loss: 0.1244\n",
      "Epoch: 8/100... Training loss: 0.1257\n",
      "Epoch: 8/100... Training loss: 0.1255\n",
      "Epoch: 8/100... Training loss: 0.1259\n",
      "Epoch: 8/100... Training loss: 0.1280\n",
      "Epoch: 8/100... Training loss: 0.1188\n",
      "Epoch: 8/100... Training loss: 0.1258\n",
      "Epoch: 8/100... Training loss: 0.1273\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1193\n",
      "Epoch: 8/100... Training loss: 0.1219\n",
      "Epoch: 8/100... Training loss: 0.1257\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1251\n",
      "Epoch: 8/100... Training loss: 0.1184\n",
      "Epoch: 8/100... Training loss: 0.1165\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1231\n",
      "Epoch: 8/100... Training loss: 0.1240\n",
      "Epoch: 8/100... Training loss: 0.1235\n",
      "Epoch: 8/100... Training loss: 0.1238\n",
      "Epoch: 8/100... Training loss: 0.1208\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1250\n",
      "Epoch: 8/100... Training loss: 0.1246\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1245\n",
      "Epoch: 8/100... Training loss: 0.1259\n",
      "Epoch: 8/100... Training loss: 0.1285\n",
      "Epoch: 8/100... Training loss: 0.1232\n",
      "Epoch: 8/100... Training loss: 0.1219\n",
      "Epoch: 8/100... Training loss: 0.1252\n",
      "Epoch: 8/100... Training loss: 0.1236\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1238\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1235\n",
      "Epoch: 8/100... Training loss: 0.1260\n",
      "Epoch: 8/100... Training loss: 0.1190\n",
      "Epoch: 8/100... Training loss: 0.1226\n",
      "Epoch: 8/100... Training loss: 0.1185\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1242\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1243\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1227\n",
      "Epoch: 8/100... Training loss: 0.1218\n",
      "Epoch: 8/100... Training loss: 0.1256\n",
      "Epoch: 8/100... Training loss: 0.1257\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1233\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1246\n",
      "Epoch: 8/100... Training loss: 0.1196\n",
      "Epoch: 8/100... Training loss: 0.1282\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1171\n",
      "Epoch: 8/100... Training loss: 0.1219\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1212\n",
      "Epoch: 8/100... Training loss: 0.1221\n",
      "Epoch: 8/100... Training loss: 0.1241\n",
      "Epoch: 8/100... Training loss: 0.1242\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1269\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1239\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1213\n",
      "Epoch: 8/100... Training loss: 0.1236\n",
      "Epoch: 8/100... Training loss: 0.1273\n",
      "Epoch: 8/100... Training loss: 0.1217\n",
      "Epoch: 8/100... Training loss: 0.1180\n",
      "Epoch: 8/100... Training loss: 0.1206\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1237\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1271\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1206\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1238\n",
      "Epoch: 8/100... Training loss: 0.1213\n",
      "Epoch: 8/100... Training loss: 0.1235\n",
      "Epoch: 8/100... Training loss: 0.1212\n",
      "Epoch: 8/100... Training loss: 0.1257\n",
      "Epoch: 8/100... Training loss: 0.1240\n",
      "Epoch: 8/100... Training loss: 0.1216\n",
      "Epoch: 8/100... Training loss: 0.1217\n",
      "Epoch: 8/100... Training loss: 0.1191\n",
      "Epoch: 8/100... Training loss: 0.1213\n",
      "Epoch: 8/100... Training loss: 0.1217\n",
      "Epoch: 8/100... Training loss: 0.1217\n",
      "Epoch: 8/100... Training loss: 0.1257\n",
      "Epoch: 8/100... Training loss: 0.1240\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1243\n",
      "Epoch: 8/100... Training loss: 0.1189\n",
      "Epoch: 8/100... Training loss: 0.1274\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1230\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1222\n",
      "Epoch: 8/100... Training loss: 0.1239\n",
      "Epoch: 8/100... Training loss: 0.1200\n",
      "Epoch: 8/100... Training loss: 0.1206\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1237\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1214\n",
      "Epoch: 8/100... Training loss: 0.1224\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1236\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 8/100... Training loss: 0.1144\n",
      "Epoch: 8/100... Training loss: 0.1209\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1222\n",
      "Epoch: 8/100... Training loss: 0.1204\n",
      "Epoch: 8/100... Training loss: 0.1247\n",
      "Epoch: 8/100... Training loss: 0.1226\n",
      "Epoch: 8/100... Training loss: 0.1238\n",
      "Epoch: 8/100... Training loss: 0.1199\n",
      "Epoch: 8/100... Training loss: 0.1214\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1198\n",
      "Epoch: 8/100... Training loss: 0.1211\n",
      "Epoch: 8/100... Training loss: 0.1210\n",
      "Epoch: 8/100... Training loss: 0.1226\n",
      "Epoch: 8/100... Training loss: 0.1221\n",
      "Epoch: 8/100... Training loss: 0.1213\n",
      "Epoch: 8/100... Training loss: 0.1197\n",
      "Epoch: 8/100... Training loss: 0.1221\n",
      "Epoch: 8/100... Training loss: 0.1235\n",
      "Epoch: 8/100... Training loss: 0.1245\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1238\n",
      "Epoch: 8/100... Training loss: 0.1207\n",
      "Epoch: 8/100... Training loss: 0.1225\n",
      "Epoch: 8/100... Training loss: 0.1228\n",
      "Epoch: 8/100... Training loss: 0.1194\n",
      "Epoch: 8/100... Training loss: 0.1205\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1230\n",
      "Epoch: 8/100... Training loss: 0.1203\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1234\n",
      "Epoch: 8/100... Training loss: 0.1201\n",
      "Epoch: 8/100... Training loss: 0.1244\n",
      "Epoch: 8/100... Training loss: 0.1262\n",
      "Epoch: 8/100... Training loss: 0.1195\n",
      "Epoch: 8/100... Training loss: 0.1202\n",
      "Epoch: 8/100... Training loss: 0.1196\n",
      "Epoch: 8/100... Training loss: 0.1229\n",
      "Epoch: 8/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1258\n",
      "Epoch: 9/100... Training loss: 0.1185\n",
      "Epoch: 9/100... Training loss: 0.1211\n",
      "Epoch: 9/100... Training loss: 0.1261\n",
      "Epoch: 9/100... Training loss: 0.1233\n",
      "Epoch: 9/100... Training loss: 0.1190\n",
      "Epoch: 9/100... Training loss: 0.1213\n",
      "Epoch: 9/100... Training loss: 0.1208\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1211\n",
      "Epoch: 9/100... Training loss: 0.1277\n",
      "Epoch: 9/100... Training loss: 0.1231\n",
      "Epoch: 9/100... Training loss: 0.1240\n",
      "Epoch: 9/100... Training loss: 0.1269\n",
      "Epoch: 9/100... Training loss: 0.1232\n",
      "Epoch: 9/100... Training loss: 0.1239\n",
      "Epoch: 9/100... Training loss: 0.1233\n",
      "Epoch: 9/100... Training loss: 0.1213\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1216\n",
      "Epoch: 9/100... Training loss: 0.1219\n",
      "Epoch: 9/100... Training loss: 0.1222\n",
      "Epoch: 9/100... Training loss: 0.1213\n",
      "Epoch: 9/100... Training loss: 0.1243\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1201\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1256\n",
      "Epoch: 9/100... Training loss: 0.1218\n",
      "Epoch: 9/100... Training loss: 0.1222\n",
      "Epoch: 9/100... Training loss: 0.1236\n",
      "Epoch: 9/100... Training loss: 0.1230\n",
      "Epoch: 9/100... Training loss: 0.1225\n",
      "Epoch: 9/100... Training loss: 0.1202\n",
      "Epoch: 9/100... Training loss: 0.1211\n",
      "Epoch: 9/100... Training loss: 0.1230\n",
      "Epoch: 9/100... Training loss: 0.1202\n",
      "Epoch: 9/100... Training loss: 0.1202\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1239\n",
      "Epoch: 9/100... Training loss: 0.1239\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1223\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1198\n",
      "Epoch: 9/100... Training loss: 0.1213\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1201\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1212\n",
      "Epoch: 9/100... Training loss: 0.1218\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1227\n",
      "Epoch: 9/100... Training loss: 0.1220\n",
      "Epoch: 9/100... Training loss: 0.1235\n",
      "Epoch: 9/100... Training loss: 0.1200\n",
      "Epoch: 9/100... Training loss: 0.1232\n",
      "Epoch: 9/100... Training loss: 0.1249\n",
      "Epoch: 9/100... Training loss: 0.1230\n",
      "Epoch: 9/100... Training loss: 0.1208\n",
      "Epoch: 9/100... Training loss: 0.1276\n",
      "Epoch: 9/100... Training loss: 0.1222\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1257\n",
      "Epoch: 9/100... Training loss: 0.1227\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1226\n",
      "Epoch: 9/100... Training loss: 0.1201\n",
      "Epoch: 9/100... Training loss: 0.1233\n",
      "Epoch: 9/100... Training loss: 0.1203\n",
      "Epoch: 9/100... Training loss: 0.1212\n",
      "Epoch: 9/100... Training loss: 0.1218\n",
      "Epoch: 9/100... Training loss: 0.1218\n",
      "Epoch: 9/100... Training loss: 0.1217\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1198\n",
      "Epoch: 9/100... Training loss: 0.1200\n",
      "Epoch: 9/100... Training loss: 0.1230\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1221\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1199\n",
      "Epoch: 9/100... Training loss: 0.1243\n",
      "Epoch: 9/100... Training loss: 0.1200\n",
      "Epoch: 9/100... Training loss: 0.1216\n",
      "Epoch: 9/100... Training loss: 0.1230\n",
      "Epoch: 9/100... Training loss: 0.1229\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1198\n",
      "Epoch: 9/100... Training loss: 0.1267\n",
      "Epoch: 9/100... Training loss: 0.1205\n",
      "Epoch: 9/100... Training loss: 0.1238\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1265\n",
      "Epoch: 9/100... Training loss: 0.1200\n",
      "Epoch: 9/100... Training loss: 0.1210\n",
      "Epoch: 9/100... Training loss: 0.1241\n",
      "Epoch: 9/100... Training loss: 0.1199\n",
      "Epoch: 9/100... Training loss: 0.1240\n",
      "Epoch: 9/100... Training loss: 0.1226\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1211\n",
      "Epoch: 9/100... Training loss: 0.1229\n",
      "Epoch: 9/100... Training loss: 0.1217\n",
      "Epoch: 9/100... Training loss: 0.1244\n",
      "Epoch: 9/100... Training loss: 0.1245\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1226\n",
      "Epoch: 9/100... Training loss: 0.1218\n",
      "Epoch: 9/100... Training loss: 0.1213\n",
      "Epoch: 9/100... Training loss: 0.1165\n",
      "Epoch: 9/100... Training loss: 0.1211\n",
      "Epoch: 9/100... Training loss: 0.1225\n",
      "Epoch: 9/100... Training loss: 0.1205\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1221\n",
      "Epoch: 9/100... Training loss: 0.1260\n",
      "Epoch: 9/100... Training loss: 0.1197\n",
      "Epoch: 9/100... Training loss: 0.1201\n",
      "Epoch: 9/100... Training loss: 0.1228\n",
      "Epoch: 9/100... Training loss: 0.1218\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1226\n",
      "Epoch: 9/100... Training loss: 0.1208\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1230\n",
      "Epoch: 9/100... Training loss: 0.1198\n",
      "Epoch: 9/100... Training loss: 0.1232\n",
      "Epoch: 9/100... Training loss: 0.1198\n",
      "Epoch: 9/100... Training loss: 0.1223\n",
      "Epoch: 9/100... Training loss: 0.1233\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1238\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1214\n",
      "Epoch: 9/100... Training loss: 0.1203\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1233\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1242\n",
      "Epoch: 9/100... Training loss: 0.1209\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1190\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1205\n",
      "Epoch: 9/100... Training loss: 0.1220\n",
      "Epoch: 9/100... Training loss: 0.1222\n",
      "Epoch: 9/100... Training loss: 0.1241\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1135\n",
      "Epoch: 9/100... Training loss: 0.1225\n",
      "Epoch: 9/100... Training loss: 0.1212\n",
      "Epoch: 9/100... Training loss: 0.1205\n",
      "Epoch: 9/100... Training loss: 0.1214\n",
      "Epoch: 9/100... Training loss: 0.1251\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1202\n",
      "Epoch: 9/100... Training loss: 0.1151\n",
      "Epoch: 9/100... Training loss: 0.1243\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1169\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1236\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1188\n",
      "Epoch: 9/100... Training loss: 0.1255\n",
      "Epoch: 9/100... Training loss: 0.1213\n",
      "Epoch: 9/100... Training loss: 0.1220\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1218\n",
      "Epoch: 9/100... Training loss: 0.1254\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1204\n",
      "Epoch: 9/100... Training loss: 0.1179\n",
      "Epoch: 9/100... Training loss: 0.1166\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1250\n",
      "Epoch: 9/100... Training loss: 0.1170\n",
      "Epoch: 9/100... Training loss: 0.1273\n",
      "Epoch: 9/100... Training loss: 0.1210\n",
      "Epoch: 9/100... Training loss: 0.1201\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1227\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1212\n",
      "Epoch: 9/100... Training loss: 0.1210\n",
      "Epoch: 9/100... Training loss: 0.1193\n",
      "Epoch: 9/100... Training loss: 0.1239\n",
      "Epoch: 9/100... Training loss: 0.1212\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1205\n",
      "Epoch: 9/100... Training loss: 0.1220\n",
      "Epoch: 9/100... Training loss: 0.1205\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1210\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1174\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1191\n",
      "Epoch: 9/100... Training loss: 0.1190\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1208\n",
      "Epoch: 9/100... Training loss: 0.1196\n",
      "Epoch: 9/100... Training loss: 0.1223\n",
      "Epoch: 9/100... Training loss: 0.1189\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1163\n",
      "Epoch: 9/100... Training loss: 0.1233\n",
      "Epoch: 9/100... Training loss: 0.1168\n",
      "Epoch: 9/100... Training loss: 0.1180\n",
      "Epoch: 9/100... Training loss: 0.1237\n",
      "Epoch: 9/100... Training loss: 0.1158\n",
      "Epoch: 9/100... Training loss: 0.1237\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 9/100... Training loss: 0.1265\n",
      "Epoch: 9/100... Training loss: 0.1212\n",
      "Epoch: 9/100... Training loss: 0.1209\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1197\n",
      "Epoch: 9/100... Training loss: 0.1193\n",
      "Epoch: 9/100... Training loss: 0.1183\n",
      "Epoch: 9/100... Training loss: 0.1214\n",
      "Epoch: 9/100... Training loss: 0.1186\n",
      "Epoch: 9/100... Training loss: 0.1228\n",
      "Epoch: 9/100... Training loss: 0.1198\n",
      "Epoch: 9/100... Training loss: 0.1226\n",
      "Epoch: 9/100... Training loss: 0.1173\n",
      "Epoch: 9/100... Training loss: 0.1164\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1167\n",
      "Epoch: 9/100... Training loss: 0.1214\n",
      "Epoch: 9/100... Training loss: 0.1240\n",
      "Epoch: 9/100... Training loss: 0.1225\n",
      "Epoch: 9/100... Training loss: 0.1199\n",
      "Epoch: 9/100... Training loss: 0.1235\n",
      "Epoch: 9/100... Training loss: 0.1161\n",
      "Epoch: 9/100... Training loss: 0.1217\n",
      "Epoch: 9/100... Training loss: 0.1216\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1181\n",
      "Epoch: 9/100... Training loss: 0.1237\n",
      "Epoch: 9/100... Training loss: 0.1240\n",
      "Epoch: 9/100... Training loss: 0.1210\n",
      "Epoch: 9/100... Training loss: 0.1203\n",
      "Epoch: 9/100... Training loss: 0.1200\n",
      "Epoch: 9/100... Training loss: 0.1223\n",
      "Epoch: 9/100... Training loss: 0.1223\n",
      "Epoch: 9/100... Training loss: 0.1175\n",
      "Epoch: 9/100... Training loss: 0.1201\n",
      "Epoch: 9/100... Training loss: 0.1202\n",
      "Epoch: 9/100... Training loss: 0.1207\n",
      "Epoch: 9/100... Training loss: 0.1220\n",
      "Epoch: 9/100... Training loss: 0.1242\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1200\n",
      "Epoch: 9/100... Training loss: 0.1231\n",
      "Epoch: 9/100... Training loss: 0.1195\n",
      "Epoch: 9/100... Training loss: 0.1177\n",
      "Epoch: 9/100... Training loss: 0.1206\n",
      "Epoch: 9/100... Training loss: 0.1184\n",
      "Epoch: 9/100... Training loss: 0.1214\n",
      "Epoch: 9/100... Training loss: 0.1206\n",
      "Epoch: 9/100... Training loss: 0.1284\n",
      "Epoch: 9/100... Training loss: 0.1214\n",
      "Epoch: 9/100... Training loss: 0.1220\n",
      "Epoch: 9/100... Training loss: 0.1197\n",
      "Epoch: 9/100... Training loss: 0.1192\n",
      "Epoch: 9/100... Training loss: 0.1172\n",
      "Epoch: 9/100... Training loss: 0.1205\n",
      "Epoch: 9/100... Training loss: 0.1210\n",
      "Epoch: 9/100... Training loss: 0.1223\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1222\n",
      "Epoch: 9/100... Training loss: 0.1197\n",
      "Epoch: 9/100... Training loss: 0.1201\n",
      "Epoch: 9/100... Training loss: 0.1178\n",
      "Epoch: 9/100... Training loss: 0.1227\n",
      "Epoch: 9/100... Training loss: 0.1171\n",
      "Epoch: 9/100... Training loss: 0.1218\n",
      "Epoch: 9/100... Training loss: 0.1233\n",
      "Epoch: 9/100... Training loss: 0.1194\n",
      "Epoch: 9/100... Training loss: 0.1134\n",
      "Epoch: 9/100... Training loss: 0.1212\n",
      "Epoch: 9/100... Training loss: 0.1218\n",
      "Epoch: 9/100... Training loss: 0.1190\n",
      "Epoch: 9/100... Training loss: 0.1226\n",
      "Epoch: 9/100... Training loss: 0.1220\n",
      "Epoch: 9/100... Training loss: 0.1217\n",
      "Epoch: 9/100... Training loss: 0.1187\n",
      "Epoch: 9/100... Training loss: 0.1215\n",
      "Epoch: 9/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1186\n",
      "Epoch: 10/100... Training loss: 0.1199\n",
      "Epoch: 10/100... Training loss: 0.1224\n",
      "Epoch: 10/100... Training loss: 0.1191\n",
      "Epoch: 10/100... Training loss: 0.1197\n",
      "Epoch: 10/100... Training loss: 0.1217\n",
      "Epoch: 10/100... Training loss: 0.1181\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1174\n",
      "Epoch: 10/100... Training loss: 0.1178\n",
      "Epoch: 10/100... Training loss: 0.1180\n",
      "Epoch: 10/100... Training loss: 0.1222\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1208\n",
      "Epoch: 10/100... Training loss: 0.1236\n",
      "Epoch: 10/100... Training loss: 0.1184\n",
      "Epoch: 10/100... Training loss: 0.1171\n",
      "Epoch: 10/100... Training loss: 0.1227\n",
      "Epoch: 10/100... Training loss: 0.1217\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1244\n",
      "Epoch: 10/100... Training loss: 0.1217\n",
      "Epoch: 10/100... Training loss: 0.1219\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1208\n",
      "Epoch: 10/100... Training loss: 0.1217\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1204\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1218\n",
      "Epoch: 10/100... Training loss: 0.1201\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1186\n",
      "Epoch: 10/100... Training loss: 0.1197\n",
      "Epoch: 10/100... Training loss: 0.1233\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1208\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1239\n",
      "Epoch: 10/100... Training loss: 0.1204\n",
      "Epoch: 10/100... Training loss: 0.1208\n",
      "Epoch: 10/100... Training loss: 0.1201\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1204\n",
      "Epoch: 10/100... Training loss: 0.1217\n",
      "Epoch: 10/100... Training loss: 0.1200\n",
      "Epoch: 10/100... Training loss: 0.1240\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1196\n",
      "Epoch: 10/100... Training loss: 0.1204\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1192\n",
      "Epoch: 10/100... Training loss: 0.1205\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1198\n",
      "Epoch: 10/100... Training loss: 0.1207\n",
      "Epoch: 10/100... Training loss: 0.1196\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1192\n",
      "Epoch: 10/100... Training loss: 0.1214\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1219\n",
      "Epoch: 10/100... Training loss: 0.1188\n",
      "Epoch: 10/100... Training loss: 0.1219\n",
      "Epoch: 10/100... Training loss: 0.1190\n",
      "Epoch: 10/100... Training loss: 0.1224\n",
      "Epoch: 10/100... Training loss: 0.1202\n",
      "Epoch: 10/100... Training loss: 0.1228\n",
      "Epoch: 10/100... Training loss: 0.1228\n",
      "Epoch: 10/100... Training loss: 0.1172\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1238\n",
      "Epoch: 10/100... Training loss: 0.1178\n",
      "Epoch: 10/100... Training loss: 0.1197\n",
      "Epoch: 10/100... Training loss: 0.1222\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1213\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1190\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1200\n",
      "Epoch: 10/100... Training loss: 0.1215\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1253\n",
      "Epoch: 10/100... Training loss: 0.1233\n",
      "Epoch: 10/100... Training loss: 0.1174\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1241\n",
      "Epoch: 10/100... Training loss: 0.1211\n",
      "Epoch: 10/100... Training loss: 0.1219\n",
      "Epoch: 10/100... Training loss: 0.1205\n",
      "Epoch: 10/100... Training loss: 0.1196\n",
      "Epoch: 10/100... Training loss: 0.1240\n",
      "Epoch: 10/100... Training loss: 0.1199\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1231\n",
      "Epoch: 10/100... Training loss: 0.1234\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1239\n",
      "Epoch: 10/100... Training loss: 0.1202\n",
      "Epoch: 10/100... Training loss: 0.1232\n",
      "Epoch: 10/100... Training loss: 0.1241\n",
      "Epoch: 10/100... Training loss: 0.1223\n",
      "Epoch: 10/100... Training loss: 0.1175\n",
      "Epoch: 10/100... Training loss: 0.1178\n",
      "Epoch: 10/100... Training loss: 0.1207\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1208\n",
      "Epoch: 10/100... Training loss: 0.1247\n",
      "Epoch: 10/100... Training loss: 0.1224\n",
      "Epoch: 10/100... Training loss: 0.1154\n",
      "Epoch: 10/100... Training loss: 0.1172\n",
      "Epoch: 10/100... Training loss: 0.1193\n",
      "Epoch: 10/100... Training loss: 0.1216\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1232\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1212\n",
      "Epoch: 10/100... Training loss: 0.1239\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1208\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1192\n",
      "Epoch: 10/100... Training loss: 0.1209\n",
      "Epoch: 10/100... Training loss: 0.1147\n",
      "Epoch: 10/100... Training loss: 0.1243\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1206\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1164\n",
      "Epoch: 10/100... Training loss: 0.1206\n",
      "Epoch: 10/100... Training loss: 0.1243\n",
      "Epoch: 10/100... Training loss: 0.1201\n",
      "Epoch: 10/100... Training loss: 0.1225\n",
      "Epoch: 10/100... Training loss: 0.1198\n",
      "Epoch: 10/100... Training loss: 0.1139\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1200\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1146\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1204\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1177\n",
      "Epoch: 10/100... Training loss: 0.1166\n",
      "Epoch: 10/100... Training loss: 0.1210\n",
      "Epoch: 10/100... Training loss: 0.1157\n",
      "Epoch: 10/100... Training loss: 0.1180\n",
      "Epoch: 10/100... Training loss: 0.1177\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1208\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1208\n",
      "Epoch: 10/100... Training loss: 0.1160\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1201\n",
      "Epoch: 10/100... Training loss: 0.1196\n",
      "Epoch: 10/100... Training loss: 0.1185\n",
      "Epoch: 10/100... Training loss: 0.1221\n",
      "Epoch: 10/100... Training loss: 0.1205\n",
      "Epoch: 10/100... Training loss: 0.1192\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1209\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1201\n",
      "Epoch: 10/100... Training loss: 0.1203\n",
      "Epoch: 10/100... Training loss: 0.1213\n",
      "Epoch: 10/100... Training loss: 0.1212\n",
      "Epoch: 10/100... Training loss: 0.1220\n",
      "Epoch: 10/100... Training loss: 0.1186\n",
      "Epoch: 10/100... Training loss: 0.1247\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1218\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1198\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1225\n",
      "Epoch: 10/100... Training loss: 0.1205\n",
      "Epoch: 10/100... Training loss: 0.1226\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1191\n",
      "Epoch: 10/100... Training loss: 0.1212\n",
      "Epoch: 10/100... Training loss: 0.1149\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1192\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1210\n",
      "Epoch: 10/100... Training loss: 0.1186\n",
      "Epoch: 10/100... Training loss: 0.1202\n",
      "Epoch: 10/100... Training loss: 0.1207\n",
      "Epoch: 10/100... Training loss: 0.1135\n",
      "Epoch: 10/100... Training loss: 0.1188\n",
      "Epoch: 10/100... Training loss: 0.1194\n",
      "Epoch: 10/100... Training loss: 0.1202\n",
      "Epoch: 10/100... Training loss: 0.1141\n",
      "Epoch: 10/100... Training loss: 0.1174\n",
      "Epoch: 10/100... Training loss: 0.1219\n",
      "Epoch: 10/100... Training loss: 0.1148\n",
      "Epoch: 10/100... Training loss: 0.1236\n",
      "Epoch: 10/100... Training loss: 0.1190\n",
      "Epoch: 10/100... Training loss: 0.1165\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1185\n",
      "Epoch: 10/100... Training loss: 0.1179\n",
      "Epoch: 10/100... Training loss: 0.1209\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1168\n",
      "Epoch: 10/100... Training loss: 0.1188\n",
      "Epoch: 10/100... Training loss: 0.1176\n",
      "Epoch: 10/100... Training loss: 0.1200\n",
      "Epoch: 10/100... Training loss: 0.1190\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1181\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1155\n",
      "Epoch: 10/100... Training loss: 0.1211\n",
      "Epoch: 10/100... Training loss: 0.1170\n",
      "Epoch: 10/100... Training loss: 0.1203\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1218\n",
      "Epoch: 10/100... Training loss: 0.1126\n",
      "Epoch: 10/100... Training loss: 0.1151\n",
      "Epoch: 10/100... Training loss: 0.1188\n",
      "Epoch: 10/100... Training loss: 0.1195\n",
      "Epoch: 10/100... Training loss: 0.1138\n",
      "Epoch: 10/100... Training loss: 0.1216\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1196\n",
      "Epoch: 10/100... Training loss: 0.1169\n",
      "Epoch: 10/100... Training loss: 0.1202\n",
      "Epoch: 10/100... Training loss: 0.1161\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1177\n",
      "Epoch: 10/100... Training loss: 0.1181\n",
      "Epoch: 10/100... Training loss: 0.1185\n",
      "Epoch: 10/100... Training loss: 0.1142\n",
      "Epoch: 10/100... Training loss: 0.1263\n",
      "Epoch: 10/100... Training loss: 0.1245\n",
      "Epoch: 10/100... Training loss: 0.1222\n",
      "Epoch: 10/100... Training loss: 0.1156\n",
      "Epoch: 10/100... Training loss: 0.1145\n",
      "Epoch: 10/100... Training loss: 0.1193\n",
      "Epoch: 10/100... Training loss: 0.1162\n",
      "Epoch: 10/100... Training loss: 0.1158\n",
      "Epoch: 10/100... Training loss: 0.1174\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1185\n",
      "Epoch: 10/100... Training loss: 0.1152\n",
      "Epoch: 10/100... Training loss: 0.1197\n",
      "Epoch: 10/100... Training loss: 0.1183\n",
      "Epoch: 10/100... Training loss: 0.1189\n",
      "Epoch: 10/100... Training loss: 0.1199\n",
      "Epoch: 10/100... Training loss: 0.1207\n",
      "Epoch: 10/100... Training loss: 0.1215\n",
      "Epoch: 10/100... Training loss: 0.1198\n",
      "Epoch: 10/100... Training loss: 0.1212\n",
      "Epoch: 10/100... Training loss: 0.1187\n",
      "Epoch: 10/100... Training loss: 0.1167\n",
      "Epoch: 10/100... Training loss: 0.1131\n",
      "Epoch: 10/100... Training loss: 0.1199\n",
      "Epoch: 10/100... Training loss: 0.1191\n",
      "Epoch: 10/100... Training loss: 0.1173\n",
      "Epoch: 10/100... Training loss: 0.1210\n",
      "Epoch: 10/100... Training loss: 0.1178\n",
      "Epoch: 10/100... Training loss: 0.1213\n",
      "Epoch: 10/100... Training loss: 0.1214\n",
      "Epoch: 10/100... Training loss: 0.1159\n",
      "Epoch: 10/100... Training loss: 0.1127\n",
      "Epoch: 10/100... Training loss: 0.1191\n",
      "Epoch: 10/100... Training loss: 0.1182\n",
      "Epoch: 10/100... Training loss: 0.1213\n",
      "Epoch: 10/100... Training loss: 0.1228\n",
      "Epoch: 10/100... Training loss: 0.1205\n",
      "Epoch: 10/100... Training loss: 0.1239\n",
      "Epoch: 10/100... Training loss: 0.1153\n",
      "Epoch: 10/100... Training loss: 0.1200\n",
      "Epoch: 10/100... Training loss: 0.1181\n",
      "Epoch: 10/100... Training loss: 0.1221\n",
      "Epoch: 10/100... Training loss: 0.1201\n",
      "Epoch: 11/100... Training loss: 0.1189\n",
      "Epoch: 11/100... Training loss: 0.1189\n",
      "Epoch: 11/100... Training loss: 0.1187\n",
      "Epoch: 11/100... Training loss: 0.1232\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1186\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1178\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1176\n",
      "Epoch: 11/100... Training loss: 0.1190\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1178\n",
      "Epoch: 11/100... Training loss: 0.1155\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1187\n",
      "Epoch: 11/100... Training loss: 0.1202\n",
      "Epoch: 11/100... Training loss: 0.1190\n",
      "Epoch: 11/100... Training loss: 0.1185\n",
      "Epoch: 11/100... Training loss: 0.1207\n",
      "Epoch: 11/100... Training loss: 0.1213\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1196\n",
      "Epoch: 11/100... Training loss: 0.1215\n",
      "Epoch: 11/100... Training loss: 0.1175\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1193\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1209\n",
      "Epoch: 11/100... Training loss: 0.1196\n",
      "Epoch: 11/100... Training loss: 0.1183\n",
      "Epoch: 11/100... Training loss: 0.1193\n",
      "Epoch: 11/100... Training loss: 0.1245\n",
      "Epoch: 11/100... Training loss: 0.1205\n",
      "Epoch: 11/100... Training loss: 0.1181\n",
      "Epoch: 11/100... Training loss: 0.1229\n",
      "Epoch: 11/100... Training loss: 0.1208\n",
      "Epoch: 11/100... Training loss: 0.1160\n",
      "Epoch: 11/100... Training loss: 0.1191\n",
      "Epoch: 11/100... Training loss: 0.1195\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1194\n",
      "Epoch: 11/100... Training loss: 0.1191\n",
      "Epoch: 11/100... Training loss: 0.1193\n",
      "Epoch: 11/100... Training loss: 0.1185\n",
      "Epoch: 11/100... Training loss: 0.1197\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1184\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1189\n",
      "Epoch: 11/100... Training loss: 0.1191\n",
      "Epoch: 11/100... Training loss: 0.1220\n",
      "Epoch: 11/100... Training loss: 0.1197\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1148\n",
      "Epoch: 11/100... Training loss: 0.1180\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1130\n",
      "Epoch: 11/100... Training loss: 0.1209\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1195\n",
      "Epoch: 11/100... Training loss: 0.1176\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1177\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1173\n",
      "Epoch: 11/100... Training loss: 0.1177\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1177\n",
      "Epoch: 11/100... Training loss: 0.1200\n",
      "Epoch: 11/100... Training loss: 0.1192\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1185\n",
      "Epoch: 11/100... Training loss: 0.1185\n",
      "Epoch: 11/100... Training loss: 0.1223\n",
      "Epoch: 11/100... Training loss: 0.1175\n",
      "Epoch: 11/100... Training loss: 0.1205\n",
      "Epoch: 11/100... Training loss: 0.1190\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1155\n",
      "Epoch: 11/100... Training loss: 0.1191\n",
      "Epoch: 11/100... Training loss: 0.1207\n",
      "Epoch: 11/100... Training loss: 0.1208\n",
      "Epoch: 11/100... Training loss: 0.1198\n",
      "Epoch: 11/100... Training loss: 0.1234\n",
      "Epoch: 11/100... Training loss: 0.1189\n",
      "Epoch: 11/100... Training loss: 0.1205\n",
      "Epoch: 11/100... Training loss: 0.1164\n",
      "Epoch: 11/100... Training loss: 0.1202\n",
      "Epoch: 11/100... Training loss: 0.1180\n",
      "Epoch: 11/100... Training loss: 0.1175\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1136\n",
      "Epoch: 11/100... Training loss: 0.1220\n",
      "Epoch: 11/100... Training loss: 0.1187\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1218\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1181\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1194\n",
      "Epoch: 11/100... Training loss: 0.1189\n",
      "Epoch: 11/100... Training loss: 0.1204\n",
      "Epoch: 11/100... Training loss: 0.1202\n",
      "Epoch: 11/100... Training loss: 0.1200\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1242\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1181\n",
      "Epoch: 11/100... Training loss: 0.1207\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1184\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1180\n",
      "Epoch: 11/100... Training loss: 0.1154\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1143\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1190\n",
      "Epoch: 11/100... Training loss: 0.1175\n",
      "Epoch: 11/100... Training loss: 0.1199\n",
      "Epoch: 11/100... Training loss: 0.1198\n",
      "Epoch: 11/100... Training loss: 0.1200\n",
      "Epoch: 11/100... Training loss: 0.1191\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1185\n",
      "Epoch: 11/100... Training loss: 0.1215\n",
      "Epoch: 11/100... Training loss: 0.1176\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1142\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1171\n",
      "Epoch: 11/100... Training loss: 0.1160\n",
      "Epoch: 11/100... Training loss: 0.1177\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1216\n",
      "Epoch: 11/100... Training loss: 0.1181\n",
      "Epoch: 11/100... Training loss: 0.1226\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1202\n",
      "Epoch: 11/100... Training loss: 0.1159\n",
      "Epoch: 11/100... Training loss: 0.1164\n",
      "Epoch: 11/100... Training loss: 0.1232\n",
      "Epoch: 11/100... Training loss: 0.1184\n",
      "Epoch: 11/100... Training loss: 0.1158\n",
      "Epoch: 11/100... Training loss: 0.1183\n",
      "Epoch: 11/100... Training loss: 0.1164\n",
      "Epoch: 11/100... Training loss: 0.1173\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1190\n",
      "Epoch: 11/100... Training loss: 0.1215\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1195\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1108\n",
      "Epoch: 11/100... Training loss: 0.1196\n",
      "Epoch: 11/100... Training loss: 0.1141\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1180\n",
      "Epoch: 11/100... Training loss: 0.1181\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1245\n",
      "Epoch: 11/100... Training loss: 0.1198\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1191\n",
      "Epoch: 11/100... Training loss: 0.1167\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1211\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1138\n",
      "Epoch: 11/100... Training loss: 0.1197\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1176\n",
      "Epoch: 11/100... Training loss: 0.1145\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1200\n",
      "Epoch: 11/100... Training loss: 0.1246\n",
      "Epoch: 11/100... Training loss: 0.1171\n",
      "Epoch: 11/100... Training loss: 0.1137\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1161\n",
      "Epoch: 11/100... Training loss: 0.1174\n",
      "Epoch: 11/100... Training loss: 0.1180\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1156\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1211\n",
      "Epoch: 11/100... Training loss: 0.1171\n",
      "Epoch: 11/100... Training loss: 0.1178\n",
      "Epoch: 11/100... Training loss: 0.1146\n",
      "Epoch: 11/100... Training loss: 0.1175\n",
      "Epoch: 11/100... Training loss: 0.1196\n",
      "Epoch: 11/100... Training loss: 0.1170\n",
      "Epoch: 11/100... Training loss: 0.1197\n",
      "Epoch: 11/100... Training loss: 0.1199\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1197\n",
      "Epoch: 11/100... Training loss: 0.1197\n",
      "Epoch: 11/100... Training loss: 0.1165\n",
      "Epoch: 11/100... Training loss: 0.1188\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1187\n",
      "Epoch: 11/100... Training loss: 0.1214\n",
      "Epoch: 11/100... Training loss: 0.1186\n",
      "Epoch: 11/100... Training loss: 0.1177\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1191\n",
      "Epoch: 11/100... Training loss: 0.1177\n",
      "Epoch: 11/100... Training loss: 0.1183\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1190\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1126\n",
      "Epoch: 11/100... Training loss: 0.1169\n",
      "Epoch: 11/100... Training loss: 0.1189\n",
      "Epoch: 11/100... Training loss: 0.1124\n",
      "Epoch: 11/100... Training loss: 0.1160\n",
      "Epoch: 11/100... Training loss: 0.1185\n",
      "Epoch: 11/100... Training loss: 0.1186\n",
      "Epoch: 11/100... Training loss: 0.1185\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1185\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1172\n",
      "Epoch: 11/100... Training loss: 0.1135\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1190\n",
      "Epoch: 11/100... Training loss: 0.1225\n",
      "Epoch: 11/100... Training loss: 0.1203\n",
      "Epoch: 11/100... Training loss: 0.1181\n",
      "Epoch: 11/100... Training loss: 0.1176\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1183\n",
      "Epoch: 11/100... Training loss: 0.1210\n",
      "Epoch: 11/100... Training loss: 0.1188\n",
      "Epoch: 11/100... Training loss: 0.1195\n",
      "Epoch: 11/100... Training loss: 0.1162\n",
      "Epoch: 11/100... Training loss: 0.1228\n",
      "Epoch: 11/100... Training loss: 0.1198\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1200\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1180\n",
      "Epoch: 11/100... Training loss: 0.1182\n",
      "Epoch: 11/100... Training loss: 0.1204\n",
      "Epoch: 11/100... Training loss: 0.1179\n",
      "Epoch: 11/100... Training loss: 0.1147\n",
      "Epoch: 11/100... Training loss: 0.1160\n",
      "Epoch: 11/100... Training loss: 0.1151\n",
      "Epoch: 11/100... Training loss: 0.1203\n",
      "Epoch: 11/100... Training loss: 0.1155\n",
      "Epoch: 11/100... Training loss: 0.1163\n",
      "Epoch: 11/100... Training loss: 0.1177\n",
      "Epoch: 11/100... Training loss: 0.1166\n",
      "Epoch: 11/100... Training loss: 0.1203\n",
      "Epoch: 11/100... Training loss: 0.1192\n",
      "Epoch: 11/100... Training loss: 0.1205\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1168\n",
      "Epoch: 11/100... Training loss: 0.1150\n",
      "Epoch: 11/100... Training loss: 0.1144\n",
      "Epoch: 11/100... Training loss: 0.1187\n",
      "Epoch: 11/100... Training loss: 0.1199\n",
      "Epoch: 11/100... Training loss: 0.1189\n",
      "Epoch: 11/100... Training loss: 0.1181\n",
      "Epoch: 11/100... Training loss: 0.1194\n",
      "Epoch: 11/100... Training loss: 0.1149\n",
      "Epoch: 11/100... Training loss: 0.1177\n",
      "Epoch: 11/100... Training loss: 0.1169\n",
      "Epoch: 11/100... Training loss: 0.1139\n",
      "Epoch: 11/100... Training loss: 0.1169\n",
      "Epoch: 11/100... Training loss: 0.1157\n",
      "Epoch: 11/100... Training loss: 0.1153\n",
      "Epoch: 11/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1175\n",
      "Epoch: 12/100... Training loss: 0.1154\n",
      "Epoch: 12/100... Training loss: 0.1207\n",
      "Epoch: 12/100... Training loss: 0.1202\n",
      "Epoch: 12/100... Training loss: 0.1197\n",
      "Epoch: 12/100... Training loss: 0.1179\n",
      "Epoch: 12/100... Training loss: 0.1162\n",
      "Epoch: 12/100... Training loss: 0.1168\n",
      "Epoch: 12/100... Training loss: 0.1192\n",
      "Epoch: 12/100... Training loss: 0.1183\n",
      "Epoch: 12/100... Training loss: 0.1189\n",
      "Epoch: 12/100... Training loss: 0.1184\n",
      "Epoch: 12/100... Training loss: 0.1167\n",
      "Epoch: 12/100... Training loss: 0.1212\n",
      "Epoch: 12/100... Training loss: 0.1194\n",
      "Epoch: 12/100... Training loss: 0.1173\n",
      "Epoch: 12/100... Training loss: 0.1150\n",
      "Epoch: 12/100... Training loss: 0.1154\n",
      "Epoch: 12/100... Training loss: 0.1215\n",
      "Epoch: 12/100... Training loss: 0.1167\n",
      "Epoch: 12/100... Training loss: 0.1150\n",
      "Epoch: 12/100... Training loss: 0.1185\n",
      "Epoch: 12/100... Training loss: 0.1156\n",
      "Epoch: 12/100... Training loss: 0.1133\n",
      "Epoch: 12/100... Training loss: 0.1179\n",
      "Epoch: 12/100... Training loss: 0.1201\n",
      "Epoch: 12/100... Training loss: 0.1192\n",
      "Epoch: 12/100... Training loss: 0.1211\n",
      "Epoch: 12/100... Training loss: 0.1193\n",
      "Epoch: 12/100... Training loss: 0.1137\n",
      "Epoch: 12/100... Training loss: 0.1183\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1179\n",
      "Epoch: 12/100... Training loss: 0.1164\n",
      "Epoch: 12/100... Training loss: 0.1180\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1169\n",
      "Epoch: 12/100... Training loss: 0.1173\n",
      "Epoch: 12/100... Training loss: 0.1165\n",
      "Epoch: 12/100... Training loss: 0.1169\n",
      "Epoch: 12/100... Training loss: 0.1156\n",
      "Epoch: 12/100... Training loss: 0.1202\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1143\n",
      "Epoch: 12/100... Training loss: 0.1180\n",
      "Epoch: 12/100... Training loss: 0.1198\n",
      "Epoch: 12/100... Training loss: 0.1186\n",
      "Epoch: 12/100... Training loss: 0.1150\n",
      "Epoch: 12/100... Training loss: 0.1177\n",
      "Epoch: 12/100... Training loss: 0.1164\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1174\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1180\n",
      "Epoch: 12/100... Training loss: 0.1165\n",
      "Epoch: 12/100... Training loss: 0.1194\n",
      "Epoch: 12/100... Training loss: 0.1187\n",
      "Epoch: 12/100... Training loss: 0.1173\n",
      "Epoch: 12/100... Training loss: 0.1173\n",
      "Epoch: 12/100... Training loss: 0.1176\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1169\n",
      "Epoch: 12/100... Training loss: 0.1165\n",
      "Epoch: 12/100... Training loss: 0.1194\n",
      "Epoch: 12/100... Training loss: 0.1189\n",
      "Epoch: 12/100... Training loss: 0.1173\n",
      "Epoch: 12/100... Training loss: 0.1191\n",
      "Epoch: 12/100... Training loss: 0.1190\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1224\n",
      "Epoch: 12/100... Training loss: 0.1198\n",
      "Epoch: 12/100... Training loss: 0.1160\n",
      "Epoch: 12/100... Training loss: 0.1155\n",
      "Epoch: 12/100... Training loss: 0.1166\n",
      "Epoch: 12/100... Training loss: 0.1175\n",
      "Epoch: 12/100... Training loss: 0.1189\n",
      "Epoch: 12/100... Training loss: 0.1177\n",
      "Epoch: 12/100... Training loss: 0.1180\n",
      "Epoch: 12/100... Training loss: 0.1164\n",
      "Epoch: 12/100... Training loss: 0.1187\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1177\n",
      "Epoch: 12/100... Training loss: 0.1170\n",
      "Epoch: 12/100... Training loss: 0.1154\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1174\n",
      "Epoch: 12/100... Training loss: 0.1195\n",
      "Epoch: 12/100... Training loss: 0.1160\n",
      "Epoch: 12/100... Training loss: 0.1173\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1176\n",
      "Epoch: 12/100... Training loss: 0.1182\n",
      "Epoch: 12/100... Training loss: 0.1165\n",
      "Epoch: 12/100... Training loss: 0.1164\n",
      "Epoch: 12/100... Training loss: 0.1144\n",
      "Epoch: 12/100... Training loss: 0.1173\n",
      "Epoch: 12/100... Training loss: 0.1196\n",
      "Epoch: 12/100... Training loss: 0.1203\n",
      "Epoch: 12/100... Training loss: 0.1216\n",
      "Epoch: 12/100... Training loss: 0.1207\n",
      "Epoch: 12/100... Training loss: 0.1196\n",
      "Epoch: 12/100... Training loss: 0.1175\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1191\n",
      "Epoch: 12/100... Training loss: 0.1199\n",
      "Epoch: 12/100... Training loss: 0.1218\n",
      "Epoch: 12/100... Training loss: 0.1197\n",
      "Epoch: 12/100... Training loss: 0.1206\n",
      "Epoch: 12/100... Training loss: 0.1194\n",
      "Epoch: 12/100... Training loss: 0.1155\n",
      "Epoch: 12/100... Training loss: 0.1182\n",
      "Epoch: 12/100... Training loss: 0.1185\n",
      "Epoch: 12/100... Training loss: 0.1193\n",
      "Epoch: 12/100... Training loss: 0.1201\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1160\n",
      "Epoch: 12/100... Training loss: 0.1201\n",
      "Epoch: 12/100... Training loss: 0.1178\n",
      "Epoch: 12/100... Training loss: 0.1207\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1182\n",
      "Epoch: 12/100... Training loss: 0.1166\n",
      "Epoch: 12/100... Training loss: 0.1186\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1218\n",
      "Epoch: 12/100... Training loss: 0.1178\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1186\n",
      "Epoch: 12/100... Training loss: 0.1162\n",
      "Epoch: 12/100... Training loss: 0.1168\n",
      "Epoch: 12/100... Training loss: 0.1164\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1168\n",
      "Epoch: 12/100... Training loss: 0.1158\n",
      "Epoch: 12/100... Training loss: 0.1158\n",
      "Epoch: 12/100... Training loss: 0.1163\n",
      "Epoch: 12/100... Training loss: 0.1147\n",
      "Epoch: 12/100... Training loss: 0.1168\n",
      "Epoch: 12/100... Training loss: 0.1174\n",
      "Epoch: 12/100... Training loss: 0.1162\n",
      "Epoch: 12/100... Training loss: 0.1173\n",
      "Epoch: 12/100... Training loss: 0.1166\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1165\n",
      "Epoch: 12/100... Training loss: 0.1196\n",
      "Epoch: 12/100... Training loss: 0.1148\n",
      "Epoch: 12/100... Training loss: 0.1176\n",
      "Epoch: 12/100... Training loss: 0.1176\n",
      "Epoch: 12/100... Training loss: 0.1172\n",
      "Epoch: 12/100... Training loss: 0.1168\n",
      "Epoch: 12/100... Training loss: 0.1213\n",
      "Epoch: 12/100... Training loss: 0.1168\n",
      "Epoch: 12/100... Training loss: 0.1139\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1163\n",
      "Epoch: 12/100... Training loss: 0.1160\n",
      "Epoch: 12/100... Training loss: 0.1191\n",
      "Epoch: 12/100... Training loss: 0.1154\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1145\n",
      "Epoch: 12/100... Training loss: 0.1160\n",
      "Epoch: 12/100... Training loss: 0.1184\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1175\n",
      "Epoch: 12/100... Training loss: 0.1160\n",
      "Epoch: 12/100... Training loss: 0.1150\n",
      "Epoch: 12/100... Training loss: 0.1174\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1161\n",
      "Epoch: 12/100... Training loss: 0.1204\n",
      "Epoch: 12/100... Training loss: 0.1176\n",
      "Epoch: 12/100... Training loss: 0.1174\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1174\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1176\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1179\n",
      "Epoch: 12/100... Training loss: 0.1151\n",
      "Epoch: 12/100... Training loss: 0.1189\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1137\n",
      "Epoch: 12/100... Training loss: 0.1142\n",
      "Epoch: 12/100... Training loss: 0.1176\n",
      "Epoch: 12/100... Training loss: 0.1140\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1114\n",
      "Epoch: 12/100... Training loss: 0.1183\n",
      "Epoch: 12/100... Training loss: 0.1185\n",
      "Epoch: 12/100... Training loss: 0.1169\n",
      "Epoch: 12/100... Training loss: 0.1180\n",
      "Epoch: 12/100... Training loss: 0.1130\n",
      "Epoch: 12/100... Training loss: 0.1118\n",
      "Epoch: 12/100... Training loss: 0.1192\n",
      "Epoch: 12/100... Training loss: 0.1172\n",
      "Epoch: 12/100... Training loss: 0.1152\n",
      "Epoch: 12/100... Training loss: 0.1179\n",
      "Epoch: 12/100... Training loss: 0.1188\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1120\n",
      "Epoch: 12/100... Training loss: 0.1171\n",
      "Epoch: 12/100... Training loss: 0.1182\n",
      "Epoch: 12/100... Training loss: 0.1162\n",
      "Epoch: 12/100... Training loss: 0.1180\n",
      "Epoch: 12/100... Training loss: 0.1124\n",
      "Epoch: 12/100... Training loss: 0.1152\n",
      "Epoch: 12/100... Training loss: 0.1195\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1099\n",
      "Epoch: 12/100... Training loss: 0.1179\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1174\n",
      "Epoch: 12/100... Training loss: 0.1180\n",
      "Epoch: 12/100... Training loss: 0.1141\n",
      "Epoch: 12/100... Training loss: 0.1166\n",
      "Epoch: 12/100... Training loss: 0.1127\n",
      "Epoch: 12/100... Training loss: 0.1152\n",
      "Epoch: 12/100... Training loss: 0.1174\n",
      "Epoch: 12/100... Training loss: 0.1147\n",
      "Epoch: 12/100... Training loss: 0.1126\n",
      "Epoch: 12/100... Training loss: 0.1222\n",
      "Epoch: 12/100... Training loss: 0.1164\n",
      "Epoch: 12/100... Training loss: 0.1129\n",
      "Epoch: 12/100... Training loss: 0.1131\n",
      "Epoch: 12/100... Training loss: 0.1104\n",
      "Epoch: 12/100... Training loss: 0.1179\n",
      "Epoch: 12/100... Training loss: 0.1150\n",
      "Epoch: 12/100... Training loss: 0.1170\n",
      "Epoch: 12/100... Training loss: 0.1122\n",
      "Epoch: 12/100... Training loss: 0.1169\n",
      "Epoch: 12/100... Training loss: 0.1125\n",
      "Epoch: 12/100... Training loss: 0.1179\n",
      "Epoch: 12/100... Training loss: 0.1177\n",
      "Epoch: 12/100... Training loss: 0.1135\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1123\n",
      "Epoch: 12/100... Training loss: 0.1160\n",
      "Epoch: 12/100... Training loss: 0.1156\n",
      "Epoch: 12/100... Training loss: 0.1158\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1156\n",
      "Epoch: 12/100... Training loss: 0.1156\n",
      "Epoch: 12/100... Training loss: 0.1184\n",
      "Epoch: 12/100... Training loss: 0.1175\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1159\n",
      "Epoch: 12/100... Training loss: 0.1168\n",
      "Epoch: 12/100... Training loss: 0.1178\n",
      "Epoch: 12/100... Training loss: 0.1169\n",
      "Epoch: 12/100... Training loss: 0.1173\n",
      "Epoch: 12/100... Training loss: 0.1161\n",
      "Epoch: 12/100... Training loss: 0.1165\n",
      "Epoch: 12/100... Training loss: 0.1196\n",
      "Epoch: 12/100... Training loss: 0.1166\n",
      "Epoch: 12/100... Training loss: 0.1192\n",
      "Epoch: 12/100... Training loss: 0.1168\n",
      "Epoch: 12/100... Training loss: 0.1190\n",
      "Epoch: 12/100... Training loss: 0.1174\n",
      "Epoch: 12/100... Training loss: 0.1172\n",
      "Epoch: 12/100... Training loss: 0.1177\n",
      "Epoch: 12/100... Training loss: 0.1172\n",
      "Epoch: 12/100... Training loss: 0.1195\n",
      "Epoch: 12/100... Training loss: 0.1189\n",
      "Epoch: 12/100... Training loss: 0.1185\n",
      "Epoch: 12/100... Training loss: 0.1182\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1150\n",
      "Epoch: 12/100... Training loss: 0.1148\n",
      "Epoch: 12/100... Training loss: 0.1202\n",
      "Epoch: 12/100... Training loss: 0.1116\n",
      "Epoch: 12/100... Training loss: 0.1117\n",
      "Epoch: 12/100... Training loss: 0.1121\n",
      "Epoch: 12/100... Training loss: 0.1134\n",
      "Epoch: 12/100... Training loss: 0.1182\n",
      "Epoch: 12/100... Training loss: 0.1168\n",
      "Epoch: 12/100... Training loss: 0.1155\n",
      "Epoch: 12/100... Training loss: 0.1170\n",
      "Epoch: 12/100... Training loss: 0.1182\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1149\n",
      "Epoch: 12/100... Training loss: 0.1178\n",
      "Epoch: 12/100... Training loss: 0.1157\n",
      "Epoch: 12/100... Training loss: 0.1200\n",
      "Epoch: 12/100... Training loss: 0.1182\n",
      "Epoch: 12/100... Training loss: 0.1169\n",
      "Epoch: 12/100... Training loss: 0.1138\n",
      "Epoch: 12/100... Training loss: 0.1184\n",
      "Epoch: 12/100... Training loss: 0.1162\n",
      "Epoch: 12/100... Training loss: 0.1174\n",
      "Epoch: 12/100... Training loss: 0.1146\n",
      "Epoch: 12/100... Training loss: 0.1148\n",
      "Epoch: 12/100... Training loss: 0.1147\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1206\n",
      "Epoch: 13/100... Training loss: 0.1187\n",
      "Epoch: 13/100... Training loss: 0.1159\n",
      "Epoch: 13/100... Training loss: 0.1136\n",
      "Epoch: 13/100... Training loss: 0.1193\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1170\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1157\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1171\n",
      "Epoch: 13/100... Training loss: 0.1171\n",
      "Epoch: 13/100... Training loss: 0.1153\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1172\n",
      "Epoch: 13/100... Training loss: 0.1212\n",
      "Epoch: 13/100... Training loss: 0.1205\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1128\n",
      "Epoch: 13/100... Training loss: 0.1136\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1166\n",
      "Epoch: 13/100... Training loss: 0.1146\n",
      "Epoch: 13/100... Training loss: 0.1131\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1169\n",
      "Epoch: 13/100... Training loss: 0.1156\n",
      "Epoch: 13/100... Training loss: 0.1098\n",
      "Epoch: 13/100... Training loss: 0.1215\n",
      "Epoch: 13/100... Training loss: 0.1162\n",
      "Epoch: 13/100... Training loss: 0.1147\n",
      "Epoch: 13/100... Training loss: 0.1192\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1164\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1169\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1156\n",
      "Epoch: 13/100... Training loss: 0.1146\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1158\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1165\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1136\n",
      "Epoch: 13/100... Training loss: 0.1189\n",
      "Epoch: 13/100... Training loss: 0.1165\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1170\n",
      "Epoch: 13/100... Training loss: 0.1176\n",
      "Epoch: 13/100... Training loss: 0.1151\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1158\n",
      "Epoch: 13/100... Training loss: 0.1207\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1169\n",
      "Epoch: 13/100... Training loss: 0.1178\n",
      "Epoch: 13/100... Training loss: 0.1164\n",
      "Epoch: 13/100... Training loss: 0.1166\n",
      "Epoch: 13/100... Training loss: 0.1170\n",
      "Epoch: 13/100... Training loss: 0.1165\n",
      "Epoch: 13/100... Training loss: 0.1139\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1166\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1192\n",
      "Epoch: 13/100... Training loss: 0.1138\n",
      "Epoch: 13/100... Training loss: 0.1196\n",
      "Epoch: 13/100... Training loss: 0.1191\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1168\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1167\n",
      "Epoch: 13/100... Training loss: 0.1157\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1179\n",
      "Epoch: 13/100... Training loss: 0.1182\n",
      "Epoch: 13/100... Training loss: 0.1159\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1147\n",
      "Epoch: 13/100... Training loss: 0.1169\n",
      "Epoch: 13/100... Training loss: 0.1105\n",
      "Epoch: 13/100... Training loss: 0.1169\n",
      "Epoch: 13/100... Training loss: 0.1156\n",
      "Epoch: 13/100... Training loss: 0.1187\n",
      "Epoch: 13/100... Training loss: 0.1147\n",
      "Epoch: 13/100... Training loss: 0.1154\n",
      "Epoch: 13/100... Training loss: 0.1124\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1192\n",
      "Epoch: 13/100... Training loss: 0.1134\n",
      "Epoch: 13/100... Training loss: 0.1156\n",
      "Epoch: 13/100... Training loss: 0.1181\n",
      "Epoch: 13/100... Training loss: 0.1173\n",
      "Epoch: 13/100... Training loss: 0.1113\n",
      "Epoch: 13/100... Training loss: 0.1162\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1128\n",
      "Epoch: 13/100... Training loss: 0.1173\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1159\n",
      "Epoch: 13/100... Training loss: 0.1136\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1179\n",
      "Epoch: 13/100... Training loss: 0.1148\n",
      "Epoch: 13/100... Training loss: 0.1155\n",
      "Epoch: 13/100... Training loss: 0.1210\n",
      "Epoch: 13/100... Training loss: 0.1159\n",
      "Epoch: 13/100... Training loss: 0.1180\n",
      "Epoch: 13/100... Training loss: 0.1174\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1147\n",
      "Epoch: 13/100... Training loss: 0.1170\n",
      "Epoch: 13/100... Training loss: 0.1154\n",
      "Epoch: 13/100... Training loss: 0.1179\n",
      "Epoch: 13/100... Training loss: 0.1130\n",
      "Epoch: 13/100... Training loss: 0.1150\n",
      "Epoch: 13/100... Training loss: 0.1187\n",
      "Epoch: 13/100... Training loss: 0.1158\n",
      "Epoch: 13/100... Training loss: 0.1165\n",
      "Epoch: 13/100... Training loss: 0.1177\n",
      "Epoch: 13/100... Training loss: 0.1202\n",
      "Epoch: 13/100... Training loss: 0.1146\n",
      "Epoch: 13/100... Training loss: 0.1155\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1179\n",
      "Epoch: 13/100... Training loss: 0.1153\n",
      "Epoch: 13/100... Training loss: 0.1163\n",
      "Epoch: 13/100... Training loss: 0.1129\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1132\n",
      "Epoch: 13/100... Training loss: 0.1159\n",
      "Epoch: 13/100... Training loss: 0.1138\n",
      "Epoch: 13/100... Training loss: 0.1156\n",
      "Epoch: 13/100... Training loss: 0.1180\n",
      "Epoch: 13/100... Training loss: 0.1203\n",
      "Epoch: 13/100... Training loss: 0.1162\n",
      "Epoch: 13/100... Training loss: 0.1192\n",
      "Epoch: 13/100... Training loss: 0.1176\n",
      "Epoch: 13/100... Training loss: 0.1138\n",
      "Epoch: 13/100... Training loss: 0.1188\n",
      "Epoch: 13/100... Training loss: 0.1191\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1167\n",
      "Epoch: 13/100... Training loss: 0.1175\n",
      "Epoch: 13/100... Training loss: 0.1158\n",
      "Epoch: 13/100... Training loss: 0.1174\n",
      "Epoch: 13/100... Training loss: 0.1141\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1147\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1116\n",
      "Epoch: 13/100... Training loss: 0.1157\n",
      "Epoch: 13/100... Training loss: 0.1136\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1182\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1143\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1178\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1141\n",
      "Epoch: 13/100... Training loss: 0.1155\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1206\n",
      "Epoch: 13/100... Training loss: 0.1158\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1150\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1165\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1154\n",
      "Epoch: 13/100... Training loss: 0.1158\n",
      "Epoch: 13/100... Training loss: 0.1198\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1100\n",
      "Epoch: 13/100... Training loss: 0.1095\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1107\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1161\n",
      "Epoch: 13/100... Training loss: 0.1123\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1141\n",
      "Epoch: 13/100... Training loss: 0.1148\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1108\n",
      "Epoch: 13/100... Training loss: 0.1151\n",
      "Epoch: 13/100... Training loss: 0.1193\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1135\n",
      "Epoch: 13/100... Training loss: 0.1138\n",
      "Epoch: 13/100... Training loss: 0.1163\n",
      "Epoch: 13/100... Training loss: 0.1181\n",
      "Epoch: 13/100... Training loss: 0.1184\n",
      "Epoch: 13/100... Training loss: 0.1137\n",
      "Epoch: 13/100... Training loss: 0.1179\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1141\n",
      "Epoch: 13/100... Training loss: 0.1134\n",
      "Epoch: 13/100... Training loss: 0.1149\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1182\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1201\n",
      "Epoch: 13/100... Training loss: 0.1209\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1147\n",
      "Epoch: 13/100... Training loss: 0.1178\n",
      "Epoch: 13/100... Training loss: 0.1151\n",
      "Epoch: 13/100... Training loss: 0.1143\n",
      "Epoch: 13/100... Training loss: 0.1179\n",
      "Epoch: 13/100... Training loss: 0.1164\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1151\n",
      "Epoch: 13/100... Training loss: 0.1133\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1178\n",
      "Epoch: 13/100... Training loss: 0.1175\n",
      "Epoch: 13/100... Training loss: 0.1161\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1092\n",
      "Epoch: 13/100... Training loss: 0.1183\n",
      "Epoch: 13/100... Training loss: 0.1201\n",
      "Epoch: 13/100... Training loss: 0.1176\n",
      "Epoch: 13/100... Training loss: 0.1163\n",
      "Epoch: 13/100... Training loss: 0.1110\n",
      "Epoch: 13/100... Training loss: 0.1194\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1172\n",
      "Epoch: 13/100... Training loss: 0.1169\n",
      "Epoch: 13/100... Training loss: 0.1164\n",
      "Epoch: 13/100... Training loss: 0.1168\n",
      "Epoch: 13/100... Training loss: 0.1141\n",
      "Epoch: 13/100... Training loss: 0.1171\n",
      "Epoch: 13/100... Training loss: 0.1152\n",
      "Epoch: 13/100... Training loss: 0.1167\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1188\n",
      "Epoch: 13/100... Training loss: 0.1151\n",
      "Epoch: 13/100... Training loss: 0.1199\n",
      "Epoch: 13/100... Training loss: 0.1177\n",
      "Epoch: 13/100... Training loss: 0.1158\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1142\n",
      "Epoch: 13/100... Training loss: 0.1125\n",
      "Epoch: 13/100... Training loss: 0.1111\n",
      "Epoch: 13/100... Training loss: 0.1089\n",
      "Epoch: 13/100... Training loss: 0.1130\n",
      "Epoch: 13/100... Training loss: 0.1141\n",
      "Epoch: 13/100... Training loss: 0.1202\n",
      "Epoch: 13/100... Training loss: 0.1115\n",
      "Epoch: 13/100... Training loss: 0.1153\n",
      "Epoch: 13/100... Training loss: 0.1164\n",
      "Epoch: 13/100... Training loss: 0.1158\n",
      "Epoch: 13/100... Training loss: 0.1153\n",
      "Epoch: 13/100... Training loss: 0.1178\n",
      "Epoch: 13/100... Training loss: 0.1170\n",
      "Epoch: 13/100... Training loss: 0.1159\n",
      "Epoch: 13/100... Training loss: 0.1183\n",
      "Epoch: 13/100... Training loss: 0.1185\n",
      "Epoch: 13/100... Training loss: 0.1178\n",
      "Epoch: 13/100... Training loss: 0.1130\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1139\n",
      "Epoch: 13/100... Training loss: 0.1140\n",
      "Epoch: 13/100... Training loss: 0.1150\n",
      "Epoch: 13/100... Training loss: 0.1136\n",
      "Epoch: 13/100... Training loss: 0.1174\n",
      "Epoch: 13/100... Training loss: 0.1181\n",
      "Epoch: 13/100... Training loss: 0.1117\n",
      "Epoch: 13/100... Training loss: 0.1173\n",
      "Epoch: 13/100... Training loss: 0.1126\n",
      "Epoch: 13/100... Training loss: 0.1161\n",
      "Epoch: 13/100... Training loss: 0.1161\n",
      "Epoch: 13/100... Training loss: 0.1145\n",
      "Epoch: 13/100... Training loss: 0.1144\n",
      "Epoch: 13/100... Training loss: 0.1118\n",
      "Epoch: 13/100... Training loss: 0.1160\n",
      "Epoch: 13/100... Training loss: 0.1154\n",
      "Epoch: 13/100... Training loss: 0.1127\n",
      "Epoch: 13/100... Training loss: 0.1146\n",
      "Epoch: 13/100... Training loss: 0.1121\n",
      "Epoch: 13/100... Training loss: 0.1163\n",
      "Epoch: 14/100... Training loss: 0.1144\n",
      "Epoch: 14/100... Training loss: 0.1106\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1152\n",
      "Epoch: 14/100... Training loss: 0.1165\n",
      "Epoch: 14/100... Training loss: 0.1159\n",
      "Epoch: 14/100... Training loss: 0.1168\n",
      "Epoch: 14/100... Training loss: 0.1171\n",
      "Epoch: 14/100... Training loss: 0.1175\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1169\n",
      "Epoch: 14/100... Training loss: 0.1165\n",
      "Epoch: 14/100... Training loss: 0.1180\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1198\n",
      "Epoch: 14/100... Training loss: 0.1152\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1135\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1177\n",
      "Epoch: 14/100... Training loss: 0.1151\n",
      "Epoch: 14/100... Training loss: 0.1181\n",
      "Epoch: 14/100... Training loss: 0.1144\n",
      "Epoch: 14/100... Training loss: 0.1146\n",
      "Epoch: 14/100... Training loss: 0.1194\n",
      "Epoch: 14/100... Training loss: 0.1160\n",
      "Epoch: 14/100... Training loss: 0.1189\n",
      "Epoch: 14/100... Training loss: 0.1142\n",
      "Epoch: 14/100... Training loss: 0.1164\n",
      "Epoch: 14/100... Training loss: 0.1180\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1150\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1159\n",
      "Epoch: 14/100... Training loss: 0.1192\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1135\n",
      "Epoch: 14/100... Training loss: 0.1199\n",
      "Epoch: 14/100... Training loss: 0.1148\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1163\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1159\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1129\n",
      "Epoch: 14/100... Training loss: 0.1175\n",
      "Epoch: 14/100... Training loss: 0.1170\n",
      "Epoch: 14/100... Training loss: 0.1152\n",
      "Epoch: 14/100... Training loss: 0.1129\n",
      "Epoch: 14/100... Training loss: 0.1178\n",
      "Epoch: 14/100... Training loss: 0.1168\n",
      "Epoch: 14/100... Training loss: 0.1172\n",
      "Epoch: 14/100... Training loss: 0.1188\n",
      "Epoch: 14/100... Training loss: 0.1154\n",
      "Epoch: 14/100... Training loss: 0.1197\n",
      "Epoch: 14/100... Training loss: 0.1190\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1149\n",
      "Epoch: 14/100... Training loss: 0.1169\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1155\n",
      "Epoch: 14/100... Training loss: 0.1153\n",
      "Epoch: 14/100... Training loss: 0.1166\n",
      "Epoch: 14/100... Training loss: 0.1157\n",
      "Epoch: 14/100... Training loss: 0.1165\n",
      "Epoch: 14/100... Training loss: 0.1152\n",
      "Epoch: 14/100... Training loss: 0.1150\n",
      "Epoch: 14/100... Training loss: 0.1139\n",
      "Epoch: 14/100... Training loss: 0.1155\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1127\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1140\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1146\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1146\n",
      "Epoch: 14/100... Training loss: 0.1171\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1142\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1155\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1147\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1181\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1181\n",
      "Epoch: 14/100... Training loss: 0.1149\n",
      "Epoch: 14/100... Training loss: 0.1178\n",
      "Epoch: 14/100... Training loss: 0.1125\n",
      "Epoch: 14/100... Training loss: 0.1125\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1154\n",
      "Epoch: 14/100... Training loss: 0.1169\n",
      "Epoch: 14/100... Training loss: 0.1154\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1194\n",
      "Epoch: 14/100... Training loss: 0.1157\n",
      "Epoch: 14/100... Training loss: 0.1174\n",
      "Epoch: 14/100... Training loss: 0.1128\n",
      "Epoch: 14/100... Training loss: 0.1158\n",
      "Epoch: 14/100... Training loss: 0.1127\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1157\n",
      "Epoch: 14/100... Training loss: 0.1147\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1096\n",
      "Epoch: 14/100... Training loss: 0.1166\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1150\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1126\n",
      "Epoch: 14/100... Training loss: 0.1142\n",
      "Epoch: 14/100... Training loss: 0.1147\n",
      "Epoch: 14/100... Training loss: 0.1171\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1158\n",
      "Epoch: 14/100... Training loss: 0.1150\n",
      "Epoch: 14/100... Training loss: 0.1144\n",
      "Epoch: 14/100... Training loss: 0.1168\n",
      "Epoch: 14/100... Training loss: 0.1102\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1195\n",
      "Epoch: 14/100... Training loss: 0.1134\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1146\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1113\n",
      "Epoch: 14/100... Training loss: 0.1129\n",
      "Epoch: 14/100... Training loss: 0.1179\n",
      "Epoch: 14/100... Training loss: 0.1146\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1211\n",
      "Epoch: 14/100... Training loss: 0.1135\n",
      "Epoch: 14/100... Training loss: 0.1169\n",
      "Epoch: 14/100... Training loss: 0.1126\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1179\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1192\n",
      "Epoch: 14/100... Training loss: 0.1153\n",
      "Epoch: 14/100... Training loss: 0.1181\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1104\n",
      "Epoch: 14/100... Training loss: 0.1150\n",
      "Epoch: 14/100... Training loss: 0.1135\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1127\n",
      "Epoch: 14/100... Training loss: 0.1173\n",
      "Epoch: 14/100... Training loss: 0.1158\n",
      "Epoch: 14/100... Training loss: 0.1148\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1117\n",
      "Epoch: 14/100... Training loss: 0.1183\n",
      "Epoch: 14/100... Training loss: 0.1158\n",
      "Epoch: 14/100... Training loss: 0.1135\n",
      "Epoch: 14/100... Training loss: 0.1150\n",
      "Epoch: 14/100... Training loss: 0.1186\n",
      "Epoch: 14/100... Training loss: 0.1163\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1155\n",
      "Epoch: 14/100... Training loss: 0.1140\n",
      "Epoch: 14/100... Training loss: 0.1129\n",
      "Epoch: 14/100... Training loss: 0.1180\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1164\n",
      "Epoch: 14/100... Training loss: 0.1179\n",
      "Epoch: 14/100... Training loss: 0.1191\n",
      "Epoch: 14/100... Training loss: 0.1146\n",
      "Epoch: 14/100... Training loss: 0.1135\n",
      "Epoch: 14/100... Training loss: 0.1139\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1170\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1156\n",
      "Epoch: 14/100... Training loss: 0.1153\n",
      "Epoch: 14/100... Training loss: 0.1099\n",
      "Epoch: 14/100... Training loss: 0.1164\n",
      "Epoch: 14/100... Training loss: 0.1163\n",
      "Epoch: 14/100... Training loss: 0.1159\n",
      "Epoch: 14/100... Training loss: 0.1177\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1129\n",
      "Epoch: 14/100... Training loss: 0.1118\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1140\n",
      "Epoch: 14/100... Training loss: 0.1186\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1159\n",
      "Epoch: 14/100... Training loss: 0.1126\n",
      "Epoch: 14/100... Training loss: 0.1147\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1156\n",
      "Epoch: 14/100... Training loss: 0.1107\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1176\n",
      "Epoch: 14/100... Training loss: 0.1162\n",
      "Epoch: 14/100... Training loss: 0.1203\n",
      "Epoch: 14/100... Training loss: 0.1120\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1159\n",
      "Epoch: 14/100... Training loss: 0.1147\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1121\n",
      "Epoch: 14/100... Training loss: 0.1124\n",
      "Epoch: 14/100... Training loss: 0.1160\n",
      "Epoch: 14/100... Training loss: 0.1137\n",
      "Epoch: 14/100... Training loss: 0.1170\n",
      "Epoch: 14/100... Training loss: 0.1123\n",
      "Epoch: 14/100... Training loss: 0.1125\n",
      "Epoch: 14/100... Training loss: 0.1126\n",
      "Epoch: 14/100... Training loss: 0.1190\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1135\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1178\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1146\n",
      "Epoch: 14/100... Training loss: 0.1148\n",
      "Epoch: 14/100... Training loss: 0.1066\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1112\n",
      "Epoch: 14/100... Training loss: 0.1174\n",
      "Epoch: 14/100... Training loss: 0.1159\n",
      "Epoch: 14/100... Training loss: 0.1154\n",
      "Epoch: 14/100... Training loss: 0.1164\n",
      "Epoch: 14/100... Training loss: 0.1160\n",
      "Epoch: 14/100... Training loss: 0.1130\n",
      "Epoch: 14/100... Training loss: 0.1196\n",
      "Epoch: 14/100... Training loss: 0.1159\n",
      "Epoch: 14/100... Training loss: 0.1160\n",
      "Epoch: 14/100... Training loss: 0.1133\n",
      "Epoch: 14/100... Training loss: 0.1139\n",
      "Epoch: 14/100... Training loss: 0.1151\n",
      "Epoch: 14/100... Training loss: 0.1110\n",
      "Epoch: 14/100... Training loss: 0.1098\n",
      "Epoch: 14/100... Training loss: 0.1153\n",
      "Epoch: 14/100... Training loss: 0.1140\n",
      "Epoch: 14/100... Training loss: 0.1140\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1108\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1121\n",
      "Epoch: 14/100... Training loss: 0.1148\n",
      "Epoch: 14/100... Training loss: 0.1151\n",
      "Epoch: 14/100... Training loss: 0.1134\n",
      "Epoch: 14/100... Training loss: 0.1094\n",
      "Epoch: 14/100... Training loss: 0.1168\n",
      "Epoch: 14/100... Training loss: 0.1136\n",
      "Epoch: 14/100... Training loss: 0.1115\n",
      "Epoch: 14/100... Training loss: 0.1134\n",
      "Epoch: 14/100... Training loss: 0.1158\n",
      "Epoch: 14/100... Training loss: 0.1143\n",
      "Epoch: 14/100... Training loss: 0.1156\n",
      "Epoch: 14/100... Training loss: 0.1109\n",
      "Epoch: 14/100... Training loss: 0.1160\n",
      "Epoch: 14/100... Training loss: 0.1131\n",
      "Epoch: 14/100... Training loss: 0.1152\n",
      "Epoch: 14/100... Training loss: 0.1163\n",
      "Epoch: 14/100... Training loss: 0.1132\n",
      "Epoch: 14/100... Training loss: 0.1186\n",
      "Epoch: 14/100... Training loss: 0.1166\n",
      "Epoch: 14/100... Training loss: 0.1126\n",
      "Epoch: 14/100... Training loss: 0.1155\n",
      "Epoch: 14/100... Training loss: 0.1177\n",
      "Epoch: 14/100... Training loss: 0.1150\n",
      "Epoch: 14/100... Training loss: 0.1141\n",
      "Epoch: 14/100... Training loss: 0.1140\n",
      "Epoch: 14/100... Training loss: 0.1145\n",
      "Epoch: 14/100... Training loss: 0.1168\n",
      "Epoch: 14/100... Training loss: 0.1138\n",
      "Epoch: 14/100... Training loss: 0.1122\n",
      "Epoch: 14/100... Training loss: 0.1116\n",
      "Epoch: 14/100... Training loss: 0.1140\n",
      "Epoch: 14/100... Training loss: 0.1155\n",
      "Epoch: 14/100... Training loss: 0.1157\n",
      "Epoch: 14/100... Training loss: 0.1134\n",
      "Epoch: 14/100... Training loss: 0.1142\n",
      "Epoch: 14/100... Training loss: 0.1100\n",
      "Epoch: 14/100... Training loss: 0.1126\n",
      "Epoch: 14/100... Training loss: 0.1145\n",
      "Epoch: 14/100... Training loss: 0.1148\n",
      "Epoch: 14/100... Training loss: 0.1162\n",
      "Epoch: 14/100... Training loss: 0.1189\n",
      "Epoch: 14/100... Training loss: 0.1180\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1187\n",
      "Epoch: 15/100... Training loss: 0.1144\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1124\n",
      "Epoch: 15/100... Training loss: 0.1139\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1153\n",
      "Epoch: 15/100... Training loss: 0.1150\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1132\n",
      "Epoch: 15/100... Training loss: 0.1167\n",
      "Epoch: 15/100... Training loss: 0.1150\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1152\n",
      "Epoch: 15/100... Training loss: 0.1148\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1178\n",
      "Epoch: 15/100... Training loss: 0.1153\n",
      "Epoch: 15/100... Training loss: 0.1129\n",
      "Epoch: 15/100... Training loss: 0.1143\n",
      "Epoch: 15/100... Training loss: 0.1139\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1108\n",
      "Epoch: 15/100... Training loss: 0.1149\n",
      "Epoch: 15/100... Training loss: 0.1149\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1144\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1170\n",
      "Epoch: 15/100... Training loss: 0.1174\n",
      "Epoch: 15/100... Training loss: 0.1161\n",
      "Epoch: 15/100... Training loss: 0.1138\n",
      "Epoch: 15/100... Training loss: 0.1160\n",
      "Epoch: 15/100... Training loss: 0.1151\n",
      "Epoch: 15/100... Training loss: 0.1140\n",
      "Epoch: 15/100... Training loss: 0.1140\n",
      "Epoch: 15/100... Training loss: 0.1147\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1154\n",
      "Epoch: 15/100... Training loss: 0.1203\n",
      "Epoch: 15/100... Training loss: 0.1194\n",
      "Epoch: 15/100... Training loss: 0.1178\n",
      "Epoch: 15/100... Training loss: 0.1193\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1151\n",
      "Epoch: 15/100... Training loss: 0.1132\n",
      "Epoch: 15/100... Training loss: 0.1131\n",
      "Epoch: 15/100... Training loss: 0.1160\n",
      "Epoch: 15/100... Training loss: 0.1160\n",
      "Epoch: 15/100... Training loss: 0.1131\n",
      "Epoch: 15/100... Training loss: 0.1156\n",
      "Epoch: 15/100... Training loss: 0.1152\n",
      "Epoch: 15/100... Training loss: 0.1168\n",
      "Epoch: 15/100... Training loss: 0.1133\n",
      "Epoch: 15/100... Training loss: 0.1158\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1131\n",
      "Epoch: 15/100... Training loss: 0.1184\n",
      "Epoch: 15/100... Training loss: 0.1168\n",
      "Epoch: 15/100... Training loss: 0.1133\n",
      "Epoch: 15/100... Training loss: 0.1123\n",
      "Epoch: 15/100... Training loss: 0.1183\n",
      "Epoch: 15/100... Training loss: 0.1164\n",
      "Epoch: 15/100... Training loss: 0.1139\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1137\n",
      "Epoch: 15/100... Training loss: 0.1160\n",
      "Epoch: 15/100... Training loss: 0.1138\n",
      "Epoch: 15/100... Training loss: 0.1141\n",
      "Epoch: 15/100... Training loss: 0.1126\n",
      "Epoch: 15/100... Training loss: 0.1167\n",
      "Epoch: 15/100... Training loss: 0.1132\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1166\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1154\n",
      "Epoch: 15/100... Training loss: 0.1138\n",
      "Epoch: 15/100... Training loss: 0.1160\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1189\n",
      "Epoch: 15/100... Training loss: 0.1121\n",
      "Epoch: 15/100... Training loss: 0.1214\n",
      "Epoch: 15/100... Training loss: 0.1121\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1151\n",
      "Epoch: 15/100... Training loss: 0.1138\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1150\n",
      "Epoch: 15/100... Training loss: 0.1138\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1140\n",
      "Epoch: 15/100... Training loss: 0.1146\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1131\n",
      "Epoch: 15/100... Training loss: 0.1133\n",
      "Epoch: 15/100... Training loss: 0.1143\n",
      "Epoch: 15/100... Training loss: 0.1155\n",
      "Epoch: 15/100... Training loss: 0.1191\n",
      "Epoch: 15/100... Training loss: 0.1079\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1132\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1132\n",
      "Epoch: 15/100... Training loss: 0.1192\n",
      "Epoch: 15/100... Training loss: 0.1153\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1175\n",
      "Epoch: 15/100... Training loss: 0.1144\n",
      "Epoch: 15/100... Training loss: 0.1155\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1132\n",
      "Epoch: 15/100... Training loss: 0.1154\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1136\n",
      "Epoch: 15/100... Training loss: 0.1164\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1168\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1132\n",
      "Epoch: 15/100... Training loss: 0.1182\n",
      "Epoch: 15/100... Training loss: 0.1124\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1133\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1138\n",
      "Epoch: 15/100... Training loss: 0.1136\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1141\n",
      "Epoch: 15/100... Training loss: 0.1174\n",
      "Epoch: 15/100... Training loss: 0.1171\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1155\n",
      "Epoch: 15/100... Training loss: 0.1110\n",
      "Epoch: 15/100... Training loss: 0.1164\n",
      "Epoch: 15/100... Training loss: 0.1117\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1144\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1066\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1139\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1157\n",
      "Epoch: 15/100... Training loss: 0.1099\n",
      "Epoch: 15/100... Training loss: 0.1121\n",
      "Epoch: 15/100... Training loss: 0.1162\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1133\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1153\n",
      "Epoch: 15/100... Training loss: 0.1133\n",
      "Epoch: 15/100... Training loss: 0.1122\n",
      "Epoch: 15/100... Training loss: 0.1173\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1143\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1143\n",
      "Epoch: 15/100... Training loss: 0.1127\n",
      "Epoch: 15/100... Training loss: 0.1166\n",
      "Epoch: 15/100... Training loss: 0.1133\n",
      "Epoch: 15/100... Training loss: 0.1085\n",
      "Epoch: 15/100... Training loss: 0.1156\n",
      "Epoch: 15/100... Training loss: 0.1126\n",
      "Epoch: 15/100... Training loss: 0.1126\n",
      "Epoch: 15/100... Training loss: 0.1185\n",
      "Epoch: 15/100... Training loss: 0.1087\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1140\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1160\n",
      "Epoch: 15/100... Training loss: 0.1143\n",
      "Epoch: 15/100... Training loss: 0.1137\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1152\n",
      "Epoch: 15/100... Training loss: 0.1125\n",
      "Epoch: 15/100... Training loss: 0.1166\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1165\n",
      "Epoch: 15/100... Training loss: 0.1140\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1155\n",
      "Epoch: 15/100... Training loss: 0.1144\n",
      "Epoch: 15/100... Training loss: 0.1136\n",
      "Epoch: 15/100... Training loss: 0.1126\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1138\n",
      "Epoch: 15/100... Training loss: 0.1155\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1204\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1147\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1131\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1113\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1139\n",
      "Epoch: 15/100... Training loss: 0.1098\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1097\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1145\n",
      "Epoch: 15/100... Training loss: 0.1188\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1112\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1111\n",
      "Epoch: 15/100... Training loss: 0.1166\n",
      "Epoch: 15/100... Training loss: 0.1107\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1146\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1164\n",
      "Epoch: 15/100... Training loss: 0.1137\n",
      "Epoch: 15/100... Training loss: 0.1173\n",
      "Epoch: 15/100... Training loss: 0.1146\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1147\n",
      "Epoch: 15/100... Training loss: 0.1106\n",
      "Epoch: 15/100... Training loss: 0.1147\n",
      "Epoch: 15/100... Training loss: 0.1100\n",
      "Epoch: 15/100... Training loss: 0.1147\n",
      "Epoch: 15/100... Training loss: 0.1148\n",
      "Epoch: 15/100... Training loss: 0.1093\n",
      "Epoch: 15/100... Training loss: 0.1169\n",
      "Epoch: 15/100... Training loss: 0.1133\n",
      "Epoch: 15/100... Training loss: 0.1157\n",
      "Epoch: 15/100... Training loss: 0.1166\n",
      "Epoch: 15/100... Training loss: 0.1123\n",
      "Epoch: 15/100... Training loss: 0.1092\n",
      "Epoch: 15/100... Training loss: 0.1102\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1115\n",
      "Epoch: 15/100... Training loss: 0.1164\n",
      "Epoch: 15/100... Training loss: 0.1103\n",
      "Epoch: 15/100... Training loss: 0.1147\n",
      "Epoch: 15/100... Training loss: 0.1130\n",
      "Epoch: 15/100... Training loss: 0.1149\n",
      "Epoch: 15/100... Training loss: 0.1132\n",
      "Epoch: 15/100... Training loss: 0.1134\n",
      "Epoch: 15/100... Training loss: 0.1090\n",
      "Epoch: 15/100... Training loss: 0.1096\n",
      "Epoch: 15/100... Training loss: 0.1144\n",
      "Epoch: 15/100... Training loss: 0.1157\n",
      "Epoch: 15/100... Training loss: 0.1116\n",
      "Epoch: 15/100... Training loss: 0.1120\n",
      "Epoch: 15/100... Training loss: 0.1119\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1109\n",
      "Epoch: 15/100... Training loss: 0.1135\n",
      "Epoch: 15/100... Training loss: 0.1166\n",
      "Epoch: 15/100... Training loss: 0.1170\n",
      "Epoch: 15/100... Training loss: 0.1139\n",
      "Epoch: 15/100... Training loss: 0.1123\n",
      "Epoch: 15/100... Training loss: 0.1165\n",
      "Epoch: 15/100... Training loss: 0.1141\n",
      "Epoch: 15/100... Training loss: 0.1168\n",
      "Epoch: 15/100... Training loss: 0.1169\n",
      "Epoch: 15/100... Training loss: 0.1118\n",
      "Epoch: 15/100... Training loss: 0.1155\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1138\n",
      "Epoch: 15/100... Training loss: 0.1121\n",
      "Epoch: 15/100... Training loss: 0.1128\n",
      "Epoch: 15/100... Training loss: 0.1167\n",
      "Epoch: 15/100... Training loss: 0.1121\n",
      "Epoch: 15/100... Training loss: 0.1121\n",
      "Epoch: 15/100... Training loss: 0.1105\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1165\n",
      "Epoch: 15/100... Training loss: 0.1101\n",
      "Epoch: 15/100... Training loss: 0.1143\n",
      "Epoch: 15/100... Training loss: 0.1161\n",
      "Epoch: 15/100... Training loss: 0.1142\n",
      "Epoch: 15/100... Training loss: 0.1138\n",
      "Epoch: 15/100... Training loss: 0.1126\n",
      "Epoch: 16/100... Training loss: 0.1140\n",
      "Epoch: 16/100... Training loss: 0.1171\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1159\n",
      "Epoch: 16/100... Training loss: 0.1140\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1116\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1158\n",
      "Epoch: 16/100... Training loss: 0.1134\n",
      "Epoch: 16/100... Training loss: 0.1133\n",
      "Epoch: 16/100... Training loss: 0.1164\n",
      "Epoch: 16/100... Training loss: 0.1128\n",
      "Epoch: 16/100... Training loss: 0.1146\n",
      "Epoch: 16/100... Training loss: 0.1146\n",
      "Epoch: 16/100... Training loss: 0.1127\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1186\n",
      "Epoch: 16/100... Training loss: 0.1137\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1145\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1155\n",
      "Epoch: 16/100... Training loss: 0.1152\n",
      "Epoch: 16/100... Training loss: 0.1163\n",
      "Epoch: 16/100... Training loss: 0.1131\n",
      "Epoch: 16/100... Training loss: 0.1159\n",
      "Epoch: 16/100... Training loss: 0.1169\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1158\n",
      "Epoch: 16/100... Training loss: 0.1078\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1081\n",
      "Epoch: 16/100... Training loss: 0.1142\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1136\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1149\n",
      "Epoch: 16/100... Training loss: 0.1152\n",
      "Epoch: 16/100... Training loss: 0.1147\n",
      "Epoch: 16/100... Training loss: 0.1127\n",
      "Epoch: 16/100... Training loss: 0.1142\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1110\n",
      "Epoch: 16/100... Training loss: 0.1153\n",
      "Epoch: 16/100... Training loss: 0.1148\n",
      "Epoch: 16/100... Training loss: 0.1108\n",
      "Epoch: 16/100... Training loss: 0.1152\n",
      "Epoch: 16/100... Training loss: 0.1152\n",
      "Epoch: 16/100... Training loss: 0.1149\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1127\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1162\n",
      "Epoch: 16/100... Training loss: 0.1139\n",
      "Epoch: 16/100... Training loss: 0.1127\n",
      "Epoch: 16/100... Training loss: 0.1135\n",
      "Epoch: 16/100... Training loss: 0.1157\n",
      "Epoch: 16/100... Training loss: 0.1108\n",
      "Epoch: 16/100... Training loss: 0.1134\n",
      "Epoch: 16/100... Training loss: 0.1137\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1134\n",
      "Epoch: 16/100... Training loss: 0.1163\n",
      "Epoch: 16/100... Training loss: 0.1128\n",
      "Epoch: 16/100... Training loss: 0.1173\n",
      "Epoch: 16/100... Training loss: 0.1133\n",
      "Epoch: 16/100... Training loss: 0.1116\n",
      "Epoch: 16/100... Training loss: 0.1142\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1143\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1108\n",
      "Epoch: 16/100... Training loss: 0.1095\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1094\n",
      "Epoch: 16/100... Training loss: 0.1148\n",
      "Epoch: 16/100... Training loss: 0.1122\n",
      "Epoch: 16/100... Training loss: 0.1161\n",
      "Epoch: 16/100... Training loss: 0.1158\n",
      "Epoch: 16/100... Training loss: 0.1157\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1141\n",
      "Epoch: 16/100... Training loss: 0.1133\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1132\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1158\n",
      "Epoch: 16/100... Training loss: 0.1150\n",
      "Epoch: 16/100... Training loss: 0.1141\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1096\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1131\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1134\n",
      "Epoch: 16/100... Training loss: 0.1143\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1144\n",
      "Epoch: 16/100... Training loss: 0.1126\n",
      "Epoch: 16/100... Training loss: 0.1147\n",
      "Epoch: 16/100... Training loss: 0.1145\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1146\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1174\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1152\n",
      "Epoch: 16/100... Training loss: 0.1134\n",
      "Epoch: 16/100... Training loss: 0.1142\n",
      "Epoch: 16/100... Training loss: 0.1120\n",
      "Epoch: 16/100... Training loss: 0.1126\n",
      "Epoch: 16/100... Training loss: 0.1125\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1178\n",
      "Epoch: 16/100... Training loss: 0.1137\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1140\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1158\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1157\n",
      "Epoch: 16/100... Training loss: 0.1172\n",
      "Epoch: 16/100... Training loss: 0.1150\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1166\n",
      "Epoch: 16/100... Training loss: 0.1148\n",
      "Epoch: 16/100... Training loss: 0.1153\n",
      "Epoch: 16/100... Training loss: 0.1084\n",
      "Epoch: 16/100... Training loss: 0.1122\n",
      "Epoch: 16/100... Training loss: 0.1162\n",
      "Epoch: 16/100... Training loss: 0.1156\n",
      "Epoch: 16/100... Training loss: 0.1158\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1168\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1116\n",
      "Epoch: 16/100... Training loss: 0.1144\n",
      "Epoch: 16/100... Training loss: 0.1099\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1141\n",
      "Epoch: 16/100... Training loss: 0.1135\n",
      "Epoch: 16/100... Training loss: 0.1156\n",
      "Epoch: 16/100... Training loss: 0.1125\n",
      "Epoch: 16/100... Training loss: 0.1137\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1118\n",
      "Epoch: 16/100... Training loss: 0.1141\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1128\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1156\n",
      "Epoch: 16/100... Training loss: 0.1122\n",
      "Epoch: 16/100... Training loss: 0.1127\n",
      "Epoch: 16/100... Training loss: 0.1170\n",
      "Epoch: 16/100... Training loss: 0.1125\n",
      "Epoch: 16/100... Training loss: 0.1137\n",
      "Epoch: 16/100... Training loss: 0.1126\n",
      "Epoch: 16/100... Training loss: 0.1139\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1156\n",
      "Epoch: 16/100... Training loss: 0.1141\n",
      "Epoch: 16/100... Training loss: 0.1122\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1126\n",
      "Epoch: 16/100... Training loss: 0.1079\n",
      "Epoch: 16/100... Training loss: 0.1128\n",
      "Epoch: 16/100... Training loss: 0.1164\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1153\n",
      "Epoch: 16/100... Training loss: 0.1152\n",
      "Epoch: 16/100... Training loss: 0.1105\n",
      "Epoch: 16/100... Training loss: 0.1104\n",
      "Epoch: 16/100... Training loss: 0.1106\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1145\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1148\n",
      "Epoch: 16/100... Training loss: 0.1158\n",
      "Epoch: 16/100... Training loss: 0.1169\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1164\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1120\n",
      "Epoch: 16/100... Training loss: 0.1122\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1121\n",
      "Epoch: 16/100... Training loss: 0.1137\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1083\n",
      "Epoch: 16/100... Training loss: 0.1164\n",
      "Epoch: 16/100... Training loss: 0.1111\n",
      "Epoch: 16/100... Training loss: 0.1172\n",
      "Epoch: 16/100... Training loss: 0.1119\n",
      "Epoch: 16/100... Training loss: 0.1076\n",
      "Epoch: 16/100... Training loss: 0.1156\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 16/100... Training loss: 0.1141\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1133\n",
      "Epoch: 16/100... Training loss: 0.1131\n",
      "Epoch: 16/100... Training loss: 0.1143\n",
      "Epoch: 16/100... Training loss: 0.1120\n",
      "Epoch: 16/100... Training loss: 0.1142\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1127\n",
      "Epoch: 16/100... Training loss: 0.1126\n",
      "Epoch: 16/100... Training loss: 0.1107\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1148\n",
      "Epoch: 16/100... Training loss: 0.1135\n",
      "Epoch: 16/100... Training loss: 0.1115\n",
      "Epoch: 16/100... Training loss: 0.1156\n",
      "Epoch: 16/100... Training loss: 0.1108\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1140\n",
      "Epoch: 16/100... Training loss: 0.1089\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1160\n",
      "Epoch: 16/100... Training loss: 0.1098\n",
      "Epoch: 16/100... Training loss: 0.1137\n",
      "Epoch: 16/100... Training loss: 0.1183\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1120\n",
      "Epoch: 16/100... Training loss: 0.1134\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1139\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1131\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1139\n",
      "Epoch: 16/100... Training loss: 0.1136\n",
      "Epoch: 16/100... Training loss: 0.1142\n",
      "Epoch: 16/100... Training loss: 0.1148\n",
      "Epoch: 16/100... Training loss: 0.1114\n",
      "Epoch: 16/100... Training loss: 0.1060\n",
      "Epoch: 16/100... Training loss: 0.1142\n",
      "Epoch: 16/100... Training loss: 0.1097\n",
      "Epoch: 16/100... Training loss: 0.1124\n",
      "Epoch: 16/100... Training loss: 0.1130\n",
      "Epoch: 16/100... Training loss: 0.1117\n",
      "Epoch: 16/100... Training loss: 0.1147\n",
      "Epoch: 16/100... Training loss: 0.1103\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1149\n",
      "Epoch: 16/100... Training loss: 0.1173\n",
      "Epoch: 16/100... Training loss: 0.1140\n",
      "Epoch: 16/100... Training loss: 0.1093\n",
      "Epoch: 16/100... Training loss: 0.1177\n",
      "Epoch: 16/100... Training loss: 0.1156\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1138\n",
      "Epoch: 16/100... Training loss: 0.1151\n",
      "Epoch: 16/100... Training loss: 0.1125\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1139\n",
      "Epoch: 16/100... Training loss: 0.1113\n",
      "Epoch: 16/100... Training loss: 0.1144\n",
      "Epoch: 16/100... Training loss: 0.1162\n",
      "Epoch: 16/100... Training loss: 0.1080\n",
      "Epoch: 16/100... Training loss: 0.1123\n",
      "Epoch: 16/100... Training loss: 0.1173\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1109\n",
      "Epoch: 16/100... Training loss: 0.1175\n",
      "Epoch: 16/100... Training loss: 0.1102\n",
      "Epoch: 16/100... Training loss: 0.1146\n",
      "Epoch: 16/100... Training loss: 0.1142\n",
      "Epoch: 16/100... Training loss: 0.1135\n",
      "Epoch: 16/100... Training loss: 0.1112\n",
      "Epoch: 16/100... Training loss: 0.1091\n",
      "Epoch: 16/100... Training loss: 0.1153\n",
      "Epoch: 16/100... Training loss: 0.1129\n",
      "Epoch: 16/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1169\n",
      "Epoch: 17/100... Training loss: 0.1151\n",
      "Epoch: 17/100... Training loss: 0.1148\n",
      "Epoch: 17/100... Training loss: 0.1128\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1131\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1137\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1138\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1144\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1112\n",
      "Epoch: 17/100... Training loss: 0.1153\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1140\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1130\n",
      "Epoch: 17/100... Training loss: 0.1109\n",
      "Epoch: 17/100... Training loss: 0.1133\n",
      "Epoch: 17/100... Training loss: 0.1112\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1133\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1164\n",
      "Epoch: 17/100... Training loss: 0.1157\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1109\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1112\n",
      "Epoch: 17/100... Training loss: 0.1137\n",
      "Epoch: 17/100... Training loss: 0.1140\n",
      "Epoch: 17/100... Training loss: 0.1092\n",
      "Epoch: 17/100... Training loss: 0.1168\n",
      "Epoch: 17/100... Training loss: 0.1138\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1145\n",
      "Epoch: 17/100... Training loss: 0.1148\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1145\n",
      "Epoch: 17/100... Training loss: 0.1131\n",
      "Epoch: 17/100... Training loss: 0.1130\n",
      "Epoch: 17/100... Training loss: 0.1154\n",
      "Epoch: 17/100... Training loss: 0.1131\n",
      "Epoch: 17/100... Training loss: 0.1140\n",
      "Epoch: 17/100... Training loss: 0.1149\n",
      "Epoch: 17/100... Training loss: 0.1082\n",
      "Epoch: 17/100... Training loss: 0.1112\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1135\n",
      "Epoch: 17/100... Training loss: 0.1165\n",
      "Epoch: 17/100... Training loss: 0.1155\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1123\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1124\n",
      "Epoch: 17/100... Training loss: 0.1134\n",
      "Epoch: 17/100... Training loss: 0.1146\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1124\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1120\n",
      "Epoch: 17/100... Training loss: 0.1096\n",
      "Epoch: 17/100... Training loss: 0.1147\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1079\n",
      "Epoch: 17/100... Training loss: 0.1120\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1140\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1139\n",
      "Epoch: 17/100... Training loss: 0.1137\n",
      "Epoch: 17/100... Training loss: 0.1113\n",
      "Epoch: 17/100... Training loss: 0.1149\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1130\n",
      "Epoch: 17/100... Training loss: 0.1158\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1133\n",
      "Epoch: 17/100... Training loss: 0.1101\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1178\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1133\n",
      "Epoch: 17/100... Training loss: 0.1127\n",
      "Epoch: 17/100... Training loss: 0.1145\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1133\n",
      "Epoch: 17/100... Training loss: 0.1127\n",
      "Epoch: 17/100... Training loss: 0.1130\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1142\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1127\n",
      "Epoch: 17/100... Training loss: 0.1094\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1156\n",
      "Epoch: 17/100... Training loss: 0.1116\n",
      "Epoch: 17/100... Training loss: 0.1154\n",
      "Epoch: 17/100... Training loss: 0.1138\n",
      "Epoch: 17/100... Training loss: 0.1146\n",
      "Epoch: 17/100... Training loss: 0.1135\n",
      "Epoch: 17/100... Training loss: 0.1139\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1133\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1142\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1139\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1169\n",
      "Epoch: 17/100... Training loss: 0.1087\n",
      "Epoch: 17/100... Training loss: 0.1068\n",
      "Epoch: 17/100... Training loss: 0.1148\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1131\n",
      "Epoch: 17/100... Training loss: 0.1136\n",
      "Epoch: 17/100... Training loss: 0.1081\n",
      "Epoch: 17/100... Training loss: 0.1204\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1165\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1113\n",
      "Epoch: 17/100... Training loss: 0.1128\n",
      "Epoch: 17/100... Training loss: 0.1137\n",
      "Epoch: 17/100... Training loss: 0.1148\n",
      "Epoch: 17/100... Training loss: 0.1136\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1130\n",
      "Epoch: 17/100... Training loss: 0.1148\n",
      "Epoch: 17/100... Training loss: 0.1117\n",
      "Epoch: 17/100... Training loss: 0.1142\n",
      "Epoch: 17/100... Training loss: 0.1154\n",
      "Epoch: 17/100... Training loss: 0.1116\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1118\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1142\n",
      "Epoch: 17/100... Training loss: 0.1133\n",
      "Epoch: 17/100... Training loss: 0.1156\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1099\n",
      "Epoch: 17/100... Training loss: 0.1149\n",
      "Epoch: 17/100... Training loss: 0.1134\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1116\n",
      "Epoch: 17/100... Training loss: 0.1113\n",
      "Epoch: 17/100... Training loss: 0.1133\n",
      "Epoch: 17/100... Training loss: 0.1083\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1123\n",
      "Epoch: 17/100... Training loss: 0.1105\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1117\n",
      "Epoch: 17/100... Training loss: 0.1147\n",
      "Epoch: 17/100... Training loss: 0.1138\n",
      "Epoch: 17/100... Training loss: 0.1138\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1123\n",
      "Epoch: 17/100... Training loss: 0.1145\n",
      "Epoch: 17/100... Training loss: 0.1089\n",
      "Epoch: 17/100... Training loss: 0.1120\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1113\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1116\n",
      "Epoch: 17/100... Training loss: 0.1153\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1140\n",
      "Epoch: 17/100... Training loss: 0.1138\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1124\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1130\n",
      "Epoch: 17/100... Training loss: 0.1129\n",
      "Epoch: 17/100... Training loss: 0.1112\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1135\n",
      "Epoch: 17/100... Training loss: 0.1139\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1113\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1140\n",
      "Epoch: 17/100... Training loss: 0.1142\n",
      "Epoch: 17/100... Training loss: 0.1095\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1084\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1173\n",
      "Epoch: 17/100... Training loss: 0.1130\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1130\n",
      "Epoch: 17/100... Training loss: 0.1131\n",
      "Epoch: 17/100... Training loss: 0.1131\n",
      "Epoch: 17/100... Training loss: 0.1145\n",
      "Epoch: 17/100... Training loss: 0.1072\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1116\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1066\n",
      "Epoch: 17/100... Training loss: 0.1154\n",
      "Epoch: 17/100... Training loss: 0.1118\n",
      "Epoch: 17/100... Training loss: 0.1136\n",
      "Epoch: 17/100... Training loss: 0.1147\n",
      "Epoch: 17/100... Training loss: 0.1088\n",
      "Epoch: 17/100... Training loss: 0.1085\n",
      "Epoch: 17/100... Training loss: 0.1093\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1150\n",
      "Epoch: 17/100... Training loss: 0.1161\n",
      "Epoch: 17/100... Training loss: 0.1117\n",
      "Epoch: 17/100... Training loss: 0.1127\n",
      "Epoch: 17/100... Training loss: 0.1147\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1154\n",
      "Epoch: 17/100... Training loss: 0.1107\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1144\n",
      "Epoch: 17/100... Training loss: 0.1135\n",
      "Epoch: 17/100... Training loss: 0.1163\n",
      "Epoch: 17/100... Training loss: 0.1141\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1117\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1183\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1132\n",
      "Epoch: 17/100... Training loss: 0.1150\n",
      "Epoch: 17/100... Training loss: 0.1155\n",
      "Epoch: 17/100... Training loss: 0.1170\n",
      "Epoch: 17/100... Training loss: 0.1111\n",
      "Epoch: 17/100... Training loss: 0.1056\n",
      "Epoch: 17/100... Training loss: 0.1098\n",
      "Epoch: 17/100... Training loss: 0.1103\n",
      "Epoch: 17/100... Training loss: 0.1150\n",
      "Epoch: 17/100... Training loss: 0.1144\n",
      "Epoch: 17/100... Training loss: 0.1076\n",
      "Epoch: 17/100... Training loss: 0.1160\n",
      "Epoch: 17/100... Training loss: 0.1163\n",
      "Epoch: 17/100... Training loss: 0.1159\n",
      "Epoch: 17/100... Training loss: 0.1149\n",
      "Epoch: 17/100... Training loss: 0.1148\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1122\n",
      "Epoch: 17/100... Training loss: 0.1126\n",
      "Epoch: 17/100... Training loss: 0.1131\n",
      "Epoch: 17/100... Training loss: 0.1149\n",
      "Epoch: 17/100... Training loss: 0.1121\n",
      "Epoch: 17/100... Training loss: 0.1100\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1127\n",
      "Epoch: 17/100... Training loss: 0.1114\n",
      "Epoch: 17/100... Training loss: 0.1125\n",
      "Epoch: 17/100... Training loss: 0.1129\n",
      "Epoch: 17/100... Training loss: 0.1142\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1104\n",
      "Epoch: 17/100... Training loss: 0.1133\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 17/100... Training loss: 0.1139\n",
      "Epoch: 17/100... Training loss: 0.1097\n",
      "Epoch: 17/100... Training loss: 0.1110\n",
      "Epoch: 17/100... Training loss: 0.1052\n",
      "Epoch: 17/100... Training loss: 0.1108\n",
      "Epoch: 17/100... Training loss: 0.1139\n",
      "Epoch: 17/100... Training loss: 0.1102\n",
      "Epoch: 17/100... Training loss: 0.1115\n",
      "Epoch: 17/100... Training loss: 0.1150\n",
      "Epoch: 17/100... Training loss: 0.1131\n",
      "Epoch: 17/100... Training loss: 0.1128\n",
      "Epoch: 17/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1125\n",
      "Epoch: 18/100... Training loss: 0.1132\n",
      "Epoch: 18/100... Training loss: 0.1121\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1123\n",
      "Epoch: 18/100... Training loss: 0.1120\n",
      "Epoch: 18/100... Training loss: 0.1135\n",
      "Epoch: 18/100... Training loss: 0.1156\n",
      "Epoch: 18/100... Training loss: 0.1135\n",
      "Epoch: 18/100... Training loss: 0.1140\n",
      "Epoch: 18/100... Training loss: 0.1144\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1127\n",
      "Epoch: 18/100... Training loss: 0.1109\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1146\n",
      "Epoch: 18/100... Training loss: 0.1123\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1122\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1131\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1149\n",
      "Epoch: 18/100... Training loss: 0.1151\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1123\n",
      "Epoch: 18/100... Training loss: 0.1134\n",
      "Epoch: 18/100... Training loss: 0.1156\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1138\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1123\n",
      "Epoch: 18/100... Training loss: 0.1077\n",
      "Epoch: 18/100... Training loss: 0.1119\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1134\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1147\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1127\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1128\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1122\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1148\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1119\n",
      "Epoch: 18/100... Training loss: 0.1143\n",
      "Epoch: 18/100... Training loss: 0.1151\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1159\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1120\n",
      "Epoch: 18/100... Training loss: 0.1147\n",
      "Epoch: 18/100... Training loss: 0.1131\n",
      "Epoch: 18/100... Training loss: 0.1121\n",
      "Epoch: 18/100... Training loss: 0.1127\n",
      "Epoch: 18/100... Training loss: 0.1128\n",
      "Epoch: 18/100... Training loss: 0.1143\n",
      "Epoch: 18/100... Training loss: 0.1130\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1126\n",
      "Epoch: 18/100... Training loss: 0.1154\n",
      "Epoch: 18/100... Training loss: 0.1125\n",
      "Epoch: 18/100... Training loss: 0.1157\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1157\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1142\n",
      "Epoch: 18/100... Training loss: 0.1151\n",
      "Epoch: 18/100... Training loss: 0.1109\n",
      "Epoch: 18/100... Training loss: 0.1095\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1122\n",
      "Epoch: 18/100... Training loss: 0.1137\n",
      "Epoch: 18/100... Training loss: 0.1087\n",
      "Epoch: 18/100... Training loss: 0.1110\n",
      "Epoch: 18/100... Training loss: 0.1157\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1134\n",
      "Epoch: 18/100... Training loss: 0.1133\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1160\n",
      "Epoch: 18/100... Training loss: 0.1127\n",
      "Epoch: 18/100... Training loss: 0.1080\n",
      "Epoch: 18/100... Training loss: 0.1133\n",
      "Epoch: 18/100... Training loss: 0.1142\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1123\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1157\n",
      "Epoch: 18/100... Training loss: 0.1123\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1157\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1144\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1110\n",
      "Epoch: 18/100... Training loss: 0.1081\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1152\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1108\n",
      "Epoch: 18/100... Training loss: 0.1128\n",
      "Epoch: 18/100... Training loss: 0.1128\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1044\n",
      "Epoch: 18/100... Training loss: 0.1125\n",
      "Epoch: 18/100... Training loss: 0.1133\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1118\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1130\n",
      "Epoch: 18/100... Training loss: 0.1128\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1119\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1150\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1115\n",
      "Epoch: 18/100... Training loss: 0.1097\n",
      "Epoch: 18/100... Training loss: 0.1118\n",
      "Epoch: 18/100... Training loss: 0.1152\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1115\n",
      "Epoch: 18/100... Training loss: 0.1140\n",
      "Epoch: 18/100... Training loss: 0.1094\n",
      "Epoch: 18/100... Training loss: 0.1138\n",
      "Epoch: 18/100... Training loss: 0.1132\n",
      "Epoch: 18/100... Training loss: 0.1108\n",
      "Epoch: 18/100... Training loss: 0.1145\n",
      "Epoch: 18/100... Training loss: 0.1165\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1115\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1153\n",
      "Epoch: 18/100... Training loss: 0.1129\n",
      "Epoch: 18/100... Training loss: 0.1144\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1108\n",
      "Epoch: 18/100... Training loss: 0.1126\n",
      "Epoch: 18/100... Training loss: 0.1148\n",
      "Epoch: 18/100... Training loss: 0.1055\n",
      "Epoch: 18/100... Training loss: 0.1131\n",
      "Epoch: 18/100... Training loss: 0.1109\n",
      "Epoch: 18/100... Training loss: 0.1133\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1131\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1140\n",
      "Epoch: 18/100... Training loss: 0.1071\n",
      "Epoch: 18/100... Training loss: 0.1090\n",
      "Epoch: 18/100... Training loss: 0.1137\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1126\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1139\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1138\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1109\n",
      "Epoch: 18/100... Training loss: 0.1110\n",
      "Epoch: 18/100... Training loss: 0.1118\n",
      "Epoch: 18/100... Training loss: 0.1151\n",
      "Epoch: 18/100... Training loss: 0.1119\n",
      "Epoch: 18/100... Training loss: 0.1114\n",
      "Epoch: 18/100... Training loss: 0.1145\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1143\n",
      "Epoch: 18/100... Training loss: 0.1159\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1150\n",
      "Epoch: 18/100... Training loss: 0.1109\n",
      "Epoch: 18/100... Training loss: 0.1126\n",
      "Epoch: 18/100... Training loss: 0.1138\n",
      "Epoch: 18/100... Training loss: 0.1130\n",
      "Epoch: 18/100... Training loss: 0.1122\n",
      "Epoch: 18/100... Training loss: 0.1138\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1089\n",
      "Epoch: 18/100... Training loss: 0.1098\n",
      "Epoch: 18/100... Training loss: 0.1101\n",
      "Epoch: 18/100... Training loss: 0.1102\n",
      "Epoch: 18/100... Training loss: 0.1125\n",
      "Epoch: 18/100... Training loss: 0.1132\n",
      "Epoch: 18/100... Training loss: 0.1108\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1155\n",
      "Epoch: 18/100... Training loss: 0.1091\n",
      "Epoch: 18/100... Training loss: 0.1130\n",
      "Epoch: 18/100... Training loss: 0.1085\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1125\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1141\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1113\n",
      "Epoch: 18/100... Training loss: 0.1120\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1125\n",
      "Epoch: 18/100... Training loss: 0.1121\n",
      "Epoch: 18/100... Training loss: 0.1078\n",
      "Epoch: 18/100... Training loss: 0.1132\n",
      "Epoch: 18/100... Training loss: 0.1146\n",
      "Epoch: 18/100... Training loss: 0.1088\n",
      "Epoch: 18/100... Training loss: 0.1079\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1145\n",
      "Epoch: 18/100... Training loss: 0.1106\n",
      "Epoch: 18/100... Training loss: 0.1154\n",
      "Epoch: 18/100... Training loss: 0.1117\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1137\n",
      "Epoch: 18/100... Training loss: 0.1125\n",
      "Epoch: 18/100... Training loss: 0.1131\n",
      "Epoch: 18/100... Training loss: 0.1132\n",
      "Epoch: 18/100... Training loss: 0.1092\n",
      "Epoch: 18/100... Training loss: 0.1140\n",
      "Epoch: 18/100... Training loss: 0.1135\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1070\n",
      "Epoch: 18/100... Training loss: 0.1108\n",
      "Epoch: 18/100... Training loss: 0.1123\n",
      "Epoch: 18/100... Training loss: 0.1144\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1116\n",
      "Epoch: 18/100... Training loss: 0.1112\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1111\n",
      "Epoch: 18/100... Training loss: 0.1105\n",
      "Epoch: 18/100... Training loss: 0.1115\n",
      "Epoch: 18/100... Training loss: 0.1128\n",
      "Epoch: 18/100... Training loss: 0.1086\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 18/100... Training loss: 0.1096\n",
      "Epoch: 18/100... Training loss: 0.1118\n",
      "Epoch: 18/100... Training loss: 0.1147\n",
      "Epoch: 18/100... Training loss: 0.1123\n",
      "Epoch: 18/100... Training loss: 0.1107\n",
      "Epoch: 18/100... Training loss: 0.1076\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1140\n",
      "Epoch: 18/100... Training loss: 0.1129\n",
      "Epoch: 18/100... Training loss: 0.1083\n",
      "Epoch: 18/100... Training loss: 0.1124\n",
      "Epoch: 18/100... Training loss: 0.1138\n",
      "Epoch: 18/100... Training loss: 0.1110\n",
      "Epoch: 18/100... Training loss: 0.1084\n",
      "Epoch: 18/100... Training loss: 0.1132\n",
      "Epoch: 18/100... Training loss: 0.1148\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 18/100... Training loss: 0.1100\n",
      "Epoch: 18/100... Training loss: 0.1144\n",
      "Epoch: 18/100... Training loss: 0.1123\n",
      "Epoch: 18/100... Training loss: 0.1104\n",
      "Epoch: 18/100... Training loss: 0.1131\n",
      "Epoch: 18/100... Training loss: 0.1099\n",
      "Epoch: 18/100... Training loss: 0.1093\n",
      "Epoch: 18/100... Training loss: 0.1120\n",
      "Epoch: 18/100... Training loss: 0.1103\n",
      "Epoch: 19/100... Training loss: 0.1130\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1132\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1077\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1062\n",
      "Epoch: 19/100... Training loss: 0.1110\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1120\n",
      "Epoch: 19/100... Training loss: 0.1114\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1100\n",
      "Epoch: 19/100... Training loss: 0.1129\n",
      "Epoch: 19/100... Training loss: 0.1133\n",
      "Epoch: 19/100... Training loss: 0.1114\n",
      "Epoch: 19/100... Training loss: 0.1120\n",
      "Epoch: 19/100... Training loss: 0.1145\n",
      "Epoch: 19/100... Training loss: 0.1054\n",
      "Epoch: 19/100... Training loss: 0.1106\n",
      "Epoch: 19/100... Training loss: 0.1139\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1126\n",
      "Epoch: 19/100... Training loss: 0.1142\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1119\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1114\n",
      "Epoch: 19/100... Training loss: 0.1127\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1114\n",
      "Epoch: 19/100... Training loss: 0.1116\n",
      "Epoch: 19/100... Training loss: 0.1110\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1122\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1134\n",
      "Epoch: 19/100... Training loss: 0.1122\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1134\n",
      "Epoch: 19/100... Training loss: 0.1061\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1161\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1115\n",
      "Epoch: 19/100... Training loss: 0.1133\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1139\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1158\n",
      "Epoch: 19/100... Training loss: 0.1105\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1131\n",
      "Epoch: 19/100... Training loss: 0.1122\n",
      "Epoch: 19/100... Training loss: 0.1127\n",
      "Epoch: 19/100... Training loss: 0.1140\n",
      "Epoch: 19/100... Training loss: 0.1116\n",
      "Epoch: 19/100... Training loss: 0.1123\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1128\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1079\n",
      "Epoch: 19/100... Training loss: 0.1141\n",
      "Epoch: 19/100... Training loss: 0.1136\n",
      "Epoch: 19/100... Training loss: 0.1119\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1142\n",
      "Epoch: 19/100... Training loss: 0.1137\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1143\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1125\n",
      "Epoch: 19/100... Training loss: 0.1126\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1163\n",
      "Epoch: 19/100... Training loss: 0.1120\n",
      "Epoch: 19/100... Training loss: 0.1146\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1134\n",
      "Epoch: 19/100... Training loss: 0.1095\n",
      "Epoch: 19/100... Training loss: 0.1138\n",
      "Epoch: 19/100... Training loss: 0.1142\n",
      "Epoch: 19/100... Training loss: 0.1110\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1137\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1159\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1082\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1138\n",
      "Epoch: 19/100... Training loss: 0.1112\n",
      "Epoch: 19/100... Training loss: 0.1067\n",
      "Epoch: 19/100... Training loss: 0.1076\n",
      "Epoch: 19/100... Training loss: 0.1091\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1119\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1120\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1125\n",
      "Epoch: 19/100... Training loss: 0.1129\n",
      "Epoch: 19/100... Training loss: 0.1132\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1125\n",
      "Epoch: 19/100... Training loss: 0.1141\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1122\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1120\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1115\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1078\n",
      "Epoch: 19/100... Training loss: 0.1125\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1124\n",
      "Epoch: 19/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1100\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1084\n",
      "Epoch: 19/100... Training loss: 0.1149\n",
      "Epoch: 19/100... Training loss: 0.1112\n",
      "Epoch: 19/100... Training loss: 0.1137\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1131\n",
      "Epoch: 19/100... Training loss: 0.1125\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1115\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1083\n",
      "Epoch: 19/100... Training loss: 0.1112\n",
      "Epoch: 19/100... Training loss: 0.1105\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1100\n",
      "Epoch: 19/100... Training loss: 0.1137\n",
      "Epoch: 19/100... Training loss: 0.1131\n",
      "Epoch: 19/100... Training loss: 0.1080\n",
      "Epoch: 19/100... Training loss: 0.1133\n",
      "Epoch: 19/100... Training loss: 0.1127\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1085\n",
      "Epoch: 19/100... Training loss: 0.1141\n",
      "Epoch: 19/100... Training loss: 0.1105\n",
      "Epoch: 19/100... Training loss: 0.1130\n",
      "Epoch: 19/100... Training loss: 0.1142\n",
      "Epoch: 19/100... Training loss: 0.1156\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1144\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1051\n",
      "Epoch: 19/100... Training loss: 0.1201\n",
      "Epoch: 19/100... Training loss: 0.1134\n",
      "Epoch: 19/100... Training loss: 0.1072\n",
      "Epoch: 19/100... Training loss: 0.1139\n",
      "Epoch: 19/100... Training loss: 0.1105\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1105\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1107\n",
      "Epoch: 19/100... Training loss: 0.1070\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1088\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1116\n",
      "Epoch: 19/100... Training loss: 0.1087\n",
      "Epoch: 19/100... Training loss: 0.1064\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1140\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1118\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1127\n",
      "Epoch: 19/100... Training loss: 0.1103\n",
      "Epoch: 19/100... Training loss: 0.1132\n",
      "Epoch: 19/100... Training loss: 0.1120\n",
      "Epoch: 19/100... Training loss: 0.1100\n",
      "Epoch: 19/100... Training loss: 0.1074\n",
      "Epoch: 19/100... Training loss: 0.1120\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1118\n",
      "Epoch: 19/100... Training loss: 0.1113\n",
      "Epoch: 19/100... Training loss: 0.1118\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1121\n",
      "Epoch: 19/100... Training loss: 0.1096\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1136\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1131\n",
      "Epoch: 19/100... Training loss: 0.1099\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1136\n",
      "Epoch: 19/100... Training loss: 0.1139\n",
      "Epoch: 19/100... Training loss: 0.1112\n",
      "Epoch: 19/100... Training loss: 0.1119\n",
      "Epoch: 19/100... Training loss: 0.1118\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1125\n",
      "Epoch: 19/100... Training loss: 0.1101\n",
      "Epoch: 19/100... Training loss: 0.1092\n",
      "Epoch: 19/100... Training loss: 0.1129\n",
      "Epoch: 19/100... Training loss: 0.1128\n",
      "Epoch: 19/100... Training loss: 0.1110\n",
      "Epoch: 19/100... Training loss: 0.1141\n",
      "Epoch: 19/100... Training loss: 0.1132\n",
      "Epoch: 19/100... Training loss: 0.1131\n",
      "Epoch: 19/100... Training loss: 0.1097\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1126\n",
      "Epoch: 19/100... Training loss: 0.1111\n",
      "Epoch: 19/100... Training loss: 0.1126\n",
      "Epoch: 19/100... Training loss: 0.1073\n",
      "Epoch: 19/100... Training loss: 0.1147\n",
      "Epoch: 19/100... Training loss: 0.1131\n",
      "Epoch: 19/100... Training loss: 0.1138\n",
      "Epoch: 19/100... Training loss: 0.1090\n",
      "Epoch: 19/100... Training loss: 0.1119\n",
      "Epoch: 19/100... Training loss: 0.1086\n",
      "Epoch: 19/100... Training loss: 0.1069\n",
      "Epoch: 19/100... Training loss: 0.1129\n",
      "Epoch: 19/100... Training loss: 0.1138\n",
      "Epoch: 19/100... Training loss: 0.1117\n",
      "Epoch: 19/100... Training loss: 0.1153\n",
      "Epoch: 19/100... Training loss: 0.1144\n",
      "Epoch: 19/100... Training loss: 0.1094\n",
      "Epoch: 19/100... Training loss: 0.1128\n",
      "Epoch: 19/100... Training loss: 0.1113\n",
      "Epoch: 19/100... Training loss: 0.1128\n",
      "Epoch: 19/100... Training loss: 0.1134\n",
      "Epoch: 19/100... Training loss: 0.1102\n",
      "Epoch: 19/100... Training loss: 0.1135\n",
      "Epoch: 19/100... Training loss: 0.1112\n",
      "Epoch: 19/100... Training loss: 0.1155\n",
      "Epoch: 19/100... Training loss: 0.1119\n",
      "Epoch: 19/100... Training loss: 0.1115\n",
      "Epoch: 19/100... Training loss: 0.1146\n",
      "Epoch: 19/100... Training loss: 0.1142\n",
      "Epoch: 19/100... Training loss: 0.1156\n",
      "Epoch: 19/100... Training loss: 0.1109\n",
      "Epoch: 19/100... Training loss: 0.1145\n",
      "Epoch: 19/100... Training loss: 0.1098\n",
      "Epoch: 19/100... Training loss: 0.1104\n",
      "Epoch: 19/100... Training loss: 0.1108\n",
      "Epoch: 19/100... Training loss: 0.1149\n",
      "Epoch: 19/100... Training loss: 0.1127\n",
      "Epoch: 19/100... Training loss: 0.1081\n",
      "Epoch: 19/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1125\n",
      "Epoch: 20/100... Training loss: 0.1115\n",
      "Epoch: 20/100... Training loss: 0.1154\n",
      "Epoch: 20/100... Training loss: 0.1107\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1142\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1126\n",
      "Epoch: 20/100... Training loss: 0.1114\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1117\n",
      "Epoch: 20/100... Training loss: 0.1120\n",
      "Epoch: 20/100... Training loss: 0.1120\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1114\n",
      "Epoch: 20/100... Training loss: 0.1134\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1086\n",
      "Epoch: 20/100... Training loss: 0.1115\n",
      "Epoch: 20/100... Training loss: 0.1139\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1123\n",
      "Epoch: 20/100... Training loss: 0.1148\n",
      "Epoch: 20/100... Training loss: 0.1125\n",
      "Epoch: 20/100... Training loss: 0.1131\n",
      "Epoch: 20/100... Training loss: 0.1114\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1115\n",
      "Epoch: 20/100... Training loss: 0.1128\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1122\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1074\n",
      "Epoch: 20/100... Training loss: 0.1073\n",
      "Epoch: 20/100... Training loss: 0.1121\n",
      "Epoch: 20/100... Training loss: 0.1138\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1115\n",
      "Epoch: 20/100... Training loss: 0.1127\n",
      "Epoch: 20/100... Training loss: 0.1107\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1104\n",
      "Epoch: 20/100... Training loss: 0.1129\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1127\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1152\n",
      "Epoch: 20/100... Training loss: 0.1118\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1144\n",
      "Epoch: 20/100... Training loss: 0.1129\n",
      "Epoch: 20/100... Training loss: 0.1089\n",
      "Epoch: 20/100... Training loss: 0.1116\n",
      "Epoch: 20/100... Training loss: 0.1159\n",
      "Epoch: 20/100... Training loss: 0.1133\n",
      "Epoch: 20/100... Training loss: 0.1130\n",
      "Epoch: 20/100... Training loss: 0.1104\n",
      "Epoch: 20/100... Training loss: 0.1156\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1115\n",
      "Epoch: 20/100... Training loss: 0.1127\n",
      "Epoch: 20/100... Training loss: 0.1110\n",
      "Epoch: 20/100... Training loss: 0.1058\n",
      "Epoch: 20/100... Training loss: 0.1102\n",
      "Epoch: 20/100... Training loss: 0.1136\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1115\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1124\n",
      "Epoch: 20/100... Training loss: 0.1112\n",
      "Epoch: 20/100... Training loss: 0.1112\n",
      "Epoch: 20/100... Training loss: 0.1121\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1104\n",
      "Epoch: 20/100... Training loss: 0.1136\n",
      "Epoch: 20/100... Training loss: 0.1134\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1153\n",
      "Epoch: 20/100... Training loss: 0.1091\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1112\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1158\n",
      "Epoch: 20/100... Training loss: 0.1120\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1159\n",
      "Epoch: 20/100... Training loss: 0.1091\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1121\n",
      "Epoch: 20/100... Training loss: 0.1075\n",
      "Epoch: 20/100... Training loss: 0.1136\n",
      "Epoch: 20/100... Training loss: 0.1127\n",
      "Epoch: 20/100... Training loss: 0.1135\n",
      "Epoch: 20/100... Training loss: 0.1091\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1129\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1125\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1119\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1135\n",
      "Epoch: 20/100... Training loss: 0.1102\n",
      "Epoch: 20/100... Training loss: 0.1126\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1118\n",
      "Epoch: 20/100... Training loss: 0.1109\n",
      "Epoch: 20/100... Training loss: 0.1124\n",
      "Epoch: 20/100... Training loss: 0.1099\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1139\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1118\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1121\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1099\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1133\n",
      "Epoch: 20/100... Training loss: 0.1151\n",
      "Epoch: 20/100... Training loss: 0.1117\n",
      "Epoch: 20/100... Training loss: 0.1091\n",
      "Epoch: 20/100... Training loss: 0.1116\n",
      "Epoch: 20/100... Training loss: 0.1116\n",
      "Epoch: 20/100... Training loss: 0.1107\n",
      "Epoch: 20/100... Training loss: 0.1139\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1126\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1084\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1120\n",
      "Epoch: 20/100... Training loss: 0.1030\n",
      "Epoch: 20/100... Training loss: 0.1099\n",
      "Epoch: 20/100... Training loss: 0.1144\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1142\n",
      "Epoch: 20/100... Training loss: 0.1116\n",
      "Epoch: 20/100... Training loss: 0.1108\n",
      "Epoch: 20/100... Training loss: 0.1119\n",
      "Epoch: 20/100... Training loss: 0.1109\n",
      "Epoch: 20/100... Training loss: 0.1121\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1119\n",
      "Epoch: 20/100... Training loss: 0.1068\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1059\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1082\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1067\n",
      "Epoch: 20/100... Training loss: 0.1131\n",
      "Epoch: 20/100... Training loss: 0.1117\n",
      "Epoch: 20/100... Training loss: 0.1120\n",
      "Epoch: 20/100... Training loss: 0.1119\n",
      "Epoch: 20/100... Training loss: 0.1114\n",
      "Epoch: 20/100... Training loss: 0.1122\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1127\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1107\n",
      "Epoch: 20/100... Training loss: 0.1128\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1104\n",
      "Epoch: 20/100... Training loss: 0.1091\n",
      "Epoch: 20/100... Training loss: 0.1132\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1148\n",
      "Epoch: 20/100... Training loss: 0.1131\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1126\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1091\n",
      "Epoch: 20/100... Training loss: 0.1118\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1109\n",
      "Epoch: 20/100... Training loss: 0.1088\n",
      "Epoch: 20/100... Training loss: 0.1121\n",
      "Epoch: 20/100... Training loss: 0.1122\n",
      "Epoch: 20/100... Training loss: 0.1118\n",
      "Epoch: 20/100... Training loss: 0.1126\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1066\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1158\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1121\n",
      "Epoch: 20/100... Training loss: 0.1132\n",
      "Epoch: 20/100... Training loss: 0.1095\n",
      "Epoch: 20/100... Training loss: 0.1124\n",
      "Epoch: 20/100... Training loss: 0.1104\n",
      "Epoch: 20/100... Training loss: 0.1145\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1116\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1131\n",
      "Epoch: 20/100... Training loss: 0.1108\n",
      "Epoch: 20/100... Training loss: 0.1097\n",
      "Epoch: 20/100... Training loss: 0.1105\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1120\n",
      "Epoch: 20/100... Training loss: 0.1134\n",
      "Epoch: 20/100... Training loss: 0.1125\n",
      "Epoch: 20/100... Training loss: 0.1076\n",
      "Epoch: 20/100... Training loss: 0.1108\n",
      "Epoch: 20/100... Training loss: 0.1072\n",
      "Epoch: 20/100... Training loss: 0.1102\n",
      "Epoch: 20/100... Training loss: 0.1084\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1125\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1057\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1110\n",
      "Epoch: 20/100... Training loss: 0.1114\n",
      "Epoch: 20/100... Training loss: 0.1139\n",
      "Epoch: 20/100... Training loss: 0.1077\n",
      "Epoch: 20/100... Training loss: 0.1097\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1097\n",
      "Epoch: 20/100... Training loss: 0.1125\n",
      "Epoch: 20/100... Training loss: 0.1115\n",
      "Epoch: 20/100... Training loss: 0.1093\n",
      "Epoch: 20/100... Training loss: 0.1101\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1102\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1090\n",
      "Epoch: 20/100... Training loss: 0.1091\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1070\n",
      "Epoch: 20/100... Training loss: 0.1043\n",
      "Epoch: 20/100... Training loss: 0.1096\n",
      "Epoch: 20/100... Training loss: 0.1110\n",
      "Epoch: 20/100... Training loss: 0.1097\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1127\n",
      "Epoch: 20/100... Training loss: 0.1094\n",
      "Epoch: 20/100... Training loss: 0.1131\n",
      "Epoch: 20/100... Training loss: 0.1114\n",
      "Epoch: 20/100... Training loss: 0.1130\n",
      "Epoch: 20/100... Training loss: 0.1113\n",
      "Epoch: 20/100... Training loss: 0.1085\n",
      "Epoch: 20/100... Training loss: 0.1122\n",
      "Epoch: 20/100... Training loss: 0.1126\n",
      "Epoch: 20/100... Training loss: 0.1098\n",
      "Epoch: 20/100... Training loss: 0.1117\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1138\n",
      "Epoch: 20/100... Training loss: 0.1084\n",
      "Epoch: 20/100... Training loss: 0.1138\n",
      "Epoch: 20/100... Training loss: 0.1087\n",
      "Epoch: 20/100... Training loss: 0.1140\n",
      "Epoch: 20/100... Training loss: 0.1107\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 20/100... Training loss: 0.1078\n",
      "Epoch: 20/100... Training loss: 0.1080\n",
      "Epoch: 20/100... Training loss: 0.1111\n",
      "Epoch: 20/100... Training loss: 0.1112\n",
      "Epoch: 20/100... Training loss: 0.1103\n",
      "Epoch: 20/100... Training loss: 0.1100\n",
      "Epoch: 20/100... Training loss: 0.1102\n",
      "Epoch: 20/100... Training loss: 0.1081\n",
      "Epoch: 20/100... Training loss: 0.1102\n",
      "Epoch: 20/100... Training loss: 0.1106\n",
      "Epoch: 20/100... Training loss: 0.1083\n",
      "Epoch: 20/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1075\n",
      "Epoch: 21/100... Training loss: 0.1137\n",
      "Epoch: 21/100... Training loss: 0.1143\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1139\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1108\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1119\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1109\n",
      "Epoch: 21/100... Training loss: 0.1111\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1147\n",
      "Epoch: 21/100... Training loss: 0.1118\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1097\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1099\n",
      "Epoch: 21/100... Training loss: 0.1121\n",
      "Epoch: 21/100... Training loss: 0.1119\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1122\n",
      "Epoch: 21/100... Training loss: 0.1114\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1105\n",
      "Epoch: 21/100... Training loss: 0.1109\n",
      "Epoch: 21/100... Training loss: 0.1114\n",
      "Epoch: 21/100... Training loss: 0.1047\n",
      "Epoch: 21/100... Training loss: 0.1112\n",
      "Epoch: 21/100... Training loss: 0.1119\n",
      "Epoch: 21/100... Training loss: 0.1115\n",
      "Epoch: 21/100... Training loss: 0.1097\n",
      "Epoch: 21/100... Training loss: 0.1135\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1130\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 21/100... Training loss: 0.1115\n",
      "Epoch: 21/100... Training loss: 0.1128\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1097\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1130\n",
      "Epoch: 21/100... Training loss: 0.1093\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1123\n",
      "Epoch: 21/100... Training loss: 0.1106\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1122\n",
      "Epoch: 21/100... Training loss: 0.1142\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1093\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1087\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1124\n",
      "Epoch: 21/100... Training loss: 0.1128\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1124\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1116\n",
      "Epoch: 21/100... Training loss: 0.1133\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1116\n",
      "Epoch: 21/100... Training loss: 0.1123\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1137\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1111\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1093\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1097\n",
      "Epoch: 21/100... Training loss: 0.1084\n",
      "Epoch: 21/100... Training loss: 0.1125\n",
      "Epoch: 21/100... Training loss: 0.1131\n",
      "Epoch: 21/100... Training loss: 0.1117\n",
      "Epoch: 21/100... Training loss: 0.1129\n",
      "Epoch: 21/100... Training loss: 0.1112\n",
      "Epoch: 21/100... Training loss: 0.1121\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1101\n",
      "Epoch: 21/100... Training loss: 0.1135\n",
      "Epoch: 21/100... Training loss: 0.1081\n",
      "Epoch: 21/100... Training loss: 0.1075\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1117\n",
      "Epoch: 21/100... Training loss: 0.1106\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 21/100... Training loss: 0.1053\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 21/100... Training loss: 0.1117\n",
      "Epoch: 21/100... Training loss: 0.1141\n",
      "Epoch: 21/100... Training loss: 0.1159\n",
      "Epoch: 21/100... Training loss: 0.1129\n",
      "Epoch: 21/100... Training loss: 0.1142\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1131\n",
      "Epoch: 21/100... Training loss: 0.1109\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1106\n",
      "Epoch: 21/100... Training loss: 0.1064\n",
      "Epoch: 21/100... Training loss: 0.1147\n",
      "Epoch: 21/100... Training loss: 0.1119\n",
      "Epoch: 21/100... Training loss: 0.1098\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1109\n",
      "Epoch: 21/100... Training loss: 0.1127\n",
      "Epoch: 21/100... Training loss: 0.1132\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1098\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1125\n",
      "Epoch: 21/100... Training loss: 0.1092\n",
      "Epoch: 21/100... Training loss: 0.1075\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1121\n",
      "Epoch: 21/100... Training loss: 0.1145\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1112\n",
      "Epoch: 21/100... Training loss: 0.1106\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1069\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1141\n",
      "Epoch: 21/100... Training loss: 0.1118\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1129\n",
      "Epoch: 21/100... Training loss: 0.1155\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1115\n",
      "Epoch: 21/100... Training loss: 0.1121\n",
      "Epoch: 21/100... Training loss: 0.1157\n",
      "Epoch: 21/100... Training loss: 0.1131\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1108\n",
      "Epoch: 21/100... Training loss: 0.1071\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1128\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1125\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1127\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1106\n",
      "Epoch: 21/100... Training loss: 0.1120\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1097\n",
      "Epoch: 21/100... Training loss: 0.1151\n",
      "Epoch: 21/100... Training loss: 0.1044\n",
      "Epoch: 21/100... Training loss: 0.1141\n",
      "Epoch: 21/100... Training loss: 0.1098\n",
      "Epoch: 21/100... Training loss: 0.1131\n",
      "Epoch: 21/100... Training loss: 0.1130\n",
      "Epoch: 21/100... Training loss: 0.1115\n",
      "Epoch: 21/100... Training loss: 0.1072\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1104\n",
      "Epoch: 21/100... Training loss: 0.1114\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1118\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1127\n",
      "Epoch: 21/100... Training loss: 0.1106\n",
      "Epoch: 21/100... Training loss: 0.1091\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1137\n",
      "Epoch: 21/100... Training loss: 0.1061\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1151\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1140\n",
      "Epoch: 21/100... Training loss: 0.1127\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1125\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1133\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1147\n",
      "Epoch: 21/100... Training loss: 0.1116\n",
      "Epoch: 21/100... Training loss: 0.1063\n",
      "Epoch: 21/100... Training loss: 0.1106\n",
      "Epoch: 21/100... Training loss: 0.1085\n",
      "Epoch: 21/100... Training loss: 0.1058\n",
      "Epoch: 21/100... Training loss: 0.1104\n",
      "Epoch: 21/100... Training loss: 0.1066\n",
      "Epoch: 21/100... Training loss: 0.1068\n",
      "Epoch: 21/100... Training loss: 0.1100\n",
      "Epoch: 21/100... Training loss: 0.1084\n",
      "Epoch: 21/100... Training loss: 0.1070\n",
      "Epoch: 21/100... Training loss: 0.1116\n",
      "Epoch: 21/100... Training loss: 0.1125\n",
      "Epoch: 21/100... Training loss: 0.1117\n",
      "Epoch: 21/100... Training loss: 0.1057\n",
      "Epoch: 21/100... Training loss: 0.1076\n",
      "Epoch: 21/100... Training loss: 0.1095\n",
      "Epoch: 21/100... Training loss: 0.1119\n",
      "Epoch: 21/100... Training loss: 0.1046\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1117\n",
      "Epoch: 21/100... Training loss: 0.1133\n",
      "Epoch: 21/100... Training loss: 0.1110\n",
      "Epoch: 21/100... Training loss: 0.1104\n",
      "Epoch: 21/100... Training loss: 0.1079\n",
      "Epoch: 21/100... Training loss: 0.1080\n",
      "Epoch: 21/100... Training loss: 0.1082\n",
      "Epoch: 21/100... Training loss: 0.1086\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1131\n",
      "Epoch: 21/100... Training loss: 0.1117\n",
      "Epoch: 21/100... Training loss: 0.1103\n",
      "Epoch: 21/100... Training loss: 0.1136\n",
      "Epoch: 21/100... Training loss: 0.1077\n",
      "Epoch: 21/100... Training loss: 0.1111\n",
      "Epoch: 21/100... Training loss: 0.1132\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1088\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1111\n",
      "Epoch: 21/100... Training loss: 0.1119\n",
      "Epoch: 21/100... Training loss: 0.1126\n",
      "Epoch: 21/100... Training loss: 0.1107\n",
      "Epoch: 21/100... Training loss: 0.1138\n",
      "Epoch: 21/100... Training loss: 0.1097\n",
      "Epoch: 21/100... Training loss: 0.1078\n",
      "Epoch: 21/100... Training loss: 0.1073\n",
      "Epoch: 21/100... Training loss: 0.1067\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1038\n",
      "Epoch: 21/100... Training loss: 0.1098\n",
      "Epoch: 21/100... Training loss: 0.1154\n",
      "Epoch: 21/100... Training loss: 0.1134\n",
      "Epoch: 21/100... Training loss: 0.1118\n",
      "Epoch: 21/100... Training loss: 0.1121\n",
      "Epoch: 21/100... Training loss: 0.1062\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 21/100... Training loss: 0.1105\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1084\n",
      "Epoch: 21/100... Training loss: 0.1121\n",
      "Epoch: 21/100... Training loss: 0.1050\n",
      "Epoch: 21/100... Training loss: 0.1134\n",
      "Epoch: 21/100... Training loss: 0.1122\n",
      "Epoch: 21/100... Training loss: 0.1101\n",
      "Epoch: 21/100... Training loss: 0.1060\n",
      "Epoch: 21/100... Training loss: 0.1065\n",
      "Epoch: 21/100... Training loss: 0.1042\n",
      "Epoch: 21/100... Training loss: 0.1094\n",
      "Epoch: 21/100... Training loss: 0.1118\n",
      "Epoch: 21/100... Training loss: 0.1121\n",
      "Epoch: 21/100... Training loss: 0.1083\n",
      "Epoch: 21/100... Training loss: 0.1096\n",
      "Epoch: 21/100... Training loss: 0.1113\n",
      "Epoch: 21/100... Training loss: 0.1089\n",
      "Epoch: 21/100... Training loss: 0.1098\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 21/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1115\n",
      "Epoch: 22/100... Training loss: 0.1086\n",
      "Epoch: 22/100... Training loss: 0.1127\n",
      "Epoch: 22/100... Training loss: 0.1126\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1106\n",
      "Epoch: 22/100... Training loss: 0.1113\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1150\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1115\n",
      "Epoch: 22/100... Training loss: 0.1100\n",
      "Epoch: 22/100... Training loss: 0.1118\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1085\n",
      "Epoch: 22/100... Training loss: 0.1132\n",
      "Epoch: 22/100... Training loss: 0.1089\n",
      "Epoch: 22/100... Training loss: 0.1123\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1100\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1105\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1127\n",
      "Epoch: 22/100... Training loss: 0.1116\n",
      "Epoch: 22/100... Training loss: 0.1139\n",
      "Epoch: 22/100... Training loss: 0.1129\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1137\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1130\n",
      "Epoch: 22/100... Training loss: 0.1108\n",
      "Epoch: 22/100... Training loss: 0.1089\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1089\n",
      "Epoch: 22/100... Training loss: 0.1105\n",
      "Epoch: 22/100... Training loss: 0.1132\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1058\n",
      "Epoch: 22/100... Training loss: 0.1086\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1122\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1113\n",
      "Epoch: 22/100... Training loss: 0.1101\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1051\n",
      "Epoch: 22/100... Training loss: 0.1112\n",
      "Epoch: 22/100... Training loss: 0.1111\n",
      "Epoch: 22/100... Training loss: 0.1148\n",
      "Epoch: 22/100... Training loss: 0.1140\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1121\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1107\n",
      "Epoch: 22/100... Training loss: 0.1107\n",
      "Epoch: 22/100... Training loss: 0.1100\n",
      "Epoch: 22/100... Training loss: 0.1108\n",
      "Epoch: 22/100... Training loss: 0.1116\n",
      "Epoch: 22/100... Training loss: 0.1130\n",
      "Epoch: 22/100... Training loss: 0.1105\n",
      "Epoch: 22/100... Training loss: 0.1114\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1122\n",
      "Epoch: 22/100... Training loss: 0.1089\n",
      "Epoch: 22/100... Training loss: 0.1106\n",
      "Epoch: 22/100... Training loss: 0.1135\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1099\n",
      "Epoch: 22/100... Training loss: 0.1127\n",
      "Epoch: 22/100... Training loss: 0.1118\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1122\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1112\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1119\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1112\n",
      "Epoch: 22/100... Training loss: 0.1105\n",
      "Epoch: 22/100... Training loss: 0.1103\n",
      "Epoch: 22/100... Training loss: 0.1129\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1122\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1117\n",
      "Epoch: 22/100... Training loss: 0.1132\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1125\n",
      "Epoch: 22/100... Training loss: 0.1122\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1145\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1138\n",
      "Epoch: 22/100... Training loss: 0.1101\n",
      "Epoch: 22/100... Training loss: 0.1059\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1105\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1086\n",
      "Epoch: 22/100... Training loss: 0.1113\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1106\n",
      "Epoch: 22/100... Training loss: 0.1123\n",
      "Epoch: 22/100... Training loss: 0.1140\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1099\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1133\n",
      "Epoch: 22/100... Training loss: 0.1134\n",
      "Epoch: 22/100... Training loss: 0.1085\n",
      "Epoch: 22/100... Training loss: 0.1142\n",
      "Epoch: 22/100... Training loss: 0.1108\n",
      "Epoch: 22/100... Training loss: 0.1136\n",
      "Epoch: 22/100... Training loss: 0.1108\n",
      "Epoch: 22/100... Training loss: 0.1100\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1066\n",
      "Epoch: 22/100... Training loss: 0.1135\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1109\n",
      "Epoch: 22/100... Training loss: 0.1109\n",
      "Epoch: 22/100... Training loss: 0.1118\n",
      "Epoch: 22/100... Training loss: 0.1105\n",
      "Epoch: 22/100... Training loss: 0.1126\n",
      "Epoch: 22/100... Training loss: 0.1125\n",
      "Epoch: 22/100... Training loss: 0.1100\n",
      "Epoch: 22/100... Training loss: 0.1115\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1128\n",
      "Epoch: 22/100... Training loss: 0.1111\n",
      "Epoch: 22/100... Training loss: 0.1126\n",
      "Epoch: 22/100... Training loss: 0.1099\n",
      "Epoch: 22/100... Training loss: 0.1089\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1112\n",
      "Epoch: 22/100... Training loss: 0.1124\n",
      "Epoch: 22/100... Training loss: 0.1063\n",
      "Epoch: 22/100... Training loss: 0.1039\n",
      "Epoch: 22/100... Training loss: 0.1113\n",
      "Epoch: 22/100... Training loss: 0.1106\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1097\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1122\n",
      "Epoch: 22/100... Training loss: 0.1117\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1113\n",
      "Epoch: 22/100... Training loss: 0.1117\n",
      "Epoch: 22/100... Training loss: 0.1115\n",
      "Epoch: 22/100... Training loss: 0.1111\n",
      "Epoch: 22/100... Training loss: 0.1126\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1086\n",
      "Epoch: 22/100... Training loss: 0.1133\n",
      "Epoch: 22/100... Training loss: 0.1107\n",
      "Epoch: 22/100... Training loss: 0.1111\n",
      "Epoch: 22/100... Training loss: 0.1115\n",
      "Epoch: 22/100... Training loss: 0.1079\n",
      "Epoch: 22/100... Training loss: 0.1050\n",
      "Epoch: 22/100... Training loss: 0.1104\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1117\n",
      "Epoch: 22/100... Training loss: 0.1127\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1108\n",
      "Epoch: 22/100... Training loss: 0.1104\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1069\n",
      "Epoch: 22/100... Training loss: 0.1107\n",
      "Epoch: 22/100... Training loss: 0.1100\n",
      "Epoch: 22/100... Training loss: 0.1123\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1100\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1119\n",
      "Epoch: 22/100... Training loss: 0.1089\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1091\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1113\n",
      "Epoch: 22/100... Training loss: 0.1074\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1035\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1096\n",
      "Epoch: 22/100... Training loss: 0.1081\n",
      "Epoch: 22/100... Training loss: 0.1097\n",
      "Epoch: 22/100... Training loss: 0.1089\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1105\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1083\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1097\n",
      "Epoch: 22/100... Training loss: 0.1099\n",
      "Epoch: 22/100... Training loss: 0.1145\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1077\n",
      "Epoch: 22/100... Training loss: 0.1099\n",
      "Epoch: 22/100... Training loss: 0.1109\n",
      "Epoch: 22/100... Training loss: 0.1084\n",
      "Epoch: 22/100... Training loss: 0.1086\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1052\n",
      "Epoch: 22/100... Training loss: 0.1098\n",
      "Epoch: 22/100... Training loss: 0.1121\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1071\n",
      "Epoch: 22/100... Training loss: 0.1117\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1110\n",
      "Epoch: 22/100... Training loss: 0.1072\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1060\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1126\n",
      "Epoch: 22/100... Training loss: 0.1107\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1100\n",
      "Epoch: 22/100... Training loss: 0.1117\n",
      "Epoch: 22/100... Training loss: 0.1090\n",
      "Epoch: 22/100... Training loss: 0.1070\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1103\n",
      "Epoch: 22/100... Training loss: 0.1078\n",
      "Epoch: 22/100... Training loss: 0.1067\n",
      "Epoch: 22/100... Training loss: 0.1106\n",
      "Epoch: 22/100... Training loss: 0.1107\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1117\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1087\n",
      "Epoch: 22/100... Training loss: 0.1080\n",
      "Epoch: 22/100... Training loss: 0.1088\n",
      "Epoch: 22/100... Training loss: 0.1101\n",
      "Epoch: 22/100... Training loss: 0.1048\n",
      "Epoch: 22/100... Training loss: 0.1099\n",
      "Epoch: 22/100... Training loss: 0.1101\n",
      "Epoch: 22/100... Training loss: 0.1102\n",
      "Epoch: 22/100... Training loss: 0.1085\n",
      "Epoch: 22/100... Training loss: 0.1129\n",
      "Epoch: 22/100... Training loss: 0.1104\n",
      "Epoch: 22/100... Training loss: 0.1064\n",
      "Epoch: 22/100... Training loss: 0.1104\n",
      "Epoch: 22/100... Training loss: 0.1122\n",
      "Epoch: 22/100... Training loss: 0.1126\n",
      "Epoch: 22/100... Training loss: 0.1092\n",
      "Epoch: 22/100... Training loss: 0.1056\n",
      "Epoch: 22/100... Training loss: 0.1100\n",
      "Epoch: 22/100... Training loss: 0.1115\n",
      "Epoch: 22/100... Training loss: 0.1076\n",
      "Epoch: 22/100... Training loss: 0.1065\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 22/100... Training loss: 0.1125\n",
      "Epoch: 22/100... Training loss: 0.1053\n",
      "Epoch: 22/100... Training loss: 0.1075\n",
      "Epoch: 22/100... Training loss: 0.1106\n",
      "Epoch: 22/100... Training loss: 0.1099\n",
      "Epoch: 22/100... Training loss: 0.1138\n",
      "Epoch: 22/100... Training loss: 0.1093\n",
      "Epoch: 22/100... Training loss: 0.1101\n",
      "Epoch: 22/100... Training loss: 0.1095\n",
      "Epoch: 22/100... Training loss: 0.1094\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1041\n",
      "Epoch: 23/100... Training loss: 0.1108\n",
      "Epoch: 23/100... Training loss: 0.1114\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1088\n",
      "Epoch: 23/100... Training loss: 0.1138\n",
      "Epoch: 23/100... Training loss: 0.1098\n",
      "Epoch: 23/100... Training loss: 0.1117\n",
      "Epoch: 23/100... Training loss: 0.1094\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1121\n",
      "Epoch: 23/100... Training loss: 0.1116\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1055\n",
      "Epoch: 23/100... Training loss: 0.1111\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1108\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1123\n",
      "Epoch: 23/100... Training loss: 0.1105\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1137\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1144\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1085\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1085\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1115\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1126\n",
      "Epoch: 23/100... Training loss: 0.1106\n",
      "Epoch: 23/100... Training loss: 0.1094\n",
      "Epoch: 23/100... Training loss: 0.1102\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1107\n",
      "Epoch: 23/100... Training loss: 0.1096\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1113\n",
      "Epoch: 23/100... Training loss: 0.1103\n",
      "Epoch: 23/100... Training loss: 0.1111\n",
      "Epoch: 23/100... Training loss: 0.1093\n",
      "Epoch: 23/100... Training loss: 0.1127\n",
      "Epoch: 23/100... Training loss: 0.1121\n",
      "Epoch: 23/100... Training loss: 0.1099\n",
      "Epoch: 23/100... Training loss: 0.1128\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1099\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1106\n",
      "Epoch: 23/100... Training loss: 0.1112\n",
      "Epoch: 23/100... Training loss: 0.1103\n",
      "Epoch: 23/100... Training loss: 0.1132\n",
      "Epoch: 23/100... Training loss: 0.1098\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1094\n",
      "Epoch: 23/100... Training loss: 0.1138\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1110\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1098\n",
      "Epoch: 23/100... Training loss: 0.1121\n",
      "Epoch: 23/100... Training loss: 0.1098\n",
      "Epoch: 23/100... Training loss: 0.1111\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1085\n",
      "Epoch: 23/100... Training loss: 0.1068\n",
      "Epoch: 23/100... Training loss: 0.1081\n",
      "Epoch: 23/100... Training loss: 0.1122\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1097\n",
      "Epoch: 23/100... Training loss: 0.1111\n",
      "Epoch: 23/100... Training loss: 0.1094\n",
      "Epoch: 23/100... Training loss: 0.1141\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1101\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1114\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1105\n",
      "Epoch: 23/100... Training loss: 0.1098\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1129\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1080\n",
      "Epoch: 23/100... Training loss: 0.1081\n",
      "Epoch: 23/100... Training loss: 0.1108\n",
      "Epoch: 23/100... Training loss: 0.1107\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1122\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1119\n",
      "Epoch: 23/100... Training loss: 0.1097\n",
      "Epoch: 23/100... Training loss: 0.1085\n",
      "Epoch: 23/100... Training loss: 0.1114\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1113\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1061\n",
      "Epoch: 23/100... Training loss: 0.1115\n",
      "Epoch: 23/100... Training loss: 0.1096\n",
      "Epoch: 23/100... Training loss: 0.1059\n",
      "Epoch: 23/100... Training loss: 0.1104\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1099\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1076\n",
      "Epoch: 23/100... Training loss: 0.1119\n",
      "Epoch: 23/100... Training loss: 0.1104\n",
      "Epoch: 23/100... Training loss: 0.1062\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1124\n",
      "Epoch: 23/100... Training loss: 0.1136\n",
      "Epoch: 23/100... Training loss: 0.1133\n",
      "Epoch: 23/100... Training loss: 0.1113\n",
      "Epoch: 23/100... Training loss: 0.1084\n",
      "Epoch: 23/100... Training loss: 0.1118\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1133\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1136\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1102\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1092\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1114\n",
      "Epoch: 23/100... Training loss: 0.1130\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1108\n",
      "Epoch: 23/100... Training loss: 0.1127\n",
      "Epoch: 23/100... Training loss: 0.1096\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1121\n",
      "Epoch: 23/100... Training loss: 0.1119\n",
      "Epoch: 23/100... Training loss: 0.1102\n",
      "Epoch: 23/100... Training loss: 0.1091\n",
      "Epoch: 23/100... Training loss: 0.1103\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1064\n",
      "Epoch: 23/100... Training loss: 0.1135\n",
      "Epoch: 23/100... Training loss: 0.1114\n",
      "Epoch: 23/100... Training loss: 0.1096\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1096\n",
      "Epoch: 23/100... Training loss: 0.1120\n",
      "Epoch: 23/100... Training loss: 0.1098\n",
      "Epoch: 23/100... Training loss: 0.1093\n",
      "Epoch: 23/100... Training loss: 0.1094\n",
      "Epoch: 23/100... Training loss: 0.1109\n",
      "Epoch: 23/100... Training loss: 0.1104\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1011\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1099\n",
      "Epoch: 23/100... Training loss: 0.1056\n",
      "Epoch: 23/100... Training loss: 0.1121\n",
      "Epoch: 23/100... Training loss: 0.1092\n",
      "Epoch: 23/100... Training loss: 0.1043\n",
      "Epoch: 23/100... Training loss: 0.1099\n",
      "Epoch: 23/100... Training loss: 0.1107\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1093\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1113\n",
      "Epoch: 23/100... Training loss: 0.1029\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1112\n",
      "Epoch: 23/100... Training loss: 0.1116\n",
      "Epoch: 23/100... Training loss: 0.1130\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1052\n",
      "Epoch: 23/100... Training loss: 0.1077\n",
      "Epoch: 23/100... Training loss: 0.1114\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1129\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1111\n",
      "Epoch: 23/100... Training loss: 0.1101\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1109\n",
      "Epoch: 23/100... Training loss: 0.1105\n",
      "Epoch: 23/100... Training loss: 0.1050\n",
      "Epoch: 23/100... Training loss: 0.1102\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1073\n",
      "Epoch: 23/100... Training loss: 0.1028\n",
      "Epoch: 23/100... Training loss: 0.1082\n",
      "Epoch: 23/100... Training loss: 0.1111\n",
      "Epoch: 23/100... Training loss: 0.1103\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1123\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1110\n",
      "Epoch: 23/100... Training loss: 0.1099\n",
      "Epoch: 23/100... Training loss: 0.1081\n",
      "Epoch: 23/100... Training loss: 0.1119\n",
      "Epoch: 23/100... Training loss: 0.1108\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1121\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1098\n",
      "Epoch: 23/100... Training loss: 0.1096\n",
      "Epoch: 23/100... Training loss: 0.1060\n",
      "Epoch: 23/100... Training loss: 0.1132\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1104\n",
      "Epoch: 23/100... Training loss: 0.1063\n",
      "Epoch: 23/100... Training loss: 0.1088\n",
      "Epoch: 23/100... Training loss: 0.1114\n",
      "Epoch: 23/100... Training loss: 0.1115\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1053\n",
      "Epoch: 23/100... Training loss: 0.1116\n",
      "Epoch: 23/100... Training loss: 0.1087\n",
      "Epoch: 23/100... Training loss: 0.1090\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1104\n",
      "Epoch: 23/100... Training loss: 0.1097\n",
      "Epoch: 23/100... Training loss: 0.1102\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1069\n",
      "Epoch: 23/100... Training loss: 0.1066\n",
      "Epoch: 23/100... Training loss: 0.1054\n",
      "Epoch: 23/100... Training loss: 0.1130\n",
      "Epoch: 23/100... Training loss: 0.1065\n",
      "Epoch: 23/100... Training loss: 0.1119\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1102\n",
      "Epoch: 23/100... Training loss: 0.1119\n",
      "Epoch: 23/100... Training loss: 0.1079\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1044\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1075\n",
      "Epoch: 23/100... Training loss: 0.1119\n",
      "Epoch: 23/100... Training loss: 0.1093\n",
      "Epoch: 23/100... Training loss: 0.1093\n",
      "Epoch: 23/100... Training loss: 0.1085\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1072\n",
      "Epoch: 23/100... Training loss: 0.1078\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1128\n",
      "Epoch: 23/100... Training loss: 0.1117\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1081\n",
      "Epoch: 23/100... Training loss: 0.1095\n",
      "Epoch: 23/100... Training loss: 0.1074\n",
      "Epoch: 23/100... Training loss: 0.1114\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 23/100... Training loss: 0.1086\n",
      "Epoch: 23/100... Training loss: 0.1067\n",
      "Epoch: 23/100... Training loss: 0.1104\n",
      "Epoch: 23/100... Training loss: 0.1089\n",
      "Epoch: 23/100... Training loss: 0.1106\n",
      "Epoch: 23/100... Training loss: 0.1100\n",
      "Epoch: 23/100... Training loss: 0.1121\n",
      "Epoch: 23/100... Training loss: 0.1088\n",
      "Epoch: 23/100... Training loss: 0.1083\n",
      "Epoch: 23/100... Training loss: 0.1118\n",
      "Epoch: 23/100... Training loss: 0.1058\n",
      "Epoch: 23/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1114\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1100\n",
      "Epoch: 24/100... Training loss: 0.1104\n",
      "Epoch: 24/100... Training loss: 0.1126\n",
      "Epoch: 24/100... Training loss: 0.1066\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1113\n",
      "Epoch: 24/100... Training loss: 0.1096\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1097\n",
      "Epoch: 24/100... Training loss: 0.1085\n",
      "Epoch: 24/100... Training loss: 0.1098\n",
      "Epoch: 24/100... Training loss: 0.1083\n",
      "Epoch: 24/100... Training loss: 0.1101\n",
      "Epoch: 24/100... Training loss: 0.1090\n",
      "Epoch: 24/100... Training loss: 0.1128\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1119\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1133\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1115\n",
      "Epoch: 24/100... Training loss: 0.1095\n",
      "Epoch: 24/100... Training loss: 0.1118\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1114\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1102\n",
      "Epoch: 24/100... Training loss: 0.1103\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1122\n",
      "Epoch: 24/100... Training loss: 0.1108\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1107\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1099\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1093\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1128\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1102\n",
      "Epoch: 24/100... Training loss: 0.1097\n",
      "Epoch: 24/100... Training loss: 0.1107\n",
      "Epoch: 24/100... Training loss: 0.1095\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1097\n",
      "Epoch: 24/100... Training loss: 0.1090\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1104\n",
      "Epoch: 24/100... Training loss: 0.1102\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1102\n",
      "Epoch: 24/100... Training loss: 0.1108\n",
      "Epoch: 24/100... Training loss: 0.1098\n",
      "Epoch: 24/100... Training loss: 0.1048\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1083\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1098\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1066\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1097\n",
      "Epoch: 24/100... Training loss: 0.1104\n",
      "Epoch: 24/100... Training loss: 0.1096\n",
      "Epoch: 24/100... Training loss: 0.1112\n",
      "Epoch: 24/100... Training loss: 0.1090\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1094\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1108\n",
      "Epoch: 24/100... Training loss: 0.1122\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1120\n",
      "Epoch: 24/100... Training loss: 0.1129\n",
      "Epoch: 24/100... Training loss: 0.1113\n",
      "Epoch: 24/100... Training loss: 0.1110\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1095\n",
      "Epoch: 24/100... Training loss: 0.1097\n",
      "Epoch: 24/100... Training loss: 0.1114\n",
      "Epoch: 24/100... Training loss: 0.1099\n",
      "Epoch: 24/100... Training loss: 0.1124\n",
      "Epoch: 24/100... Training loss: 0.1110\n",
      "Epoch: 24/100... Training loss: 0.1102\n",
      "Epoch: 24/100... Training loss: 0.1100\n",
      "Epoch: 24/100... Training loss: 0.1115\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1096\n",
      "Epoch: 24/100... Training loss: 0.1085\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1098\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1097\n",
      "Epoch: 24/100... Training loss: 0.1061\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1094\n",
      "Epoch: 24/100... Training loss: 0.1110\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1039\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1104\n",
      "Epoch: 24/100... Training loss: 0.1131\n",
      "Epoch: 24/100... Training loss: 0.1123\n",
      "Epoch: 24/100... Training loss: 0.1127\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1116\n",
      "Epoch: 24/100... Training loss: 0.1068\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1138\n",
      "Epoch: 24/100... Training loss: 0.1093\n",
      "Epoch: 24/100... Training loss: 0.1108\n",
      "Epoch: 24/100... Training loss: 0.1099\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1116\n",
      "Epoch: 24/100... Training loss: 0.1104\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1104\n",
      "Epoch: 24/100... Training loss: 0.1098\n",
      "Epoch: 24/100... Training loss: 0.1120\n",
      "Epoch: 24/100... Training loss: 0.1109\n",
      "Epoch: 24/100... Training loss: 0.1098\n",
      "Epoch: 24/100... Training loss: 0.1126\n",
      "Epoch: 24/100... Training loss: 0.1104\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1106\n",
      "Epoch: 24/100... Training loss: 0.1051\n",
      "Epoch: 24/100... Training loss: 0.1108\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1116\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1096\n",
      "Epoch: 24/100... Training loss: 0.1069\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1119\n",
      "Epoch: 24/100... Training loss: 0.1093\n",
      "Epoch: 24/100... Training loss: 0.1086\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1116\n",
      "Epoch: 24/100... Training loss: 0.1099\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1089\n",
      "Epoch: 24/100... Training loss: 0.1114\n",
      "Epoch: 24/100... Training loss: 0.1080\n",
      "Epoch: 24/100... Training loss: 0.1056\n",
      "Epoch: 24/100... Training loss: 0.1031\n",
      "Epoch: 24/100... Training loss: 0.1140\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1101\n",
      "Epoch: 24/100... Training loss: 0.1092\n",
      "Epoch: 24/100... Training loss: 0.1120\n",
      "Epoch: 24/100... Training loss: 0.1095\n",
      "Epoch: 24/100... Training loss: 0.1105\n",
      "Epoch: 24/100... Training loss: 0.1108\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1053\n",
      "Epoch: 24/100... Training loss: 0.1125\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1118\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1117\n",
      "Epoch: 24/100... Training loss: 0.1090\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1095\n",
      "Epoch: 24/100... Training loss: 0.1049\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1098\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1121\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1107\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1102\n",
      "Epoch: 24/100... Training loss: 0.1075\n",
      "Epoch: 24/100... Training loss: 0.1097\n",
      "Epoch: 24/100... Training loss: 0.1089\n",
      "Epoch: 24/100... Training loss: 0.1086\n",
      "Epoch: 24/100... Training loss: 0.1110\n",
      "Epoch: 24/100... Training loss: 0.1127\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1126\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1096\n",
      "Epoch: 24/100... Training loss: 0.1074\n",
      "Epoch: 24/100... Training loss: 0.1113\n",
      "Epoch: 24/100... Training loss: 0.1098\n",
      "Epoch: 24/100... Training loss: 0.1079\n",
      "Epoch: 24/100... Training loss: 0.1123\n",
      "Epoch: 24/100... Training loss: 0.1089\n",
      "Epoch: 24/100... Training loss: 0.1101\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1117\n",
      "Epoch: 24/100... Training loss: 0.1162\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1123\n",
      "Epoch: 24/100... Training loss: 0.1114\n",
      "Epoch: 24/100... Training loss: 0.1091\n",
      "Epoch: 24/100... Training loss: 0.1114\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1125\n",
      "Epoch: 24/100... Training loss: 0.1070\n",
      "Epoch: 24/100... Training loss: 0.1125\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1102\n",
      "Epoch: 24/100... Training loss: 0.1096\n",
      "Epoch: 24/100... Training loss: 0.1094\n",
      "Epoch: 24/100... Training loss: 0.1136\n",
      "Epoch: 24/100... Training loss: 0.1078\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1103\n",
      "Epoch: 24/100... Training loss: 0.1108\n",
      "Epoch: 24/100... Training loss: 0.1089\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1064\n",
      "Epoch: 24/100... Training loss: 0.1113\n",
      "Epoch: 24/100... Training loss: 0.1054\n",
      "Epoch: 24/100... Training loss: 0.1138\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1076\n",
      "Epoch: 24/100... Training loss: 0.1055\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1097\n",
      "Epoch: 24/100... Training loss: 0.1057\n",
      "Epoch: 24/100... Training loss: 0.1116\n",
      "Epoch: 24/100... Training loss: 0.1077\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1063\n",
      "Epoch: 24/100... Training loss: 0.1105\n",
      "Epoch: 24/100... Training loss: 0.1091\n",
      "Epoch: 24/100... Training loss: 0.1084\n",
      "Epoch: 24/100... Training loss: 0.1104\n",
      "Epoch: 24/100... Training loss: 0.1067\n",
      "Epoch: 24/100... Training loss: 0.1086\n",
      "Epoch: 24/100... Training loss: 0.1105\n",
      "Epoch: 24/100... Training loss: 0.1059\n",
      "Epoch: 24/100... Training loss: 0.1087\n",
      "Epoch: 24/100... Training loss: 0.1073\n",
      "Epoch: 24/100... Training loss: 0.1052\n",
      "Epoch: 24/100... Training loss: 0.1102\n",
      "Epoch: 24/100... Training loss: 0.1088\n",
      "Epoch: 24/100... Training loss: 0.1093\n",
      "Epoch: 24/100... Training loss: 0.1081\n",
      "Epoch: 24/100... Training loss: 0.1125\n",
      "Epoch: 24/100... Training loss: 0.1102\n",
      "Epoch: 24/100... Training loss: 0.1045\n",
      "Epoch: 24/100... Training loss: 0.1128\n",
      "Epoch: 24/100... Training loss: 0.1109\n",
      "Epoch: 24/100... Training loss: 0.1047\n",
      "Epoch: 24/100... Training loss: 0.1106\n",
      "Epoch: 24/100... Training loss: 0.1060\n",
      "Epoch: 24/100... Training loss: 0.1103\n",
      "Epoch: 24/100... Training loss: 0.1085\n",
      "Epoch: 24/100... Training loss: 0.1082\n",
      "Epoch: 24/100... Training loss: 0.1146\n",
      "Epoch: 24/100... Training loss: 0.1072\n",
      "Epoch: 24/100... Training loss: 0.1103\n",
      "Epoch: 24/100... Training loss: 0.1089\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1106\n",
      "Epoch: 25/100... Training loss: 0.1122\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1095\n",
      "Epoch: 25/100... Training loss: 0.1091\n",
      "Epoch: 25/100... Training loss: 0.1090\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1098\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1145\n",
      "Epoch: 25/100... Training loss: 0.1100\n",
      "Epoch: 25/100... Training loss: 0.1089\n",
      "Epoch: 25/100... Training loss: 0.1095\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1130\n",
      "Epoch: 25/100... Training loss: 0.1102\n",
      "Epoch: 25/100... Training loss: 0.1092\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1122\n",
      "Epoch: 25/100... Training loss: 0.1108\n",
      "Epoch: 25/100... Training loss: 0.1111\n",
      "Epoch: 25/100... Training loss: 0.1120\n",
      "Epoch: 25/100... Training loss: 0.1085\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1100\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1100\n",
      "Epoch: 25/100... Training loss: 0.1021\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1137\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1102\n",
      "Epoch: 25/100... Training loss: 0.1093\n",
      "Epoch: 25/100... Training loss: 0.1092\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1117\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1118\n",
      "Epoch: 25/100... Training loss: 0.1106\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1125\n",
      "Epoch: 25/100... Training loss: 0.1038\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1086\n",
      "Epoch: 25/100... Training loss: 0.1110\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1103\n",
      "Epoch: 25/100... Training loss: 0.1049\n",
      "Epoch: 25/100... Training loss: 0.1110\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1093\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1094\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1101\n",
      "Epoch: 25/100... Training loss: 0.1145\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1104\n",
      "Epoch: 25/100... Training loss: 0.1097\n",
      "Epoch: 25/100... Training loss: 0.1132\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1046\n",
      "Epoch: 25/100... Training loss: 0.1113\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1100\n",
      "Epoch: 25/100... Training loss: 0.1116\n",
      "Epoch: 25/100... Training loss: 0.1101\n",
      "Epoch: 25/100... Training loss: 0.1085\n",
      "Epoch: 25/100... Training loss: 0.1108\n",
      "Epoch: 25/100... Training loss: 0.1094\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1122\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1129\n",
      "Epoch: 25/100... Training loss: 0.1106\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1043\n",
      "Epoch: 25/100... Training loss: 0.1106\n",
      "Epoch: 25/100... Training loss: 0.1090\n",
      "Epoch: 25/100... Training loss: 0.1094\n",
      "Epoch: 25/100... Training loss: 0.1137\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1095\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1099\n",
      "Epoch: 25/100... Training loss: 0.1094\n",
      "Epoch: 25/100... Training loss: 0.1109\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1117\n",
      "Epoch: 25/100... Training loss: 0.1097\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1110\n",
      "Epoch: 25/100... Training loss: 0.1063\n",
      "Epoch: 25/100... Training loss: 0.1102\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1117\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1099\n",
      "Epoch: 25/100... Training loss: 0.1106\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1053\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1091\n",
      "Epoch: 25/100... Training loss: 0.1095\n",
      "Epoch: 25/100... Training loss: 0.1037\n",
      "Epoch: 25/100... Training loss: 0.1091\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1106\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1136\n",
      "Epoch: 25/100... Training loss: 0.1127\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1039\n",
      "Epoch: 25/100... Training loss: 0.1096\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1106\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1061\n",
      "Epoch: 25/100... Training loss: 0.1090\n",
      "Epoch: 25/100... Training loss: 0.1115\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1058\n",
      "Epoch: 25/100... Training loss: 0.1085\n",
      "Epoch: 25/100... Training loss: 0.1098\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1057\n",
      "Epoch: 25/100... Training loss: 0.1104\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1111\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1107\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1107\n",
      "Epoch: 25/100... Training loss: 0.1056\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1124\n",
      "Epoch: 25/100... Training loss: 0.1054\n",
      "Epoch: 25/100... Training loss: 0.1052\n",
      "Epoch: 25/100... Training loss: 0.1117\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1103\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1091\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1105\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1117\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1029\n",
      "Epoch: 25/100... Training loss: 0.1095\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1098\n",
      "Epoch: 25/100... Training loss: 0.1098\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1102\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1126\n",
      "Epoch: 25/100... Training loss: 0.1081\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1092\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1115\n",
      "Epoch: 25/100... Training loss: 0.1076\n",
      "Epoch: 25/100... Training loss: 0.1090\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1099\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1093\n",
      "Epoch: 25/100... Training loss: 0.1072\n",
      "Epoch: 25/100... Training loss: 0.1114\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1099\n",
      "Epoch: 25/100... Training loss: 0.1098\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 25/100... Training loss: 0.1101\n",
      "Epoch: 25/100... Training loss: 0.1075\n",
      "Epoch: 25/100... Training loss: 0.1108\n",
      "Epoch: 25/100... Training loss: 0.1121\n",
      "Epoch: 25/100... Training loss: 0.1100\n",
      "Epoch: 25/100... Training loss: 0.1111\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1060\n",
      "Epoch: 25/100... Training loss: 0.1096\n",
      "Epoch: 25/100... Training loss: 0.1114\n",
      "Epoch: 25/100... Training loss: 0.1121\n",
      "Epoch: 25/100... Training loss: 0.1067\n",
      "Epoch: 25/100... Training loss: 0.1098\n",
      "Epoch: 25/100... Training loss: 0.1086\n",
      "Epoch: 25/100... Training loss: 0.1108\n",
      "Epoch: 25/100... Training loss: 0.1068\n",
      "Epoch: 25/100... Training loss: 0.1069\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1064\n",
      "Epoch: 25/100... Training loss: 0.1086\n",
      "Epoch: 25/100... Training loss: 0.1047\n",
      "Epoch: 25/100... Training loss: 0.1062\n",
      "Epoch: 25/100... Training loss: 0.1104\n",
      "Epoch: 25/100... Training loss: 0.1096\n",
      "Epoch: 25/100... Training loss: 0.1090\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1123\n",
      "Epoch: 25/100... Training loss: 0.1055\n",
      "Epoch: 25/100... Training loss: 0.1082\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1041\n",
      "Epoch: 25/100... Training loss: 0.1122\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1100\n",
      "Epoch: 25/100... Training loss: 0.1111\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1095\n",
      "Epoch: 25/100... Training loss: 0.1115\n",
      "Epoch: 25/100... Training loss: 0.1028\n",
      "Epoch: 25/100... Training loss: 0.1100\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1083\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1101\n",
      "Epoch: 25/100... Training loss: 0.1078\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1087\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1094\n",
      "Epoch: 25/100... Training loss: 0.1111\n",
      "Epoch: 25/100... Training loss: 0.1106\n",
      "Epoch: 25/100... Training loss: 0.1050\n",
      "Epoch: 25/100... Training loss: 0.1073\n",
      "Epoch: 25/100... Training loss: 0.1096\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1098\n",
      "Epoch: 25/100... Training loss: 0.1059\n",
      "Epoch: 25/100... Training loss: 0.1084\n",
      "Epoch: 25/100... Training loss: 0.1066\n",
      "Epoch: 25/100... Training loss: 0.1071\n",
      "Epoch: 25/100... Training loss: 0.1080\n",
      "Epoch: 25/100... Training loss: 0.1079\n",
      "Epoch: 25/100... Training loss: 0.1070\n",
      "Epoch: 25/100... Training loss: 0.1077\n",
      "Epoch: 25/100... Training loss: 0.1089\n",
      "Epoch: 25/100... Training loss: 0.1112\n",
      "Epoch: 25/100... Training loss: 0.1074\n",
      "Epoch: 25/100... Training loss: 0.1088\n",
      "Epoch: 26/100... Training loss: 0.1105\n",
      "Epoch: 26/100... Training loss: 0.1104\n",
      "Epoch: 26/100... Training loss: 0.1088\n",
      "Epoch: 26/100... Training loss: 0.1128\n",
      "Epoch: 26/100... Training loss: 0.1105\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1075\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1095\n",
      "Epoch: 26/100... Training loss: 0.1075\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1037\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1043\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1103\n",
      "Epoch: 26/100... Training loss: 0.1092\n",
      "Epoch: 26/100... Training loss: 0.1075\n",
      "Epoch: 26/100... Training loss: 0.1099\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1052\n",
      "Epoch: 26/100... Training loss: 0.1100\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1100\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1108\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1049\n",
      "Epoch: 26/100... Training loss: 0.1116\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1082\n",
      "Epoch: 26/100... Training loss: 0.1112\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1127\n",
      "Epoch: 26/100... Training loss: 0.1101\n",
      "Epoch: 26/100... Training loss: 0.1115\n",
      "Epoch: 26/100... Training loss: 0.1088\n",
      "Epoch: 26/100... Training loss: 0.1101\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1102\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1100\n",
      "Epoch: 26/100... Training loss: 0.1107\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1086\n",
      "Epoch: 26/100... Training loss: 0.1053\n",
      "Epoch: 26/100... Training loss: 0.1092\n",
      "Epoch: 26/100... Training loss: 0.1088\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1097\n",
      "Epoch: 26/100... Training loss: 0.1118\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1084\n",
      "Epoch: 26/100... Training loss: 0.1090\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1093\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1110\n",
      "Epoch: 26/100... Training loss: 0.1090\n",
      "Epoch: 26/100... Training loss: 0.1086\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1094\n",
      "Epoch: 26/100... Training loss: 0.1082\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1100\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1041\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1097\n",
      "Epoch: 26/100... Training loss: 0.1102\n",
      "Epoch: 26/100... Training loss: 0.1096\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1042\n",
      "Epoch: 26/100... Training loss: 0.1106\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1060\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1050\n",
      "Epoch: 26/100... Training loss: 0.1102\n",
      "Epoch: 26/100... Training loss: 0.1084\n",
      "Epoch: 26/100... Training loss: 0.1067\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1047\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1102\n",
      "Epoch: 26/100... Training loss: 0.1090\n",
      "Epoch: 26/100... Training loss: 0.1112\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1056\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1125\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1080\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1095\n",
      "Epoch: 26/100... Training loss: 0.1118\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1080\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1102\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1093\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1103\n",
      "Epoch: 26/100... Training loss: 0.1048\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1094\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1122\n",
      "Epoch: 26/100... Training loss: 0.1111\n",
      "Epoch: 26/100... Training loss: 0.1114\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1101\n",
      "Epoch: 26/100... Training loss: 0.1086\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1113\n",
      "Epoch: 26/100... Training loss: 0.1105\n",
      "Epoch: 26/100... Training loss: 0.1085\n",
      "Epoch: 26/100... Training loss: 0.1131\n",
      "Epoch: 26/100... Training loss: 0.1075\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1113\n",
      "Epoch: 26/100... Training loss: 0.1112\n",
      "Epoch: 26/100... Training loss: 0.1108\n",
      "Epoch: 26/100... Training loss: 0.1099\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1097\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1109\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1093\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1057\n",
      "Epoch: 26/100... Training loss: 0.1097\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1098\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1094\n",
      "Epoch: 26/100... Training loss: 0.1084\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1107\n",
      "Epoch: 26/100... Training loss: 0.1102\n",
      "Epoch: 26/100... Training loss: 0.1108\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1104\n",
      "Epoch: 26/100... Training loss: 0.1054\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1094\n",
      "Epoch: 26/100... Training loss: 0.1110\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1101\n",
      "Epoch: 26/100... Training loss: 0.1099\n",
      "Epoch: 26/100... Training loss: 0.1098\n",
      "Epoch: 26/100... Training loss: 0.1090\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1113\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1135\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1100\n",
      "Epoch: 26/100... Training loss: 0.1096\n",
      "Epoch: 26/100... Training loss: 0.1112\n",
      "Epoch: 26/100... Training loss: 0.1103\n",
      "Epoch: 26/100... Training loss: 0.1083\n",
      "Epoch: 26/100... Training loss: 0.1117\n",
      "Epoch: 26/100... Training loss: 0.1090\n",
      "Epoch: 26/100... Training loss: 0.1059\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1051\n",
      "Epoch: 26/100... Training loss: 0.1159\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1093\n",
      "Epoch: 26/100... Training loss: 0.1150\n",
      "Epoch: 26/100... Training loss: 0.1100\n",
      "Epoch: 26/100... Training loss: 0.1086\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1046\n",
      "Epoch: 26/100... Training loss: 0.1108\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1111\n",
      "Epoch: 26/100... Training loss: 0.1084\n",
      "Epoch: 26/100... Training loss: 0.1058\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1089\n",
      "Epoch: 26/100... Training loss: 0.1080\n",
      "Epoch: 26/100... Training loss: 0.1113\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1080\n",
      "Epoch: 26/100... Training loss: 0.1055\n",
      "Epoch: 26/100... Training loss: 0.1127\n",
      "Epoch: 26/100... Training loss: 0.1064\n",
      "Epoch: 26/100... Training loss: 0.1103\n",
      "Epoch: 26/100... Training loss: 0.1103\n",
      "Epoch: 26/100... Training loss: 0.1061\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1092\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1101\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1086\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1079\n",
      "Epoch: 26/100... Training loss: 0.1075\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1100\n",
      "Epoch: 26/100... Training loss: 0.1091\n",
      "Epoch: 26/100... Training loss: 0.1089\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1036\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1062\n",
      "Epoch: 26/100... Training loss: 0.1069\n",
      "Epoch: 26/100... Training loss: 0.1092\n",
      "Epoch: 26/100... Training loss: 0.1071\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1096\n",
      "Epoch: 26/100... Training loss: 0.1103\n",
      "Epoch: 26/100... Training loss: 0.1070\n",
      "Epoch: 26/100... Training loss: 0.1073\n",
      "Epoch: 26/100... Training loss: 0.1080\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1074\n",
      "Epoch: 26/100... Training loss: 0.1096\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1075\n",
      "Epoch: 26/100... Training loss: 0.1097\n",
      "Epoch: 26/100... Training loss: 0.1096\n",
      "Epoch: 26/100... Training loss: 0.1039\n",
      "Epoch: 26/100... Training loss: 0.1122\n",
      "Epoch: 26/100... Training loss: 0.1066\n",
      "Epoch: 26/100... Training loss: 0.1084\n",
      "Epoch: 26/100... Training loss: 0.1094\n",
      "Epoch: 26/100... Training loss: 0.1143\n",
      "Epoch: 26/100... Training loss: 0.1085\n",
      "Epoch: 26/100... Training loss: 0.1076\n",
      "Epoch: 26/100... Training loss: 0.1125\n",
      "Epoch: 26/100... Training loss: 0.1087\n",
      "Epoch: 26/100... Training loss: 0.1077\n",
      "Epoch: 26/100... Training loss: 0.1099\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1081\n",
      "Epoch: 26/100... Training loss: 0.1072\n",
      "Epoch: 26/100... Training loss: 0.1045\n",
      "Epoch: 26/100... Training loss: 0.1080\n",
      "Epoch: 26/100... Training loss: 0.1065\n",
      "Epoch: 26/100... Training loss: 0.1088\n",
      "Epoch: 26/100... Training loss: 0.1063\n",
      "Epoch: 26/100... Training loss: 0.1032\n",
      "Epoch: 26/100... Training loss: 0.1096\n",
      "Epoch: 26/100... Training loss: 0.1068\n",
      "Epoch: 26/100... Training loss: 0.1078\n",
      "Epoch: 26/100... Training loss: 0.1101\n",
      "Epoch: 27/100... Training loss: 0.1102\n",
      "Epoch: 27/100... Training loss: 0.1092\n",
      "Epoch: 27/100... Training loss: 0.1070\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1122\n",
      "Epoch: 27/100... Training loss: 0.1107\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1070\n",
      "Epoch: 27/100... Training loss: 0.1073\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1086\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1073\n",
      "Epoch: 27/100... Training loss: 0.1103\n",
      "Epoch: 27/100... Training loss: 0.1088\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1120\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1106\n",
      "Epoch: 27/100... Training loss: 0.1104\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1107\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1138\n",
      "Epoch: 27/100... Training loss: 0.1099\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1085\n",
      "Epoch: 27/100... Training loss: 0.1052\n",
      "Epoch: 27/100... Training loss: 0.1086\n",
      "Epoch: 27/100... Training loss: 0.1087\n",
      "Epoch: 27/100... Training loss: 0.1073\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1113\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1112\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1075\n",
      "Epoch: 27/100... Training loss: 0.1087\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1111\n",
      "Epoch: 27/100... Training loss: 0.1073\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1076\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1090\n",
      "Epoch: 27/100... Training loss: 0.1106\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1124\n",
      "Epoch: 27/100... Training loss: 0.1086\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1086\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1045\n",
      "Epoch: 27/100... Training loss: 0.1092\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1095\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1119\n",
      "Epoch: 27/100... Training loss: 0.1064\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1081\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1091\n",
      "Epoch: 27/100... Training loss: 0.1105\n",
      "Epoch: 27/100... Training loss: 0.1097\n",
      "Epoch: 27/100... Training loss: 0.1104\n",
      "Epoch: 27/100... Training loss: 0.1084\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1122\n",
      "Epoch: 27/100... Training loss: 0.1084\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1088\n",
      "Epoch: 27/100... Training loss: 0.1041\n",
      "Epoch: 27/100... Training loss: 0.1115\n",
      "Epoch: 27/100... Training loss: 0.1105\n",
      "Epoch: 27/100... Training loss: 0.1084\n",
      "Epoch: 27/100... Training loss: 0.1092\n",
      "Epoch: 27/100... Training loss: 0.1090\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1075\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1085\n",
      "Epoch: 27/100... Training loss: 0.1128\n",
      "Epoch: 27/100... Training loss: 0.1086\n",
      "Epoch: 27/100... Training loss: 0.1046\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1086\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1098\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.1082\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1105\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1050\n",
      "Epoch: 27/100... Training loss: 0.1047\n",
      "Epoch: 27/100... Training loss: 0.1085\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1092\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1099\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1104\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1088\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1092\n",
      "Epoch: 27/100... Training loss: 0.1091\n",
      "Epoch: 27/100... Training loss: 0.1070\n",
      "Epoch: 27/100... Training loss: 0.1036\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1113\n",
      "Epoch: 27/100... Training loss: 0.1097\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1053\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1059\n",
      "Epoch: 27/100... Training loss: 0.1030\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1110\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1075\n",
      "Epoch: 27/100... Training loss: 0.1075\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1120\n",
      "Epoch: 27/100... Training loss: 0.1094\n",
      "Epoch: 27/100... Training loss: 0.1094\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1115\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1126\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1099\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1116\n",
      "Epoch: 27/100... Training loss: 0.1104\n",
      "Epoch: 27/100... Training loss: 0.1048\n",
      "Epoch: 27/100... Training loss: 0.1102\n",
      "Epoch: 27/100... Training loss: 0.1043\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1102\n",
      "Epoch: 27/100... Training loss: 0.1105\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1075\n",
      "Epoch: 27/100... Training loss: 0.1034\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1075\n",
      "Epoch: 27/100... Training loss: 0.1081\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1100\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1091\n",
      "Epoch: 27/100... Training loss: 0.1083\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1110\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1081\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1101\n",
      "Epoch: 27/100... Training loss: 0.1104\n",
      "Epoch: 27/100... Training loss: 0.1042\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1056\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1111\n",
      "Epoch: 27/100... Training loss: 0.1106\n",
      "Epoch: 27/100... Training loss: 0.1108\n",
      "Epoch: 27/100... Training loss: 0.1073\n",
      "Epoch: 27/100... Training loss: 0.1116\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1105\n",
      "Epoch: 27/100... Training loss: 0.1099\n",
      "Epoch: 27/100... Training loss: 0.1106\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1103\n",
      "Epoch: 27/100... Training loss: 0.1087\n",
      "Epoch: 27/100... Training loss: 0.1084\n",
      "Epoch: 27/100... Training loss: 0.1084\n",
      "Epoch: 27/100... Training loss: 0.1065\n",
      "Epoch: 27/100... Training loss: 0.1117\n",
      "Epoch: 27/100... Training loss: 0.1066\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1096\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1076\n",
      "Epoch: 27/100... Training loss: 0.1095\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1051\n",
      "Epoch: 27/100... Training loss: 0.1101\n",
      "Epoch: 27/100... Training loss: 0.1102\n",
      "Epoch: 27/100... Training loss: 0.1094\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1049\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1085\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1067\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1079\n",
      "Epoch: 27/100... Training loss: 0.1055\n",
      "Epoch: 27/100... Training loss: 0.1092\n",
      "Epoch: 27/100... Training loss: 0.1061\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1060\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1122\n",
      "Epoch: 27/100... Training loss: 0.1078\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1073\n",
      "Epoch: 27/100... Training loss: 0.1090\n",
      "Epoch: 27/100... Training loss: 0.1091\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1062\n",
      "Epoch: 27/100... Training loss: 0.1089\n",
      "Epoch: 27/100... Training loss: 0.1084\n",
      "Epoch: 27/100... Training loss: 0.1057\n",
      "Epoch: 27/100... Training loss: 0.1096\n",
      "Epoch: 27/100... Training loss: 0.1058\n",
      "Epoch: 27/100... Training loss: 0.1076\n",
      "Epoch: 27/100... Training loss: 0.1100\n",
      "Epoch: 27/100... Training loss: 0.1074\n",
      "Epoch: 27/100... Training loss: 0.1090\n",
      "Epoch: 27/100... Training loss: 0.1093\n",
      "Epoch: 27/100... Training loss: 0.1108\n",
      "Epoch: 27/100... Training loss: 0.1101\n",
      "Epoch: 27/100... Training loss: 0.1109\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1103\n",
      "Epoch: 27/100... Training loss: 0.1071\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1039\n",
      "Epoch: 27/100... Training loss: 0.1063\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1085\n",
      "Epoch: 27/100... Training loss: 0.1099\n",
      "Epoch: 27/100... Training loss: 0.1037\n",
      "Epoch: 27/100... Training loss: 0.1068\n",
      "Epoch: 27/100... Training loss: 0.1077\n",
      "Epoch: 27/100... Training loss: 0.1100\n",
      "Epoch: 27/100... Training loss: 0.1106\n",
      "Epoch: 27/100... Training loss: 0.1115\n",
      "Epoch: 27/100... Training loss: 0.1081\n",
      "Epoch: 27/100... Training loss: 0.1096\n",
      "Epoch: 27/100... Training loss: 0.1082\n",
      "Epoch: 27/100... Training loss: 0.1086\n",
      "Epoch: 27/100... Training loss: 0.1072\n",
      "Epoch: 27/100... Training loss: 0.1102\n",
      "Epoch: 27/100... Training loss: 0.1080\n",
      "Epoch: 27/100... Training loss: 0.1025\n",
      "Epoch: 27/100... Training loss: 0.1090\n",
      "Epoch: 27/100... Training loss: 0.1107\n",
      "Epoch: 27/100... Training loss: 0.1085\n",
      "Epoch: 27/100... Training loss: 0.1081\n",
      "Epoch: 27/100... Training loss: 0.1111\n",
      "Epoch: 27/100... Training loss: 0.1073\n",
      "Epoch: 27/100... Training loss: 0.1069\n",
      "Epoch: 27/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1105\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1097\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1071\n",
      "Epoch: 28/100... Training loss: 0.1107\n",
      "Epoch: 28/100... Training loss: 0.1093\n",
      "Epoch: 28/100... Training loss: 0.1085\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1089\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1108\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1088\n",
      "Epoch: 28/100... Training loss: 0.1112\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1088\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1105\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1099\n",
      "Epoch: 28/100... Training loss: 0.1095\n",
      "Epoch: 28/100... Training loss: 0.1091\n",
      "Epoch: 28/100... Training loss: 0.1092\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1088\n",
      "Epoch: 28/100... Training loss: 0.1100\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1097\n",
      "Epoch: 28/100... Training loss: 0.1081\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1027\n",
      "Epoch: 28/100... Training loss: 0.1096\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1100\n",
      "Epoch: 28/100... Training loss: 0.1035\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1106\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1109\n",
      "Epoch: 28/100... Training loss: 0.1101\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1091\n",
      "Epoch: 28/100... Training loss: 0.1085\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1100\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1090\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1094\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1049\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1071\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1120\n",
      "Epoch: 28/100... Training loss: 0.1094\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1129\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1089\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1092\n",
      "Epoch: 28/100... Training loss: 0.1083\n",
      "Epoch: 28/100... Training loss: 0.1130\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1095\n",
      "Epoch: 28/100... Training loss: 0.1141\n",
      "Epoch: 28/100... Training loss: 0.1036\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1081\n",
      "Epoch: 28/100... Training loss: 0.1119\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1091\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1094\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1103\n",
      "Epoch: 28/100... Training loss: 0.1034\n",
      "Epoch: 28/100... Training loss: 0.1088\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1089\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1095\n",
      "Epoch: 28/100... Training loss: 0.1089\n",
      "Epoch: 28/100... Training loss: 0.1087\n",
      "Epoch: 28/100... Training loss: 0.1094\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1115\n",
      "Epoch: 28/100... Training loss: 0.1045\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1104\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1088\n",
      "Epoch: 28/100... Training loss: 0.1080\n",
      "Epoch: 28/100... Training loss: 0.1098\n",
      "Epoch: 28/100... Training loss: 0.1071\n",
      "Epoch: 28/100... Training loss: 0.1087\n",
      "Epoch: 28/100... Training loss: 0.1041\n",
      "Epoch: 28/100... Training loss: 0.1102\n",
      "Epoch: 28/100... Training loss: 0.1101\n",
      "Epoch: 28/100... Training loss: 0.1111\n",
      "Epoch: 28/100... Training loss: 0.1107\n",
      "Epoch: 28/100... Training loss: 0.1092\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1081\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1102\n",
      "Epoch: 28/100... Training loss: 0.1026\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1112\n",
      "Epoch: 28/100... Training loss: 0.1110\n",
      "Epoch: 28/100... Training loss: 0.1106\n",
      "Epoch: 28/100... Training loss: 0.1099\n",
      "Epoch: 28/100... Training loss: 0.1122\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1043\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1098\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1096\n",
      "Epoch: 28/100... Training loss: 0.1086\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1117\n",
      "Epoch: 28/100... Training loss: 0.1081\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1123\n",
      "Epoch: 28/100... Training loss: 0.1091\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1119\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1087\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1101\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1085\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1087\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1086\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1100\n",
      "Epoch: 28/100... Training loss: 0.1071\n",
      "Epoch: 28/100... Training loss: 0.1094\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1097\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1093\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1117\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1095\n",
      "Epoch: 28/100... Training loss: 0.1053\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1058\n",
      "Epoch: 28/100... Training loss: 0.1083\n",
      "Epoch: 28/100... Training loss: 0.1082\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1106\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1083\n",
      "Epoch: 28/100... Training loss: 0.1071\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1042\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1051\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1060\n",
      "Epoch: 28/100... Training loss: 0.1084\n",
      "Epoch: 28/100... Training loss: 0.1095\n",
      "Epoch: 28/100... Training loss: 0.1081\n",
      "Epoch: 28/100... Training loss: 0.1047\n",
      "Epoch: 28/100... Training loss: 0.1052\n",
      "Epoch: 28/100... Training loss: 0.1104\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1116\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1092\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1088\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1122\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1061\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1066\n",
      "Epoch: 28/100... Training loss: 0.1104\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1077\n",
      "Epoch: 28/100... Training loss: 0.1048\n",
      "Epoch: 28/100... Training loss: 0.1069\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1087\n",
      "Epoch: 28/100... Training loss: 0.1062\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1087\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1050\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1078\n",
      "Epoch: 28/100... Training loss: 0.1079\n",
      "Epoch: 28/100... Training loss: 0.1055\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1067\n",
      "Epoch: 28/100... Training loss: 0.1098\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1068\n",
      "Epoch: 28/100... Training loss: 0.1064\n",
      "Epoch: 28/100... Training loss: 0.1054\n",
      "Epoch: 28/100... Training loss: 0.1101\n",
      "Epoch: 28/100... Training loss: 0.1110\n",
      "Epoch: 28/100... Training loss: 0.1083\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1108\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1103\n",
      "Epoch: 28/100... Training loss: 0.1074\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1086\n",
      "Epoch: 28/100... Training loss: 0.1089\n",
      "Epoch: 28/100... Training loss: 0.1097\n",
      "Epoch: 28/100... Training loss: 0.1112\n",
      "Epoch: 28/100... Training loss: 0.1097\n",
      "Epoch: 28/100... Training loss: 0.1070\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 28/100... Training loss: 0.1046\n",
      "Epoch: 28/100... Training loss: 0.1044\n",
      "Epoch: 28/100... Training loss: 0.1033\n",
      "Epoch: 28/100... Training loss: 0.1102\n",
      "Epoch: 28/100... Training loss: 0.1072\n",
      "Epoch: 28/100... Training loss: 0.1083\n",
      "Epoch: 28/100... Training loss: 0.1076\n",
      "Epoch: 28/100... Training loss: 0.1087\n",
      "Epoch: 28/100... Training loss: 0.1090\n",
      "Epoch: 28/100... Training loss: 0.1106\n",
      "Epoch: 28/100... Training loss: 0.1085\n",
      "Epoch: 28/100... Training loss: 0.1073\n",
      "Epoch: 28/100... Training loss: 0.1056\n",
      "Epoch: 28/100... Training loss: 0.1102\n",
      "Epoch: 28/100... Training loss: 0.1098\n",
      "Epoch: 28/100... Training loss: 0.1086\n",
      "Epoch: 28/100... Training loss: 0.1088\n",
      "Epoch: 28/100... Training loss: 0.1065\n",
      "Epoch: 28/100... Training loss: 0.1075\n",
      "Epoch: 28/100... Training loss: 0.1057\n",
      "Epoch: 28/100... Training loss: 0.1095\n",
      "Epoch: 28/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1100\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1092\n",
      "Epoch: 29/100... Training loss: 0.1107\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.1087\n",
      "Epoch: 29/100... Training loss: 0.1075\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1078\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.1080\n",
      "Epoch: 29/100... Training loss: 0.1072\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1087\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1103\n",
      "Epoch: 29/100... Training loss: 0.1080\n",
      "Epoch: 29/100... Training loss: 0.1113\n",
      "Epoch: 29/100... Training loss: 0.1088\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1080\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1090\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1069\n",
      "Epoch: 29/100... Training loss: 0.1088\n",
      "Epoch: 29/100... Training loss: 0.1076\n",
      "Epoch: 29/100... Training loss: 0.1115\n",
      "Epoch: 29/100... Training loss: 0.1084\n",
      "Epoch: 29/100... Training loss: 0.1078\n",
      "Epoch: 29/100... Training loss: 0.1108\n",
      "Epoch: 29/100... Training loss: 0.1021\n",
      "Epoch: 29/100... Training loss: 0.1103\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1092\n",
      "Epoch: 29/100... Training loss: 0.1071\n",
      "Epoch: 29/100... Training loss: 0.1110\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1112\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.1099\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1099\n",
      "Epoch: 29/100... Training loss: 0.1084\n",
      "Epoch: 29/100... Training loss: 0.1076\n",
      "Epoch: 29/100... Training loss: 0.1095\n",
      "Epoch: 29/100... Training loss: 0.1107\n",
      "Epoch: 29/100... Training loss: 0.1089\n",
      "Epoch: 29/100... Training loss: 0.1111\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1129\n",
      "Epoch: 29/100... Training loss: 0.1080\n",
      "Epoch: 29/100... Training loss: 0.1127\n",
      "Epoch: 29/100... Training loss: 0.1072\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1110\n",
      "Epoch: 29/100... Training loss: 0.1094\n",
      "Epoch: 29/100... Training loss: 0.1080\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1095\n",
      "Epoch: 29/100... Training loss: 0.1111\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1149\n",
      "Epoch: 29/100... Training loss: 0.1095\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1138\n",
      "Epoch: 29/100... Training loss: 0.1076\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1108\n",
      "Epoch: 29/100... Training loss: 0.1090\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1110\n",
      "Epoch: 29/100... Training loss: 0.1119\n",
      "Epoch: 29/100... Training loss: 0.1033\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.1091\n",
      "Epoch: 29/100... Training loss: 0.1088\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1098\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1072\n",
      "Epoch: 29/100... Training loss: 0.1082\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1026\n",
      "Epoch: 29/100... Training loss: 0.1072\n",
      "Epoch: 29/100... Training loss: 0.1116\n",
      "Epoch: 29/100... Training loss: 0.1105\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1087\n",
      "Epoch: 29/100... Training loss: 0.1126\n",
      "Epoch: 29/100... Training loss: 0.1088\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1100\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1067\n",
      "Epoch: 29/100... Training loss: 0.1041\n",
      "Epoch: 29/100... Training loss: 0.1091\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1074\n",
      "Epoch: 29/100... Training loss: 0.1040\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1122\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1074\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1075\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1093\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1078\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1096\n",
      "Epoch: 29/100... Training loss: 0.1078\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1084\n",
      "Epoch: 29/100... Training loss: 0.1078\n",
      "Epoch: 29/100... Training loss: 0.1047\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1082\n",
      "Epoch: 29/100... Training loss: 0.1083\n",
      "Epoch: 29/100... Training loss: 0.1097\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1102\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1072\n",
      "Epoch: 29/100... Training loss: 0.1119\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1100\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1075\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1095\n",
      "Epoch: 29/100... Training loss: 0.1093\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1107\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1075\n",
      "Epoch: 29/100... Training loss: 0.1083\n",
      "Epoch: 29/100... Training loss: 0.1094\n",
      "Epoch: 29/100... Training loss: 0.1096\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1091\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1088\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1130\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1049\n",
      "Epoch: 29/100... Training loss: 0.1090\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1097\n",
      "Epoch: 29/100... Training loss: 0.1095\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1091\n",
      "Epoch: 29/100... Training loss: 0.1100\n",
      "Epoch: 29/100... Training loss: 0.1113\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1074\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1103\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1084\n",
      "Epoch: 29/100... Training loss: 0.1039\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1076\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1080\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1045\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1075\n",
      "Epoch: 29/100... Training loss: 0.1058\n",
      "Epoch: 29/100... Training loss: 0.1094\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1089\n",
      "Epoch: 29/100... Training loss: 0.1074\n",
      "Epoch: 29/100... Training loss: 0.1028\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1077\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1098\n",
      "Epoch: 29/100... Training loss: 0.1087\n",
      "Epoch: 29/100... Training loss: 0.1064\n",
      "Epoch: 29/100... Training loss: 0.1085\n",
      "Epoch: 29/100... Training loss: 0.1102\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1096\n",
      "Epoch: 29/100... Training loss: 0.1073\n",
      "Epoch: 29/100... Training loss: 0.1063\n",
      "Epoch: 29/100... Training loss: 0.1074\n",
      "Epoch: 29/100... Training loss: 0.1053\n",
      "Epoch: 29/100... Training loss: 0.1123\n",
      "Epoch: 29/100... Training loss: 0.1075\n",
      "Epoch: 29/100... Training loss: 0.1078\n",
      "Epoch: 29/100... Training loss: 0.1098\n",
      "Epoch: 29/100... Training loss: 0.1083\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1056\n",
      "Epoch: 29/100... Training loss: 0.1087\n",
      "Epoch: 29/100... Training loss: 0.1076\n",
      "Epoch: 29/100... Training loss: 0.1116\n",
      "Epoch: 29/100... Training loss: 0.1074\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1057\n",
      "Epoch: 29/100... Training loss: 0.1044\n",
      "Epoch: 29/100... Training loss: 0.1072\n",
      "Epoch: 29/100... Training loss: 0.1098\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1055\n",
      "Epoch: 29/100... Training loss: 0.1032\n",
      "Epoch: 29/100... Training loss: 0.1092\n",
      "Epoch: 29/100... Training loss: 0.1069\n",
      "Epoch: 29/100... Training loss: 0.1048\n",
      "Epoch: 29/100... Training loss: 0.1096\n",
      "Epoch: 29/100... Training loss: 0.1079\n",
      "Epoch: 29/100... Training loss: 0.1025\n",
      "Epoch: 29/100... Training loss: 0.1087\n",
      "Epoch: 29/100... Training loss: 0.1082\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1052\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1037\n",
      "Epoch: 29/100... Training loss: 0.1051\n",
      "Epoch: 29/100... Training loss: 0.1081\n",
      "Epoch: 29/100... Training loss: 0.1060\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1110\n",
      "Epoch: 29/100... Training loss: 0.1062\n",
      "Epoch: 29/100... Training loss: 0.1070\n",
      "Epoch: 29/100... Training loss: 0.1042\n",
      "Epoch: 29/100... Training loss: 0.1059\n",
      "Epoch: 29/100... Training loss: 0.1024\n",
      "Epoch: 29/100... Training loss: 0.1087\n",
      "Epoch: 29/100... Training loss: 0.1069\n",
      "Epoch: 29/100... Training loss: 0.1050\n",
      "Epoch: 29/100... Training loss: 0.1087\n",
      "Epoch: 29/100... Training loss: 0.1080\n",
      "Epoch: 29/100... Training loss: 0.1072\n",
      "Epoch: 29/100... Training loss: 0.1109\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1061\n",
      "Epoch: 29/100... Training loss: 0.1046\n",
      "Epoch: 29/100... Training loss: 0.1043\n",
      "Epoch: 29/100... Training loss: 0.1087\n",
      "Epoch: 29/100... Training loss: 0.1054\n",
      "Epoch: 29/100... Training loss: 0.1096\n",
      "Epoch: 29/100... Training loss: 0.1065\n",
      "Epoch: 29/100... Training loss: 0.1086\n",
      "Epoch: 29/100... Training loss: 0.1066\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1076\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1087\n",
      "Epoch: 30/100... Training loss: 0.1075\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1110\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1026\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1082\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1096\n",
      "Epoch: 30/100... Training loss: 0.1110\n",
      "Epoch: 30/100... Training loss: 0.1096\n",
      "Epoch: 30/100... Training loss: 0.1013\n",
      "Epoch: 30/100... Training loss: 0.1126\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1094\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1033\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1066\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1109\n",
      "Epoch: 30/100... Training loss: 0.1108\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1087\n",
      "Epoch: 30/100... Training loss: 0.1089\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1078\n",
      "Epoch: 30/100... Training loss: 0.1106\n",
      "Epoch: 30/100... Training loss: 0.1090\n",
      "Epoch: 30/100... Training loss: 0.1088\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1095\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1082\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1110\n",
      "Epoch: 30/100... Training loss: 0.1050\n",
      "Epoch: 30/100... Training loss: 0.1040\n",
      "Epoch: 30/100... Training loss: 0.1095\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1034\n",
      "Epoch: 30/100... Training loss: 0.1082\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1017\n",
      "Epoch: 30/100... Training loss: 0.1089\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1084\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1082\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1078\n",
      "Epoch: 30/100... Training loss: 0.1058\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1076\n",
      "Epoch: 30/100... Training loss: 0.1100\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1095\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1075\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1047\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1085\n",
      "Epoch: 30/100... Training loss: 0.1099\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1095\n",
      "Epoch: 30/100... Training loss: 0.1075\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1092\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1063\n",
      "Epoch: 30/100... Training loss: 0.1079\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1128\n",
      "Epoch: 30/100... Training loss: 0.1095\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1063\n",
      "Epoch: 30/100... Training loss: 0.1140\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1101\n",
      "Epoch: 30/100... Training loss: 0.1029\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1048\n",
      "Epoch: 30/100... Training loss: 0.1072\n",
      "Epoch: 30/100... Training loss: 0.1095\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1084\n",
      "Epoch: 30/100... Training loss: 0.1079\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1038\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1055\n",
      "Epoch: 30/100... Training loss: 0.1092\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1113\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1094\n",
      "Epoch: 30/100... Training loss: 0.1087\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1072\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1094\n",
      "Epoch: 30/100... Training loss: 0.1034\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1121\n",
      "Epoch: 30/100... Training loss: 0.1100\n",
      "Epoch: 30/100... Training loss: 0.1107\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1075\n",
      "Epoch: 30/100... Training loss: 0.1014\n",
      "Epoch: 30/100... Training loss: 0.1063\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1085\n",
      "Epoch: 30/100... Training loss: 0.1066\n",
      "Epoch: 30/100... Training loss: 0.1063\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1072\n",
      "Epoch: 30/100... Training loss: 0.1083\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1108\n",
      "Epoch: 30/100... Training loss: 0.1116\n",
      "Epoch: 30/100... Training loss: 0.1052\n",
      "Epoch: 30/100... Training loss: 0.1091\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1012\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1067\n",
      "Epoch: 30/100... Training loss: 0.1035\n",
      "Epoch: 30/100... Training loss: 0.1016\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1018\n",
      "Epoch: 30/100... Training loss: 0.1122\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1112\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1094\n",
      "Epoch: 30/100... Training loss: 0.1086\n",
      "Epoch: 30/100... Training loss: 0.1090\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1095\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1105\n",
      "Epoch: 30/100... Training loss: 0.1095\n",
      "Epoch: 30/100... Training loss: 0.1103\n",
      "Epoch: 30/100... Training loss: 0.1082\n",
      "Epoch: 30/100... Training loss: 0.1036\n",
      "Epoch: 30/100... Training loss: 0.1075\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1062\n",
      "Epoch: 30/100... Training loss: 0.1084\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1087\n",
      "Epoch: 30/100... Training loss: 0.1042\n",
      "Epoch: 30/100... Training loss: 0.1032\n",
      "Epoch: 30/100... Training loss: 0.1081\n",
      "Epoch: 30/100... Training loss: 0.1027\n",
      "Epoch: 30/100... Training loss: 0.1060\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1054\n",
      "Epoch: 30/100... Training loss: 0.1057\n",
      "Epoch: 30/100... Training loss: 0.1089\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1091\n",
      "Epoch: 30/100... Training loss: 0.1066\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1093\n",
      "Epoch: 30/100... Training loss: 0.1056\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1005\n",
      "Epoch: 30/100... Training loss: 0.1098\n",
      "Epoch: 30/100... Training loss: 0.1049\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1069\n",
      "Epoch: 30/100... Training loss: 0.1098\n",
      "Epoch: 30/100... Training loss: 0.1077\n",
      "Epoch: 30/100... Training loss: 0.1094\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1001\n",
      "Epoch: 30/100... Training loss: 0.1039\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1094\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1107\n",
      "Epoch: 30/100... Training loss: 0.1068\n",
      "Epoch: 30/100... Training loss: 0.1100\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1102\n",
      "Epoch: 30/100... Training loss: 0.1065\n",
      "Epoch: 30/100... Training loss: 0.1074\n",
      "Epoch: 30/100... Training loss: 0.1051\n",
      "Epoch: 30/100... Training loss: 0.1071\n",
      "Epoch: 30/100... Training loss: 0.1066\n",
      "Epoch: 30/100... Training loss: 0.1064\n",
      "Epoch: 30/100... Training loss: 0.1116\n",
      "Epoch: 30/100... Training loss: 0.1046\n",
      "Epoch: 30/100... Training loss: 0.1053\n",
      "Epoch: 30/100... Training loss: 0.1045\n",
      "Epoch: 30/100... Training loss: 0.1063\n",
      "Epoch: 30/100... Training loss: 0.1094\n",
      "Epoch: 30/100... Training loss: 0.1073\n",
      "Epoch: 30/100... Training loss: 0.1080\n",
      "Epoch: 30/100... Training loss: 0.1088\n",
      "Epoch: 30/100... Training loss: 0.1061\n",
      "Epoch: 30/100... Training loss: 0.1070\n",
      "Epoch: 30/100... Training loss: 0.1059\n",
      "Epoch: 30/100... Training loss: 0.1044\n",
      "Epoch: 30/100... Training loss: 0.1075\n",
      "Epoch: 30/100... Training loss: 0.1090\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1070\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1082\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1015\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1100\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1083\n",
      "Epoch: 31/100... Training loss: 0.1093\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1096\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1074\n",
      "Epoch: 31/100... Training loss: 0.1082\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1103\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1099\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1081\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1093\n",
      "Epoch: 31/100... Training loss: 0.1073\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1100\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1075\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1110\n",
      "Epoch: 31/100... Training loss: 0.1101\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1103\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1063\n",
      "Epoch: 31/100... Training loss: 0.1080\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1082\n",
      "Epoch: 31/100... Training loss: 0.1075\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1098\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1088\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1084\n",
      "Epoch: 31/100... Training loss: 0.1094\n",
      "Epoch: 31/100... Training loss: 0.1082\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1097\n",
      "Epoch: 31/100... Training loss: 0.1067\n",
      "Epoch: 31/100... Training loss: 0.1087\n",
      "Epoch: 31/100... Training loss: 0.1088\n",
      "Epoch: 31/100... Training loss: 0.1101\n",
      "Epoch: 31/100... Training loss: 0.1083\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1098\n",
      "Epoch: 31/100... Training loss: 0.1091\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1099\n",
      "Epoch: 31/100... Training loss: 0.1080\n",
      "Epoch: 31/100... Training loss: 0.1074\n",
      "Epoch: 31/100... Training loss: 0.1082\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1032\n",
      "Epoch: 31/100... Training loss: 0.1081\n",
      "Epoch: 31/100... Training loss: 0.1116\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1071\n",
      "Epoch: 31/100... Training loss: 0.1110\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1074\n",
      "Epoch: 31/100... Training loss: 0.1087\n",
      "Epoch: 31/100... Training loss: 0.1103\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1086\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1073\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1082\n",
      "Epoch: 31/100... Training loss: 0.1090\n",
      "Epoch: 31/100... Training loss: 0.1073\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1085\n",
      "Epoch: 31/100... Training loss: 0.1087\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1081\n",
      "Epoch: 31/100... Training loss: 0.1093\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1071\n",
      "Epoch: 31/100... Training loss: 0.1029\n",
      "Epoch: 31/100... Training loss: 0.1087\n",
      "Epoch: 31/100... Training loss: 0.1099\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1081\n",
      "Epoch: 31/100... Training loss: 0.1084\n",
      "Epoch: 31/100... Training loss: 0.1075\n",
      "Epoch: 31/100... Training loss: 0.1096\n",
      "Epoch: 31/100... Training loss: 0.1025\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1057\n",
      "Epoch: 31/100... Training loss: 0.1041\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1119\n",
      "Epoch: 31/100... Training loss: 0.1027\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1073\n",
      "Epoch: 31/100... Training loss: 0.1073\n",
      "Epoch: 31/100... Training loss: 0.1056\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1125\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1114\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1081\n",
      "Epoch: 31/100... Training loss: 0.1101\n",
      "Epoch: 31/100... Training loss: 0.1079\n",
      "Epoch: 31/100... Training loss: 0.1095\n",
      "Epoch: 31/100... Training loss: 0.1067\n",
      "Epoch: 31/100... Training loss: 0.1079\n",
      "Epoch: 31/100... Training loss: 0.1071\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1094\n",
      "Epoch: 31/100... Training loss: 0.1104\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1079\n",
      "Epoch: 31/100... Training loss: 0.1094\n",
      "Epoch: 31/100... Training loss: 0.1042\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1067\n",
      "Epoch: 31/100... Training loss: 0.1089\n",
      "Epoch: 31/100... Training loss: 0.1094\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1090\n",
      "Epoch: 31/100... Training loss: 0.1053\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1086\n",
      "Epoch: 31/100... Training loss: 0.1092\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1074\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1083\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1092\n",
      "Epoch: 31/100... Training loss: 0.1043\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1103\n",
      "Epoch: 31/100... Training loss: 0.1101\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1046\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1084\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1073\n",
      "Epoch: 31/100... Training loss: 0.1091\n",
      "Epoch: 31/100... Training loss: 0.1031\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1020\n",
      "Epoch: 31/100... Training loss: 0.1083\n",
      "Epoch: 31/100... Training loss: 0.1087\n",
      "Epoch: 31/100... Training loss: 0.1030\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1090\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1054\n",
      "Epoch: 31/100... Training loss: 0.1090\n",
      "Epoch: 31/100... Training loss: 0.1084\n",
      "Epoch: 31/100... Training loss: 0.1075\n",
      "Epoch: 31/100... Training loss: 0.1038\n",
      "Epoch: 31/100... Training loss: 0.1075\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1082\n",
      "Epoch: 31/100... Training loss: 0.1084\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1059\n",
      "Epoch: 31/100... Training loss: 0.1098\n",
      "Epoch: 31/100... Training loss: 0.1068\n",
      "Epoch: 31/100... Training loss: 0.1089\n",
      "Epoch: 31/100... Training loss: 0.1033\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1086\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1071\n",
      "Epoch: 31/100... Training loss: 0.1097\n",
      "Epoch: 31/100... Training loss: 0.1055\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1021\n",
      "Epoch: 31/100... Training loss: 0.1087\n",
      "Epoch: 31/100... Training loss: 0.1080\n",
      "Epoch: 31/100... Training loss: 0.1069\n",
      "Epoch: 31/100... Training loss: 0.1113\n",
      "Epoch: 31/100... Training loss: 0.1040\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1061\n",
      "Epoch: 31/100... Training loss: 0.1049\n",
      "Epoch: 31/100... Training loss: 0.1047\n",
      "Epoch: 31/100... Training loss: 0.1079\n",
      "Epoch: 31/100... Training loss: 0.1072\n",
      "Epoch: 31/100... Training loss: 0.1071\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1076\n",
      "Epoch: 31/100... Training loss: 0.1048\n",
      "Epoch: 31/100... Training loss: 0.1102\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1066\n",
      "Epoch: 31/100... Training loss: 0.1094\n",
      "Epoch: 31/100... Training loss: 0.1079\n",
      "Epoch: 31/100... Training loss: 0.1077\n",
      "Epoch: 31/100... Training loss: 0.1064\n",
      "Epoch: 31/100... Training loss: 0.1036\n",
      "Epoch: 31/100... Training loss: 0.1073\n",
      "Epoch: 31/100... Training loss: 0.1028\n",
      "Epoch: 31/100... Training loss: 0.1052\n",
      "Epoch: 31/100... Training loss: 0.1058\n",
      "Epoch: 31/100... Training loss: 0.1082\n",
      "Epoch: 31/100... Training loss: 0.1087\n",
      "Epoch: 31/100... Training loss: 0.1096\n",
      "Epoch: 31/100... Training loss: 0.1078\n",
      "Epoch: 31/100... Training loss: 0.1051\n",
      "Epoch: 31/100... Training loss: 0.1085\n",
      "Epoch: 31/100... Training loss: 0.1050\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 31/100... Training loss: 0.1067\n",
      "Epoch: 31/100... Training loss: 0.1062\n",
      "Epoch: 31/100... Training loss: 0.1089\n",
      "Epoch: 31/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1074\n",
      "Epoch: 32/100... Training loss: 0.1073\n",
      "Epoch: 32/100... Training loss: 0.1095\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1036\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1058\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1084\n",
      "Epoch: 32/100... Training loss: 0.1039\n",
      "Epoch: 32/100... Training loss: 0.1080\n",
      "Epoch: 32/100... Training loss: 0.1040\n",
      "Epoch: 32/100... Training loss: 0.1081\n",
      "Epoch: 32/100... Training loss: 0.1078\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1094\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1080\n",
      "Epoch: 32/100... Training loss: 0.1067\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1029\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1093\n",
      "Epoch: 32/100... Training loss: 0.1088\n",
      "Epoch: 32/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1098\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1087\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1035\n",
      "Epoch: 32/100... Training loss: 0.1088\n",
      "Epoch: 32/100... Training loss: 0.1086\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1084\n",
      "Epoch: 32/100... Training loss: 0.1093\n",
      "Epoch: 32/100... Training loss: 0.1096\n",
      "Epoch: 32/100... Training loss: 0.1016\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1020\n",
      "Epoch: 32/100... Training loss: 0.1084\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1082\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1093\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1116\n",
      "Epoch: 32/100... Training loss: 0.1093\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1066\n",
      "Epoch: 32/100... Training loss: 0.1091\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1085\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1090\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1082\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1083\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1073\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1037\n",
      "Epoch: 32/100... Training loss: 0.1067\n",
      "Epoch: 32/100... Training loss: 0.1042\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1069\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1094\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1122\n",
      "Epoch: 32/100... Training loss: 0.1088\n",
      "Epoch: 32/100... Training loss: 0.1078\n",
      "Epoch: 32/100... Training loss: 0.1089\n",
      "Epoch: 32/100... Training loss: 0.1084\n",
      "Epoch: 32/100... Training loss: 0.1115\n",
      "Epoch: 32/100... Training loss: 0.1096\n",
      "Epoch: 32/100... Training loss: 0.1095\n",
      "Epoch: 32/100... Training loss: 0.1067\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1086\n",
      "Epoch: 32/100... Training loss: 0.1066\n",
      "Epoch: 32/100... Training loss: 0.1099\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1091\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1075\n",
      "Epoch: 32/100... Training loss: 0.1073\n",
      "Epoch: 32/100... Training loss: 0.1101\n",
      "Epoch: 32/100... Training loss: 0.1058\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1075\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1091\n",
      "Epoch: 32/100... Training loss: 0.1081\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1066\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1085\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1087\n",
      "Epoch: 32/100... Training loss: 0.1102\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1053\n",
      "Epoch: 32/100... Training loss: 0.1086\n",
      "Epoch: 32/100... Training loss: 0.1069\n",
      "Epoch: 32/100... Training loss: 0.1106\n",
      "Epoch: 32/100... Training loss: 0.1084\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1084\n",
      "Epoch: 32/100... Training loss: 0.1114\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1085\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1098\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1076\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1046\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1092\n",
      "Epoch: 32/100... Training loss: 0.1113\n",
      "Epoch: 32/100... Training loss: 0.1080\n",
      "Epoch: 32/100... Training loss: 0.1085\n",
      "Epoch: 32/100... Training loss: 0.1078\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1090\n",
      "Epoch: 32/100... Training loss: 0.1088\n",
      "Epoch: 32/100... Training loss: 0.1087\n",
      "Epoch: 32/100... Training loss: 0.1080\n",
      "Epoch: 32/100... Training loss: 0.1106\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1048\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1054\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1097\n",
      "Epoch: 32/100... Training loss: 0.1053\n",
      "Epoch: 32/100... Training loss: 0.1024\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1047\n",
      "Epoch: 32/100... Training loss: 0.1087\n",
      "Epoch: 32/100... Training loss: 0.1074\n",
      "Epoch: 32/100... Training loss: 0.1076\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1027\n",
      "Epoch: 32/100... Training loss: 0.1062\n",
      "Epoch: 32/100... Training loss: 0.1028\n",
      "Epoch: 32/100... Training loss: 0.1067\n",
      "Epoch: 32/100... Training loss: 0.1080\n",
      "Epoch: 32/100... Training loss: 0.1068\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1105\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1017\n",
      "Epoch: 32/100... Training loss: 0.1078\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1067\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1074\n",
      "Epoch: 32/100... Training loss: 0.1015\n",
      "Epoch: 32/100... Training loss: 0.1038\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1059\n",
      "Epoch: 32/100... Training loss: 0.1092\n",
      "Epoch: 32/100... Training loss: 0.1067\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1044\n",
      "Epoch: 32/100... Training loss: 0.1093\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1034\n",
      "Epoch: 32/100... Training loss: 0.1064\n",
      "Epoch: 32/100... Training loss: 0.1032\n",
      "Epoch: 32/100... Training loss: 0.1050\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1065\n",
      "Epoch: 32/100... Training loss: 0.1085\n",
      "Epoch: 32/100... Training loss: 0.1073\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1051\n",
      "Epoch: 32/100... Training loss: 0.1049\n",
      "Epoch: 32/100... Training loss: 0.1099\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1033\n",
      "Epoch: 32/100... Training loss: 0.1074\n",
      "Epoch: 32/100... Training loss: 0.1111\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1074\n",
      "Epoch: 32/100... Training loss: 0.1063\n",
      "Epoch: 32/100... Training loss: 0.1089\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1082\n",
      "Epoch: 32/100... Training loss: 0.1071\n",
      "Epoch: 32/100... Training loss: 0.1090\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1031\n",
      "Epoch: 32/100... Training loss: 0.1073\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1098\n",
      "Epoch: 32/100... Training loss: 0.1080\n",
      "Epoch: 32/100... Training loss: 0.1055\n",
      "Epoch: 32/100... Training loss: 0.1058\n",
      "Epoch: 32/100... Training loss: 0.1070\n",
      "Epoch: 32/100... Training loss: 0.1060\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1093\n",
      "Epoch: 32/100... Training loss: 0.1056\n",
      "Epoch: 32/100... Training loss: 0.1086\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1073\n",
      "Epoch: 32/100... Training loss: 0.1081\n",
      "Epoch: 32/100... Training loss: 0.1090\n",
      "Epoch: 32/100... Training loss: 0.1076\n",
      "Epoch: 32/100... Training loss: 0.1045\n",
      "Epoch: 32/100... Training loss: 0.1077\n",
      "Epoch: 32/100... Training loss: 0.1057\n",
      "Epoch: 32/100... Training loss: 0.1091\n",
      "Epoch: 32/100... Training loss: 0.1043\n",
      "Epoch: 32/100... Training loss: 0.1109\n",
      "Epoch: 32/100... Training loss: 0.1052\n",
      "Epoch: 32/100... Training loss: 0.1079\n",
      "Epoch: 32/100... Training loss: 0.1073\n",
      "Epoch: 32/100... Training loss: 0.1093\n",
      "Epoch: 32/100... Training loss: 0.1090\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1089\n",
      "Epoch: 32/100... Training loss: 0.1083\n",
      "Epoch: 32/100... Training loss: 0.1058\n",
      "Epoch: 32/100... Training loss: 0.1080\n",
      "Epoch: 32/100... Training loss: 0.1076\n",
      "Epoch: 32/100... Training loss: 0.1081\n",
      "Epoch: 32/100... Training loss: 0.1021\n",
      "Epoch: 32/100... Training loss: 0.1069\n",
      "Epoch: 32/100... Training loss: 0.1086\n",
      "Epoch: 32/100... Training loss: 0.1072\n",
      "Epoch: 32/100... Training loss: 0.1092\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 32/100... Training loss: 0.1117\n",
      "Epoch: 32/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1100\n",
      "Epoch: 33/100... Training loss: 0.1057\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1086\n",
      "Epoch: 33/100... Training loss: 0.1075\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1108\n",
      "Epoch: 33/100... Training loss: 0.1083\n",
      "Epoch: 33/100... Training loss: 0.1123\n",
      "Epoch: 33/100... Training loss: 0.1066\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1075\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1020\n",
      "Epoch: 33/100... Training loss: 0.1073\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1024\n",
      "Epoch: 33/100... Training loss: 0.1084\n",
      "Epoch: 33/100... Training loss: 0.1069\n",
      "Epoch: 33/100... Training loss: 0.1076\n",
      "Epoch: 33/100... Training loss: 0.1069\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1094\n",
      "Epoch: 33/100... Training loss: 0.1077\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1033\n",
      "Epoch: 33/100... Training loss: 0.1088\n",
      "Epoch: 33/100... Training loss: 0.1118\n",
      "Epoch: 33/100... Training loss: 0.1075\n",
      "Epoch: 33/100... Training loss: 0.1110\n",
      "Epoch: 33/100... Training loss: 0.1094\n",
      "Epoch: 33/100... Training loss: 0.1093\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1069\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1069\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1087\n",
      "Epoch: 33/100... Training loss: 0.1087\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1076\n",
      "Epoch: 33/100... Training loss: 0.1088\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1118\n",
      "Epoch: 33/100... Training loss: 0.1081\n",
      "Epoch: 33/100... Training loss: 0.1068\n",
      "Epoch: 33/100... Training loss: 0.1092\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1081\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1056\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1077\n",
      "Epoch: 33/100... Training loss: 0.1102\n",
      "Epoch: 33/100... Training loss: 0.1082\n",
      "Epoch: 33/100... Training loss: 0.1076\n",
      "Epoch: 33/100... Training loss: 0.1066\n",
      "Epoch: 33/100... Training loss: 0.1087\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1076\n",
      "Epoch: 33/100... Training loss: 0.1087\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1071\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1085\n",
      "Epoch: 33/100... Training loss: 0.1076\n",
      "Epoch: 33/100... Training loss: 0.1066\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1083\n",
      "Epoch: 33/100... Training loss: 0.1079\n",
      "Epoch: 33/100... Training loss: 0.1110\n",
      "Epoch: 33/100... Training loss: 0.1083\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1112\n",
      "Epoch: 33/100... Training loss: 0.1088\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1090\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1118\n",
      "Epoch: 33/100... Training loss: 0.1052\n",
      "Epoch: 33/100... Training loss: 0.1092\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1075\n",
      "Epoch: 33/100... Training loss: 0.1085\n",
      "Epoch: 33/100... Training loss: 0.1075\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1084\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1069\n",
      "Epoch: 33/100... Training loss: 0.1068\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1085\n",
      "Epoch: 33/100... Training loss: 0.1078\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1038\n",
      "Epoch: 33/100... Training loss: 0.1057\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1056\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1085\n",
      "Epoch: 33/100... Training loss: 0.1094\n",
      "Epoch: 33/100... Training loss: 0.1076\n",
      "Epoch: 33/100... Training loss: 0.1015\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1090\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1071\n",
      "Epoch: 33/100... Training loss: 0.1094\n",
      "Epoch: 33/100... Training loss: 0.1003\n",
      "Epoch: 33/100... Training loss: 0.1088\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1075\n",
      "Epoch: 33/100... Training loss: 0.1090\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1077\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1082\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1068\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1057\n",
      "Epoch: 33/100... Training loss: 0.1083\n",
      "Epoch: 33/100... Training loss: 0.1035\n",
      "Epoch: 33/100... Training loss: 0.1071\n",
      "Epoch: 33/100... Training loss: 0.1086\n",
      "Epoch: 33/100... Training loss: 0.1086\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1069\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1075\n",
      "Epoch: 33/100... Training loss: 0.1076\n",
      "Epoch: 33/100... Training loss: 0.1041\n",
      "Epoch: 33/100... Training loss: 0.1091\n",
      "Epoch: 33/100... Training loss: 0.1078\n",
      "Epoch: 33/100... Training loss: 0.1056\n",
      "Epoch: 33/100... Training loss: 0.1045\n",
      "Epoch: 33/100... Training loss: 0.1096\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1081\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1072\n",
      "Epoch: 33/100... Training loss: 0.1073\n",
      "Epoch: 33/100... Training loss: 0.1014\n",
      "Epoch: 33/100... Training loss: 0.1053\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1082\n",
      "Epoch: 33/100... Training loss: 0.1031\n",
      "Epoch: 33/100... Training loss: 0.1075\n",
      "Epoch: 33/100... Training loss: 0.1082\n",
      "Epoch: 33/100... Training loss: 0.1092\n",
      "Epoch: 33/100... Training loss: 0.1011\n",
      "Epoch: 33/100... Training loss: 0.1046\n",
      "Epoch: 33/100... Training loss: 0.1093\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1076\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1056\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1059\n",
      "Epoch: 33/100... Training loss: 0.1049\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1073\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1037\n",
      "Epoch: 33/100... Training loss: 0.1107\n",
      "Epoch: 33/100... Training loss: 0.1086\n",
      "Epoch: 33/100... Training loss: 0.1050\n",
      "Epoch: 33/100... Training loss: 0.1078\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1043\n",
      "Epoch: 33/100... Training loss: 0.1087\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 33/100... Training loss: 0.1080\n",
      "Epoch: 33/100... Training loss: 0.1071\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1058\n",
      "Epoch: 33/100... Training loss: 0.1025\n",
      "Epoch: 33/100... Training loss: 0.1003\n",
      "Epoch: 33/100... Training loss: 0.1029\n",
      "Epoch: 33/100... Training loss: 0.1096\n",
      "Epoch: 33/100... Training loss: 0.1101\n",
      "Epoch: 33/100... Training loss: 0.1092\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1069\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1065\n",
      "Epoch: 33/100... Training loss: 0.1048\n",
      "Epoch: 33/100... Training loss: 0.1081\n",
      "Epoch: 33/100... Training loss: 0.1039\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1021\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1063\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1089\n",
      "Epoch: 33/100... Training loss: 0.1078\n",
      "Epoch: 33/100... Training loss: 0.1064\n",
      "Epoch: 33/100... Training loss: 0.1092\n",
      "Epoch: 33/100... Training loss: 0.1100\n",
      "Epoch: 33/100... Training loss: 0.1044\n",
      "Epoch: 33/100... Training loss: 0.1054\n",
      "Epoch: 33/100... Training loss: 0.1075\n",
      "Epoch: 33/100... Training loss: 0.1060\n",
      "Epoch: 33/100... Training loss: 0.1034\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1087\n",
      "Epoch: 33/100... Training loss: 0.1078\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1055\n",
      "Epoch: 33/100... Training loss: 0.1040\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1061\n",
      "Epoch: 33/100... Training loss: 0.1042\n",
      "Epoch: 33/100... Training loss: 0.1051\n",
      "Epoch: 33/100... Training loss: 0.1047\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 33/100... Training loss: 0.1070\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1016\n",
      "Epoch: 33/100... Training loss: 0.1062\n",
      "Epoch: 33/100... Training loss: 0.1074\n",
      "Epoch: 33/100... Training loss: 0.1057\n",
      "Epoch: 33/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1098\n",
      "Epoch: 34/100... Training loss: 0.1074\n",
      "Epoch: 34/100... Training loss: 0.1071\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1114\n",
      "Epoch: 34/100... Training loss: 0.1108\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1093\n",
      "Epoch: 34/100... Training loss: 0.1062\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1070\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1075\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1103\n",
      "Epoch: 34/100... Training loss: 0.1032\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1064\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1078\n",
      "Epoch: 34/100... Training loss: 0.1075\n",
      "Epoch: 34/100... Training loss: 0.1083\n",
      "Epoch: 34/100... Training loss: 0.1074\n",
      "Epoch: 34/100... Training loss: 0.1078\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1070\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1075\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1053\n",
      "Epoch: 34/100... Training loss: 0.1075\n",
      "Epoch: 34/100... Training loss: 0.1078\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1010\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1064\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1090\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1062\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1077\n",
      "Epoch: 34/100... Training loss: 0.1090\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1087\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1086\n",
      "Epoch: 34/100... Training loss: 0.1072\n",
      "Epoch: 34/100... Training loss: 0.1077\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1071\n",
      "Epoch: 34/100... Training loss: 0.1084\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1064\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1072\n",
      "Epoch: 34/100... Training loss: 0.1091\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1081\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1064\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1077\n",
      "Epoch: 34/100... Training loss: 0.1074\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1086\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1073\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1130\n",
      "Epoch: 34/100... Training loss: 0.1072\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1062\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1069\n",
      "Epoch: 34/100... Training loss: 0.1025\n",
      "Epoch: 34/100... Training loss: 0.1078\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1064\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1114\n",
      "Epoch: 34/100... Training loss: 0.1094\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1073\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1083\n",
      "Epoch: 34/100... Training loss: 0.1064\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1073\n",
      "Epoch: 34/100... Training loss: 0.1086\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1044\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1089\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1048\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1042\n",
      "Epoch: 34/100... Training loss: 0.1101\n",
      "Epoch: 34/100... Training loss: 0.1043\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1108\n",
      "Epoch: 34/100... Training loss: 0.1078\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1077\n",
      "Epoch: 34/100... Training loss: 0.1078\n",
      "Epoch: 34/100... Training loss: 0.1075\n",
      "Epoch: 34/100... Training loss: 0.1081\n",
      "Epoch: 34/100... Training loss: 0.1072\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1079\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1064\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1089\n",
      "Epoch: 34/100... Training loss: 0.1023\n",
      "Epoch: 34/100... Training loss: 0.1070\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1078\n",
      "Epoch: 34/100... Training loss: 0.1026\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1095\n",
      "Epoch: 34/100... Training loss: 0.1072\n",
      "Epoch: 34/100... Training loss: 0.1103\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1006\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1085\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1092\n",
      "Epoch: 34/100... Training loss: 0.1081\n",
      "Epoch: 34/100... Training loss: 0.1018\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1077\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1081\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1021\n",
      "Epoch: 34/100... Training loss: 0.1086\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1080\n",
      "Epoch: 34/100... Training loss: 0.1063\n",
      "Epoch: 34/100... Training loss: 0.1073\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1096\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1080\n",
      "Epoch: 34/100... Training loss: 0.1077\n",
      "Epoch: 34/100... Training loss: 0.1058\n",
      "Epoch: 34/100... Training loss: 0.1100\n",
      "Epoch: 34/100... Training loss: 0.1072\n",
      "Epoch: 34/100... Training loss: 0.1062\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1071\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1082\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1075\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1073\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1072\n",
      "Epoch: 34/100... Training loss: 0.1100\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1078\n",
      "Epoch: 34/100... Training loss: 0.1040\n",
      "Epoch: 34/100... Training loss: 0.1038\n",
      "Epoch: 34/100... Training loss: 0.1039\n",
      "Epoch: 34/100... Training loss: 0.1074\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.1079\n",
      "Epoch: 34/100... Training loss: 0.1082\n",
      "Epoch: 34/100... Training loss: 0.1055\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1089\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1068\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1074\n",
      "Epoch: 34/100... Training loss: 0.1081\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1077\n",
      "Epoch: 34/100... Training loss: 0.1065\n",
      "Epoch: 34/100... Training loss: 0.1036\n",
      "Epoch: 34/100... Training loss: 0.1051\n",
      "Epoch: 34/100... Training loss: 0.1031\n",
      "Epoch: 34/100... Training loss: 0.1024\n",
      "Epoch: 34/100... Training loss: 0.1069\n",
      "Epoch: 34/100... Training loss: 0.1073\n",
      "Epoch: 34/100... Training loss: 0.1027\n",
      "Epoch: 34/100... Training loss: 0.1035\n",
      "Epoch: 34/100... Training loss: 0.1060\n",
      "Epoch: 34/100... Training loss: 0.1030\n",
      "Epoch: 34/100... Training loss: 0.1084\n",
      "Epoch: 34/100... Training loss: 0.1046\n",
      "Epoch: 34/100... Training loss: 0.1041\n",
      "Epoch: 34/100... Training loss: 0.1047\n",
      "Epoch: 34/100... Training loss: 0.1079\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1019\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1017\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1084\n",
      "Epoch: 34/100... Training loss: 0.1052\n",
      "Epoch: 34/100... Training loss: 0.1066\n",
      "Epoch: 34/100... Training loss: 0.1020\n",
      "Epoch: 34/100... Training loss: 0.1079\n",
      "Epoch: 34/100... Training loss: 0.1029\n",
      "Epoch: 34/100... Training loss: 0.1033\n",
      "Epoch: 34/100... Training loss: 0.1094\n",
      "Epoch: 34/100... Training loss: 0.1069\n",
      "Epoch: 34/100... Training loss: 0.1057\n",
      "Epoch: 34/100... Training loss: 0.1065\n",
      "Epoch: 34/100... Training loss: 0.1050\n",
      "Epoch: 34/100... Training loss: 0.1056\n",
      "Epoch: 34/100... Training loss: 0.1061\n",
      "Epoch: 34/100... Training loss: 0.1076\n",
      "Epoch: 34/100... Training loss: 0.1037\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1045\n",
      "Epoch: 34/100... Training loss: 0.1054\n",
      "Epoch: 34/100... Training loss: 0.1059\n",
      "Epoch: 34/100... Training loss: 0.1049\n",
      "Epoch: 34/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1079\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1074\n",
      "Epoch: 35/100... Training loss: 0.1072\n",
      "Epoch: 35/100... Training loss: 0.1085\n",
      "Epoch: 35/100... Training loss: 0.1086\n",
      "Epoch: 35/100... Training loss: 0.1047\n",
      "Epoch: 35/100... Training loss: 0.1080\n",
      "Epoch: 35/100... Training loss: 0.1063\n",
      "Epoch: 35/100... Training loss: 0.1069\n",
      "Epoch: 35/100... Training loss: 0.1069\n",
      "Epoch: 35/100... Training loss: 0.1075\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1080\n",
      "Epoch: 35/100... Training loss: 0.1100\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1105\n",
      "Epoch: 35/100... Training loss: 0.1116\n",
      "Epoch: 35/100... Training loss: 0.1047\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1063\n",
      "Epoch: 35/100... Training loss: 0.1112\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1094\n",
      "Epoch: 35/100... Training loss: 0.1073\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1070\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1095\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1080\n",
      "Epoch: 35/100... Training loss: 0.1076\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1076\n",
      "Epoch: 35/100... Training loss: 0.1078\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1080\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1047\n",
      "Epoch: 35/100... Training loss: 0.1088\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1088\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1070\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1082\n",
      "Epoch: 35/100... Training loss: 0.1081\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1092\n",
      "Epoch: 35/100... Training loss: 0.1033\n",
      "Epoch: 35/100... Training loss: 0.1024\n",
      "Epoch: 35/100... Training loss: 0.1075\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1032\n",
      "Epoch: 35/100... Training loss: 0.1082\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1083\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1057\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1095\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1074\n",
      "Epoch: 35/100... Training loss: 0.1090\n",
      "Epoch: 35/100... Training loss: 0.1010\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1082\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1082\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1091\n",
      "Epoch: 35/100... Training loss: 0.1102\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1064\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1083\n",
      "Epoch: 35/100... Training loss: 0.1077\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 35/100... Training loss: 0.1021\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1078\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1079\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1093\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1063\n",
      "Epoch: 35/100... Training loss: 0.1112\n",
      "Epoch: 35/100... Training loss: 0.1039\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1092\n",
      "Epoch: 35/100... Training loss: 0.1064\n",
      "Epoch: 35/100... Training loss: 0.1083\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1075\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1063\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1080\n",
      "Epoch: 35/100... Training loss: 0.1087\n",
      "Epoch: 35/100... Training loss: 0.1031\n",
      "Epoch: 35/100... Training loss: 0.1087\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1097\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1086\n",
      "Epoch: 35/100... Training loss: 0.1046\n",
      "Epoch: 35/100... Training loss: 0.1082\n",
      "Epoch: 35/100... Training loss: 0.1081\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1073\n",
      "Epoch: 35/100... Training loss: 0.1036\n",
      "Epoch: 35/100... Training loss: 0.1056\n",
      "Epoch: 35/100... Training loss: 0.1096\n",
      "Epoch: 35/100... Training loss: 0.1055\n",
      "Epoch: 35/100... Training loss: 0.1076\n",
      "Epoch: 35/100... Training loss: 0.1008\n",
      "Epoch: 35/100... Training loss: 0.1091\n",
      "Epoch: 35/100... Training loss: 0.1085\n",
      "Epoch: 35/100... Training loss: 0.1064\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1072\n",
      "Epoch: 35/100... Training loss: 0.1088\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1040\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1064\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1092\n",
      "Epoch: 35/100... Training loss: 0.1063\n",
      "Epoch: 35/100... Training loss: 0.1082\n",
      "Epoch: 35/100... Training loss: 0.1076\n",
      "Epoch: 35/100... Training loss: 0.1098\n",
      "Epoch: 35/100... Training loss: 0.1062\n",
      "Epoch: 35/100... Training loss: 0.1047\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1060\n",
      "Epoch: 35/100... Training loss: 0.1086\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1109\n",
      "Epoch: 35/100... Training loss: 0.1080\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1050\n",
      "Epoch: 35/100... Training loss: 0.1015\n",
      "Epoch: 35/100... Training loss: 0.1080\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1053\n",
      "Epoch: 35/100... Training loss: 0.1054\n",
      "Epoch: 35/100... Training loss: 0.1083\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1045\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1069\n",
      "Epoch: 35/100... Training loss: 0.1070\n",
      "Epoch: 35/100... Training loss: 0.1017\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1099\n",
      "Epoch: 35/100... Training loss: 0.1084\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1063\n",
      "Epoch: 35/100... Training loss: 0.1095\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1025\n",
      "Epoch: 35/100... Training loss: 0.1075\n",
      "Epoch: 35/100... Training loss: 0.1023\n",
      "Epoch: 35/100... Training loss: 0.1037\n",
      "Epoch: 35/100... Training loss: 0.1076\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1035\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1071\n",
      "Epoch: 35/100... Training loss: 0.1028\n",
      "Epoch: 35/100... Training loss: 0.1078\n",
      "Epoch: 35/100... Training loss: 0.1075\n",
      "Epoch: 35/100... Training loss: 0.1085\n",
      "Epoch: 35/100... Training loss: 0.1061\n",
      "Epoch: 35/100... Training loss: 0.1093\n",
      "Epoch: 35/100... Training loss: 0.1074\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1072\n",
      "Epoch: 35/100... Training loss: 0.1051\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1058\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1082\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1067\n",
      "Epoch: 35/100... Training loss: 0.1041\n",
      "Epoch: 35/100... Training loss: 0.1068\n",
      "Epoch: 35/100... Training loss: 0.1048\n",
      "Epoch: 35/100... Training loss: 0.1038\n",
      "Epoch: 35/100... Training loss: 0.1083\n",
      "Epoch: 35/100... Training loss: 0.1075\n",
      "Epoch: 35/100... Training loss: 0.1057\n",
      "Epoch: 35/100... Training loss: 0.1078\n",
      "Epoch: 35/100... Training loss: 0.1072\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1091\n",
      "Epoch: 35/100... Training loss: 0.1063\n",
      "Epoch: 35/100... Training loss: 0.1082\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1027\n",
      "Epoch: 35/100... Training loss: 0.1052\n",
      "Epoch: 35/100... Training loss: 0.1066\n",
      "Epoch: 35/100... Training loss: 0.1049\n",
      "Epoch: 35/100... Training loss: 0.1059\n",
      "Epoch: 35/100... Training loss: 0.1042\n",
      "Epoch: 35/100... Training loss: 0.1043\n",
      "Epoch: 35/100... Training loss: 0.1081\n",
      "Epoch: 35/100... Training loss: 0.1076\n",
      "Epoch: 35/100... Training loss: 0.1095\n",
      "Epoch: 35/100... Training loss: 0.1064\n",
      "Epoch: 35/100... Training loss: 0.1065\n",
      "Epoch: 35/100... Training loss: 0.1034\n",
      "Epoch: 35/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1063\n",
      "Epoch: 36/100... Training loss: 0.1057\n",
      "Epoch: 36/100... Training loss: 0.1060\n",
      "Epoch: 36/100... Training loss: 0.1066\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1062\n",
      "Epoch: 36/100... Training loss: 0.1092\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1090\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1086\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1080\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1079\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1079\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1078\n",
      "Epoch: 36/100... Training loss: 0.1074\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1074\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1093\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1081\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1083\n",
      "Epoch: 36/100... Training loss: 0.1054\n",
      "Epoch: 36/100... Training loss: 0.1073\n",
      "Epoch: 36/100... Training loss: 0.1066\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1076\n",
      "Epoch: 36/100... Training loss: 0.1075\n",
      "Epoch: 36/100... Training loss: 0.1080\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1074\n",
      "Epoch: 36/100... Training loss: 0.1041\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1068\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1054\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1114\n",
      "Epoch: 36/100... Training loss: 0.1084\n",
      "Epoch: 36/100... Training loss: 0.1091\n",
      "Epoch: 36/100... Training loss: 0.1078\n",
      "Epoch: 36/100... Training loss: 0.1082\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1080\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1085\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1079\n",
      "Epoch: 36/100... Training loss: 0.1065\n",
      "Epoch: 36/100... Training loss: 0.1085\n",
      "Epoch: 36/100... Training loss: 0.1087\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1082\n",
      "Epoch: 36/100... Training loss: 0.1092\n",
      "Epoch: 36/100... Training loss: 0.1071\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1097\n",
      "Epoch: 36/100... Training loss: 0.1116\n",
      "Epoch: 36/100... Training loss: 0.1063\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1106\n",
      "Epoch: 36/100... Training loss: 0.1014\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1067\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1079\n",
      "Epoch: 36/100... Training loss: 0.1008\n",
      "Epoch: 36/100... Training loss: 0.1073\n",
      "Epoch: 36/100... Training loss: 0.1000\n",
      "Epoch: 36/100... Training loss: 0.1066\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1084\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1088\n",
      "Epoch: 36/100... Training loss: 0.1080\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1078\n",
      "Epoch: 36/100... Training loss: 0.1077\n",
      "Epoch: 36/100... Training loss: 0.1073\n",
      "Epoch: 36/100... Training loss: 0.1062\n",
      "Epoch: 36/100... Training loss: 0.1108\n",
      "Epoch: 36/100... Training loss: 0.1093\n",
      "Epoch: 36/100... Training loss: 0.1080\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1018\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1066\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1054\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1057\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1070\n",
      "Epoch: 36/100... Training loss: 0.1070\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1076\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1013\n",
      "Epoch: 36/100... Training loss: 0.1082\n",
      "Epoch: 36/100... Training loss: 0.1071\n",
      "Epoch: 36/100... Training loss: 0.1098\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1084\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1102\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1079\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1024\n",
      "Epoch: 36/100... Training loss: 0.1068\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1103\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1019\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1065\n",
      "Epoch: 36/100... Training loss: 0.1054\n",
      "Epoch: 36/100... Training loss: 0.1033\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1074\n",
      "Epoch: 36/100... Training loss: 0.1077\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1027\n",
      "Epoch: 36/100... Training loss: 0.1103\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1058\n",
      "Epoch: 36/100... Training loss: 0.1079\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1081\n",
      "Epoch: 36/100... Training loss: 0.1078\n",
      "Epoch: 36/100... Training loss: 0.1029\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1060\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1037\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1054\n",
      "Epoch: 36/100... Training loss: 0.1105\n",
      "Epoch: 36/100... Training loss: 0.1054\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1043\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1066\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1071\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1061\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1090\n",
      "Epoch: 36/100... Training loss: 0.1080\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1063\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1022\n",
      "Epoch: 36/100... Training loss: 0.1067\n",
      "Epoch: 36/100... Training loss: 0.0996\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1092\n",
      "Epoch: 36/100... Training loss: 0.1060\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1089\n",
      "Epoch: 36/100... Training loss: 0.1093\n",
      "Epoch: 36/100... Training loss: 0.1039\n",
      "Epoch: 36/100... Training loss: 0.1089\n",
      "Epoch: 36/100... Training loss: 0.1086\n",
      "Epoch: 36/100... Training loss: 0.1060\n",
      "Epoch: 36/100... Training loss: 0.1069\n",
      "Epoch: 36/100... Training loss: 0.1040\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1034\n",
      "Epoch: 36/100... Training loss: 0.1062\n",
      "Epoch: 36/100... Training loss: 0.1052\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1036\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1062\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1000\n",
      "Epoch: 36/100... Training loss: 0.1074\n",
      "Epoch: 36/100... Training loss: 0.1070\n",
      "Epoch: 36/100... Training loss: 0.1020\n",
      "Epoch: 36/100... Training loss: 0.1075\n",
      "Epoch: 36/100... Training loss: 0.1077\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1080\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1078\n",
      "Epoch: 36/100... Training loss: 0.1060\n",
      "Epoch: 36/100... Training loss: 0.1083\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1065\n",
      "Epoch: 36/100... Training loss: 0.1054\n",
      "Epoch: 36/100... Training loss: 0.1074\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1064\n",
      "Epoch: 36/100... Training loss: 0.1104\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1083\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1053\n",
      "Epoch: 36/100... Training loss: 0.1084\n",
      "Epoch: 36/100... Training loss: 0.1038\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1026\n",
      "Epoch: 36/100... Training loss: 0.1044\n",
      "Epoch: 36/100... Training loss: 0.1059\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1098\n",
      "Epoch: 36/100... Training loss: 0.1084\n",
      "Epoch: 36/100... Training loss: 0.1102\n",
      "Epoch: 36/100... Training loss: 0.1072\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1045\n",
      "Epoch: 36/100... Training loss: 0.1068\n",
      "Epoch: 36/100... Training loss: 0.1075\n",
      "Epoch: 36/100... Training loss: 0.1031\n",
      "Epoch: 36/100... Training loss: 0.1077\n",
      "Epoch: 36/100... Training loss: 0.1050\n",
      "Epoch: 36/100... Training loss: 0.1023\n",
      "Epoch: 36/100... Training loss: 0.1046\n",
      "Epoch: 36/100... Training loss: 0.1055\n",
      "Epoch: 36/100... Training loss: 0.1060\n",
      "Epoch: 36/100... Training loss: 0.1032\n",
      "Epoch: 36/100... Training loss: 0.1076\n",
      "Epoch: 36/100... Training loss: 0.1051\n",
      "Epoch: 36/100... Training loss: 0.1021\n",
      "Epoch: 36/100... Training loss: 0.1056\n",
      "Epoch: 36/100... Training loss: 0.1054\n",
      "Epoch: 36/100... Training loss: 0.1030\n",
      "Epoch: 36/100... Training loss: 0.1066\n",
      "Epoch: 36/100... Training loss: 0.1049\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1042\n",
      "Epoch: 36/100... Training loss: 0.1048\n",
      "Epoch: 36/100... Training loss: 0.1047\n",
      "Epoch: 36/100... Training loss: 0.1080\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1070\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1106\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1116\n",
      "Epoch: 37/100... Training loss: 0.1080\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1069\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1074\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1072\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1087\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1061\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1077\n",
      "Epoch: 37/100... Training loss: 0.1084\n",
      "Epoch: 37/100... Training loss: 0.1093\n",
      "Epoch: 37/100... Training loss: 0.1069\n",
      "Epoch: 37/100... Training loss: 0.1068\n",
      "Epoch: 37/100... Training loss: 0.1061\n",
      "Epoch: 37/100... Training loss: 0.1070\n",
      "Epoch: 37/100... Training loss: 0.1071\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1103\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1078\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1061\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1063\n",
      "Epoch: 37/100... Training loss: 0.1018\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1074\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1079\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1096\n",
      "Epoch: 37/100... Training loss: 0.1085\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1076\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1022\n",
      "Epoch: 37/100... Training loss: 0.1065\n",
      "Epoch: 37/100... Training loss: 0.1072\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1077\n",
      "Epoch: 37/100... Training loss: 0.1073\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1070\n",
      "Epoch: 37/100... Training loss: 0.1020\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1021\n",
      "Epoch: 37/100... Training loss: 0.1072\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1069\n",
      "Epoch: 37/100... Training loss: 0.1080\n",
      "Epoch: 37/100... Training loss: 0.1071\n",
      "Epoch: 37/100... Training loss: 0.1104\n",
      "Epoch: 37/100... Training loss: 0.1069\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1076\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1073\n",
      "Epoch: 37/100... Training loss: 0.1083\n",
      "Epoch: 37/100... Training loss: 0.1072\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1079\n",
      "Epoch: 37/100... Training loss: 0.1081\n",
      "Epoch: 37/100... Training loss: 0.1065\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1073\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1061\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1072\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1065\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1076\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1104\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1034\n",
      "Epoch: 37/100... Training loss: 0.1072\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1050\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1069\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1070\n",
      "Epoch: 37/100... Training loss: 0.1095\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1011\n",
      "Epoch: 37/100... Training loss: 0.1063\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.1072\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1066\n",
      "Epoch: 37/100... Training loss: 0.1007\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.1040\n",
      "Epoch: 37/100... Training loss: 0.1052\n",
      "Epoch: 37/100... Training loss: 0.1107\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.1079\n",
      "Epoch: 37/100... Training loss: 0.1088\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1048\n",
      "Epoch: 37/100... Training loss: 0.1089\n",
      "Epoch: 37/100... Training loss: 0.1069\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1064\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1065\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1076\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.1017\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1076\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1058\n",
      "Epoch: 37/100... Training loss: 0.1037\n",
      "Epoch: 37/100... Training loss: 0.1088\n",
      "Epoch: 37/100... Training loss: 0.1002\n",
      "Epoch: 37/100... Training loss: 0.1063\n",
      "Epoch: 37/100... Training loss: 0.1086\n",
      "Epoch: 37/100... Training loss: 0.1083\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1028\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1073\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.1056\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1055\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1068\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1093\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1098\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1038\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1042\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1041\n",
      "Epoch: 37/100... Training loss: 0.1077\n",
      "Epoch: 37/100... Training loss: 0.1029\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1107\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1039\n",
      "Epoch: 37/100... Training loss: 0.1013\n",
      "Epoch: 37/100... Training loss: 0.1026\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1006\n",
      "Epoch: 37/100... Training loss: 0.1072\n",
      "Epoch: 37/100... Training loss: 0.1078\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1063\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1059\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1063\n",
      "Epoch: 37/100... Training loss: 0.0993\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1069\n",
      "Epoch: 37/100... Training loss: 0.1015\n",
      "Epoch: 37/100... Training loss: 0.1071\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1077\n",
      "Epoch: 37/100... Training loss: 0.1072\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1032\n",
      "Epoch: 37/100... Training loss: 0.1074\n",
      "Epoch: 37/100... Training loss: 0.1030\n",
      "Epoch: 37/100... Training loss: 0.1044\n",
      "Epoch: 37/100... Training loss: 0.1025\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1097\n",
      "Epoch: 37/100... Training loss: 0.1027\n",
      "Epoch: 37/100... Training loss: 0.1051\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1093\n",
      "Epoch: 37/100... Training loss: 0.1049\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1057\n",
      "Epoch: 37/100... Training loss: 0.1067\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1082\n",
      "Epoch: 37/100... Training loss: 0.1065\n",
      "Epoch: 37/100... Training loss: 0.1043\n",
      "Epoch: 37/100... Training loss: 0.1036\n",
      "Epoch: 37/100... Training loss: 0.1023\n",
      "Epoch: 37/100... Training loss: 0.1082\n",
      "Epoch: 37/100... Training loss: 0.1045\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1035\n",
      "Epoch: 37/100... Training loss: 0.1065\n",
      "Epoch: 37/100... Training loss: 0.1063\n",
      "Epoch: 37/100... Training loss: 0.1047\n",
      "Epoch: 37/100... Training loss: 0.1075\n",
      "Epoch: 37/100... Training loss: 0.1054\n",
      "Epoch: 37/100... Training loss: 0.1024\n",
      "Epoch: 37/100... Training loss: 0.1062\n",
      "Epoch: 37/100... Training loss: 0.1031\n",
      "Epoch: 37/100... Training loss: 0.1074\n",
      "Epoch: 37/100... Training loss: 0.1063\n",
      "Epoch: 37/100... Training loss: 0.1053\n",
      "Epoch: 37/100... Training loss: 0.1060\n",
      "Epoch: 37/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1068\n",
      "Epoch: 38/100... Training loss: 0.1080\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1081\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1073\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1097\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1065\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1059\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1090\n",
      "Epoch: 38/100... Training loss: 0.1064\n",
      "Epoch: 38/100... Training loss: 0.1075\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1009\n",
      "Epoch: 38/100... Training loss: 0.1072\n",
      "Epoch: 38/100... Training loss: 0.1079\n",
      "Epoch: 38/100... Training loss: 0.1083\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1079\n",
      "Epoch: 38/100... Training loss: 0.1063\n",
      "Epoch: 38/100... Training loss: 0.1061\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1063\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1085\n",
      "Epoch: 38/100... Training loss: 0.1033\n",
      "Epoch: 38/100... Training loss: 0.1066\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1101\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1025\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1079\n",
      "Epoch: 38/100... Training loss: 0.1016\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1074\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1067\n",
      "Epoch: 38/100... Training loss: 0.1064\n",
      "Epoch: 38/100... Training loss: 0.1060\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1036\n",
      "Epoch: 38/100... Training loss: 0.1073\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1063\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1066\n",
      "Epoch: 38/100... Training loss: 0.1077\n",
      "Epoch: 38/100... Training loss: 0.1012\n",
      "Epoch: 38/100... Training loss: 0.1074\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1071\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1058\n",
      "Epoch: 38/100... Training loss: 0.1115\n",
      "Epoch: 38/100... Training loss: 0.1076\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1069\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1080\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1086\n",
      "Epoch: 38/100... Training loss: 0.1056\n",
      "Epoch: 38/100... Training loss: 0.1093\n",
      "Epoch: 38/100... Training loss: 0.1061\n",
      "Epoch: 38/100... Training loss: 0.1060\n",
      "Epoch: 38/100... Training loss: 0.1063\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1040\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1066\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1087\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1084\n",
      "Epoch: 38/100... Training loss: 0.1075\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1067\n",
      "Epoch: 38/100... Training loss: 0.1066\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1014\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1102\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1081\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1071\n",
      "Epoch: 38/100... Training loss: 0.1068\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1077\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1058\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1107\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1005\n",
      "Epoch: 38/100... Training loss: 0.1060\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1065\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1069\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1058\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1058\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1067\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1024\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1058\n",
      "Epoch: 38/100... Training loss: 0.1060\n",
      "Epoch: 38/100... Training loss: 0.1058\n",
      "Epoch: 38/100... Training loss: 0.1071\n",
      "Epoch: 38/100... Training loss: 0.1093\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1073\n",
      "Epoch: 38/100... Training loss: 0.1081\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1083\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1067\n",
      "Epoch: 38/100... Training loss: 0.1018\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1073\n",
      "Epoch: 38/100... Training loss: 0.1080\n",
      "Epoch: 38/100... Training loss: 0.1064\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1041\n",
      "Epoch: 38/100... Training loss: 0.1058\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1067\n",
      "Epoch: 38/100... Training loss: 0.1066\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1066\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1064\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1062\n",
      "Epoch: 38/100... Training loss: 0.1079\n",
      "Epoch: 38/100... Training loss: 0.1086\n",
      "Epoch: 38/100... Training loss: 0.1099\n",
      "Epoch: 38/100... Training loss: 0.1081\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1035\n",
      "Epoch: 38/100... Training loss: 0.1079\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1059\n",
      "Epoch: 38/100... Training loss: 0.1064\n",
      "Epoch: 38/100... Training loss: 0.1091\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1111\n",
      "Epoch: 38/100... Training loss: 0.1032\n",
      "Epoch: 38/100... Training loss: 0.1072\n",
      "Epoch: 38/100... Training loss: 0.1043\n",
      "Epoch: 38/100... Training loss: 0.1058\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1005\n",
      "Epoch: 38/100... Training loss: 0.1077\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1061\n",
      "Epoch: 38/100... Training loss: 0.1087\n",
      "Epoch: 38/100... Training loss: 0.1076\n",
      "Epoch: 38/100... Training loss: 0.1099\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1068\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1060\n",
      "Epoch: 38/100... Training loss: 0.1049\n",
      "Epoch: 38/100... Training loss: 0.1037\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1077\n",
      "Epoch: 38/100... Training loss: 0.1048\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1080\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1074\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1034\n",
      "Epoch: 38/100... Training loss: 0.1047\n",
      "Epoch: 38/100... Training loss: 0.1085\n",
      "Epoch: 38/100... Training loss: 0.1039\n",
      "Epoch: 38/100... Training loss: 0.1027\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1081\n",
      "Epoch: 38/100... Training loss: 0.1099\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1020\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1021\n",
      "Epoch: 38/100... Training loss: 0.1045\n",
      "Epoch: 38/100... Training loss: 0.1029\n",
      "Epoch: 38/100... Training loss: 0.1070\n",
      "Epoch: 38/100... Training loss: 0.1063\n",
      "Epoch: 38/100... Training loss: 0.1072\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1053\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1022\n",
      "Epoch: 38/100... Training loss: 0.1038\n",
      "Epoch: 38/100... Training loss: 0.1059\n",
      "Epoch: 38/100... Training loss: 0.1028\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1042\n",
      "Epoch: 38/100... Training loss: 0.1057\n",
      "Epoch: 38/100... Training loss: 0.1071\n",
      "Epoch: 38/100... Training loss: 0.1054\n",
      "Epoch: 38/100... Training loss: 0.1051\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1030\n",
      "Epoch: 38/100... Training loss: 0.1069\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1052\n",
      "Epoch: 38/100... Training loss: 0.1044\n",
      "Epoch: 38/100... Training loss: 0.1082\n",
      "Epoch: 38/100... Training loss: 0.1056\n",
      "Epoch: 38/100... Training loss: 0.1050\n",
      "Epoch: 38/100... Training loss: 0.1067\n",
      "Epoch: 38/100... Training loss: 0.1055\n",
      "Epoch: 38/100... Training loss: 0.1056\n",
      "Epoch: 38/100... Training loss: 0.1046\n",
      "Epoch: 38/100... Training loss: 0.1067\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1061\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1082\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1053\n",
      "Epoch: 39/100... Training loss: 0.1053\n",
      "Epoch: 39/100... Training loss: 0.1069\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1069\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1076\n",
      "Epoch: 39/100... Training loss: 0.1064\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1078\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1076\n",
      "Epoch: 39/100... Training loss: 0.1066\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1066\n",
      "Epoch: 39/100... Training loss: 0.1080\n",
      "Epoch: 39/100... Training loss: 0.1057\n",
      "Epoch: 39/100... Training loss: 0.1005\n",
      "Epoch: 39/100... Training loss: 0.1050\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1074\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1079\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1077\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.1087\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1063\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1114\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1068\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1081\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1071\n",
      "Epoch: 39/100... Training loss: 0.1064\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1061\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1078\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1046\n",
      "Epoch: 39/100... Training loss: 0.1057\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1070\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1079\n",
      "Epoch: 39/100... Training loss: 0.1070\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1046\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1068\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1065\n",
      "Epoch: 39/100... Training loss: 0.1065\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1069\n",
      "Epoch: 39/100... Training loss: 0.1028\n",
      "Epoch: 39/100... Training loss: 0.0997\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1027\n",
      "Epoch: 39/100... Training loss: 0.1100\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1053\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1050\n",
      "Epoch: 39/100... Training loss: 0.1020\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1066\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1086\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1077\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1053\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1077\n",
      "Epoch: 39/100... Training loss: 0.1025\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1046\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1045\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1064\n",
      "Epoch: 39/100... Training loss: 0.1065\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1069\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1075\n",
      "Epoch: 39/100... Training loss: 0.1073\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1092\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1066\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1032\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1046\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1079\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.1040\n",
      "Epoch: 39/100... Training loss: 0.1057\n",
      "Epoch: 39/100... Training loss: 0.1083\n",
      "Epoch: 39/100... Training loss: 0.1083\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1073\n",
      "Epoch: 39/100... Training loss: 0.1070\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1069\n",
      "Epoch: 39/100... Training loss: 0.1046\n",
      "Epoch: 39/100... Training loss: 0.1075\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1069\n",
      "Epoch: 39/100... Training loss: 0.1018\n",
      "Epoch: 39/100... Training loss: 0.1061\n",
      "Epoch: 39/100... Training loss: 0.1029\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1078\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1019\n",
      "Epoch: 39/100... Training loss: 0.1071\n",
      "Epoch: 39/100... Training loss: 0.1038\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1073\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1068\n",
      "Epoch: 39/100... Training loss: 0.1049\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1036\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1054\n",
      "Epoch: 39/100... Training loss: 0.1073\n",
      "Epoch: 39/100... Training loss: 0.1078\n",
      "Epoch: 39/100... Training loss: 0.1063\n",
      "Epoch: 39/100... Training loss: 0.1050\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1080\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1091\n",
      "Epoch: 39/100... Training loss: 0.1010\n",
      "Epoch: 39/100... Training loss: 0.1014\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1068\n",
      "Epoch: 39/100... Training loss: 0.1061\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1057\n",
      "Epoch: 39/100... Training loss: 0.1011\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1030\n",
      "Epoch: 39/100... Training loss: 0.1071\n",
      "Epoch: 39/100... Training loss: 0.1089\n",
      "Epoch: 39/100... Training loss: 0.1007\n",
      "Epoch: 39/100... Training loss: 0.1060\n",
      "Epoch: 39/100... Training loss: 0.1046\n",
      "Epoch: 39/100... Training loss: 0.1081\n",
      "Epoch: 39/100... Training loss: 0.1044\n",
      "Epoch: 39/100... Training loss: 0.1097\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1075\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1065\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1065\n",
      "Epoch: 39/100... Training loss: 0.1067\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1075\n",
      "Epoch: 39/100... Training loss: 0.1070\n",
      "Epoch: 39/100... Training loss: 0.1065\n",
      "Epoch: 39/100... Training loss: 0.1026\n",
      "Epoch: 39/100... Training loss: 0.1024\n",
      "Epoch: 39/100... Training loss: 0.1093\n",
      "Epoch: 39/100... Training loss: 0.1084\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1043\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1047\n",
      "Epoch: 39/100... Training loss: 0.1001\n",
      "Epoch: 39/100... Training loss: 0.1052\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1021\n",
      "Epoch: 39/100... Training loss: 0.1068\n",
      "Epoch: 39/100... Training loss: 0.1066\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1058\n",
      "Epoch: 39/100... Training loss: 0.1039\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.0989\n",
      "Epoch: 39/100... Training loss: 0.1094\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1055\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1041\n",
      "Epoch: 39/100... Training loss: 0.1098\n",
      "Epoch: 39/100... Training loss: 0.1048\n",
      "Epoch: 39/100... Training loss: 0.1062\n",
      "Epoch: 39/100... Training loss: 0.1034\n",
      "Epoch: 39/100... Training loss: 0.1037\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1035\n",
      "Epoch: 39/100... Training loss: 0.1051\n",
      "Epoch: 39/100... Training loss: 0.1050\n",
      "Epoch: 39/100... Training loss: 0.1075\n",
      "Epoch: 39/100... Training loss: 0.1089\n",
      "Epoch: 39/100... Training loss: 0.1059\n",
      "Epoch: 39/100... Training loss: 0.1073\n",
      "Epoch: 39/100... Training loss: 0.1023\n",
      "Epoch: 39/100... Training loss: 0.1050\n",
      "Epoch: 39/100... Training loss: 0.1033\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1064\n",
      "Epoch: 39/100... Training loss: 0.1086\n",
      "Epoch: 39/100... Training loss: 0.1083\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1069\n",
      "Epoch: 39/100... Training loss: 0.1042\n",
      "Epoch: 39/100... Training loss: 0.1056\n",
      "Epoch: 39/100... Training loss: 0.1071\n",
      "Epoch: 39/100... Training loss: 0.1069\n",
      "Epoch: 39/100... Training loss: 0.1031\n",
      "Epoch: 39/100... Training loss: 0.1116\n",
      "Epoch: 39/100... Training loss: 0.1082\n",
      "Epoch: 40/100... Training loss: 0.1077\n",
      "Epoch: 40/100... Training loss: 0.1098\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1010\n",
      "Epoch: 40/100... Training loss: 0.1087\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1086\n",
      "Epoch: 40/100... Training loss: 0.1092\n",
      "Epoch: 40/100... Training loss: 0.1103\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1069\n",
      "Epoch: 40/100... Training loss: 0.1056\n",
      "Epoch: 40/100... Training loss: 0.1082\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1074\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1077\n",
      "Epoch: 40/100... Training loss: 0.1066\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1077\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1070\n",
      "Epoch: 40/100... Training loss: 0.1067\n",
      "Epoch: 40/100... Training loss: 0.1031\n",
      "Epoch: 40/100... Training loss: 0.1061\n",
      "Epoch: 40/100... Training loss: 0.1028\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1083\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1063\n",
      "Epoch: 40/100... Training loss: 0.1066\n",
      "Epoch: 40/100... Training loss: 0.1065\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1071\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1065\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1071\n",
      "Epoch: 40/100... Training loss: 0.1079\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1067\n",
      "Epoch: 40/100... Training loss: 0.1085\n",
      "Epoch: 40/100... Training loss: 0.1078\n",
      "Epoch: 40/100... Training loss: 0.1062\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1066\n",
      "Epoch: 40/100... Training loss: 0.1061\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1080\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1064\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1079\n",
      "Epoch: 40/100... Training loss: 0.1019\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1089\n",
      "Epoch: 40/100... Training loss: 0.1066\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1013\n",
      "Epoch: 40/100... Training loss: 0.1072\n",
      "Epoch: 40/100... Training loss: 0.1025\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1070\n",
      "Epoch: 40/100... Training loss: 0.1073\n",
      "Epoch: 40/100... Training loss: 0.1062\n",
      "Epoch: 40/100... Training loss: 0.1071\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1086\n",
      "Epoch: 40/100... Training loss: 0.1004\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1108\n",
      "Epoch: 40/100... Training loss: 0.1062\n",
      "Epoch: 40/100... Training loss: 0.1065\n",
      "Epoch: 40/100... Training loss: 0.1070\n",
      "Epoch: 40/100... Training loss: 0.1068\n",
      "Epoch: 40/100... Training loss: 0.1084\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1014\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1006\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1009\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1069\n",
      "Epoch: 40/100... Training loss: 0.1003\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1088\n",
      "Epoch: 40/100... Training loss: 0.1056\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1052\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1075\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1071\n",
      "Epoch: 40/100... Training loss: 0.1059\n",
      "Epoch: 40/100... Training loss: 0.1081\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1029\n",
      "Epoch: 40/100... Training loss: 0.1022\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1084\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1075\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1062\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1063\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1056\n",
      "Epoch: 40/100... Training loss: 0.1089\n",
      "Epoch: 40/100... Training loss: 0.1072\n",
      "Epoch: 40/100... Training loss: 0.1091\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1069\n",
      "Epoch: 40/100... Training loss: 0.1082\n",
      "Epoch: 40/100... Training loss: 0.1077\n",
      "Epoch: 40/100... Training loss: 0.1076\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1071\n",
      "Epoch: 40/100... Training loss: 0.1067\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1087\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1080\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.0994\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1041\n",
      "Epoch: 40/100... Training loss: 0.1059\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1064\n",
      "Epoch: 40/100... Training loss: 0.1073\n",
      "Epoch: 40/100... Training loss: 0.1059\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1024\n",
      "Epoch: 40/100... Training loss: 0.1078\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1060\n",
      "Epoch: 40/100... Training loss: 0.1061\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1055\n",
      "Epoch: 40/100... Training loss: 0.1068\n",
      "Epoch: 40/100... Training loss: 0.1054\n",
      "Epoch: 40/100... Training loss: 0.1032\n",
      "Epoch: 40/100... Training loss: 0.1076\n",
      "Epoch: 40/100... Training loss: 0.1055\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1082\n",
      "Epoch: 40/100... Training loss: 0.1083\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1064\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1055\n",
      "Epoch: 40/100... Training loss: 0.1048\n",
      "Epoch: 40/100... Training loss: 0.1020\n",
      "Epoch: 40/100... Training loss: 0.1088\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1008\n",
      "Epoch: 40/100... Training loss: 0.1056\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1061\n",
      "Epoch: 40/100... Training loss: 0.1026\n",
      "Epoch: 40/100... Training loss: 0.1035\n",
      "Epoch: 40/100... Training loss: 0.1064\n",
      "Epoch: 40/100... Training loss: 0.1072\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1046\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1049\n",
      "Epoch: 40/100... Training loss: 0.1064\n",
      "Epoch: 40/100... Training loss: 0.1030\n",
      "Epoch: 40/100... Training loss: 0.1036\n",
      "Epoch: 40/100... Training loss: 0.1072\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1091\n",
      "Epoch: 40/100... Training loss: 0.1076\n",
      "Epoch: 40/100... Training loss: 0.1017\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1039\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1027\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1042\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1088\n",
      "Epoch: 40/100... Training loss: 0.1065\n",
      "Epoch: 40/100... Training loss: 0.1057\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1051\n",
      "Epoch: 40/100... Training loss: 0.1070\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1075\n",
      "Epoch: 40/100... Training loss: 0.1053\n",
      "Epoch: 40/100... Training loss: 0.1021\n",
      "Epoch: 40/100... Training loss: 0.1047\n",
      "Epoch: 40/100... Training loss: 0.1089\n",
      "Epoch: 40/100... Training loss: 0.1085\n",
      "Epoch: 40/100... Training loss: 0.1058\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1085\n",
      "Epoch: 40/100... Training loss: 0.1061\n",
      "Epoch: 40/100... Training loss: 0.1038\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1043\n",
      "Epoch: 40/100... Training loss: 0.1076\n",
      "Epoch: 40/100... Training loss: 0.1037\n",
      "Epoch: 40/100... Training loss: 0.1055\n",
      "Epoch: 40/100... Training loss: 0.1066\n",
      "Epoch: 40/100... Training loss: 0.1072\n",
      "Epoch: 40/100... Training loss: 0.1081\n",
      "Epoch: 40/100... Training loss: 0.1070\n",
      "Epoch: 40/100... Training loss: 0.1067\n",
      "Epoch: 40/100... Training loss: 0.1044\n",
      "Epoch: 40/100... Training loss: 0.1045\n",
      "Epoch: 40/100... Training loss: 0.1015\n",
      "Epoch: 40/100... Training loss: 0.1065\n",
      "Epoch: 40/100... Training loss: 0.1034\n",
      "Epoch: 40/100... Training loss: 0.1061\n",
      "Epoch: 40/100... Training loss: 0.1068\n",
      "Epoch: 40/100... Training loss: 0.1033\n",
      "Epoch: 40/100... Training loss: 0.1040\n",
      "Epoch: 40/100... Training loss: 0.1050\n",
      "Epoch: 40/100... Training loss: 0.1067\n",
      "Epoch: 41/100... Training loss: 0.1072\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1050\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1072\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1062\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1085\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.0990\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1054\n",
      "Epoch: 41/100... Training loss: 0.1057\n",
      "Epoch: 41/100... Training loss: 0.1090\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1081\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1056\n",
      "Epoch: 41/100... Training loss: 0.1070\n",
      "Epoch: 41/100... Training loss: 0.1084\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1077\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1056\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1086\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1078\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1059\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1064\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1062\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1016\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1079\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1072\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1096\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1088\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1012\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1088\n",
      "Epoch: 41/100... Training loss: 0.1059\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1065\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1055\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1084\n",
      "Epoch: 41/100... Training loss: 0.1050\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1055\n",
      "Epoch: 41/100... Training loss: 0.1082\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1079\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1077\n",
      "Epoch: 41/100... Training loss: 0.1057\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1085\n",
      "Epoch: 41/100... Training loss: 0.1071\n",
      "Epoch: 41/100... Training loss: 0.1064\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1050\n",
      "Epoch: 41/100... Training loss: 0.1098\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1070\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1047\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1056\n",
      "Epoch: 41/100... Training loss: 0.1081\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1098\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1110\n",
      "Epoch: 41/100... Training loss: 0.1089\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1085\n",
      "Epoch: 41/100... Training loss: 0.1054\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1081\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1066\n",
      "Epoch: 41/100... Training loss: 0.1075\n",
      "Epoch: 41/100... Training loss: 0.1065\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1083\n",
      "Epoch: 41/100... Training loss: 0.1058\n",
      "Epoch: 41/100... Training loss: 0.1059\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1088\n",
      "Epoch: 41/100... Training loss: 0.1021\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1055\n",
      "Epoch: 41/100... Training loss: 0.1069\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1081\n",
      "Epoch: 41/100... Training loss: 0.1071\n",
      "Epoch: 41/100... Training loss: 0.1064\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1037\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1055\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1059\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1051\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1062\n",
      "Epoch: 41/100... Training loss: 0.1058\n",
      "Epoch: 41/100... Training loss: 0.1018\n",
      "Epoch: 41/100... Training loss: 0.1026\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1059\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1028\n",
      "Epoch: 41/100... Training loss: 0.1011\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1072\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1071\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1070\n",
      "Epoch: 41/100... Training loss: 0.1055\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1072\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1063\n",
      "Epoch: 41/100... Training loss: 0.1049\n",
      "Epoch: 41/100... Training loss: 0.1034\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1071\n",
      "Epoch: 41/100... Training loss: 0.1007\n",
      "Epoch: 41/100... Training loss: 0.1092\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1045\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1065\n",
      "Epoch: 41/100... Training loss: 0.1013\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1030\n",
      "Epoch: 41/100... Training loss: 0.1092\n",
      "Epoch: 41/100... Training loss: 0.1009\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1025\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1072\n",
      "Epoch: 41/100... Training loss: 0.1082\n",
      "Epoch: 41/100... Training loss: 0.1050\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1072\n",
      "Epoch: 41/100... Training loss: 0.1066\n",
      "Epoch: 41/100... Training loss: 0.1073\n",
      "Epoch: 41/100... Training loss: 0.1017\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1019\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1036\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1083\n",
      "Epoch: 41/100... Training loss: 0.1054\n",
      "Epoch: 41/100... Training loss: 0.1075\n",
      "Epoch: 41/100... Training loss: 0.1048\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1063\n",
      "Epoch: 41/100... Training loss: 0.1038\n",
      "Epoch: 41/100... Training loss: 0.1023\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1082\n",
      "Epoch: 41/100... Training loss: 0.1043\n",
      "Epoch: 41/100... Training loss: 0.1031\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1032\n",
      "Epoch: 41/100... Training loss: 0.1075\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1069\n",
      "Epoch: 41/100... Training loss: 0.1059\n",
      "Epoch: 41/100... Training loss: 0.1027\n",
      "Epoch: 41/100... Training loss: 0.1074\n",
      "Epoch: 41/100... Training loss: 0.1065\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1096\n",
      "Epoch: 41/100... Training loss: 0.1061\n",
      "Epoch: 41/100... Training loss: 0.1076\n",
      "Epoch: 41/100... Training loss: 0.1022\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1058\n",
      "Epoch: 41/100... Training loss: 0.1062\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1020\n",
      "Epoch: 41/100... Training loss: 0.1064\n",
      "Epoch: 41/100... Training loss: 0.1068\n",
      "Epoch: 41/100... Training loss: 0.1033\n",
      "Epoch: 41/100... Training loss: 0.1069\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1024\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1113\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1039\n",
      "Epoch: 41/100... Training loss: 0.1093\n",
      "Epoch: 41/100... Training loss: 0.1035\n",
      "Epoch: 41/100... Training loss: 0.1065\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1080\n",
      "Epoch: 41/100... Training loss: 0.1053\n",
      "Epoch: 41/100... Training loss: 0.1003\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1041\n",
      "Epoch: 41/100... Training loss: 0.1052\n",
      "Epoch: 41/100... Training loss: 0.1060\n",
      "Epoch: 41/100... Training loss: 0.1046\n",
      "Epoch: 41/100... Training loss: 0.1050\n",
      "Epoch: 41/100... Training loss: 0.1054\n",
      "Epoch: 41/100... Training loss: 0.1066\n",
      "Epoch: 41/100... Training loss: 0.1044\n",
      "Epoch: 41/100... Training loss: 0.1042\n",
      "Epoch: 41/100... Training loss: 0.1040\n",
      "Epoch: 41/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1062\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1060\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1053\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1069\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1077\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1100\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1010\n",
      "Epoch: 42/100... Training loss: 0.1054\n",
      "Epoch: 42/100... Training loss: 0.1005\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1088\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.1053\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1004\n",
      "Epoch: 42/100... Training loss: 0.1103\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1066\n",
      "Epoch: 42/100... Training loss: 0.1061\n",
      "Epoch: 42/100... Training loss: 0.1061\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1075\n",
      "Epoch: 42/100... Training loss: 0.1065\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1085\n",
      "Epoch: 42/100... Training loss: 0.1092\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1074\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1044\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1074\n",
      "Epoch: 42/100... Training loss: 0.1076\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1060\n",
      "Epoch: 42/100... Training loss: 0.1082\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1066\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1063\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1082\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1061\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1061\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1022\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.1070\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1004\n",
      "Epoch: 42/100... Training loss: 0.1068\n",
      "Epoch: 42/100... Training loss: 0.1085\n",
      "Epoch: 42/100... Training loss: 0.1033\n",
      "Epoch: 42/100... Training loss: 0.1065\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1097\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1075\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1064\n",
      "Epoch: 42/100... Training loss: 0.1070\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1048\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1053\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1059\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1071\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1087\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1063\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1067\n",
      "Epoch: 42/100... Training loss: 0.1068\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1064\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1024\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1068\n",
      "Epoch: 42/100... Training loss: 0.1084\n",
      "Epoch: 42/100... Training loss: 0.1054\n",
      "Epoch: 42/100... Training loss: 0.1054\n",
      "Epoch: 42/100... Training loss: 0.1018\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1064\n",
      "Epoch: 42/100... Training loss: 0.1067\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1081\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1089\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1064\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1072\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1073\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1059\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1059\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1077\n",
      "Epoch: 42/100... Training loss: 0.1020\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1081\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1016\n",
      "Epoch: 42/100... Training loss: 0.1073\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1021\n",
      "Epoch: 42/100... Training loss: 0.1048\n",
      "Epoch: 42/100... Training loss: 0.1093\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1048\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1000\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1076\n",
      "Epoch: 42/100... Training loss: 0.1064\n",
      "Epoch: 42/100... Training loss: 0.1054\n",
      "Epoch: 42/100... Training loss: 0.1088\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1075\n",
      "Epoch: 42/100... Training loss: 0.1091\n",
      "Epoch: 42/100... Training loss: 0.1035\n",
      "Epoch: 42/100... Training loss: 0.1073\n",
      "Epoch: 42/100... Training loss: 0.1067\n",
      "Epoch: 42/100... Training loss: 0.1017\n",
      "Epoch: 42/100... Training loss: 0.1067\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1095\n",
      "Epoch: 42/100... Training loss: 0.1046\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1025\n",
      "Epoch: 42/100... Training loss: 0.1088\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1095\n",
      "Epoch: 42/100... Training loss: 0.1051\n",
      "Epoch: 42/100... Training loss: 0.1062\n",
      "Epoch: 42/100... Training loss: 0.1082\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1066\n",
      "Epoch: 42/100... Training loss: 0.1057\n",
      "Epoch: 42/100... Training loss: 0.1042\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1111\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1089\n",
      "Epoch: 42/100... Training loss: 0.1026\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1055\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1014\n",
      "Epoch: 42/100... Training loss: 0.1043\n",
      "Epoch: 42/100... Training loss: 0.1064\n",
      "Epoch: 42/100... Training loss: 0.1052\n",
      "Epoch: 42/100... Training loss: 0.1085\n",
      "Epoch: 42/100... Training loss: 0.1077\n",
      "Epoch: 42/100... Training loss: 0.1060\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1066\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1045\n",
      "Epoch: 42/100... Training loss: 0.1030\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1048\n",
      "Epoch: 42/100... Training loss: 0.1059\n",
      "Epoch: 42/100... Training loss: 0.1027\n",
      "Epoch: 42/100... Training loss: 0.1036\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1023\n",
      "Epoch: 42/100... Training loss: 0.1034\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1080\n",
      "Epoch: 42/100... Training loss: 0.1037\n",
      "Epoch: 42/100... Training loss: 0.1053\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1064\n",
      "Epoch: 42/100... Training loss: 0.1068\n",
      "Epoch: 42/100... Training loss: 0.1032\n",
      "Epoch: 42/100... Training loss: 0.1059\n",
      "Epoch: 42/100... Training loss: 0.1067\n",
      "Epoch: 42/100... Training loss: 0.1041\n",
      "Epoch: 42/100... Training loss: 0.1074\n",
      "Epoch: 42/100... Training loss: 0.1048\n",
      "Epoch: 42/100... Training loss: 0.1062\n",
      "Epoch: 42/100... Training loss: 0.1076\n",
      "Epoch: 42/100... Training loss: 0.1068\n",
      "Epoch: 42/100... Training loss: 0.1060\n",
      "Epoch: 42/100... Training loss: 0.1040\n",
      "Epoch: 42/100... Training loss: 0.1063\n",
      "Epoch: 42/100... Training loss: 0.1071\n",
      "Epoch: 42/100... Training loss: 0.1029\n",
      "Epoch: 42/100... Training loss: 0.1028\n",
      "Epoch: 42/100... Training loss: 0.1031\n",
      "Epoch: 42/100... Training loss: 0.1047\n",
      "Epoch: 42/100... Training loss: 0.1064\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 42/100... Training loss: 0.1039\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1074\n",
      "Epoch: 42/100... Training loss: 0.1115\n",
      "Epoch: 42/100... Training loss: 0.1009\n",
      "Epoch: 42/100... Training loss: 0.1050\n",
      "Epoch: 42/100... Training loss: 0.1013\n",
      "Epoch: 42/100... Training loss: 0.1061\n",
      "Epoch: 42/100... Training loss: 0.1056\n",
      "Epoch: 42/100... Training loss: 0.1090\n",
      "Epoch: 42/100... Training loss: 0.1105\n",
      "Epoch: 42/100... Training loss: 0.1012\n",
      "Epoch: 42/100... Training loss: 0.1049\n",
      "Epoch: 42/100... Training loss: 0.1081\n",
      "Epoch: 42/100... Training loss: 0.1066\n",
      "Epoch: 42/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1065\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1063\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1076\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1054\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1054\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1071\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1064\n",
      "Epoch: 43/100... Training loss: 0.1054\n",
      "Epoch: 43/100... Training loss: 0.1063\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1067\n",
      "Epoch: 43/100... Training loss: 0.1064\n",
      "Epoch: 43/100... Training loss: 0.1070\n",
      "Epoch: 43/100... Training loss: 0.1065\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1076\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.1065\n",
      "Epoch: 43/100... Training loss: 0.1067\n",
      "Epoch: 43/100... Training loss: 0.1060\n",
      "Epoch: 43/100... Training loss: 0.1075\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.1053\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1063\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1071\n",
      "Epoch: 43/100... Training loss: 0.1044\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1028\n",
      "Epoch: 43/100... Training loss: 0.1066\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1076\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1074\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1079\n",
      "Epoch: 43/100... Training loss: 0.1085\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1044\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1083\n",
      "Epoch: 43/100... Training loss: 0.1044\n",
      "Epoch: 43/100... Training loss: 0.1069\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.1044\n",
      "Epoch: 43/100... Training loss: 0.1056\n",
      "Epoch: 43/100... Training loss: 0.1093\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1014\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1058\n",
      "Epoch: 43/100... Training loss: 0.1069\n",
      "Epoch: 43/100... Training loss: 0.1061\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1053\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1059\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1086\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1065\n",
      "Epoch: 43/100... Training loss: 0.1067\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1058\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1015\n",
      "Epoch: 43/100... Training loss: 0.1068\n",
      "Epoch: 43/100... Training loss: 0.1066\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1023\n",
      "Epoch: 43/100... Training loss: 0.1063\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.0989\n",
      "Epoch: 43/100... Training loss: 0.1062\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1045\n",
      "Epoch: 43/100... Training loss: 0.1044\n",
      "Epoch: 43/100... Training loss: 0.1057\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1080\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1053\n",
      "Epoch: 43/100... Training loss: 0.1072\n",
      "Epoch: 43/100... Training loss: 0.1051\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1069\n",
      "Epoch: 43/100... Training loss: 0.1011\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1031\n",
      "Epoch: 43/100... Training loss: 0.1064\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.1080\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1064\n",
      "Epoch: 43/100... Training loss: 0.1054\n",
      "Epoch: 43/100... Training loss: 0.1060\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1068\n",
      "Epoch: 43/100... Training loss: 0.1013\n",
      "Epoch: 43/100... Training loss: 0.1067\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1079\n",
      "Epoch: 43/100... Training loss: 0.1058\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1019\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1060\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1051\n",
      "Epoch: 43/100... Training loss: 0.1059\n",
      "Epoch: 43/100... Training loss: 0.1068\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1060\n",
      "Epoch: 43/100... Training loss: 0.1002\n",
      "Epoch: 43/100... Training loss: 0.1029\n",
      "Epoch: 43/100... Training loss: 0.1068\n",
      "Epoch: 43/100... Training loss: 0.1048\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1053\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1070\n",
      "Epoch: 43/100... Training loss: 0.1025\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1058\n",
      "Epoch: 43/100... Training loss: 0.1034\n",
      "Epoch: 43/100... Training loss: 0.1067\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1080\n",
      "Epoch: 43/100... Training loss: 0.1060\n",
      "Epoch: 43/100... Training loss: 0.1075\n",
      "Epoch: 43/100... Training loss: 0.1027\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1077\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1065\n",
      "Epoch: 43/100... Training loss: 0.0983\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1093\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1044\n",
      "Epoch: 43/100... Training loss: 0.1054\n",
      "Epoch: 43/100... Training loss: 0.1084\n",
      "Epoch: 43/100... Training loss: 0.0999\n",
      "Epoch: 43/100... Training loss: 0.1021\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1075\n",
      "Epoch: 43/100... Training loss: 0.1061\n",
      "Epoch: 43/100... Training loss: 0.1086\n",
      "Epoch: 43/100... Training loss: 0.1072\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1058\n",
      "Epoch: 43/100... Training loss: 0.1065\n",
      "Epoch: 43/100... Training loss: 0.1035\n",
      "Epoch: 43/100... Training loss: 0.1050\n",
      "Epoch: 43/100... Training loss: 0.1010\n",
      "Epoch: 43/100... Training loss: 0.1024\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1020\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1056\n",
      "Epoch: 43/100... Training loss: 0.1003\n",
      "Epoch: 43/100... Training loss: 0.1056\n",
      "Epoch: 43/100... Training loss: 0.1065\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1068\n",
      "Epoch: 43/100... Training loss: 0.1061\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1071\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1007\n",
      "Epoch: 43/100... Training loss: 0.1062\n",
      "Epoch: 43/100... Training loss: 0.1063\n",
      "Epoch: 43/100... Training loss: 0.1061\n",
      "Epoch: 43/100... Training loss: 0.1058\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1086\n",
      "Epoch: 43/100... Training loss: 0.1093\n",
      "Epoch: 43/100... Training loss: 0.1053\n",
      "Epoch: 43/100... Training loss: 0.1039\n",
      "Epoch: 43/100... Training loss: 0.1062\n",
      "Epoch: 43/100... Training loss: 0.1070\n",
      "Epoch: 43/100... Training loss: 0.1030\n",
      "Epoch: 43/100... Training loss: 0.1064\n",
      "Epoch: 43/100... Training loss: 0.1036\n",
      "Epoch: 43/100... Training loss: 0.1041\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1065\n",
      "Epoch: 43/100... Training loss: 0.1064\n",
      "Epoch: 43/100... Training loss: 0.1056\n",
      "Epoch: 43/100... Training loss: 0.0989\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1079\n",
      "Epoch: 43/100... Training loss: 0.1040\n",
      "Epoch: 43/100... Training loss: 0.1044\n",
      "Epoch: 43/100... Training loss: 0.1006\n",
      "Epoch: 43/100... Training loss: 0.1033\n",
      "Epoch: 43/100... Training loss: 0.1053\n",
      "Epoch: 43/100... Training loss: 0.1018\n",
      "Epoch: 43/100... Training loss: 0.1046\n",
      "Epoch: 43/100... Training loss: 0.1038\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1054\n",
      "Epoch: 43/100... Training loss: 0.1042\n",
      "Epoch: 43/100... Training loss: 0.1071\n",
      "Epoch: 43/100... Training loss: 0.1032\n",
      "Epoch: 43/100... Training loss: 0.1026\n",
      "Epoch: 43/100... Training loss: 0.1052\n",
      "Epoch: 43/100... Training loss: 0.0987\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 43/100... Training loss: 0.1043\n",
      "Epoch: 43/100... Training loss: 0.1037\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1049\n",
      "Epoch: 43/100... Training loss: 0.1061\n",
      "Epoch: 43/100... Training loss: 0.1067\n",
      "Epoch: 43/100... Training loss: 0.1017\n",
      "Epoch: 43/100... Training loss: 0.1022\n",
      "Epoch: 43/100... Training loss: 0.1059\n",
      "Epoch: 43/100... Training loss: 0.1047\n",
      "Epoch: 43/100... Training loss: 0.1055\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1053\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1070\n",
      "Epoch: 44/100... Training loss: 0.1059\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1094\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1015\n",
      "Epoch: 44/100... Training loss: 0.1071\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1062\n",
      "Epoch: 44/100... Training loss: 0.1053\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1064\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.1048\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1051\n",
      "Epoch: 44/100... Training loss: 0.1053\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1025\n",
      "Epoch: 44/100... Training loss: 0.1074\n",
      "Epoch: 44/100... Training loss: 0.1051\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1068\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1070\n",
      "Epoch: 44/100... Training loss: 0.1050\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1090\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1044\n",
      "Epoch: 44/100... Training loss: 0.1044\n",
      "Epoch: 44/100... Training loss: 0.1059\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1090\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.1087\n",
      "Epoch: 44/100... Training loss: 0.1062\n",
      "Epoch: 44/100... Training loss: 0.1072\n",
      "Epoch: 44/100... Training loss: 0.1064\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1065\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1090\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1082\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1062\n",
      "Epoch: 44/100... Training loss: 0.1002\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1103\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1067\n",
      "Epoch: 44/100... Training loss: 0.1070\n",
      "Epoch: 44/100... Training loss: 0.1079\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1050\n",
      "Epoch: 44/100... Training loss: 0.1001\n",
      "Epoch: 44/100... Training loss: 0.1077\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1081\n",
      "Epoch: 44/100... Training loss: 0.1055\n",
      "Epoch: 44/100... Training loss: 0.1067\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1101\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1061\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1055\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1056\n",
      "Epoch: 44/100... Training loss: 0.1067\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1065\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1067\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1016\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1017\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1067\n",
      "Epoch: 44/100... Training loss: 0.1051\n",
      "Epoch: 44/100... Training loss: 0.1007\n",
      "Epoch: 44/100... Training loss: 0.1069\n",
      "Epoch: 44/100... Training loss: 0.1012\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1064\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1061\n",
      "Epoch: 44/100... Training loss: 0.1050\n",
      "Epoch: 44/100... Training loss: 0.1077\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1041\n",
      "Epoch: 44/100... Training loss: 0.1008\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1063\n",
      "Epoch: 44/100... Training loss: 0.1037\n",
      "Epoch: 44/100... Training loss: 0.0989\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1074\n",
      "Epoch: 44/100... Training loss: 0.1055\n",
      "Epoch: 44/100... Training loss: 0.1075\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1066\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1062\n",
      "Epoch: 44/100... Training loss: 0.1071\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1069\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1074\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1035\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1044\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1013\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1064\n",
      "Epoch: 44/100... Training loss: 0.1028\n",
      "Epoch: 44/100... Training loss: 0.1056\n",
      "Epoch: 44/100... Training loss: 0.1054\n",
      "Epoch: 44/100... Training loss: 0.1074\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1060\n",
      "Epoch: 44/100... Training loss: 0.1081\n",
      "Epoch: 44/100... Training loss: 0.1093\n",
      "Epoch: 44/100... Training loss: 0.1075\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1067\n",
      "Epoch: 44/100... Training loss: 0.1044\n",
      "Epoch: 44/100... Training loss: 0.1011\n",
      "Epoch: 44/100... Training loss: 0.1079\n",
      "Epoch: 44/100... Training loss: 0.1070\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1009\n",
      "Epoch: 44/100... Training loss: 0.1068\n",
      "Epoch: 44/100... Training loss: 0.1053\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1071\n",
      "Epoch: 44/100... Training loss: 0.1065\n",
      "Epoch: 44/100... Training loss: 0.1043\n",
      "Epoch: 44/100... Training loss: 0.1050\n",
      "Epoch: 44/100... Training loss: 0.1020\n",
      "Epoch: 44/100... Training loss: 0.1048\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1072\n",
      "Epoch: 44/100... Training loss: 0.1005\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1032\n",
      "Epoch: 44/100... Training loss: 0.1078\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1055\n",
      "Epoch: 44/100... Training loss: 0.1060\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1069\n",
      "Epoch: 44/100... Training loss: 0.1061\n",
      "Epoch: 44/100... Training loss: 0.1063\n",
      "Epoch: 44/100... Training loss: 0.1004\n",
      "Epoch: 44/100... Training loss: 0.1051\n",
      "Epoch: 44/100... Training loss: 0.1061\n",
      "Epoch: 44/100... Training loss: 0.1000\n",
      "Epoch: 44/100... Training loss: 0.1068\n",
      "Epoch: 44/100... Training loss: 0.1024\n",
      "Epoch: 44/100... Training loss: 0.1052\n",
      "Epoch: 44/100... Training loss: 0.1027\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1062\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1068\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.1065\n",
      "Epoch: 44/100... Training loss: 0.1056\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1064\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1070\n",
      "Epoch: 44/100... Training loss: 0.1023\n",
      "Epoch: 44/100... Training loss: 0.1086\n",
      "Epoch: 44/100... Training loss: 0.1078\n",
      "Epoch: 44/100... Training loss: 0.1058\n",
      "Epoch: 44/100... Training loss: 0.1061\n",
      "Epoch: 44/100... Training loss: 0.1019\n",
      "Epoch: 44/100... Training loss: 0.1026\n",
      "Epoch: 44/100... Training loss: 0.1080\n",
      "Epoch: 44/100... Training loss: 0.1045\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1068\n",
      "Epoch: 44/100... Training loss: 0.1042\n",
      "Epoch: 44/100... Training loss: 0.1048\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1048\n",
      "Epoch: 44/100... Training loss: 0.1056\n",
      "Epoch: 44/100... Training loss: 0.1038\n",
      "Epoch: 44/100... Training loss: 0.1046\n",
      "Epoch: 44/100... Training loss: 0.1063\n",
      "Epoch: 44/100... Training loss: 0.1018\n",
      "Epoch: 44/100... Training loss: 0.1034\n",
      "Epoch: 44/100... Training loss: 0.1079\n",
      "Epoch: 44/100... Training loss: 0.1049\n",
      "Epoch: 44/100... Training loss: 0.1031\n",
      "Epoch: 44/100... Training loss: 0.1030\n",
      "Epoch: 44/100... Training loss: 0.1057\n",
      "Epoch: 44/100... Training loss: 0.1039\n",
      "Epoch: 44/100... Training loss: 0.1059\n",
      "Epoch: 44/100... Training loss: 0.1078\n",
      "Epoch: 44/100... Training loss: 0.1029\n",
      "Epoch: 44/100... Training loss: 0.1040\n",
      "Epoch: 44/100... Training loss: 0.1069\n",
      "Epoch: 44/100... Training loss: 0.1047\n",
      "Epoch: 44/100... Training loss: 0.1036\n",
      "Epoch: 44/100... Training loss: 0.1021\n",
      "Epoch: 44/100... Training loss: 0.1014\n",
      "Epoch: 44/100... Training loss: 0.1059\n",
      "Epoch: 44/100... Training loss: 0.1070\n",
      "Epoch: 44/100... Training loss: 0.1053\n",
      "Epoch: 44/100... Training loss: 0.1096\n",
      "Epoch: 44/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1083\n",
      "Epoch: 45/100... Training loss: 0.1097\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1058\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1068\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1064\n",
      "Epoch: 45/100... Training loss: 0.1054\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1072\n",
      "Epoch: 45/100... Training loss: 0.1042\n",
      "Epoch: 45/100... Training loss: 0.1062\n",
      "Epoch: 45/100... Training loss: 0.1080\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1040\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1055\n",
      "Epoch: 45/100... Training loss: 0.1066\n",
      "Epoch: 45/100... Training loss: 0.1042\n",
      "Epoch: 45/100... Training loss: 0.1067\n",
      "Epoch: 45/100... Training loss: 0.1065\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1062\n",
      "Epoch: 45/100... Training loss: 0.1079\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1074\n",
      "Epoch: 45/100... Training loss: 0.1055\n",
      "Epoch: 45/100... Training loss: 0.1001\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1008\n",
      "Epoch: 45/100... Training loss: 0.1088\n",
      "Epoch: 45/100... Training loss: 0.1016\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1068\n",
      "Epoch: 45/100... Training loss: 0.1059\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1040\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1078\n",
      "Epoch: 45/100... Training loss: 0.1079\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1055\n",
      "Epoch: 45/100... Training loss: 0.1012\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1072\n",
      "Epoch: 45/100... Training loss: 0.1086\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1042\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1044\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1085\n",
      "Epoch: 45/100... Training loss: 0.0992\n",
      "Epoch: 45/100... Training loss: 0.1029\n",
      "Epoch: 45/100... Training loss: 0.1079\n",
      "Epoch: 45/100... Training loss: 0.1048\n",
      "Epoch: 45/100... Training loss: 0.1078\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1067\n",
      "Epoch: 45/100... Training loss: 0.0984\n",
      "Epoch: 45/100... Training loss: 0.1061\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1023\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1076\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 45/100... Training loss: 0.1055\n",
      "Epoch: 45/100... Training loss: 0.1065\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1053\n",
      "Epoch: 45/100... Training loss: 0.1053\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1047\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1086\n",
      "Epoch: 45/100... Training loss: 0.1056\n",
      "Epoch: 45/100... Training loss: 0.1062\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1076\n",
      "Epoch: 45/100... Training loss: 0.1100\n",
      "Epoch: 45/100... Training loss: 0.1064\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1007\n",
      "Epoch: 45/100... Training loss: 0.1055\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1062\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1056\n",
      "Epoch: 45/100... Training loss: 0.1090\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1061\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1058\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1053\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1059\n",
      "Epoch: 45/100... Training loss: 0.1034\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1061\n",
      "Epoch: 45/100... Training loss: 0.1053\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.1079\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1077\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1053\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1076\n",
      "Epoch: 45/100... Training loss: 0.1004\n",
      "Epoch: 45/100... Training loss: 0.1094\n",
      "Epoch: 45/100... Training loss: 0.1045\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1047\n",
      "Epoch: 45/100... Training loss: 0.1078\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1066\n",
      "Epoch: 45/100... Training loss: 0.1028\n",
      "Epoch: 45/100... Training loss: 0.1059\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1066\n",
      "Epoch: 45/100... Training loss: 0.1047\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1079\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1061\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1069\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1073\n",
      "Epoch: 45/100... Training loss: 0.1013\n",
      "Epoch: 45/100... Training loss: 0.1065\n",
      "Epoch: 45/100... Training loss: 0.1055\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1044\n",
      "Epoch: 45/100... Training loss: 0.1056\n",
      "Epoch: 45/100... Training loss: 0.1049\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1019\n",
      "Epoch: 45/100... Training loss: 0.1041\n",
      "Epoch: 45/100... Training loss: 0.1089\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1072\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1066\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1017\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1054\n",
      "Epoch: 45/100... Training loss: 0.1022\n",
      "Epoch: 45/100... Training loss: 0.1047\n",
      "Epoch: 45/100... Training loss: 0.1075\n",
      "Epoch: 45/100... Training loss: 0.1000\n",
      "Epoch: 45/100... Training loss: 0.1026\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1039\n",
      "Epoch: 45/100... Training loss: 0.1095\n",
      "Epoch: 45/100... Training loss: 0.1037\n",
      "Epoch: 45/100... Training loss: 0.1051\n",
      "Epoch: 45/100... Training loss: 0.1003\n",
      "Epoch: 45/100... Training loss: 0.1058\n",
      "Epoch: 45/100... Training loss: 0.1070\n",
      "Epoch: 45/100... Training loss: 0.1021\n",
      "Epoch: 45/100... Training loss: 0.1018\n",
      "Epoch: 45/100... Training loss: 0.1081\n",
      "Epoch: 45/100... Training loss: 0.1067\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1033\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1053\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1002\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1009\n",
      "Epoch: 45/100... Training loss: 0.1067\n",
      "Epoch: 45/100... Training loss: 0.1040\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1042\n",
      "Epoch: 45/100... Training loss: 0.1042\n",
      "Epoch: 45/100... Training loss: 0.1080\n",
      "Epoch: 45/100... Training loss: 0.1088\n",
      "Epoch: 45/100... Training loss: 0.1043\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1032\n",
      "Epoch: 45/100... Training loss: 0.1069\n",
      "Epoch: 45/100... Training loss: 0.1011\n",
      "Epoch: 45/100... Training loss: 0.1081\n",
      "Epoch: 45/100... Training loss: 0.1071\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1044\n",
      "Epoch: 45/100... Training loss: 0.1065\n",
      "Epoch: 45/100... Training loss: 0.1014\n",
      "Epoch: 45/100... Training loss: 0.1059\n",
      "Epoch: 45/100... Training loss: 0.1066\n",
      "Epoch: 45/100... Training loss: 0.1036\n",
      "Epoch: 45/100... Training loss: 0.1025\n",
      "Epoch: 45/100... Training loss: 0.1069\n",
      "Epoch: 45/100... Training loss: 0.1020\n",
      "Epoch: 45/100... Training loss: 0.1078\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1057\n",
      "Epoch: 45/100... Training loss: 0.1047\n",
      "Epoch: 45/100... Training loss: 0.1060\n",
      "Epoch: 45/100... Training loss: 0.1046\n",
      "Epoch: 45/100... Training loss: 0.1047\n",
      "Epoch: 45/100... Training loss: 0.1052\n",
      "Epoch: 45/100... Training loss: 0.1054\n",
      "Epoch: 45/100... Training loss: 0.1038\n",
      "Epoch: 45/100... Training loss: 0.1050\n",
      "Epoch: 45/100... Training loss: 0.1030\n",
      "Epoch: 45/100... Training loss: 0.1042\n",
      "Epoch: 45/100... Training loss: 0.1024\n",
      "Epoch: 45/100... Training loss: 0.1031\n",
      "Epoch: 45/100... Training loss: 0.1063\n",
      "Epoch: 45/100... Training loss: 0.1035\n",
      "Epoch: 45/100... Training loss: 0.1060\n",
      "Epoch: 45/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1077\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1111\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1063\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1083\n",
      "Epoch: 46/100... Training loss: 0.1063\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1070\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1048\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1066\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1070\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1058\n",
      "Epoch: 46/100... Training loss: 0.1051\n",
      "Epoch: 46/100... Training loss: 0.1048\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1077\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1056\n",
      "Epoch: 46/100... Training loss: 0.1078\n",
      "Epoch: 46/100... Training loss: 0.1056\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1048\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1067\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1000\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1048\n",
      "Epoch: 46/100... Training loss: 0.1051\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1057\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1058\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1062\n",
      "Epoch: 46/100... Training loss: 0.1087\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1060\n",
      "Epoch: 46/100... Training loss: 0.1059\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1076\n",
      "Epoch: 46/100... Training loss: 0.1052\n",
      "Epoch: 46/100... Training loss: 0.1051\n",
      "Epoch: 46/100... Training loss: 0.1075\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1060\n",
      "Epoch: 46/100... Training loss: 0.1065\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1039\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1067\n",
      "Epoch: 46/100... Training loss: 0.1048\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1064\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1034\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1057\n",
      "Epoch: 46/100... Training loss: 0.1010\n",
      "Epoch: 46/100... Training loss: 0.1085\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1057\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1004\n",
      "Epoch: 46/100... Training loss: 0.1092\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1013\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1064\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1001\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1023\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1073\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1007\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1059\n",
      "Epoch: 46/100... Training loss: 0.1056\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1027\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1060\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1078\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1036\n",
      "Epoch: 46/100... Training loss: 0.1079\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1019\n",
      "Epoch: 46/100... Training loss: 0.0996\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1044\n",
      "Epoch: 46/100... Training loss: 0.1008\n",
      "Epoch: 46/100... Training loss: 0.1077\n",
      "Epoch: 46/100... Training loss: 0.1076\n",
      "Epoch: 46/100... Training loss: 0.1082\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1017\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1067\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1016\n",
      "Epoch: 46/100... Training loss: 0.1095\n",
      "Epoch: 46/100... Training loss: 0.1061\n",
      "Epoch: 46/100... Training loss: 0.1055\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1069\n",
      "Epoch: 46/100... Training loss: 0.1035\n",
      "Epoch: 46/100... Training loss: 0.1024\n",
      "Epoch: 46/100... Training loss: 0.1083\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1056\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1070\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1038\n",
      "Epoch: 46/100... Training loss: 0.1063\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1044\n",
      "Epoch: 46/100... Training loss: 0.1065\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1044\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1066\n",
      "Epoch: 46/100... Training loss: 0.1015\n",
      "Epoch: 46/100... Training loss: 0.1100\n",
      "Epoch: 46/100... Training loss: 0.1070\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1063\n",
      "Epoch: 46/100... Training loss: 0.1020\n",
      "Epoch: 46/100... Training loss: 0.1048\n",
      "Epoch: 46/100... Training loss: 0.1014\n",
      "Epoch: 46/100... Training loss: 0.1066\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1053\n",
      "Epoch: 46/100... Training loss: 0.0993\n",
      "Epoch: 46/100... Training loss: 0.1058\n",
      "Epoch: 46/100... Training loss: 0.1064\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.1046\n",
      "Epoch: 46/100... Training loss: 0.1049\n",
      "Epoch: 46/100... Training loss: 0.1068\n",
      "Epoch: 46/100... Training loss: 0.1089\n",
      "Epoch: 46/100... Training loss: 0.1026\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1041\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1006\n",
      "Epoch: 46/100... Training loss: 0.1044\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1062\n",
      "Epoch: 46/100... Training loss: 0.1022\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1060\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1028\n",
      "Epoch: 46/100... Training loss: 0.1068\n",
      "Epoch: 46/100... Training loss: 0.1018\n",
      "Epoch: 46/100... Training loss: 0.1037\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1089\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1075\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1064\n",
      "Epoch: 46/100... Training loss: 0.0999\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1056\n",
      "Epoch: 46/100... Training loss: 0.1005\n",
      "Epoch: 46/100... Training loss: 0.1052\n",
      "Epoch: 46/100... Training loss: 0.1058\n",
      "Epoch: 46/100... Training loss: 0.1044\n",
      "Epoch: 46/100... Training loss: 0.1044\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1029\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1021\n",
      "Epoch: 46/100... Training loss: 0.1012\n",
      "Epoch: 46/100... Training loss: 0.1048\n",
      "Epoch: 46/100... Training loss: 0.1025\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1032\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1094\n",
      "Epoch: 46/100... Training loss: 0.1061\n",
      "Epoch: 46/100... Training loss: 0.1054\n",
      "Epoch: 46/100... Training loss: 0.1061\n",
      "Epoch: 46/100... Training loss: 0.1042\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.0991\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1047\n",
      "Epoch: 46/100... Training loss: 0.1040\n",
      "Epoch: 46/100... Training loss: 0.1069\n",
      "Epoch: 46/100... Training loss: 0.1033\n",
      "Epoch: 46/100... Training loss: 0.1043\n",
      "Epoch: 46/100... Training loss: 0.1045\n",
      "Epoch: 46/100... Training loss: 0.1031\n",
      "Epoch: 46/100... Training loss: 0.1030\n",
      "Epoch: 46/100... Training loss: 0.1050\n",
      "Epoch: 46/100... Training loss: 0.1088\n",
      "Epoch: 46/100... Training loss: 0.1069\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1081\n",
      "Epoch: 47/100... Training loss: 0.1054\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1055\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1076\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1087\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1067\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1081\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1057\n",
      "Epoch: 47/100... Training loss: 0.1046\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1048\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1063\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1035\n",
      "Epoch: 47/100... Training loss: 0.1052\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1077\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1051\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1051\n",
      "Epoch: 47/100... Training loss: 0.1055\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1061\n",
      "Epoch: 47/100... Training loss: 0.1055\n",
      "Epoch: 47/100... Training loss: 0.1063\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1057\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1051\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1067\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1066\n",
      "Epoch: 47/100... Training loss: 0.1060\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1068\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1058\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1063\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1048\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1082\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1049\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.0991\n",
      "Epoch: 47/100... Training loss: 0.1058\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1080\n",
      "Epoch: 47/100... Training loss: 0.1077\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1063\n",
      "Epoch: 47/100... Training loss: 0.1073\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1069\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1061\n",
      "Epoch: 47/100... Training loss: 0.1062\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1071\n",
      "Epoch: 47/100... Training loss: 0.1013\n",
      "Epoch: 47/100... Training loss: 0.1074\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1049\n",
      "Epoch: 47/100... Training loss: 0.1066\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1065\n",
      "Epoch: 47/100... Training loss: 0.0993\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1052\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1054\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1021\n",
      "Epoch: 47/100... Training loss: 0.1054\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1076\n",
      "Epoch: 47/100... Training loss: 0.1048\n",
      "Epoch: 47/100... Training loss: 0.1051\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1078\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1038\n",
      "Epoch: 47/100... Training loss: 0.1010\n",
      "Epoch: 47/100... Training loss: 0.1072\n",
      "Epoch: 47/100... Training loss: 0.1067\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1052\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1066\n",
      "Epoch: 47/100... Training loss: 0.1055\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1060\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1048\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1051\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1073\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1072\n",
      "Epoch: 47/100... Training loss: 0.1076\n",
      "Epoch: 47/100... Training loss: 0.1065\n",
      "Epoch: 47/100... Training loss: 0.1074\n",
      "Epoch: 47/100... Training loss: 0.1035\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1055\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1044\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1071\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1055\n",
      "Epoch: 47/100... Training loss: 0.1048\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1073\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1066\n",
      "Epoch: 47/100... Training loss: 0.1049\n",
      "Epoch: 47/100... Training loss: 0.1042\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1070\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 47/100... Training loss: 0.1048\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1047\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1018\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1035\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.1057\n",
      "Epoch: 47/100... Training loss: 0.1047\n",
      "Epoch: 47/100... Training loss: 0.1079\n",
      "Epoch: 47/100... Training loss: 0.1014\n",
      "Epoch: 47/100... Training loss: 0.1049\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1020\n",
      "Epoch: 47/100... Training loss: 0.1040\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1007\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1027\n",
      "Epoch: 47/100... Training loss: 0.1046\n",
      "Epoch: 47/100... Training loss: 0.0999\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1028\n",
      "Epoch: 47/100... Training loss: 0.1066\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1000\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1026\n",
      "Epoch: 47/100... Training loss: 0.1064\n",
      "Epoch: 47/100... Training loss: 0.1054\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1078\n",
      "Epoch: 47/100... Training loss: 0.1002\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1046\n",
      "Epoch: 47/100... Training loss: 0.1048\n",
      "Epoch: 47/100... Training loss: 0.1045\n",
      "Epoch: 47/100... Training loss: 0.1053\n",
      "Epoch: 47/100... Training loss: 0.1083\n",
      "Epoch: 47/100... Training loss: 0.1097\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1043\n",
      "Epoch: 47/100... Training loss: 0.1058\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1056\n",
      "Epoch: 47/100... Training loss: 0.1006\n",
      "Epoch: 47/100... Training loss: 0.1051\n",
      "Epoch: 47/100... Training loss: 0.0980\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1041\n",
      "Epoch: 47/100... Training loss: 0.1029\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1017\n",
      "Epoch: 47/100... Training loss: 0.1060\n",
      "Epoch: 47/100... Training loss: 0.1015\n",
      "Epoch: 47/100... Training loss: 0.1047\n",
      "Epoch: 47/100... Training loss: 0.1055\n",
      "Epoch: 47/100... Training loss: 0.1057\n",
      "Epoch: 47/100... Training loss: 0.1054\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1066\n",
      "Epoch: 47/100... Training loss: 0.1033\n",
      "Epoch: 47/100... Training loss: 0.1023\n",
      "Epoch: 47/100... Training loss: 0.1050\n",
      "Epoch: 47/100... Training loss: 0.1082\n",
      "Epoch: 47/100... Training loss: 0.1030\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1011\n",
      "Epoch: 47/100... Training loss: 0.1031\n",
      "Epoch: 47/100... Training loss: 0.1024\n",
      "Epoch: 47/100... Training loss: 0.1022\n",
      "Epoch: 47/100... Training loss: 0.1034\n",
      "Epoch: 47/100... Training loss: 0.1072\n",
      "Epoch: 47/100... Training loss: 0.1025\n",
      "Epoch: 47/100... Training loss: 0.1032\n",
      "Epoch: 47/100... Training loss: 0.1016\n",
      "Epoch: 47/100... Training loss: 0.1037\n",
      "Epoch: 47/100... Training loss: 0.1019\n",
      "Epoch: 47/100... Training loss: 0.1012\n",
      "Epoch: 47/100... Training loss: 0.1036\n",
      "Epoch: 47/100... Training loss: 0.1039\n",
      "Epoch: 47/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1065\n",
      "Epoch: 48/100... Training loss: 0.1074\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1060\n",
      "Epoch: 48/100... Training loss: 0.1089\n",
      "Epoch: 48/100... Training loss: 0.1068\n",
      "Epoch: 48/100... Training loss: 0.0990\n",
      "Epoch: 48/100... Training loss: 0.1050\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1058\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1073\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1054\n",
      "Epoch: 48/100... Training loss: 0.1062\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1034\n",
      "Epoch: 48/100... Training loss: 0.1048\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.1018\n",
      "Epoch: 48/100... Training loss: 0.1064\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1060\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1050\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1076\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.0989\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1054\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1034\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1070\n",
      "Epoch: 48/100... Training loss: 0.1054\n",
      "Epoch: 48/100... Training loss: 0.1064\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1050\n",
      "Epoch: 48/100... Training loss: 0.1060\n",
      "Epoch: 48/100... Training loss: 0.1067\n",
      "Epoch: 48/100... Training loss: 0.1059\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.0976\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1067\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1057\n",
      "Epoch: 48/100... Training loss: 0.1034\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1077\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1046\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1057\n",
      "Epoch: 48/100... Training loss: 0.1078\n",
      "Epoch: 48/100... Training loss: 0.1085\n",
      "Epoch: 48/100... Training loss: 0.1054\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1071\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1070\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1075\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1066\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1077\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1044\n",
      "Epoch: 48/100... Training loss: 0.0996\n",
      "Epoch: 48/100... Training loss: 0.1058\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1062\n",
      "Epoch: 48/100... Training loss: 0.1044\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1044\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1087\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1004\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.0992\n",
      "Epoch: 48/100... Training loss: 0.1044\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1062\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1044\n",
      "Epoch: 48/100... Training loss: 0.1059\n",
      "Epoch: 48/100... Training loss: 0.1061\n",
      "Epoch: 48/100... Training loss: 0.1060\n",
      "Epoch: 48/100... Training loss: 0.1050\n",
      "Epoch: 48/100... Training loss: 0.1056\n",
      "Epoch: 48/100... Training loss: 0.1070\n",
      "Epoch: 48/100... Training loss: 0.1050\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1048\n",
      "Epoch: 48/100... Training loss: 0.1077\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1061\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1055\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1054\n",
      "Epoch: 48/100... Training loss: 0.1054\n",
      "Epoch: 48/100... Training loss: 0.1064\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1051\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1028\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1089\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1055\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1031\n",
      "Epoch: 48/100... Training loss: 0.1060\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1053\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1060\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1014\n",
      "Epoch: 48/100... Training loss: 0.1083\n",
      "Epoch: 48/100... Training loss: 0.1059\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.0993\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1048\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1013\n",
      "Epoch: 48/100... Training loss: 0.1070\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1098\n",
      "Epoch: 48/100... Training loss: 0.1027\n",
      "Epoch: 48/100... Training loss: 0.1099\n",
      "Epoch: 48/100... Training loss: 0.1075\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1012\n",
      "Epoch: 48/100... Training loss: 0.1067\n",
      "Epoch: 48/100... Training loss: 0.1025\n",
      "Epoch: 48/100... Training loss: 0.1032\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1069\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1084\n",
      "Epoch: 48/100... Training loss: 0.1062\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.0998\n",
      "Epoch: 48/100... Training loss: 0.1076\n",
      "Epoch: 48/100... Training loss: 0.1057\n",
      "Epoch: 48/100... Training loss: 0.1059\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1071\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1030\n",
      "Epoch: 48/100... Training loss: 0.1058\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1024\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1090\n",
      "Epoch: 48/100... Training loss: 0.1020\n",
      "Epoch: 48/100... Training loss: 0.1063\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1071\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1044\n",
      "Epoch: 48/100... Training loss: 0.1006\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.1021\n",
      "Epoch: 48/100... Training loss: 0.1049\n",
      "Epoch: 48/100... Training loss: 0.1043\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1063\n",
      "Epoch: 48/100... Training loss: 0.1063\n",
      "Epoch: 48/100... Training loss: 0.1067\n",
      "Epoch: 48/100... Training loss: 0.1001\n",
      "Epoch: 48/100... Training loss: 0.1055\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1067\n",
      "Epoch: 48/100... Training loss: 0.1038\n",
      "Epoch: 48/100... Training loss: 0.1017\n",
      "Epoch: 48/100... Training loss: 0.1058\n",
      "Epoch: 48/100... Training loss: 0.1052\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.1002\n",
      "Epoch: 48/100... Training loss: 0.1063\n",
      "Epoch: 48/100... Training loss: 0.1029\n",
      "Epoch: 48/100... Training loss: 0.0997\n",
      "Epoch: 48/100... Training loss: 0.1055\n",
      "Epoch: 48/100... Training loss: 0.1077\n",
      "Epoch: 48/100... Training loss: 0.1040\n",
      "Epoch: 48/100... Training loss: 0.1045\n",
      "Epoch: 48/100... Training loss: 0.1044\n",
      "Epoch: 48/100... Training loss: 0.1065\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1008\n",
      "Epoch: 48/100... Training loss: 0.1011\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1026\n",
      "Epoch: 48/100... Training loss: 0.1035\n",
      "Epoch: 48/100... Training loss: 0.1072\n",
      "Epoch: 48/100... Training loss: 0.1010\n",
      "Epoch: 48/100... Training loss: 0.1015\n",
      "Epoch: 48/100... Training loss: 0.1016\n",
      "Epoch: 48/100... Training loss: 0.1055\n",
      "Epoch: 48/100... Training loss: 0.1033\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1066\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1042\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1019\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1058\n",
      "Epoch: 48/100... Training loss: 0.1036\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1022\n",
      "Epoch: 48/100... Training loss: 0.1037\n",
      "Epoch: 48/100... Training loss: 0.1039\n",
      "Epoch: 48/100... Training loss: 0.1009\n",
      "Epoch: 48/100... Training loss: 0.1023\n",
      "Epoch: 48/100... Training loss: 0.1047\n",
      "Epoch: 48/100... Training loss: 0.1041\n",
      "Epoch: 48/100... Training loss: 0.1074\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1054\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1057\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1045\n",
      "Epoch: 49/100... Training loss: 0.1014\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1028\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.0994\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1074\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1053\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1008\n",
      "Epoch: 49/100... Training loss: 0.1060\n",
      "Epoch: 49/100... Training loss: 0.1052\n",
      "Epoch: 49/100... Training loss: 0.1078\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1084\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1067\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.0995\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1069\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1071\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1051\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1059\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1085\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1082\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1053\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.1064\n",
      "Epoch: 49/100... Training loss: 0.1058\n",
      "Epoch: 49/100... Training loss: 0.1064\n",
      "Epoch: 49/100... Training loss: 0.1058\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.0981\n",
      "Epoch: 49/100... Training loss: 0.1076\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1051\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1028\n",
      "Epoch: 49/100... Training loss: 0.0996\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1052\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1062\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1118\n",
      "Epoch: 49/100... Training loss: 0.1077\n",
      "Epoch: 49/100... Training loss: 0.1070\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.1073\n",
      "Epoch: 49/100... Training loss: 0.1049\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1071\n",
      "Epoch: 49/100... Training loss: 0.1064\n",
      "Epoch: 49/100... Training loss: 0.1082\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1056\n",
      "Epoch: 49/100... Training loss: 0.1059\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1064\n",
      "Epoch: 49/100... Training loss: 0.0998\n",
      "Epoch: 49/100... Training loss: 0.0997\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1051\n",
      "Epoch: 49/100... Training loss: 0.1029\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1045\n",
      "Epoch: 49/100... Training loss: 0.1032\n",
      "Epoch: 49/100... Training loss: 0.1059\n",
      "Epoch: 49/100... Training loss: 0.1056\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.1069\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1089\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.1032\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1081\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 49/100... Training loss: 0.1047\n",
      "Epoch: 49/100... Training loss: 0.1026\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1062\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1032\n",
      "Epoch: 49/100... Training loss: 0.1070\n",
      "Epoch: 49/100... Training loss: 0.1063\n",
      "Epoch: 49/100... Training loss: 0.1053\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1060\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1070\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.1053\n",
      "Epoch: 49/100... Training loss: 0.1073\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1009\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1083\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1028\n",
      "Epoch: 49/100... Training loss: 0.1003\n",
      "Epoch: 49/100... Training loss: 0.1011\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1071\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1006\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1045\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1072\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1043\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1000\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1066\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.1056\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.0999\n",
      "Epoch: 49/100... Training loss: 0.0992\n",
      "Epoch: 49/100... Training loss: 0.1010\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1031\n",
      "Epoch: 49/100... Training loss: 0.1004\n",
      "Epoch: 49/100... Training loss: 0.1058\n",
      "Epoch: 49/100... Training loss: 0.1051\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1072\n",
      "Epoch: 49/100... Training loss: 0.1059\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1061\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1072\n",
      "Epoch: 49/100... Training loss: 0.1030\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.1061\n",
      "Epoch: 49/100... Training loss: 0.1062\n",
      "Epoch: 49/100... Training loss: 0.1045\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1035\n",
      "Epoch: 49/100... Training loss: 0.1068\n",
      "Epoch: 49/100... Training loss: 0.1041\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1050\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.1056\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1049\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1015\n",
      "Epoch: 49/100... Training loss: 0.1061\n",
      "Epoch: 49/100... Training loss: 0.1074\n",
      "Epoch: 49/100... Training loss: 0.1027\n",
      "Epoch: 49/100... Training loss: 0.1059\n",
      "Epoch: 49/100... Training loss: 0.1076\n",
      "Epoch: 49/100... Training loss: 0.1005\n",
      "Epoch: 49/100... Training loss: 0.1047\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1053\n",
      "Epoch: 49/100... Training loss: 0.1018\n",
      "Epoch: 49/100... Training loss: 0.1016\n",
      "Epoch: 49/100... Training loss: 0.1024\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.1021\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1073\n",
      "Epoch: 49/100... Training loss: 0.1039\n",
      "Epoch: 49/100... Training loss: 0.1049\n",
      "Epoch: 49/100... Training loss: 0.1019\n",
      "Epoch: 49/100... Training loss: 0.1051\n",
      "Epoch: 49/100... Training loss: 0.1032\n",
      "Epoch: 49/100... Training loss: 0.1044\n",
      "Epoch: 49/100... Training loss: 0.1057\n",
      "Epoch: 49/100... Training loss: 0.1033\n",
      "Epoch: 49/100... Training loss: 0.1049\n",
      "Epoch: 49/100... Training loss: 0.1042\n",
      "Epoch: 49/100... Training loss: 0.1048\n",
      "Epoch: 49/100... Training loss: 0.1060\n",
      "Epoch: 49/100... Training loss: 0.1061\n",
      "Epoch: 49/100... Training loss: 0.1040\n",
      "Epoch: 49/100... Training loss: 0.1013\n",
      "Epoch: 49/100... Training loss: 0.1081\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1037\n",
      "Epoch: 49/100... Training loss: 0.1045\n",
      "Epoch: 49/100... Training loss: 0.1023\n",
      "Epoch: 49/100... Training loss: 0.1058\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1045\n",
      "Epoch: 49/100... Training loss: 0.1055\n",
      "Epoch: 49/100... Training loss: 0.1046\n",
      "Epoch: 49/100... Training loss: 0.1038\n",
      "Epoch: 49/100... Training loss: 0.1058\n",
      "Epoch: 49/100... Training loss: 0.1051\n",
      "Epoch: 49/100... Training loss: 0.1071\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1025\n",
      "Epoch: 49/100... Training loss: 0.1034\n",
      "Epoch: 49/100... Training loss: 0.1047\n",
      "Epoch: 49/100... Training loss: 0.1036\n",
      "Epoch: 49/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1051\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.1044\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1067\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1058\n",
      "Epoch: 50/100... Training loss: 0.1073\n",
      "Epoch: 50/100... Training loss: 0.1058\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1065\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1067\n",
      "Epoch: 50/100... Training loss: 0.1084\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1054\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1065\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1047\n",
      "Epoch: 50/100... Training loss: 0.1072\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1055\n",
      "Epoch: 50/100... Training loss: 0.1086\n",
      "Epoch: 50/100... Training loss: 0.1061\n",
      "Epoch: 50/100... Training loss: 0.1121\n",
      "Epoch: 50/100... Training loss: 0.1006\n",
      "Epoch: 50/100... Training loss: 0.1072\n",
      "Epoch: 50/100... Training loss: 0.1059\n",
      "Epoch: 50/100... Training loss: 0.1049\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1072\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1061\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1057\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1057\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1042\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.0976\n",
      "Epoch: 50/100... Training loss: 0.1072\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1055\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1067\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1044\n",
      "Epoch: 50/100... Training loss: 0.0999\n",
      "Epoch: 50/100... Training loss: 0.1051\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1058\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1056\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1047\n",
      "Epoch: 50/100... Training loss: 0.1048\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1049\n",
      "Epoch: 50/100... Training loss: 0.1055\n",
      "Epoch: 50/100... Training loss: 0.1003\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1062\n",
      "Epoch: 50/100... Training loss: 0.1010\n",
      "Epoch: 50/100... Training loss: 0.1044\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1042\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1069\n",
      "Epoch: 50/100... Training loss: 0.1058\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.1063\n",
      "Epoch: 50/100... Training loss: 0.1021\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1012\n",
      "Epoch: 50/100... Training loss: 0.0984\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1042\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1037\n",
      "Epoch: 50/100... Training loss: 0.1007\n",
      "Epoch: 50/100... Training loss: 0.1059\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1054\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1067\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1067\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1048\n",
      "Epoch: 50/100... Training loss: 0.1058\n",
      "Epoch: 50/100... Training loss: 0.1050\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1025\n",
      "Epoch: 50/100... Training loss: 0.1020\n",
      "Epoch: 50/100... Training loss: 0.1051\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.0994\n",
      "Epoch: 50/100... Training loss: 0.1072\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1054\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1028\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1071\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.0991\n",
      "Epoch: 50/100... Training loss: 0.1055\n",
      "Epoch: 50/100... Training loss: 0.1023\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1042\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1059\n",
      "Epoch: 50/100... Training loss: 0.1051\n",
      "Epoch: 50/100... Training loss: 0.1065\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1058\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1004\n",
      "Epoch: 50/100... Training loss: 0.1058\n",
      "Epoch: 50/100... Training loss: 0.1062\n",
      "Epoch: 50/100... Training loss: 0.1074\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1034\n",
      "Epoch: 50/100... Training loss: 0.1074\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1058\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1017\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1048\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1015\n",
      "Epoch: 50/100... Training loss: 0.1043\n",
      "Epoch: 50/100... Training loss: 0.0986\n",
      "Epoch: 50/100... Training loss: 0.1066\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1054\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.1070\n",
      "Epoch: 50/100... Training loss: 0.1049\n",
      "Epoch: 50/100... Training loss: 0.1085\n",
      "Epoch: 50/100... Training loss: 0.1044\n",
      "Epoch: 50/100... Training loss: 0.1060\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1030\n",
      "Epoch: 50/100... Training loss: 0.1014\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1039\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1064\n",
      "Epoch: 50/100... Training loss: 0.1061\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1002\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1074\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1046\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1081\n",
      "Epoch: 50/100... Training loss: 0.1031\n",
      "Epoch: 50/100... Training loss: 0.1073\n",
      "Epoch: 50/100... Training loss: 0.1036\n",
      "Epoch: 50/100... Training loss: 0.1016\n",
      "Epoch: 50/100... Training loss: 0.1029\n",
      "Epoch: 50/100... Training loss: 0.1064\n",
      "Epoch: 50/100... Training loss: 0.0973\n",
      "Epoch: 50/100... Training loss: 0.1060\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1053\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1059\n",
      "Epoch: 50/100... Training loss: 0.1078\n",
      "Epoch: 50/100... Training loss: 0.1032\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1044\n",
      "Epoch: 50/100... Training loss: 0.1013\n",
      "Epoch: 50/100... Training loss: 0.1040\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1064\n",
      "Epoch: 50/100... Training loss: 0.1048\n",
      "Epoch: 50/100... Training loss: 0.1087\n",
      "Epoch: 50/100... Training loss: 0.1045\n",
      "Epoch: 50/100... Training loss: 0.1070\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1035\n",
      "Epoch: 50/100... Training loss: 0.1008\n",
      "Epoch: 50/100... Training loss: 0.1038\n",
      "Epoch: 50/100... Training loss: 0.1026\n",
      "Epoch: 50/100... Training loss: 0.1022\n",
      "Epoch: 50/100... Training loss: 0.1060\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1042\n",
      "Epoch: 50/100... Training loss: 0.1033\n",
      "Epoch: 50/100... Training loss: 0.1057\n",
      "Epoch: 50/100... Training loss: 0.1064\n",
      "Epoch: 50/100... Training loss: 0.1044\n",
      "Epoch: 50/100... Training loss: 0.1066\n",
      "Epoch: 50/100... Training loss: 0.1019\n",
      "Epoch: 50/100... Training loss: 0.1052\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1024\n",
      "Epoch: 50/100... Training loss: 0.1042\n",
      "Epoch: 50/100... Training loss: 0.1062\n",
      "Epoch: 50/100... Training loss: 0.1041\n",
      "Epoch: 50/100... Training loss: 0.1005\n",
      "Epoch: 50/100... Training loss: 0.1027\n",
      "Epoch: 50/100... Training loss: 0.1007\n",
      "Epoch: 50/100... Training loss: 0.1060\n",
      "Epoch: 50/100... Training loss: 0.1075\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1065\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1052\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1017\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1056\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1057\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1054\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.0995\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1052\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.0999\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1057\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1049\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1046\n",
      "Epoch: 51/100... Training loss: 0.1058\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1040\n",
      "Epoch: 51/100... Training loss: 0.1054\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1048\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1064\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1065\n",
      "Epoch: 51/100... Training loss: 0.1011\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1015\n",
      "Epoch: 51/100... Training loss: 0.1002\n",
      "Epoch: 51/100... Training loss: 0.1013\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1052\n",
      "Epoch: 51/100... Training loss: 0.0981\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1071\n",
      "Epoch: 51/100... Training loss: 0.1042\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.0983\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1051\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.0997\n",
      "Epoch: 51/100... Training loss: 0.1073\n",
      "Epoch: 51/100... Training loss: 0.0994\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1086\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1061\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1049\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1055\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1053\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1075\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1040\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.1100\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1054\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1053\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1076\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1046\n",
      "Epoch: 51/100... Training loss: 0.1048\n",
      "Epoch: 51/100... Training loss: 0.1054\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1042\n",
      "Epoch: 51/100... Training loss: 0.1003\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1051\n",
      "Epoch: 51/100... Training loss: 0.1004\n",
      "Epoch: 51/100... Training loss: 0.1051\n",
      "Epoch: 51/100... Training loss: 0.1048\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1008\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1057\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1058\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1054\n",
      "Epoch: 51/100... Training loss: 0.1048\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1051\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1052\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1063\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1065\n",
      "Epoch: 51/100... Training loss: 0.1061\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1076\n",
      "Epoch: 51/100... Training loss: 0.1060\n",
      "Epoch: 51/100... Training loss: 0.1109\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1040\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1049\n",
      "Epoch: 51/100... Training loss: 0.1001\n",
      "Epoch: 51/100... Training loss: 0.1058\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1059\n",
      "Epoch: 51/100... Training loss: 0.1051\n",
      "Epoch: 51/100... Training loss: 0.1021\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1054\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1067\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1046\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1064\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1057\n",
      "Epoch: 51/100... Training loss: 0.1069\n",
      "Epoch: 51/100... Training loss: 0.1092\n",
      "Epoch: 51/100... Training loss: 0.1066\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1034\n",
      "Epoch: 51/100... Training loss: 0.1056\n",
      "Epoch: 51/100... Training loss: 0.1052\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1027\n",
      "Epoch: 51/100... Training loss: 0.1057\n",
      "Epoch: 51/100... Training loss: 0.1052\n",
      "Epoch: 51/100... Training loss: 0.1040\n",
      "Epoch: 51/100... Training loss: 0.1048\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1058\n",
      "Epoch: 51/100... Training loss: 0.1030\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1023\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1059\n",
      "Epoch: 51/100... Training loss: 0.1022\n",
      "Epoch: 51/100... Training loss: 0.1046\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1060\n",
      "Epoch: 51/100... Training loss: 0.1006\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1060\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1052\n",
      "Epoch: 51/100... Training loss: 0.1064\n",
      "Epoch: 51/100... Training loss: 0.1040\n",
      "Epoch: 51/100... Training loss: 0.1039\n",
      "Epoch: 51/100... Training loss: 0.1049\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1055\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1009\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1020\n",
      "Epoch: 51/100... Training loss: 0.1063\n",
      "Epoch: 51/100... Training loss: 0.1036\n",
      "Epoch: 51/100... Training loss: 0.1025\n",
      "Epoch: 51/100... Training loss: 0.1045\n",
      "Epoch: 51/100... Training loss: 0.1000\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.0998\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1035\n",
      "Epoch: 51/100... Training loss: 0.1041\n",
      "Epoch: 51/100... Training loss: 0.1070\n",
      "Epoch: 51/100... Training loss: 0.1037\n",
      "Epoch: 51/100... Training loss: 0.1031\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1064\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1055\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1050\n",
      "Epoch: 51/100... Training loss: 0.1038\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1043\n",
      "Epoch: 51/100... Training loss: 0.1024\n",
      "Epoch: 51/100... Training loss: 0.1018\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1047\n",
      "Epoch: 51/100... Training loss: 0.1033\n",
      "Epoch: 51/100... Training loss: 0.1028\n",
      "Epoch: 51/100... Training loss: 0.1044\n",
      "Epoch: 51/100... Training loss: 0.1053\n",
      "Epoch: 51/100... Training loss: 0.1029\n",
      "Epoch: 51/100... Training loss: 0.1032\n",
      "Epoch: 51/100... Training loss: 0.1014\n",
      "Epoch: 51/100... Training loss: 0.1065\n",
      "Epoch: 51/100... Training loss: 0.1083\n",
      "Epoch: 51/100... Training loss: 0.1019\n",
      "Epoch: 51/100... Training loss: 0.1026\n",
      "Epoch: 51/100... Training loss: 0.1067\n",
      "Epoch: 51/100... Training loss: 0.1054\n",
      "Epoch: 51/100... Training loss: 0.1016\n",
      "Epoch: 51/100... Training loss: 0.1049\n",
      "Epoch: 51/100... Training loss: 0.1056\n",
      "Epoch: 51/100... Training loss: 0.1062\n",
      "Epoch: 51/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1055\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1048\n",
      "Epoch: 52/100... Training loss: 0.1048\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1004\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1051\n",
      "Epoch: 52/100... Training loss: 0.1090\n",
      "Epoch: 52/100... Training loss: 0.1077\n",
      "Epoch: 52/100... Training loss: 0.1048\n",
      "Epoch: 52/100... Training loss: 0.1069\n",
      "Epoch: 52/100... Training loss: 0.1045\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.1063\n",
      "Epoch: 52/100... Training loss: 0.1037\n",
      "Epoch: 52/100... Training loss: 0.0995\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1064\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1072\n",
      "Epoch: 52/100... Training loss: 0.1014\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1063\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1055\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1051\n",
      "Epoch: 52/100... Training loss: 0.1062\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1055\n",
      "Epoch: 52/100... Training loss: 0.1068\n",
      "Epoch: 52/100... Training loss: 0.1013\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1006\n",
      "Epoch: 52/100... Training loss: 0.1055\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1056\n",
      "Epoch: 52/100... Training loss: 0.1046\n",
      "Epoch: 52/100... Training loss: 0.1070\n",
      "Epoch: 52/100... Training loss: 0.1054\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.1060\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1037\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1063\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1058\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1045\n",
      "Epoch: 52/100... Training loss: 0.1067\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.0997\n",
      "Epoch: 52/100... Training loss: 0.1051\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1083\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1055\n",
      "Epoch: 52/100... Training loss: 0.1028\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1066\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.1051\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1080\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.1058\n",
      "Epoch: 52/100... Training loss: 0.1045\n",
      "Epoch: 52/100... Training loss: 0.1069\n",
      "Epoch: 52/100... Training loss: 0.1070\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1059\n",
      "Epoch: 52/100... Training loss: 0.1056\n",
      "Epoch: 52/100... Training loss: 0.1046\n",
      "Epoch: 52/100... Training loss: 0.1053\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.1068\n",
      "Epoch: 52/100... Training loss: 0.1045\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.1008\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1037\n",
      "Epoch: 52/100... Training loss: 0.1024\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1032\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1045\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1073\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1068\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1059\n",
      "Epoch: 52/100... Training loss: 0.1071\n",
      "Epoch: 52/100... Training loss: 0.1059\n",
      "Epoch: 52/100... Training loss: 0.1060\n",
      "Epoch: 52/100... Training loss: 0.1058\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.0998\n",
      "Epoch: 52/100... Training loss: 0.0999\n",
      "Epoch: 52/100... Training loss: 0.1051\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.1054\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1088\n",
      "Epoch: 52/100... Training loss: 0.1061\n",
      "Epoch: 52/100... Training loss: 0.1054\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.1046\n",
      "Epoch: 52/100... Training loss: 0.1066\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1052\n",
      "Epoch: 52/100... Training loss: 0.1079\n",
      "Epoch: 52/100... Training loss: 0.1018\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1080\n",
      "Epoch: 52/100... Training loss: 0.1071\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.1020\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.0982\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1048\n",
      "Epoch: 52/100... Training loss: 0.1034\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1049\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1000\n",
      "Epoch: 52/100... Training loss: 0.1051\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1062\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1019\n",
      "Epoch: 52/100... Training loss: 0.1016\n",
      "Epoch: 52/100... Training loss: 0.0993\n",
      "Epoch: 52/100... Training loss: 0.1015\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1042\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1010\n",
      "Epoch: 52/100... Training loss: 0.1011\n",
      "Epoch: 52/100... Training loss: 0.1072\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1073\n",
      "Epoch: 52/100... Training loss: 0.1060\n",
      "Epoch: 52/100... Training loss: 0.1002\n",
      "Epoch: 52/100... Training loss: 0.1038\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1037\n",
      "Epoch: 52/100... Training loss: 0.1075\n",
      "Epoch: 52/100... Training loss: 0.1012\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.0986\n",
      "Epoch: 52/100... Training loss: 0.1017\n",
      "Epoch: 52/100... Training loss: 0.0985\n",
      "Epoch: 52/100... Training loss: 0.1070\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1044\n",
      "Epoch: 52/100... Training loss: 0.1003\n",
      "Epoch: 52/100... Training loss: 0.1056\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1033\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1046\n",
      "Epoch: 52/100... Training loss: 0.1005\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1056\n",
      "Epoch: 52/100... Training loss: 0.1026\n",
      "Epoch: 52/100... Training loss: 0.1043\n",
      "Epoch: 52/100... Training loss: 0.1023\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1045\n",
      "Epoch: 52/100... Training loss: 0.1056\n",
      "Epoch: 52/100... Training loss: 0.1027\n",
      "Epoch: 52/100... Training loss: 0.1055\n",
      "Epoch: 52/100... Training loss: 0.1055\n",
      "Epoch: 52/100... Training loss: 0.1035\n",
      "Epoch: 52/100... Training loss: 0.1021\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.1077\n",
      "Epoch: 52/100... Training loss: 0.1047\n",
      "Epoch: 52/100... Training loss: 0.1066\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1051\n",
      "Epoch: 52/100... Training loss: 0.1051\n",
      "Epoch: 52/100... Training loss: 0.1022\n",
      "Epoch: 52/100... Training loss: 0.1041\n",
      "Epoch: 52/100... Training loss: 0.1025\n",
      "Epoch: 52/100... Training loss: 0.1007\n",
      "Epoch: 52/100... Training loss: 0.1056\n",
      "Epoch: 52/100... Training loss: 0.1036\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1059\n",
      "Epoch: 52/100... Training loss: 0.1050\n",
      "Epoch: 52/100... Training loss: 0.1031\n",
      "Epoch: 52/100... Training loss: 0.1051\n",
      "Epoch: 52/100... Training loss: 0.1037\n",
      "Epoch: 52/100... Training loss: 0.1040\n",
      "Epoch: 52/100... Training loss: 0.1009\n",
      "Epoch: 52/100... Training loss: 0.1052\n",
      "Epoch: 52/100... Training loss: 0.1052\n",
      "Epoch: 52/100... Training loss: 0.1045\n",
      "Epoch: 52/100... Training loss: 0.1037\n",
      "Epoch: 52/100... Training loss: 0.1029\n",
      "Epoch: 52/100... Training loss: 0.1039\n",
      "Epoch: 52/100... Training loss: 0.0982\n",
      "Epoch: 52/100... Training loss: 0.1030\n",
      "Epoch: 52/100... Training loss: 0.1053\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1064\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1061\n",
      "Epoch: 53/100... Training loss: 0.1043\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1073\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1048\n",
      "Epoch: 53/100... Training loss: 0.1070\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1055\n",
      "Epoch: 53/100... Training loss: 0.1067\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1057\n",
      "Epoch: 53/100... Training loss: 0.1068\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1055\n",
      "Epoch: 53/100... Training loss: 0.0995\n",
      "Epoch: 53/100... Training loss: 0.1049\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1086\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1051\n",
      "Epoch: 53/100... Training loss: 0.1048\n",
      "Epoch: 53/100... Training loss: 0.1049\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1070\n",
      "Epoch: 53/100... Training loss: 0.1042\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.0992\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.1059\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1016\n",
      "Epoch: 53/100... Training loss: 0.1059\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1074\n",
      "Epoch: 53/100... Training loss: 0.1067\n",
      "Epoch: 53/100... Training loss: 0.1058\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1091\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1062\n",
      "Epoch: 53/100... Training loss: 0.1053\n",
      "Epoch: 53/100... Training loss: 0.1002\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1048\n",
      "Epoch: 53/100... Training loss: 0.1051\n",
      "Epoch: 53/100... Training loss: 0.1046\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1054\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1049\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1057\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1073\n",
      "Epoch: 53/100... Training loss: 0.1046\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1048\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1072\n",
      "Epoch: 53/100... Training loss: 0.1010\n",
      "Epoch: 53/100... Training loss: 0.1074\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1044\n",
      "Epoch: 53/100... Training loss: 0.0999\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1087\n",
      "Epoch: 53/100... Training loss: 0.1054\n",
      "Epoch: 53/100... Training loss: 0.1065\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1048\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.0968\n",
      "Epoch: 53/100... Training loss: 0.1050\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1052\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1064\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1057\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1053\n",
      "Epoch: 53/100... Training loss: 0.1065\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1067\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1054\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1046\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1060\n",
      "Epoch: 53/100... Training loss: 0.1044\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1065\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1043\n",
      "Epoch: 53/100... Training loss: 0.1057\n",
      "Epoch: 53/100... Training loss: 0.1027\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1049\n",
      "Epoch: 53/100... Training loss: 0.1042\n",
      "Epoch: 53/100... Training loss: 0.1050\n",
      "Epoch: 53/100... Training loss: 0.1042\n",
      "Epoch: 53/100... Training loss: 0.1059\n",
      "Epoch: 53/100... Training loss: 0.0998\n",
      "Epoch: 53/100... Training loss: 0.1034\n",
      "Epoch: 53/100... Training loss: 0.1054\n",
      "Epoch: 53/100... Training loss: 0.1038\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 53/100... Training loss: 0.1043\n",
      "Epoch: 53/100... Training loss: 0.1046\n",
      "Epoch: 53/100... Training loss: 0.1022\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1043\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1060\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1006\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1035\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1067\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1050\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1015\n",
      "Epoch: 53/100... Training loss: 0.1058\n",
      "Epoch: 53/100... Training loss: 0.1014\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1004\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1059\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1058\n",
      "Epoch: 53/100... Training loss: 0.1055\n",
      "Epoch: 53/100... Training loss: 0.1052\n",
      "Epoch: 53/100... Training loss: 0.1021\n",
      "Epoch: 53/100... Training loss: 0.1043\n",
      "Epoch: 53/100... Training loss: 0.1050\n",
      "Epoch: 53/100... Training loss: 0.1017\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1024\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1005\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1057\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1041\n",
      "Epoch: 53/100... Training loss: 0.1049\n",
      "Epoch: 53/100... Training loss: 0.1082\n",
      "Epoch: 53/100... Training loss: 0.1046\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.1051\n",
      "Epoch: 53/100... Training loss: 0.1019\n",
      "Epoch: 53/100... Training loss: 0.1083\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 53/100... Training loss: 0.1030\n",
      "Epoch: 53/100... Training loss: 0.1045\n",
      "Epoch: 53/100... Training loss: 0.0983\n",
      "Epoch: 53/100... Training loss: 0.1056\n",
      "Epoch: 53/100... Training loss: 0.1064\n",
      "Epoch: 53/100... Training loss: 0.1046\n",
      "Epoch: 53/100... Training loss: 0.1059\n",
      "Epoch: 53/100... Training loss: 0.1008\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1009\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1052\n",
      "Epoch: 53/100... Training loss: 0.1012\n",
      "Epoch: 53/100... Training loss: 0.1032\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1001\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1023\n",
      "Epoch: 53/100... Training loss: 0.1036\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1018\n",
      "Epoch: 53/100... Training loss: 0.1051\n",
      "Epoch: 53/100... Training loss: 0.0993\n",
      "Epoch: 53/100... Training loss: 0.1037\n",
      "Epoch: 53/100... Training loss: 0.1020\n",
      "Epoch: 53/100... Training loss: 0.1013\n",
      "Epoch: 53/100... Training loss: 0.1048\n",
      "Epoch: 53/100... Training loss: 0.1033\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1091\n",
      "Epoch: 53/100... Training loss: 0.1046\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 53/100... Training loss: 0.1056\n",
      "Epoch: 53/100... Training loss: 0.1040\n",
      "Epoch: 53/100... Training loss: 0.1046\n",
      "Epoch: 53/100... Training loss: 0.1050\n",
      "Epoch: 53/100... Training loss: 0.1069\n",
      "Epoch: 53/100... Training loss: 0.1028\n",
      "Epoch: 53/100... Training loss: 0.1049\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1025\n",
      "Epoch: 53/100... Training loss: 0.1007\n",
      "Epoch: 53/100... Training loss: 0.1029\n",
      "Epoch: 53/100... Training loss: 0.1026\n",
      "Epoch: 53/100... Training loss: 0.1075\n",
      "Epoch: 53/100... Training loss: 0.1031\n",
      "Epoch: 53/100... Training loss: 0.1047\n",
      "Epoch: 54/100... Training loss: 0.1050\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1061\n",
      "Epoch: 54/100... Training loss: 0.1047\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1050\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1004\n",
      "Epoch: 54/100... Training loss: 0.1062\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.1061\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.1074\n",
      "Epoch: 54/100... Training loss: 0.1058\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.1064\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1052\n",
      "Epoch: 54/100... Training loss: 0.1065\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1052\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1051\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1069\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1047\n",
      "Epoch: 54/100... Training loss: 0.1019\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.0996\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1071\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1059\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1058\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1059\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1054\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1034\n",
      "Epoch: 54/100... Training loss: 0.1054\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1053\n",
      "Epoch: 54/100... Training loss: 0.1071\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1060\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.1079\n",
      "Epoch: 54/100... Training loss: 0.1047\n",
      "Epoch: 54/100... Training loss: 0.1047\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1028\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1042\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1056\n",
      "Epoch: 54/100... Training loss: 0.1053\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1042\n",
      "Epoch: 54/100... Training loss: 0.0998\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1042\n",
      "Epoch: 54/100... Training loss: 0.1012\n",
      "Epoch: 54/100... Training loss: 0.1021\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1002\n",
      "Epoch: 54/100... Training loss: 0.1016\n",
      "Epoch: 54/100... Training loss: 0.1058\n",
      "Epoch: 54/100... Training loss: 0.1057\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1055\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1058\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1039\n",
      "Epoch: 54/100... Training loss: 0.1051\n",
      "Epoch: 54/100... Training loss: 0.1071\n",
      "Epoch: 54/100... Training loss: 0.1026\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1082\n",
      "Epoch: 54/100... Training loss: 0.1048\n",
      "Epoch: 54/100... Training loss: 0.1052\n",
      "Epoch: 54/100... Training loss: 0.1059\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.0999\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.1041\n",
      "Epoch: 54/100... Training loss: 0.1059\n",
      "Epoch: 54/100... Training loss: 0.1099\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1061\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1047\n",
      "Epoch: 54/100... Training loss: 0.1027\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.0977\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1073\n",
      "Epoch: 54/100... Training loss: 0.1052\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1037\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1079\n",
      "Epoch: 54/100... Training loss: 0.1036\n",
      "Epoch: 54/100... Training loss: 0.1073\n",
      "Epoch: 54/100... Training loss: 0.1059\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1000\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.1050\n",
      "Epoch: 54/100... Training loss: 0.1080\n",
      "Epoch: 54/100... Training loss: 0.1003\n",
      "Epoch: 54/100... Training loss: 0.1031\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1059\n",
      "Epoch: 54/100... Training loss: 0.1050\n",
      "Epoch: 54/100... Training loss: 0.1060\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1048\n",
      "Epoch: 54/100... Training loss: 0.1051\n",
      "Epoch: 54/100... Training loss: 0.1008\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1071\n",
      "Epoch: 54/100... Training loss: 0.1048\n",
      "Epoch: 54/100... Training loss: 0.1052\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1053\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1056\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1035\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 54/100... Training loss: 0.1007\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1018\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1063\n",
      "Epoch: 54/100... Training loss: 0.1062\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.0989\n",
      "Epoch: 54/100... Training loss: 0.1022\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1020\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1033\n",
      "Epoch: 54/100... Training loss: 0.1070\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1045\n",
      "Epoch: 54/100... Training loss: 0.1049\n",
      "Epoch: 54/100... Training loss: 0.1009\n",
      "Epoch: 54/100... Training loss: 0.1014\n",
      "Epoch: 54/100... Training loss: 0.1081\n",
      "Epoch: 54/100... Training loss: 0.1052\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1044\n",
      "Epoch: 54/100... Training loss: 0.1053\n",
      "Epoch: 54/100... Training loss: 0.1006\n",
      "Epoch: 54/100... Training loss: 0.1066\n",
      "Epoch: 54/100... Training loss: 0.1043\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1010\n",
      "Epoch: 54/100... Training loss: 0.1059\n",
      "Epoch: 54/100... Training loss: 0.1001\n",
      "Epoch: 54/100... Training loss: 0.1055\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1042\n",
      "Epoch: 54/100... Training loss: 0.1053\n",
      "Epoch: 54/100... Training loss: 0.1059\n",
      "Epoch: 54/100... Training loss: 0.1051\n",
      "Epoch: 54/100... Training loss: 0.1024\n",
      "Epoch: 54/100... Training loss: 0.1047\n",
      "Epoch: 54/100... Training loss: 0.1075\n",
      "Epoch: 54/100... Training loss: 0.1025\n",
      "Epoch: 54/100... Training loss: 0.1046\n",
      "Epoch: 54/100... Training loss: 0.1058\n",
      "Epoch: 54/100... Training loss: 0.1011\n",
      "Epoch: 54/100... Training loss: 0.1055\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1029\n",
      "Epoch: 54/100... Training loss: 0.1015\n",
      "Epoch: 54/100... Training loss: 0.1017\n",
      "Epoch: 54/100... Training loss: 0.1023\n",
      "Epoch: 54/100... Training loss: 0.0993\n",
      "Epoch: 54/100... Training loss: 0.1053\n",
      "Epoch: 54/100... Training loss: 0.1030\n",
      "Epoch: 54/100... Training loss: 0.1069\n",
      "Epoch: 54/100... Training loss: 0.1040\n",
      "Epoch: 54/100... Training loss: 0.1032\n",
      "Epoch: 54/100... Training loss: 0.1054\n",
      "Epoch: 54/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.0991\n",
      "Epoch: 55/100... Training loss: 0.1055\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.0999\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1055\n",
      "Epoch: 55/100... Training loss: 0.1051\n",
      "Epoch: 55/100... Training loss: 0.1073\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1061\n",
      "Epoch: 55/100... Training loss: 0.1059\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1001\n",
      "Epoch: 55/100... Training loss: 0.1064\n",
      "Epoch: 55/100... Training loss: 0.1050\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1039\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1053\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1049\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.1063\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.0998\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.0996\n",
      "Epoch: 55/100... Training loss: 0.1057\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1063\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1040\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1058\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.0997\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1074\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1060\n",
      "Epoch: 55/100... Training loss: 0.1060\n",
      "Epoch: 55/100... Training loss: 0.1058\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1051\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1060\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1063\n",
      "Epoch: 55/100... Training loss: 0.1059\n",
      "Epoch: 55/100... Training loss: 0.1041\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.1030\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1066\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1051\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1005\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1059\n",
      "Epoch: 55/100... Training loss: 0.1059\n",
      "Epoch: 55/100... Training loss: 0.1040\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1080\n",
      "Epoch: 55/100... Training loss: 0.1024\n",
      "Epoch: 55/100... Training loss: 0.1061\n",
      "Epoch: 55/100... Training loss: 0.1061\n",
      "Epoch: 55/100... Training loss: 0.1065\n",
      "Epoch: 55/100... Training loss: 0.1050\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1048\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1063\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1057\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1077\n",
      "Epoch: 55/100... Training loss: 0.0988\n",
      "Epoch: 55/100... Training loss: 0.1049\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.1048\n",
      "Epoch: 55/100... Training loss: 0.1064\n",
      "Epoch: 55/100... Training loss: 0.1055\n",
      "Epoch: 55/100... Training loss: 0.1080\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1059\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1020\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.1050\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1109\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1059\n",
      "Epoch: 55/100... Training loss: 0.1048\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.1065\n",
      "Epoch: 55/100... Training loss: 0.1049\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1057\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.1027\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1004\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1061\n",
      "Epoch: 55/100... Training loss: 0.1039\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.0993\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1050\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.1051\n",
      "Epoch: 55/100... Training loss: 0.0992\n",
      "Epoch: 55/100... Training loss: 0.1074\n",
      "Epoch: 55/100... Training loss: 0.1061\n",
      "Epoch: 55/100... Training loss: 0.1037\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1046\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1014\n",
      "Epoch: 55/100... Training loss: 0.1033\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1034\n",
      "Epoch: 55/100... Training loss: 0.1048\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1048\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1016\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1057\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1050\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1032\n",
      "Epoch: 55/100... Training loss: 0.1041\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1061\n",
      "Epoch: 55/100... Training loss: 0.1050\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.1051\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.1012\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1013\n",
      "Epoch: 55/100... Training loss: 0.1051\n",
      "Epoch: 55/100... Training loss: 0.1053\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1063\n",
      "Epoch: 55/100... Training loss: 0.1046\n",
      "Epoch: 55/100... Training loss: 0.1066\n",
      "Epoch: 55/100... Training loss: 0.1018\n",
      "Epoch: 55/100... Training loss: 0.1063\n",
      "Epoch: 55/100... Training loss: 0.1067\n",
      "Epoch: 55/100... Training loss: 0.1042\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1039\n",
      "Epoch: 55/100... Training loss: 0.1083\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 55/100... Training loss: 0.1050\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.1010\n",
      "Epoch: 55/100... Training loss: 0.1008\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1019\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1058\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1035\n",
      "Epoch: 55/100... Training loss: 0.1054\n",
      "Epoch: 55/100... Training loss: 0.1006\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1045\n",
      "Epoch: 55/100... Training loss: 0.1021\n",
      "Epoch: 55/100... Training loss: 0.0990\n",
      "Epoch: 55/100... Training loss: 0.1056\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1047\n",
      "Epoch: 55/100... Training loss: 0.1067\n",
      "Epoch: 55/100... Training loss: 0.1025\n",
      "Epoch: 55/100... Training loss: 0.1011\n",
      "Epoch: 55/100... Training loss: 0.1028\n",
      "Epoch: 55/100... Training loss: 0.1003\n",
      "Epoch: 55/100... Training loss: 0.1022\n",
      "Epoch: 55/100... Training loss: 0.1044\n",
      "Epoch: 55/100... Training loss: 0.1023\n",
      "Epoch: 55/100... Training loss: 0.1038\n",
      "Epoch: 55/100... Training loss: 0.1036\n",
      "Epoch: 55/100... Training loss: 0.1031\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.1015\n",
      "Epoch: 55/100... Training loss: 0.1058\n",
      "Epoch: 55/100... Training loss: 0.1009\n",
      "Epoch: 55/100... Training loss: 0.1055\n",
      "Epoch: 55/100... Training loss: 0.1043\n",
      "Epoch: 55/100... Training loss: 0.1051\n",
      "Epoch: 55/100... Training loss: 0.1026\n",
      "Epoch: 55/100... Training loss: 0.1029\n",
      "Epoch: 55/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1047\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1077\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1055\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1077\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1077\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.1068\n",
      "Epoch: 56/100... Training loss: 0.1055\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1043\n",
      "Epoch: 56/100... Training loss: 0.1063\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1044\n",
      "Epoch: 56/100... Training loss: 0.1081\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1070\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1041\n",
      "Epoch: 56/100... Training loss: 0.1048\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1047\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1071\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.1049\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1054\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1047\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1058\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.0998\n",
      "Epoch: 56/100... Training loss: 0.1049\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1055\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1037\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.0988\n",
      "Epoch: 56/100... Training loss: 0.1056\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1057\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.0972\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1044\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1061\n",
      "Epoch: 56/100... Training loss: 0.1049\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1066\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1048\n",
      "Epoch: 56/100... Training loss: 0.1046\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1038\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1016\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1038\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1061\n",
      "Epoch: 56/100... Training loss: 0.1052\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1051\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1005\n",
      "Epoch: 56/100... Training loss: 0.1054\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1047\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1052\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1068\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1021\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1043\n",
      "Epoch: 56/100... Training loss: 0.1046\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1060\n",
      "Epoch: 56/100... Training loss: 0.1048\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.1009\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1046\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1060\n",
      "Epoch: 56/100... Training loss: 0.1024\n",
      "Epoch: 56/100... Training loss: 0.0994\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1062\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1041\n",
      "Epoch: 56/100... Training loss: 0.1077\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1044\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1052\n",
      "Epoch: 56/100... Training loss: 0.1059\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1046\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.1001\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1053\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1033\n",
      "Epoch: 56/100... Training loss: 0.1029\n",
      "Epoch: 56/100... Training loss: 0.1037\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.1059\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1037\n",
      "Epoch: 56/100... Training loss: 0.1066\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1051\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.1020\n",
      "Epoch: 56/100... Training loss: 0.1045\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1010\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1058\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1030\n",
      "Epoch: 56/100... Training loss: 0.1043\n",
      "Epoch: 56/100... Training loss: 0.1060\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1043\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1038\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1036\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1047\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1044\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1000\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1004\n",
      "Epoch: 56/100... Training loss: 0.1051\n",
      "Epoch: 56/100... Training loss: 0.1037\n",
      "Epoch: 56/100... Training loss: 0.1075\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1052\n",
      "Epoch: 56/100... Training loss: 0.1056\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1047\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.1050\n",
      "Epoch: 56/100... Training loss: 0.0993\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1007\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1053\n",
      "Epoch: 56/100... Training loss: 0.1035\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1055\n",
      "Epoch: 56/100... Training loss: 0.1011\n",
      "Epoch: 56/100... Training loss: 0.1062\n",
      "Epoch: 56/100... Training loss: 0.1049\n",
      "Epoch: 56/100... Training loss: 0.0984\n",
      "Epoch: 56/100... Training loss: 0.1037\n",
      "Epoch: 56/100... Training loss: 0.0999\n",
      "Epoch: 56/100... Training loss: 0.1006\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1061\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1037\n",
      "Epoch: 56/100... Training loss: 0.1037\n",
      "Epoch: 56/100... Training loss: 0.1028\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1054\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1027\n",
      "Epoch: 56/100... Training loss: 0.0991\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1044\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1026\n",
      "Epoch: 56/100... Training loss: 0.1013\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1034\n",
      "Epoch: 56/100... Training loss: 0.0994\n",
      "Epoch: 56/100... Training loss: 0.1041\n",
      "Epoch: 56/100... Training loss: 0.1014\n",
      "Epoch: 56/100... Training loss: 0.1060\n",
      "Epoch: 56/100... Training loss: 0.1023\n",
      "Epoch: 56/100... Training loss: 0.0996\n",
      "Epoch: 56/100... Training loss: 0.1047\n",
      "Epoch: 56/100... Training loss: 0.1076\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.1025\n",
      "Epoch: 56/100... Training loss: 0.1039\n",
      "Epoch: 56/100... Training loss: 0.1003\n",
      "Epoch: 56/100... Training loss: 0.1017\n",
      "Epoch: 56/100... Training loss: 0.1012\n",
      "Epoch: 56/100... Training loss: 0.1031\n",
      "Epoch: 56/100... Training loss: 0.1018\n",
      "Epoch: 56/100... Training loss: 0.0997\n",
      "Epoch: 56/100... Training loss: 0.1008\n",
      "Epoch: 56/100... Training loss: 0.1032\n",
      "Epoch: 56/100... Training loss: 0.1042\n",
      "Epoch: 56/100... Training loss: 0.1040\n",
      "Epoch: 56/100... Training loss: 0.1022\n",
      "Epoch: 56/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1047\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1060\n",
      "Epoch: 57/100... Training loss: 0.1069\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1050\n",
      "Epoch: 57/100... Training loss: 0.1043\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.1060\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1058\n",
      "Epoch: 57/100... Training loss: 0.1064\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1056\n",
      "Epoch: 57/100... Training loss: 0.1053\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1050\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1074\n",
      "Epoch: 57/100... Training loss: 0.0982\n",
      "Epoch: 57/100... Training loss: 0.0992\n",
      "Epoch: 57/100... Training loss: 0.1047\n",
      "Epoch: 57/100... Training loss: 0.1090\n",
      "Epoch: 57/100... Training loss: 0.1055\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1047\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1043\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1055\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1078\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1054\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1061\n",
      "Epoch: 57/100... Training loss: 0.1043\n",
      "Epoch: 57/100... Training loss: 0.1033\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.1042\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.1048\n",
      "Epoch: 57/100... Training loss: 0.1005\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.1033\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1065\n",
      "Epoch: 57/100... Training loss: 0.1062\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1035\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1059\n",
      "Epoch: 57/100... Training loss: 0.1002\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1071\n",
      "Epoch: 57/100... Training loss: 0.0991\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1043\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.1035\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1054\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1046\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.1064\n",
      "Epoch: 57/100... Training loss: 0.1046\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.0998\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1042\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1015\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1004\n",
      "Epoch: 57/100... Training loss: 0.1060\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1068\n",
      "Epoch: 57/100... Training loss: 0.1066\n",
      "Epoch: 57/100... Training loss: 0.1053\n",
      "Epoch: 57/100... Training loss: 0.1113\n",
      "Epoch: 57/100... Training loss: 0.1043\n",
      "Epoch: 57/100... Training loss: 0.1081\n",
      "Epoch: 57/100... Training loss: 0.1050\n",
      "Epoch: 57/100... Training loss: 0.1073\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1051\n",
      "Epoch: 57/100... Training loss: 0.1053\n",
      "Epoch: 57/100... Training loss: 0.1057\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1056\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1008\n",
      "Epoch: 57/100... Training loss: 0.1079\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.1089\n",
      "Epoch: 57/100... Training loss: 0.1060\n",
      "Epoch: 57/100... Training loss: 0.1056\n",
      "Epoch: 57/100... Training loss: 0.1027\n",
      "Epoch: 57/100... Training loss: 0.1063\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1039\n",
      "Epoch: 57/100... Training loss: 0.1089\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1058\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1048\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1026\n",
      "Epoch: 57/100... Training loss: 0.1046\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1068\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1042\n",
      "Epoch: 57/100... Training loss: 0.0977\n",
      "Epoch: 57/100... Training loss: 0.1007\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1053\n",
      "Epoch: 57/100... Training loss: 0.1037\n",
      "Epoch: 57/100... Training loss: 0.1029\n",
      "Epoch: 57/100... Training loss: 0.1035\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1052\n",
      "Epoch: 57/100... Training loss: 0.0999\n",
      "Epoch: 57/100... Training loss: 0.1054\n",
      "Epoch: 57/100... Training loss: 0.1012\n",
      "Epoch: 57/100... Training loss: 0.1068\n",
      "Epoch: 57/100... Training loss: 0.1043\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1020\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1065\n",
      "Epoch: 57/100... Training loss: 0.1014\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.0995\n",
      "Epoch: 57/100... Training loss: 0.1073\n",
      "Epoch: 57/100... Training loss: 0.1048\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1016\n",
      "Epoch: 57/100... Training loss: 0.1072\n",
      "Epoch: 57/100... Training loss: 0.1080\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1032\n",
      "Epoch: 57/100... Training loss: 0.1063\n",
      "Epoch: 57/100... Training loss: 0.1058\n",
      "Epoch: 57/100... Training loss: 0.1047\n",
      "Epoch: 57/100... Training loss: 0.1036\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.1011\n",
      "Epoch: 57/100... Training loss: 0.1043\n",
      "Epoch: 57/100... Training loss: 0.1060\n",
      "Epoch: 57/100... Training loss: 0.1045\n",
      "Epoch: 57/100... Training loss: 0.1034\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1059\n",
      "Epoch: 57/100... Training loss: 0.1040\n",
      "Epoch: 57/100... Training loss: 0.1038\n",
      "Epoch: 57/100... Training loss: 0.1042\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1051\n",
      "Epoch: 57/100... Training loss: 0.1035\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1050\n",
      "Epoch: 57/100... Training loss: 0.1024\n",
      "Epoch: 57/100... Training loss: 0.1049\n",
      "Epoch: 57/100... Training loss: 0.1031\n",
      "Epoch: 57/100... Training loss: 0.1009\n",
      "Epoch: 57/100... Training loss: 0.0993\n",
      "Epoch: 57/100... Training loss: 0.1018\n",
      "Epoch: 57/100... Training loss: 0.0997\n",
      "Epoch: 57/100... Training loss: 0.0986\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.1077\n",
      "Epoch: 57/100... Training loss: 0.1013\n",
      "Epoch: 57/100... Training loss: 0.1030\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1041\n",
      "Epoch: 57/100... Training loss: 0.1019\n",
      "Epoch: 57/100... Training loss: 0.1059\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1025\n",
      "Epoch: 57/100... Training loss: 0.1017\n",
      "Epoch: 57/100... Training loss: 0.1051\n",
      "Epoch: 57/100... Training loss: 0.1048\n",
      "Epoch: 57/100... Training loss: 0.1023\n",
      "Epoch: 57/100... Training loss: 0.1033\n",
      "Epoch: 57/100... Training loss: 0.1022\n",
      "Epoch: 57/100... Training loss: 0.1006\n",
      "Epoch: 57/100... Training loss: 0.1003\n",
      "Epoch: 57/100... Training loss: 0.1050\n",
      "Epoch: 57/100... Training loss: 0.1028\n",
      "Epoch: 57/100... Training loss: 0.1044\n",
      "Epoch: 57/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1053\n",
      "Epoch: 58/100... Training loss: 0.1048\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1049\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.0990\n",
      "Epoch: 58/100... Training loss: 0.1045\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1051\n",
      "Epoch: 58/100... Training loss: 0.1063\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.0996\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1075\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.1051\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1044\n",
      "Epoch: 58/100... Training loss: 0.1045\n",
      "Epoch: 58/100... Training loss: 0.0988\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1049\n",
      "Epoch: 58/100... Training loss: 0.1038\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.1049\n",
      "Epoch: 58/100... Training loss: 0.1053\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.1049\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1062\n",
      "Epoch: 58/100... Training loss: 0.1077\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1064\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1064\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1059\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.1044\n",
      "Epoch: 58/100... Training loss: 0.1056\n",
      "Epoch: 58/100... Training loss: 0.1050\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1069\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.1058\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1046\n",
      "Epoch: 58/100... Training loss: 0.1035\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1058\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1045\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1062\n",
      "Epoch: 58/100... Training loss: 0.0979\n",
      "Epoch: 58/100... Training loss: 0.1068\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1007\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1055\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1052\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.0999\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1040\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1038\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1046\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1003\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1048\n",
      "Epoch: 58/100... Training loss: 0.1065\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1056\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1013\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1082\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1044\n",
      "Epoch: 58/100... Training loss: 0.1072\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1019\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1044\n",
      "Epoch: 58/100... Training loss: 0.1066\n",
      "Epoch: 58/100... Training loss: 0.1046\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1036\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1052\n",
      "Epoch: 58/100... Training loss: 0.1028\n",
      "Epoch: 58/100... Training loss: 0.1070\n",
      "Epoch: 58/100... Training loss: 0.1044\n",
      "Epoch: 58/100... Training loss: 0.1011\n",
      "Epoch: 58/100... Training loss: 0.1069\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.0997\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1043\n",
      "Epoch: 58/100... Training loss: 0.1022\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.1052\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1051\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1055\n",
      "Epoch: 58/100... Training loss: 0.1055\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1002\n",
      "Epoch: 58/100... Training loss: 0.1038\n",
      "Epoch: 58/100... Training loss: 0.1060\n",
      "Epoch: 58/100... Training loss: 0.1058\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1012\n",
      "Epoch: 58/100... Training loss: 0.1046\n",
      "Epoch: 58/100... Training loss: 0.1053\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1009\n",
      "Epoch: 58/100... Training loss: 0.1030\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1063\n",
      "Epoch: 58/100... Training loss: 0.1058\n",
      "Epoch: 58/100... Training loss: 0.1067\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1023\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1050\n",
      "Epoch: 58/100... Training loss: 0.1049\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1026\n",
      "Epoch: 58/100... Training loss: 0.1037\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1043\n",
      "Epoch: 58/100... Training loss: 0.1059\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1045\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1038\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.1050\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1035\n",
      "Epoch: 58/100... Training loss: 0.1050\n",
      "Epoch: 58/100... Training loss: 0.1064\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1015\n",
      "Epoch: 58/100... Training loss: 0.1045\n",
      "Epoch: 58/100... Training loss: 0.0994\n",
      "Epoch: 58/100... Training loss: 0.1001\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.1049\n",
      "Epoch: 58/100... Training loss: 0.1020\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1031\n",
      "Epoch: 58/100... Training loss: 0.1047\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1043\n",
      "Epoch: 58/100... Training loss: 0.1046\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.0995\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1043\n",
      "Epoch: 58/100... Training loss: 0.1039\n",
      "Epoch: 58/100... Training loss: 0.1044\n",
      "Epoch: 58/100... Training loss: 0.1021\n",
      "Epoch: 58/100... Training loss: 0.1000\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1077\n",
      "Epoch: 58/100... Training loss: 0.1066\n",
      "Epoch: 58/100... Training loss: 0.1017\n",
      "Epoch: 58/100... Training loss: 0.1041\n",
      "Epoch: 58/100... Training loss: 0.1052\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1025\n",
      "Epoch: 58/100... Training loss: 0.1055\n",
      "Epoch: 58/100... Training loss: 0.1033\n",
      "Epoch: 58/100... Training loss: 0.0998\n",
      "Epoch: 58/100... Training loss: 0.0989\n",
      "Epoch: 58/100... Training loss: 0.1032\n",
      "Epoch: 58/100... Training loss: 0.1034\n",
      "Epoch: 58/100... Training loss: 0.1005\n",
      "Epoch: 58/100... Training loss: 0.1050\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.1027\n",
      "Epoch: 58/100... Training loss: 0.1035\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1008\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1051\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1024\n",
      "Epoch: 58/100... Training loss: 0.1042\n",
      "Epoch: 58/100... Training loss: 0.1064\n",
      "Epoch: 58/100... Training loss: 0.1043\n",
      "Epoch: 58/100... Training loss: 0.0992\n",
      "Epoch: 58/100... Training loss: 0.1018\n",
      "Epoch: 58/100... Training loss: 0.1010\n",
      "Epoch: 58/100... Training loss: 0.1016\n",
      "Epoch: 58/100... Training loss: 0.1050\n",
      "Epoch: 58/100... Training loss: 0.1049\n",
      "Epoch: 58/100... Training loss: 0.0993\n",
      "Epoch: 58/100... Training loss: 0.1069\n",
      "Epoch: 58/100... Training loss: 0.1054\n",
      "Epoch: 58/100... Training loss: 0.1077\n",
      "Epoch: 58/100... Training loss: 0.1029\n",
      "Epoch: 58/100... Training loss: 0.1006\n",
      "Epoch: 58/100... Training loss: 0.1014\n",
      "Epoch: 58/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.0991\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1051\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1045\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1018\n",
      "Epoch: 59/100... Training loss: 0.1015\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.1044\n",
      "Epoch: 59/100... Training loss: 0.1045\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1045\n",
      "Epoch: 59/100... Training loss: 0.1049\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1063\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.0994\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.0990\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.1056\n",
      "Epoch: 59/100... Training loss: 0.1056\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.0996\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.1049\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.1057\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1056\n",
      "Epoch: 59/100... Training loss: 0.1054\n",
      "Epoch: 59/100... Training loss: 0.1048\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.1047\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1045\n",
      "Epoch: 59/100... Training loss: 0.1054\n",
      "Epoch: 59/100... Training loss: 0.1041\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1071\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1043\n",
      "Epoch: 59/100... Training loss: 0.1053\n",
      "Epoch: 59/100... Training loss: 0.1027\n",
      "Epoch: 59/100... Training loss: 0.1064\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1001\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1053\n",
      "Epoch: 59/100... Training loss: 0.1052\n",
      "Epoch: 59/100... Training loss: 0.1065\n",
      "Epoch: 59/100... Training loss: 0.0992\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.0959\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1060\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1049\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.1052\n",
      "Epoch: 59/100... Training loss: 0.1071\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.0970\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1083\n",
      "Epoch: 59/100... Training loss: 0.1060\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1045\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1074\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1064\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1037\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1031\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1058\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.1048\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1065\n",
      "Epoch: 59/100... Training loss: 0.1062\n",
      "Epoch: 59/100... Training loss: 0.1060\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.1010\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1055\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1055\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1064\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1067\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1043\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1009\n",
      "Epoch: 59/100... Training loss: 0.1003\n",
      "Epoch: 59/100... Training loss: 0.1052\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.1080\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.1071\n",
      "Epoch: 59/100... Training loss: 0.1045\n",
      "Epoch: 59/100... Training loss: 0.1043\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.1069\n",
      "Epoch: 59/100... Training loss: 0.0986\n",
      "Epoch: 59/100... Training loss: 0.1019\n",
      "Epoch: 59/100... Training loss: 0.1063\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1054\n",
      "Epoch: 59/100... Training loss: 0.1012\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1070\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.0982\n",
      "Epoch: 59/100... Training loss: 0.1029\n",
      "Epoch: 59/100... Training loss: 0.1041\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1042\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1041\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1045\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.1054\n",
      "Epoch: 59/100... Training loss: 0.1044\n",
      "Epoch: 59/100... Training loss: 0.1044\n",
      "Epoch: 59/100... Training loss: 0.1043\n",
      "Epoch: 59/100... Training loss: 0.1046\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.1061\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1045\n",
      "Epoch: 59/100... Training loss: 0.1032\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1044\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1044\n",
      "Epoch: 59/100... Training loss: 0.1022\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1061\n",
      "Epoch: 59/100... Training loss: 0.1057\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.1045\n",
      "Epoch: 59/100... Training loss: 0.1039\n",
      "Epoch: 59/100... Training loss: 0.1038\n",
      "Epoch: 59/100... Training loss: 0.1055\n",
      "Epoch: 59/100... Training loss: 0.1043\n",
      "Epoch: 59/100... Training loss: 0.1049\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1049\n",
      "Epoch: 59/100... Training loss: 0.1011\n",
      "Epoch: 59/100... Training loss: 0.1005\n",
      "Epoch: 59/100... Training loss: 0.1016\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1048\n",
      "Epoch: 59/100... Training loss: 0.1025\n",
      "Epoch: 59/100... Training loss: 0.1033\n",
      "Epoch: 59/100... Training loss: 0.1062\n",
      "Epoch: 59/100... Training loss: 0.1057\n",
      "Epoch: 59/100... Training loss: 0.1034\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1002\n",
      "Epoch: 59/100... Training loss: 0.1065\n",
      "Epoch: 59/100... Training loss: 0.1030\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1028\n",
      "Epoch: 59/100... Training loss: 0.0993\n",
      "Epoch: 59/100... Training loss: 0.1023\n",
      "Epoch: 59/100... Training loss: 0.1035\n",
      "Epoch: 59/100... Training loss: 0.1020\n",
      "Epoch: 59/100... Training loss: 0.1040\n",
      "Epoch: 59/100... Training loss: 0.1004\n",
      "Epoch: 59/100... Training loss: 0.1041\n",
      "Epoch: 59/100... Training loss: 0.1066\n",
      "Epoch: 59/100... Training loss: 0.1024\n",
      "Epoch: 59/100... Training loss: 0.1013\n",
      "Epoch: 59/100... Training loss: 0.1007\n",
      "Epoch: 59/100... Training loss: 0.1006\n",
      "Epoch: 59/100... Training loss: 0.1044\n",
      "Epoch: 59/100... Training loss: 0.1047\n",
      "Epoch: 59/100... Training loss: 0.1036\n",
      "Epoch: 59/100... Training loss: 0.1053\n",
      "Epoch: 59/100... Training loss: 0.1017\n",
      "Epoch: 59/100... Training loss: 0.1008\n",
      "Epoch: 59/100... Training loss: 0.1021\n",
      "Epoch: 59/100... Training loss: 0.1044\n",
      "Epoch: 59/100... Training loss: 0.1046\n",
      "Epoch: 59/100... Training loss: 0.1026\n",
      "Epoch: 59/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1054\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1041\n",
      "Epoch: 60/100... Training loss: 0.1077\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1051\n",
      "Epoch: 60/100... Training loss: 0.1052\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1043\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1038\n",
      "Epoch: 60/100... Training loss: 0.1082\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1044\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1041\n",
      "Epoch: 60/100... Training loss: 0.1042\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1006\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.1063\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1061\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1043\n",
      "Epoch: 60/100... Training loss: 0.1063\n",
      "Epoch: 60/100... Training loss: 0.1049\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1072\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.1043\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1044\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.1044\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1052\n",
      "Epoch: 60/100... Training loss: 0.1073\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1046\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1050\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1009\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1041\n",
      "Epoch: 60/100... Training loss: 0.0996\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1048\n",
      "Epoch: 60/100... Training loss: 0.1061\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.1048\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1070\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.0987\n",
      "Epoch: 60/100... Training loss: 0.1061\n",
      "Epoch: 60/100... Training loss: 0.1065\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1071\n",
      "Epoch: 60/100... Training loss: 0.1004\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1033\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.1010\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1049\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1053\n",
      "Epoch: 60/100... Training loss: 0.1044\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.0988\n",
      "Epoch: 60/100... Training loss: 0.1000\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1015\n",
      "Epoch: 60/100... Training loss: 0.1065\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1072\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1049\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1038\n",
      "Epoch: 60/100... Training loss: 0.1050\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.0980\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1050\n",
      "Epoch: 60/100... Training loss: 0.1054\n",
      "Epoch: 60/100... Training loss: 0.1046\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1058\n",
      "Epoch: 60/100... Training loss: 0.1065\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1052\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.0990\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.1044\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1083\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1028\n",
      "Epoch: 60/100... Training loss: 0.1038\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1047\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1043\n",
      "Epoch: 60/100... Training loss: 0.1007\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1011\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1059\n",
      "Epoch: 60/100... Training loss: 0.1056\n",
      "Epoch: 60/100... Training loss: 0.1056\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1058\n",
      "Epoch: 60/100... Training loss: 0.1047\n",
      "Epoch: 60/100... Training loss: 0.1072\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1036\n",
      "Epoch: 60/100... Training loss: 0.1041\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1044\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1038\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1055\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.0997\n",
      "Epoch: 60/100... Training loss: 0.0999\n",
      "Epoch: 60/100... Training loss: 0.1055\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1065\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1049\n",
      "Epoch: 60/100... Training loss: 0.1063\n",
      "Epoch: 60/100... Training loss: 0.1054\n",
      "Epoch: 60/100... Training loss: 0.1047\n",
      "Epoch: 60/100... Training loss: 0.1050\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1002\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.1048\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1060\n",
      "Epoch: 60/100... Training loss: 0.1030\n",
      "Epoch: 60/100... Training loss: 0.1050\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1014\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1053\n",
      "Epoch: 60/100... Training loss: 0.1051\n",
      "Epoch: 60/100... Training loss: 0.1025\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.1020\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.1047\n",
      "Epoch: 60/100... Training loss: 0.1019\n",
      "Epoch: 60/100... Training loss: 0.1076\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1042\n",
      "Epoch: 60/100... Training loss: 0.1033\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1054\n",
      "Epoch: 60/100... Training loss: 0.0992\n",
      "Epoch: 60/100... Training loss: 0.1001\n",
      "Epoch: 60/100... Training loss: 0.1042\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1045\n",
      "Epoch: 60/100... Training loss: 0.0993\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1013\n",
      "Epoch: 60/100... Training loss: 0.1049\n",
      "Epoch: 60/100... Training loss: 0.1022\n",
      "Epoch: 60/100... Training loss: 0.1016\n",
      "Epoch: 60/100... Training loss: 0.1058\n",
      "Epoch: 60/100... Training loss: 0.1040\n",
      "Epoch: 60/100... Training loss: 0.1048\n",
      "Epoch: 60/100... Training loss: 0.1037\n",
      "Epoch: 60/100... Training loss: 0.1034\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1060\n",
      "Epoch: 60/100... Training loss: 0.1054\n",
      "Epoch: 60/100... Training loss: 0.1053\n",
      "Epoch: 60/100... Training loss: 0.1064\n",
      "Epoch: 60/100... Training loss: 0.1012\n",
      "Epoch: 60/100... Training loss: 0.1059\n",
      "Epoch: 60/100... Training loss: 0.1029\n",
      "Epoch: 60/100... Training loss: 0.1038\n",
      "Epoch: 60/100... Training loss: 0.1005\n",
      "Epoch: 60/100... Training loss: 0.1026\n",
      "Epoch: 60/100... Training loss: 0.1018\n",
      "Epoch: 60/100... Training loss: 0.1048\n",
      "Epoch: 60/100... Training loss: 0.1003\n",
      "Epoch: 60/100... Training loss: 0.1017\n",
      "Epoch: 60/100... Training loss: 0.1008\n",
      "Epoch: 60/100... Training loss: 0.0970\n",
      "Epoch: 60/100... Training loss: 0.1047\n",
      "Epoch: 60/100... Training loss: 0.1024\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 60/100... Training loss: 0.1080\n",
      "Epoch: 60/100... Training loss: 0.1021\n",
      "Epoch: 60/100... Training loss: 0.1051\n",
      "Epoch: 60/100... Training loss: 0.0998\n",
      "Epoch: 60/100... Training loss: 0.1032\n",
      "Epoch: 60/100... Training loss: 0.1035\n",
      "Epoch: 60/100... Training loss: 0.1065\n",
      "Epoch: 60/100... Training loss: 0.1031\n",
      "Epoch: 60/100... Training loss: 0.1027\n",
      "Epoch: 60/100... Training loss: 0.1062\n",
      "Epoch: 60/100... Training loss: 0.1023\n",
      "Epoch: 60/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1056\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.0977\n",
      "Epoch: 61/100... Training loss: 0.1059\n",
      "Epoch: 61/100... Training loss: 0.0995\n",
      "Epoch: 61/100... Training loss: 0.1078\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1008\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1053\n",
      "Epoch: 61/100... Training loss: 0.1044\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1041\n",
      "Epoch: 61/100... Training loss: 0.1053\n",
      "Epoch: 61/100... Training loss: 0.0983\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1052\n",
      "Epoch: 61/100... Training loss: 0.0969\n",
      "Epoch: 61/100... Training loss: 0.1053\n",
      "Epoch: 61/100... Training loss: 0.1049\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1049\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1071\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1046\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1035\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1076\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1062\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1065\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1075\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1000\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1075\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1053\n",
      "Epoch: 61/100... Training loss: 0.0992\n",
      "Epoch: 61/100... Training loss: 0.0990\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1059\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1044\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1050\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1041\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1058\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1044\n",
      "Epoch: 61/100... Training loss: 0.1020\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1037\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.1067\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1058\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1018\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1053\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.0997\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1009\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1051\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.0991\n",
      "Epoch: 61/100... Training loss: 0.1067\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1059\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1050\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1010\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1041\n",
      "Epoch: 61/100... Training loss: 0.0985\n",
      "Epoch: 61/100... Training loss: 0.1051\n",
      "Epoch: 61/100... Training loss: 0.1046\n",
      "Epoch: 61/100... Training loss: 0.1023\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1042\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1005\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1068\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1045\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1012\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1048\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.1048\n",
      "Epoch: 61/100... Training loss: 0.1055\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1065\n",
      "Epoch: 61/100... Training loss: 0.1047\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.1060\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1043\n",
      "Epoch: 61/100... Training loss: 0.1046\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1050\n",
      "Epoch: 61/100... Training loss: 0.1041\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1050\n",
      "Epoch: 61/100... Training loss: 0.1030\n",
      "Epoch: 61/100... Training loss: 0.1048\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1042\n",
      "Epoch: 61/100... Training loss: 0.1045\n",
      "Epoch: 61/100... Training loss: 0.1035\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1016\n",
      "Epoch: 61/100... Training loss: 0.1047\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1065\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.1035\n",
      "Epoch: 61/100... Training loss: 0.0991\n",
      "Epoch: 61/100... Training loss: 0.1057\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1042\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1055\n",
      "Epoch: 61/100... Training loss: 0.1051\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1014\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1067\n",
      "Epoch: 61/100... Training loss: 0.1007\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1055\n",
      "Epoch: 61/100... Training loss: 0.1050\n",
      "Epoch: 61/100... Training loss: 0.1037\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.1060\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1006\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1042\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1049\n",
      "Epoch: 61/100... Training loss: 0.1041\n",
      "Epoch: 61/100... Training loss: 0.1031\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1002\n",
      "Epoch: 61/100... Training loss: 0.1041\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1011\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1045\n",
      "Epoch: 61/100... Training loss: 0.1058\n",
      "Epoch: 61/100... Training loss: 0.1032\n",
      "Epoch: 61/100... Training loss: 0.1027\n",
      "Epoch: 61/100... Training loss: 0.1083\n",
      "Epoch: 61/100... Training loss: 0.1048\n",
      "Epoch: 61/100... Training loss: 0.1045\n",
      "Epoch: 61/100... Training loss: 0.0989\n",
      "Epoch: 61/100... Training loss: 0.1057\n",
      "Epoch: 61/100... Training loss: 0.0996\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1019\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1061\n",
      "Epoch: 61/100... Training loss: 0.1037\n",
      "Epoch: 61/100... Training loss: 0.1038\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1035\n",
      "Epoch: 61/100... Training loss: 0.1029\n",
      "Epoch: 61/100... Training loss: 0.1017\n",
      "Epoch: 61/100... Training loss: 0.1001\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1025\n",
      "Epoch: 61/100... Training loss: 0.1047\n",
      "Epoch: 61/100... Training loss: 0.1054\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1050\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1028\n",
      "Epoch: 61/100... Training loss: 0.1064\n",
      "Epoch: 61/100... Training loss: 0.1040\n",
      "Epoch: 61/100... Training loss: 0.1035\n",
      "Epoch: 61/100... Training loss: 0.1015\n",
      "Epoch: 61/100... Training loss: 0.1049\n",
      "Epoch: 61/100... Training loss: 0.1022\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 61/100... Training loss: 0.1036\n",
      "Epoch: 61/100... Training loss: 0.1080\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1039\n",
      "Epoch: 61/100... Training loss: 0.1072\n",
      "Epoch: 61/100... Training loss: 0.1041\n",
      "Epoch: 61/100... Training loss: 0.1013\n",
      "Epoch: 61/100... Training loss: 0.1046\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1026\n",
      "Epoch: 61/100... Training loss: 0.1044\n",
      "Epoch: 61/100... Training loss: 0.1004\n",
      "Epoch: 61/100... Training loss: 0.1003\n",
      "Epoch: 61/100... Training loss: 0.1067\n",
      "Epoch: 61/100... Training loss: 0.1024\n",
      "Epoch: 61/100... Training loss: 0.1033\n",
      "Epoch: 61/100... Training loss: 0.1021\n",
      "Epoch: 61/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1047\n",
      "Epoch: 62/100... Training loss: 0.1043\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1052\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.1036\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.0953\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.0992\n",
      "Epoch: 62/100... Training loss: 0.1038\n",
      "Epoch: 62/100... Training loss: 0.1043\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1048\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1042\n",
      "Epoch: 62/100... Training loss: 0.1068\n",
      "Epoch: 62/100... Training loss: 0.1049\n",
      "Epoch: 62/100... Training loss: 0.0966\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1038\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1047\n",
      "Epoch: 62/100... Training loss: 0.1040\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1047\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1044\n",
      "Epoch: 62/100... Training loss: 0.1044\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1049\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1049\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1036\n",
      "Epoch: 62/100... Training loss: 0.1053\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1068\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.1059\n",
      "Epoch: 62/100... Training loss: 0.1049\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1040\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1043\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.0998\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1039\n",
      "Epoch: 62/100... Training loss: 0.1047\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1043\n",
      "Epoch: 62/100... Training loss: 0.0984\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1042\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1042\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1047\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1084\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1037\n",
      "Epoch: 62/100... Training loss: 0.1038\n",
      "Epoch: 62/100... Training loss: 0.1056\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1072\n",
      "Epoch: 62/100... Training loss: 0.1081\n",
      "Epoch: 62/100... Training loss: 0.1055\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.1050\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.1044\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1073\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.0996\n",
      "Epoch: 62/100... Training loss: 0.1016\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1037\n",
      "Epoch: 62/100... Training loss: 0.1003\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1062\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1070\n",
      "Epoch: 62/100... Training loss: 0.1061\n",
      "Epoch: 62/100... Training loss: 0.1051\n",
      "Epoch: 62/100... Training loss: 0.1049\n",
      "Epoch: 62/100... Training loss: 0.1056\n",
      "Epoch: 62/100... Training loss: 0.1040\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1058\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1059\n",
      "Epoch: 62/100... Training loss: 0.1070\n",
      "Epoch: 62/100... Training loss: 0.0966\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1048\n",
      "Epoch: 62/100... Training loss: 0.1065\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1038\n",
      "Epoch: 62/100... Training loss: 0.1037\n",
      "Epoch: 62/100... Training loss: 0.0991\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.0997\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1059\n",
      "Epoch: 62/100... Training loss: 0.1047\n",
      "Epoch: 62/100... Training loss: 0.1047\n",
      "Epoch: 62/100... Training loss: 0.1025\n",
      "Epoch: 62/100... Training loss: 0.1038\n",
      "Epoch: 62/100... Training loss: 0.1062\n",
      "Epoch: 62/100... Training loss: 0.1054\n",
      "Epoch: 62/100... Training loss: 0.1028\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.0993\n",
      "Epoch: 62/100... Training loss: 0.1062\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.0994\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1058\n",
      "Epoch: 62/100... Training loss: 0.1038\n",
      "Epoch: 62/100... Training loss: 0.0995\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.0976\n",
      "Epoch: 62/100... Training loss: 0.1042\n",
      "Epoch: 62/100... Training loss: 0.1005\n",
      "Epoch: 62/100... Training loss: 0.1062\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1059\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1052\n",
      "Epoch: 62/100... Training loss: 0.1037\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.0986\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1043\n",
      "Epoch: 62/100... Training loss: 0.1062\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1076\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1059\n",
      "Epoch: 62/100... Training loss: 0.1045\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1032\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1059\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1023\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1014\n",
      "Epoch: 62/100... Training loss: 0.1013\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1043\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1029\n",
      "Epoch: 62/100... Training loss: 0.1041\n",
      "Epoch: 62/100... Training loss: 0.1056\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1034\n",
      "Epoch: 62/100... Training loss: 0.1000\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1017\n",
      "Epoch: 62/100... Training loss: 0.1015\n",
      "Epoch: 62/100... Training loss: 0.1024\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.1030\n",
      "Epoch: 62/100... Training loss: 0.1042\n",
      "Epoch: 62/100... Training loss: 0.1055\n",
      "Epoch: 62/100... Training loss: 0.1044\n",
      "Epoch: 62/100... Training loss: 0.1051\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1060\n",
      "Epoch: 62/100... Training loss: 0.1035\n",
      "Epoch: 62/100... Training loss: 0.1022\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.1019\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1008\n",
      "Epoch: 62/100... Training loss: 0.1033\n",
      "Epoch: 62/100... Training loss: 0.1021\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1011\n",
      "Epoch: 62/100... Training loss: 0.1044\n",
      "Epoch: 62/100... Training loss: 0.1047\n",
      "Epoch: 62/100... Training loss: 0.1001\n",
      "Epoch: 62/100... Training loss: 0.1010\n",
      "Epoch: 62/100... Training loss: 0.1067\n",
      "Epoch: 62/100... Training loss: 0.1031\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1006\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1058\n",
      "Epoch: 62/100... Training loss: 0.1009\n",
      "Epoch: 62/100... Training loss: 0.1018\n",
      "Epoch: 62/100... Training loss: 0.1039\n",
      "Epoch: 62/100... Training loss: 0.1063\n",
      "Epoch: 62/100... Training loss: 0.1027\n",
      "Epoch: 62/100... Training loss: 0.1020\n",
      "Epoch: 62/100... Training loss: 0.0999\n",
      "Epoch: 62/100... Training loss: 0.1002\n",
      "Epoch: 62/100... Training loss: 0.1026\n",
      "Epoch: 62/100... Training loss: 0.1046\n",
      "Epoch: 62/100... Training loss: 0.1004\n",
      "Epoch: 62/100... Training loss: 0.1012\n",
      "Epoch: 62/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1048\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.0984\n",
      "Epoch: 63/100... Training loss: 0.1042\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1054\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1033\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1049\n",
      "Epoch: 63/100... Training loss: 0.1053\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1045\n",
      "Epoch: 63/100... Training loss: 0.1068\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1038\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1056\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1041\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1050\n",
      "Epoch: 63/100... Training loss: 0.1041\n",
      "Epoch: 63/100... Training loss: 0.1040\n",
      "Epoch: 63/100... Training loss: 0.1035\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1047\n",
      "Epoch: 63/100... Training loss: 0.1048\n",
      "Epoch: 63/100... Training loss: 0.1059\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.0972\n",
      "Epoch: 63/100... Training loss: 0.1058\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1045\n",
      "Epoch: 63/100... Training loss: 0.1011\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1037\n",
      "Epoch: 63/100... Training loss: 0.1040\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.0977\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.1061\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1046\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.1066\n",
      "Epoch: 63/100... Training loss: 0.0981\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.1064\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1006\n",
      "Epoch: 63/100... Training loss: 0.0985\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1051\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.0992\n",
      "Epoch: 63/100... Training loss: 0.1042\n",
      "Epoch: 63/100... Training loss: 0.1041\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.0990\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1039\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.1041\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.0982\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1046\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.1052\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1035\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1037\n",
      "Epoch: 63/100... Training loss: 0.1056\n",
      "Epoch: 63/100... Training loss: 0.1052\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1062\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1048\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1012\n",
      "Epoch: 63/100... Training loss: 0.1058\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1037\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.1051\n",
      "Epoch: 63/100... Training loss: 0.1066\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1009\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1035\n",
      "Epoch: 63/100... Training loss: 0.1021\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.0996\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1056\n",
      "Epoch: 63/100... Training loss: 0.1066\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.0981\n",
      "Epoch: 63/100... Training loss: 0.0997\n",
      "Epoch: 63/100... Training loss: 0.1058\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.0971\n",
      "Epoch: 63/100... Training loss: 0.1041\n",
      "Epoch: 63/100... Training loss: 0.1046\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1038\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.0983\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1000\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1025\n",
      "Epoch: 63/100... Training loss: 0.1037\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.0989\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1051\n",
      "Epoch: 63/100... Training loss: 0.1041\n",
      "Epoch: 63/100... Training loss: 0.1035\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.0987\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1038\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.0989\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1027\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.1054\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1039\n",
      "Epoch: 63/100... Training loss: 0.1072\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.1061\n",
      "Epoch: 63/100... Training loss: 0.1053\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1051\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.1037\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1042\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 63/100... Training loss: 0.1046\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.1046\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1046\n",
      "Epoch: 63/100... Training loss: 0.1069\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1014\n",
      "Epoch: 63/100... Training loss: 0.1008\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.0980\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1002\n",
      "Epoch: 63/100... Training loss: 0.1007\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1050\n",
      "Epoch: 63/100... Training loss: 0.1041\n",
      "Epoch: 63/100... Training loss: 0.1039\n",
      "Epoch: 63/100... Training loss: 0.0998\n",
      "Epoch: 63/100... Training loss: 0.1068\n",
      "Epoch: 63/100... Training loss: 0.1022\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1052\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1037\n",
      "Epoch: 63/100... Training loss: 0.1060\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1010\n",
      "Epoch: 63/100... Training loss: 0.1001\n",
      "Epoch: 63/100... Training loss: 0.1020\n",
      "Epoch: 63/100... Training loss: 0.1004\n",
      "Epoch: 63/100... Training loss: 0.1032\n",
      "Epoch: 63/100... Training loss: 0.1061\n",
      "Epoch: 63/100... Training loss: 0.1039\n",
      "Epoch: 63/100... Training loss: 0.1057\n",
      "Epoch: 63/100... Training loss: 0.1059\n",
      "Epoch: 63/100... Training loss: 0.1017\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1048\n",
      "Epoch: 63/100... Training loss: 0.1044\n",
      "Epoch: 63/100... Training loss: 0.1028\n",
      "Epoch: 63/100... Training loss: 0.1033\n",
      "Epoch: 63/100... Training loss: 0.1036\n",
      "Epoch: 63/100... Training loss: 0.1043\n",
      "Epoch: 63/100... Training loss: 0.1051\n",
      "Epoch: 63/100... Training loss: 0.1040\n",
      "Epoch: 63/100... Training loss: 0.1038\n",
      "Epoch: 63/100... Training loss: 0.1033\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1042\n",
      "Epoch: 63/100... Training loss: 0.1067\n",
      "Epoch: 63/100... Training loss: 0.1070\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.0999\n",
      "Epoch: 63/100... Training loss: 0.1013\n",
      "Epoch: 63/100... Training loss: 0.1023\n",
      "Epoch: 63/100... Training loss: 0.1048\n",
      "Epoch: 63/100... Training loss: 0.1054\n",
      "Epoch: 63/100... Training loss: 0.1005\n",
      "Epoch: 63/100... Training loss: 0.1018\n",
      "Epoch: 63/100... Training loss: 0.1050\n",
      "Epoch: 63/100... Training loss: 0.1035\n",
      "Epoch: 63/100... Training loss: 0.1041\n",
      "Epoch: 63/100... Training loss: 0.1019\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1024\n",
      "Epoch: 63/100... Training loss: 0.1055\n",
      "Epoch: 63/100... Training loss: 0.1016\n",
      "Epoch: 63/100... Training loss: 0.1029\n",
      "Epoch: 63/100... Training loss: 0.1049\n",
      "Epoch: 63/100... Training loss: 0.1046\n",
      "Epoch: 63/100... Training loss: 0.1003\n",
      "Epoch: 63/100... Training loss: 0.1015\n",
      "Epoch: 63/100... Training loss: 0.1031\n",
      "Epoch: 63/100... Training loss: 0.1034\n",
      "Epoch: 63/100... Training loss: 0.1054\n",
      "Epoch: 63/100... Training loss: 0.1030\n",
      "Epoch: 63/100... Training loss: 0.1041\n",
      "Epoch: 63/100... Training loss: 0.1046\n",
      "Epoch: 63/100... Training loss: 0.1026\n",
      "Epoch: 64/100... Training loss: 0.0984\n",
      "Epoch: 64/100... Training loss: 0.1051\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1046\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1033\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.0989\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1044\n",
      "Epoch: 64/100... Training loss: 0.1007\n",
      "Epoch: 64/100... Training loss: 0.1065\n",
      "Epoch: 64/100... Training loss: 0.1033\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.1067\n",
      "Epoch: 64/100... Training loss: 0.1054\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1056\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1044\n",
      "Epoch: 64/100... Training loss: 0.1047\n",
      "Epoch: 64/100... Training loss: 0.1039\n",
      "Epoch: 64/100... Training loss: 0.1080\n",
      "Epoch: 64/100... Training loss: 0.1038\n",
      "Epoch: 64/100... Training loss: 0.1050\n",
      "Epoch: 64/100... Training loss: 0.1048\n",
      "Epoch: 64/100... Training loss: 0.1049\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1035\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1044\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.0973\n",
      "Epoch: 64/100... Training loss: 0.1074\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1064\n",
      "Epoch: 64/100... Training loss: 0.1059\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1086\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1051\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1061\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1038\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1059\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1041\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1037\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1045\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1044\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1038\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1066\n",
      "Epoch: 64/100... Training loss: 0.1051\n",
      "Epoch: 64/100... Training loss: 0.1047\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.0996\n",
      "Epoch: 64/100... Training loss: 0.1046\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1047\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.0995\n",
      "Epoch: 64/100... Training loss: 0.1055\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1035\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1092\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1046\n",
      "Epoch: 64/100... Training loss: 0.1033\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1034\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1049\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1013\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1055\n",
      "Epoch: 64/100... Training loss: 0.0993\n",
      "Epoch: 64/100... Training loss: 0.1043\n",
      "Epoch: 64/100... Training loss: 0.0978\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1049\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1057\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1051\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1017\n",
      "Epoch: 64/100... Training loss: 0.1006\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1033\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1044\n",
      "Epoch: 64/100... Training loss: 0.1054\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1060\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1039\n",
      "Epoch: 64/100... Training loss: 0.1055\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1084\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.0987\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1008\n",
      "Epoch: 64/100... Training loss: 0.1049\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1049\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1011\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.0981\n",
      "Epoch: 64/100... Training loss: 0.1044\n",
      "Epoch: 64/100... Training loss: 0.1037\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1035\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1038\n",
      "Epoch: 64/100... Training loss: 0.1052\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.0992\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1061\n",
      "Epoch: 64/100... Training loss: 0.1049\n",
      "Epoch: 64/100... Training loss: 0.1038\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1034\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.0991\n",
      "Epoch: 64/100... Training loss: 0.1049\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1009\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1047\n",
      "Epoch: 64/100... Training loss: 0.1051\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1041\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1041\n",
      "Epoch: 64/100... Training loss: 0.1057\n",
      "Epoch: 64/100... Training loss: 0.1039\n",
      "Epoch: 64/100... Training loss: 0.1043\n",
      "Epoch: 64/100... Training loss: 0.1040\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1060\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1041\n",
      "Epoch: 64/100... Training loss: 0.1020\n",
      "Epoch: 64/100... Training loss: 0.1057\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1012\n",
      "Epoch: 64/100... Training loss: 0.1058\n",
      "Epoch: 64/100... Training loss: 0.1061\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.0999\n",
      "Epoch: 64/100... Training loss: 0.1033\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1042\n",
      "Epoch: 64/100... Training loss: 0.1002\n",
      "Epoch: 64/100... Training loss: 0.1052\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1044\n",
      "Epoch: 64/100... Training loss: 0.1004\n",
      "Epoch: 64/100... Training loss: 0.1003\n",
      "Epoch: 64/100... Training loss: 0.1044\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.0994\n",
      "Epoch: 64/100... Training loss: 0.1070\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1049\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.1000\n",
      "Epoch: 64/100... Training loss: 0.1015\n",
      "Epoch: 64/100... Training loss: 0.1028\n",
      "Epoch: 64/100... Training loss: 0.1061\n",
      "Epoch: 64/100... Training loss: 0.0990\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1041\n",
      "Epoch: 64/100... Training loss: 0.1039\n",
      "Epoch: 64/100... Training loss: 0.1030\n",
      "Epoch: 64/100... Training loss: 0.1005\n",
      "Epoch: 64/100... Training loss: 0.1019\n",
      "Epoch: 64/100... Training loss: 0.1022\n",
      "Epoch: 64/100... Training loss: 0.1025\n",
      "Epoch: 64/100... Training loss: 0.1033\n",
      "Epoch: 64/100... Training loss: 0.1062\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1033\n",
      "Epoch: 64/100... Training loss: 0.1051\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.0998\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1046\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1021\n",
      "Epoch: 64/100... Training loss: 0.1027\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.0997\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1057\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.0982\n",
      "Epoch: 64/100... Training loss: 0.1029\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1016\n",
      "Epoch: 64/100... Training loss: 0.1055\n",
      "Epoch: 64/100... Training loss: 0.1058\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.1055\n",
      "Epoch: 64/100... Training loss: 0.1001\n",
      "Epoch: 64/100... Training loss: 0.1031\n",
      "Epoch: 64/100... Training loss: 0.1024\n",
      "Epoch: 64/100... Training loss: 0.1010\n",
      "Epoch: 64/100... Training loss: 0.0980\n",
      "Epoch: 64/100... Training loss: 0.1018\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1023\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 64/100... Training loss: 0.1036\n",
      "Epoch: 64/100... Training loss: 0.1014\n",
      "Epoch: 64/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.0980\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1035\n",
      "Epoch: 65/100... Training loss: 0.1062\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1037\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.0988\n",
      "Epoch: 65/100... Training loss: 0.1042\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.1063\n",
      "Epoch: 65/100... Training loss: 0.1034\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1063\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1043\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1036\n",
      "Epoch: 65/100... Training loss: 0.1045\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.1057\n",
      "Epoch: 65/100... Training loss: 0.1052\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1040\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.0984\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1034\n",
      "Epoch: 65/100... Training loss: 0.0996\n",
      "Epoch: 65/100... Training loss: 0.1055\n",
      "Epoch: 65/100... Training loss: 0.1072\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1045\n",
      "Epoch: 65/100... Training loss: 0.1043\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.0990\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.0979\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1047\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1061\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1057\n",
      "Epoch: 65/100... Training loss: 0.0993\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1038\n",
      "Epoch: 65/100... Training loss: 0.0994\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1053\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1060\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.1042\n",
      "Epoch: 65/100... Training loss: 0.1041\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1040\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1041\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1042\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1049\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1035\n",
      "Epoch: 65/100... Training loss: 0.1053\n",
      "Epoch: 65/100... Training loss: 0.1000\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1045\n",
      "Epoch: 65/100... Training loss: 0.1053\n",
      "Epoch: 65/100... Training loss: 0.1049\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1036\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1058\n",
      "Epoch: 65/100... Training loss: 0.1050\n",
      "Epoch: 65/100... Training loss: 0.1056\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1045\n",
      "Epoch: 65/100... Training loss: 0.1053\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1060\n",
      "Epoch: 65/100... Training loss: 0.1051\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1038\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.0978\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1058\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.1047\n",
      "Epoch: 65/100... Training loss: 0.1042\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1016\n",
      "Epoch: 65/100... Training loss: 0.1059\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1069\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1013\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1049\n",
      "Epoch: 65/100... Training loss: 0.1050\n",
      "Epoch: 65/100... Training loss: 0.1047\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.0989\n",
      "Epoch: 65/100... Training loss: 0.1011\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1041\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1051\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1045\n",
      "Epoch: 65/100... Training loss: 0.1059\n",
      "Epoch: 65/100... Training loss: 0.1045\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1043\n",
      "Epoch: 65/100... Training loss: 0.0992\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1057\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1057\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1043\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1012\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.0968\n",
      "Epoch: 65/100... Training loss: 0.1005\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1059\n",
      "Epoch: 65/100... Training loss: 0.1038\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1017\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1001\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.1062\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.1036\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1062\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1022\n",
      "Epoch: 65/100... Training loss: 0.1042\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.1024\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.1035\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1035\n",
      "Epoch: 65/100... Training loss: 0.1076\n",
      "Epoch: 65/100... Training loss: 0.1048\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1007\n",
      "Epoch: 65/100... Training loss: 0.1040\n",
      "Epoch: 65/100... Training loss: 0.1041\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1029\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.0997\n",
      "Epoch: 65/100... Training loss: 0.1003\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.0982\n",
      "Epoch: 65/100... Training loss: 0.1027\n",
      "Epoch: 65/100... Training loss: 0.1033\n",
      "Epoch: 65/100... Training loss: 0.0987\n",
      "Epoch: 65/100... Training loss: 0.1015\n",
      "Epoch: 65/100... Training loss: 0.1052\n",
      "Epoch: 65/100... Training loss: 0.1023\n",
      "Epoch: 65/100... Training loss: 0.1043\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1010\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1025\n",
      "Epoch: 65/100... Training loss: 0.1028\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.1060\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.0999\n",
      "Epoch: 65/100... Training loss: 0.0998\n",
      "Epoch: 65/100... Training loss: 0.1026\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1060\n",
      "Epoch: 65/100... Training loss: 0.1036\n",
      "Epoch: 65/100... Training loss: 0.1079\n",
      "Epoch: 65/100... Training loss: 0.1009\n",
      "Epoch: 65/100... Training loss: 0.1038\n",
      "Epoch: 65/100... Training loss: 0.1047\n",
      "Epoch: 65/100... Training loss: 0.1044\n",
      "Epoch: 65/100... Training loss: 0.1054\n",
      "Epoch: 65/100... Training loss: 0.1004\n",
      "Epoch: 65/100... Training loss: 0.1039\n",
      "Epoch: 65/100... Training loss: 0.1020\n",
      "Epoch: 65/100... Training loss: 0.1032\n",
      "Epoch: 65/100... Training loss: 0.1034\n",
      "Epoch: 65/100... Training loss: 0.1019\n",
      "Epoch: 65/100... Training loss: 0.1014\n",
      "Epoch: 65/100... Training loss: 0.1030\n",
      "Epoch: 65/100... Training loss: 0.1018\n",
      "Epoch: 65/100... Training loss: 0.1047\n",
      "Epoch: 65/100... Training loss: 0.1070\n",
      "Epoch: 65/100... Training loss: 0.1031\n",
      "Epoch: 65/100... Training loss: 0.1045\n",
      "Epoch: 65/100... Training loss: 0.1021\n",
      "Epoch: 65/100... Training loss: 0.1008\n",
      "Epoch: 65/100... Training loss: 0.1034\n",
      "Epoch: 65/100... Training loss: 0.1006\n",
      "Epoch: 65/100... Training loss: 0.1036\n",
      "Epoch: 65/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.1048\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1044\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1010\n",
      "Epoch: 66/100... Training loss: 0.1054\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.1033\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1076\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.1044\n",
      "Epoch: 66/100... Training loss: 0.0992\n",
      "Epoch: 66/100... Training loss: 0.1072\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1040\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1035\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1056\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.0974\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1056\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1054\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1051\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1051\n",
      "Epoch: 66/100... Training loss: 0.1047\n",
      "Epoch: 66/100... Training loss: 0.1040\n",
      "Epoch: 66/100... Training loss: 0.1035\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1049\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1062\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1048\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.0982\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1005\n",
      "Epoch: 66/100... Training loss: 0.1050\n",
      "Epoch: 66/100... Training loss: 0.0989\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1036\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.1071\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.0983\n",
      "Epoch: 66/100... Training loss: 0.1026\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1045\n",
      "Epoch: 66/100... Training loss: 0.1049\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1035\n",
      "Epoch: 66/100... Training loss: 0.0990\n",
      "Epoch: 66/100... Training loss: 0.1059\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1044\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1045\n",
      "Epoch: 66/100... Training loss: 0.1030\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1064\n",
      "Epoch: 66/100... Training loss: 0.0993\n",
      "Epoch: 66/100... Training loss: 0.1002\n",
      "Epoch: 66/100... Training loss: 0.1052\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1051\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1060\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1016\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1062\n",
      "Epoch: 66/100... Training loss: 0.1035\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1042\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1049\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.0995\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.0988\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1059\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1004\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1057\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1030\n",
      "Epoch: 66/100... Training loss: 0.1055\n",
      "Epoch: 66/100... Training loss: 0.1059\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1045\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1041\n",
      "Epoch: 66/100... Training loss: 0.1030\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1060\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.0986\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1065\n",
      "Epoch: 66/100... Training loss: 0.0973\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1049\n",
      "Epoch: 66/100... Training loss: 0.1072\n",
      "Epoch: 66/100... Training loss: 0.1058\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1029\n",
      "Epoch: 66/100... Training loss: 0.0985\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1024\n",
      "Epoch: 66/100... Training loss: 0.1056\n",
      "Epoch: 66/100... Training loss: 0.1041\n",
      "Epoch: 66/100... Training loss: 0.1045\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.1052\n",
      "Epoch: 66/100... Training loss: 0.1056\n",
      "Epoch: 66/100... Training loss: 0.0984\n",
      "Epoch: 66/100... Training loss: 0.1067\n",
      "Epoch: 66/100... Training loss: 0.1014\n",
      "Epoch: 66/100... Training loss: 0.1028\n",
      "Epoch: 66/100... Training loss: 0.0987\n",
      "Epoch: 66/100... Training loss: 0.1032\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1051\n",
      "Epoch: 66/100... Training loss: 0.1051\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.0985\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.1066\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1015\n",
      "Epoch: 66/100... Training loss: 0.1019\n",
      "Epoch: 66/100... Training loss: 0.1041\n",
      "Epoch: 66/100... Training loss: 0.1072\n",
      "Epoch: 66/100... Training loss: 0.0980\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.1033\n",
      "Epoch: 66/100... Training loss: 0.1000\n",
      "Epoch: 66/100... Training loss: 0.1044\n",
      "Epoch: 66/100... Training loss: 0.1056\n",
      "Epoch: 66/100... Training loss: 0.1041\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0999\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1001\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.0994\n",
      "Epoch: 66/100... Training loss: 0.1033\n",
      "Epoch: 66/100... Training loss: 0.0998\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1051\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1013\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1023\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1017\n",
      "Epoch: 66/100... Training loss: 0.1033\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1035\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1034\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.1022\n",
      "Epoch: 66/100... Training loss: 0.1026\n",
      "Epoch: 66/100... Training loss: 0.1003\n",
      "Epoch: 66/100... Training loss: 0.1009\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1008\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1025\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.0974\n",
      "Epoch: 66/100... Training loss: 0.1030\n",
      "Epoch: 66/100... Training loss: 0.1007\n",
      "Epoch: 66/100... Training loss: 0.1041\n",
      "Epoch: 66/100... Training loss: 0.1051\n",
      "Epoch: 66/100... Training loss: 0.1044\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.1037\n",
      "Epoch: 66/100... Training loss: 0.1048\n",
      "Epoch: 66/100... Training loss: 0.1058\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.1044\n",
      "Epoch: 66/100... Training loss: 0.1020\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1043\n",
      "Epoch: 66/100... Training loss: 0.1045\n",
      "Epoch: 66/100... Training loss: 0.1067\n",
      "Epoch: 66/100... Training loss: 0.1006\n",
      "Epoch: 66/100... Training loss: 0.1011\n",
      "Epoch: 66/100... Training loss: 0.0997\n",
      "Epoch: 66/100... Training loss: 0.1069\n",
      "Epoch: 66/100... Training loss: 0.1035\n",
      "Epoch: 66/100... Training loss: 0.1012\n",
      "Epoch: 66/100... Training loss: 0.1031\n",
      "Epoch: 66/100... Training loss: 0.1021\n",
      "Epoch: 66/100... Training loss: 0.1018\n",
      "Epoch: 66/100... Training loss: 0.1039\n",
      "Epoch: 66/100... Training loss: 0.1027\n",
      "Epoch: 66/100... Training loss: 0.1038\n",
      "Epoch: 66/100... Training loss: 0.1065\n",
      "Epoch: 66/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1046\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.0999\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1055\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1042\n",
      "Epoch: 67/100... Training loss: 0.1034\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.1034\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1035\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1064\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1037\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1046\n",
      "Epoch: 67/100... Training loss: 0.1048\n",
      "Epoch: 67/100... Training loss: 0.1034\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1042\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1039\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1039\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1054\n",
      "Epoch: 67/100... Training loss: 0.1044\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1053\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.1039\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1039\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1055\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.1042\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1044\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1050\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1024\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1050\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.1044\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1058\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.0975\n",
      "Epoch: 67/100... Training loss: 0.1043\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.1040\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.0994\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.1037\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0991\n",
      "Epoch: 67/100... Training loss: 0.1044\n",
      "Epoch: 67/100... Training loss: 0.0979\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1051\n",
      "Epoch: 67/100... Training loss: 0.1065\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1058\n",
      "Epoch: 67/100... Training loss: 0.1043\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.0997\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.0969\n",
      "Epoch: 67/100... Training loss: 0.0969\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.1020\n",
      "Epoch: 67/100... Training loss: 0.1043\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1064\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1034\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1052\n",
      "Epoch: 67/100... Training loss: 0.1046\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1006\n",
      "Epoch: 67/100... Training loss: 0.1044\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1040\n",
      "Epoch: 67/100... Training loss: 0.1064\n",
      "Epoch: 67/100... Training loss: 0.1043\n",
      "Epoch: 67/100... Training loss: 0.1044\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1048\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.1064\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1039\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.0996\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.1037\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1040\n",
      "Epoch: 67/100... Training loss: 0.1056\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1037\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1042\n",
      "Epoch: 67/100... Training loss: 0.1018\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1028\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1003\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.0993\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.0988\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1021\n",
      "Epoch: 67/100... Training loss: 0.1008\n",
      "Epoch: 67/100... Training loss: 0.1059\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.0998\n",
      "Epoch: 67/100... Training loss: 0.1023\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.1044\n",
      "Epoch: 67/100... Training loss: 0.1004\n",
      "Epoch: 67/100... Training loss: 0.1025\n",
      "Epoch: 67/100... Training loss: 0.1001\n",
      "Epoch: 67/100... Training loss: 0.1038\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1016\n",
      "Epoch: 67/100... Training loss: 0.1033\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1030\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1013\n",
      "Epoch: 67/100... Training loss: 0.1039\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1031\n",
      "Epoch: 67/100... Training loss: 0.1027\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1009\n",
      "Epoch: 67/100... Training loss: 0.1051\n",
      "Epoch: 67/100... Training loss: 0.1037\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1047\n",
      "Epoch: 67/100... Training loss: 0.0972\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.0979\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1010\n",
      "Epoch: 67/100... Training loss: 0.1051\n",
      "Epoch: 67/100... Training loss: 0.1045\n",
      "Epoch: 67/100... Training loss: 0.1046\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1040\n",
      "Epoch: 67/100... Training loss: 0.1035\n",
      "Epoch: 67/100... Training loss: 0.1032\n",
      "Epoch: 67/100... Training loss: 0.1026\n",
      "Epoch: 67/100... Training loss: 0.1022\n",
      "Epoch: 67/100... Training loss: 0.1064\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.1062\n",
      "Epoch: 67/100... Training loss: 0.1005\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1019\n",
      "Epoch: 67/100... Training loss: 0.1046\n",
      "Epoch: 67/100... Training loss: 0.1007\n",
      "Epoch: 67/100... Training loss: 0.1012\n",
      "Epoch: 67/100... Training loss: 0.1036\n",
      "Epoch: 67/100... Training loss: 0.1011\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1017\n",
      "Epoch: 67/100... Training loss: 0.1014\n",
      "Epoch: 67/100... Training loss: 0.1015\n",
      "Epoch: 67/100... Training loss: 0.1029\n",
      "Epoch: 67/100... Training loss: 0.1052\n",
      "Epoch: 67/100... Training loss: 0.1049\n",
      "Epoch: 67/100... Training loss: 0.1041\n",
      "Epoch: 68/100... Training loss: 0.1045\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.0968\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1065\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1042\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1033\n",
      "Epoch: 68/100... Training loss: 0.1053\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.1046\n",
      "Epoch: 68/100... Training loss: 0.1033\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.1045\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.1003\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.0987\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1055\n",
      "Epoch: 68/100... Training loss: 0.1049\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1038\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1044\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.1038\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.1033\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1046\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1045\n",
      "Epoch: 68/100... Training loss: 0.1057\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1026\n",
      "Epoch: 68/100... Training loss: 0.1038\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.0985\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1049\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.0977\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.1045\n",
      "Epoch: 68/100... Training loss: 0.1049\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1041\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1033\n",
      "Epoch: 68/100... Training loss: 0.1047\n",
      "Epoch: 68/100... Training loss: 0.0979\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1041\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1056\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1042\n",
      "Epoch: 68/100... Training loss: 0.1075\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.1044\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.1062\n",
      "Epoch: 68/100... Training loss: 0.1029\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.1041\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1052\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1080\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1048\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.1048\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1008\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1038\n",
      "Epoch: 68/100... Training loss: 0.0996\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.1063\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.1052\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1047\n",
      "Epoch: 68/100... Training loss: 0.1049\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.1048\n",
      "Epoch: 68/100... Training loss: 0.1065\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1038\n",
      "Epoch: 68/100... Training loss: 0.1044\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1042\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.0984\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1046\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1060\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1038\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.1068\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.1041\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.1045\n",
      "Epoch: 68/100... Training loss: 0.1059\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1042\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1045\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1052\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1010\n",
      "Epoch: 68/100... Training loss: 0.0999\n",
      "Epoch: 68/100... Training loss: 0.0986\n",
      "Epoch: 68/100... Training loss: 0.1056\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.0995\n",
      "Epoch: 68/100... Training loss: 0.1002\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1063\n",
      "Epoch: 68/100... Training loss: 0.1009\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1016\n",
      "Epoch: 68/100... Training loss: 0.1061\n",
      "Epoch: 68/100... Training loss: 0.1013\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1061\n",
      "Epoch: 68/100... Training loss: 0.1038\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1007\n",
      "Epoch: 68/100... Training loss: 0.1011\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1014\n",
      "Epoch: 68/100... Training loss: 0.1059\n",
      "Epoch: 68/100... Training loss: 0.1049\n",
      "Epoch: 68/100... Training loss: 0.0968\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.1034\n",
      "Epoch: 68/100... Training loss: 0.1006\n",
      "Epoch: 68/100... Training loss: 0.1017\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1059\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1024\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1042\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.1048\n",
      "Epoch: 68/100... Training loss: 0.1025\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.1015\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1045\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1036\n",
      "Epoch: 68/100... Training loss: 0.1057\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1027\n",
      "Epoch: 68/100... Training loss: 0.1030\n",
      "Epoch: 68/100... Training loss: 0.0990\n",
      "Epoch: 68/100... Training loss: 0.1069\n",
      "Epoch: 68/100... Training loss: 0.1022\n",
      "Epoch: 68/100... Training loss: 0.1035\n",
      "Epoch: 68/100... Training loss: 0.1004\n",
      "Epoch: 68/100... Training loss: 0.0991\n",
      "Epoch: 68/100... Training loss: 0.0998\n",
      "Epoch: 68/100... Training loss: 0.1043\n",
      "Epoch: 68/100... Training loss: 0.0982\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1044\n",
      "Epoch: 68/100... Training loss: 0.1048\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1028\n",
      "Epoch: 68/100... Training loss: 0.1040\n",
      "Epoch: 68/100... Training loss: 0.1023\n",
      "Epoch: 68/100... Training loss: 0.1012\n",
      "Epoch: 68/100... Training loss: 0.1050\n",
      "Epoch: 68/100... Training loss: 0.1037\n",
      "Epoch: 68/100... Training loss: 0.1005\n",
      "Epoch: 68/100... Training loss: 0.1020\n",
      "Epoch: 68/100... Training loss: 0.1019\n",
      "Epoch: 68/100... Training loss: 0.0989\n",
      "Epoch: 68/100... Training loss: 0.1039\n",
      "Epoch: 68/100... Training loss: 0.0997\n",
      "Epoch: 68/100... Training loss: 0.1036\n",
      "Epoch: 68/100... Training loss: 0.1021\n",
      "Epoch: 68/100... Training loss: 0.1031\n",
      "Epoch: 68/100... Training loss: 0.1018\n",
      "Epoch: 68/100... Training loss: 0.1000\n",
      "Epoch: 68/100... Training loss: 0.1001\n",
      "Epoch: 68/100... Training loss: 0.0993\n",
      "Epoch: 68/100... Training loss: 0.1032\n",
      "Epoch: 68/100... Training loss: 0.1057\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1037\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1041\n",
      "Epoch: 69/100... Training loss: 0.1037\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1047\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1051\n",
      "Epoch: 69/100... Training loss: 0.1046\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.1057\n",
      "Epoch: 69/100... Training loss: 0.0994\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1039\n",
      "Epoch: 69/100... Training loss: 0.0992\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1045\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1066\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.1037\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1055\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1062\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.1039\n",
      "Epoch: 69/100... Training loss: 0.1036\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1049\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1040\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1046\n",
      "Epoch: 69/100... Training loss: 0.1042\n",
      "Epoch: 69/100... Training loss: 0.1036\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1007\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.1047\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1041\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1050\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1041\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1038\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1063\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1045\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1056\n",
      "Epoch: 69/100... Training loss: 0.1052\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1033\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1048\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1042\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1053\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1036\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.1059\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.1008\n",
      "Epoch: 69/100... Training loss: 0.1048\n",
      "Epoch: 69/100... Training loss: 0.1034\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1045\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.1049\n",
      "Epoch: 69/100... Training loss: 0.0985\n",
      "Epoch: 69/100... Training loss: 0.1056\n",
      "Epoch: 69/100... Training loss: 0.1033\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.0983\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1056\n",
      "Epoch: 69/100... Training loss: 0.0980\n",
      "Epoch: 69/100... Training loss: 0.1045\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.1010\n",
      "Epoch: 69/100... Training loss: 0.1033\n",
      "Epoch: 69/100... Training loss: 0.1063\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1044\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.0995\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1048\n",
      "Epoch: 69/100... Training loss: 0.1048\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1063\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1044\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1037\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1053\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.1040\n",
      "Epoch: 69/100... Training loss: 0.1042\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1049\n",
      "Epoch: 69/100... Training loss: 0.1042\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.1029\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1079\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1040\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1034\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1042\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.1045\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1034\n",
      "Epoch: 69/100... Training loss: 0.1042\n",
      "Epoch: 69/100... Training loss: 0.1006\n",
      "Epoch: 69/100... Training loss: 0.1037\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1016\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1034\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1038\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.1011\n",
      "Epoch: 69/100... Training loss: 0.1009\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.1045\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1057\n",
      "Epoch: 69/100... Training loss: 0.1014\n",
      "Epoch: 69/100... Training loss: 0.0998\n",
      "Epoch: 69/100... Training loss: 0.1033\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.0987\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.1051\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.1017\n",
      "Epoch: 69/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.1035\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.0997\n",
      "Epoch: 69/100... Training loss: 0.1000\n",
      "Epoch: 69/100... Training loss: 0.1043\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.1031\n",
      "Epoch: 69/100... Training loss: 0.0982\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.1061\n",
      "Epoch: 69/100... Training loss: 0.1019\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1024\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.0991\n",
      "Epoch: 69/100... Training loss: 0.1066\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 69/100... Training loss: 0.1026\n",
      "Epoch: 69/100... Training loss: 0.1005\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1057\n",
      "Epoch: 69/100... Training loss: 0.1057\n",
      "Epoch: 69/100... Training loss: 0.1045\n",
      "Epoch: 69/100... Training loss: 0.1044\n",
      "Epoch: 69/100... Training loss: 0.0989\n",
      "Epoch: 69/100... Training loss: 0.1004\n",
      "Epoch: 69/100... Training loss: 0.1036\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1003\n",
      "Epoch: 69/100... Training loss: 0.1034\n",
      "Epoch: 69/100... Training loss: 0.0999\n",
      "Epoch: 69/100... Training loss: 0.1027\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1021\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1030\n",
      "Epoch: 69/100... Training loss: 0.0988\n",
      "Epoch: 69/100... Training loss: 0.1049\n",
      "Epoch: 69/100... Training loss: 0.1002\n",
      "Epoch: 69/100... Training loss: 0.1023\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1041\n",
      "Epoch: 69/100... Training loss: 0.1057\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1012\n",
      "Epoch: 69/100... Training loss: 0.0993\n",
      "Epoch: 69/100... Training loss: 0.1037\n",
      "Epoch: 69/100... Training loss: 0.1032\n",
      "Epoch: 69/100... Training loss: 0.1045\n",
      "Epoch: 69/100... Training loss: 0.1039\n",
      "Epoch: 69/100... Training loss: 0.1057\n",
      "Epoch: 69/100... Training loss: 0.1025\n",
      "Epoch: 69/100... Training loss: 0.0977\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1034\n",
      "Epoch: 69/100... Training loss: 0.1062\n",
      "Epoch: 69/100... Training loss: 0.1022\n",
      "Epoch: 69/100... Training loss: 0.1001\n",
      "Epoch: 69/100... Training loss: 0.1015\n",
      "Epoch: 69/100... Training loss: 0.1018\n",
      "Epoch: 69/100... Training loss: 0.1042\n",
      "Epoch: 69/100... Training loss: 0.1013\n",
      "Epoch: 69/100... Training loss: 0.1028\n",
      "Epoch: 69/100... Training loss: 0.1046\n",
      "Epoch: 69/100... Training loss: 0.0974\n",
      "Epoch: 69/100... Training loss: 0.1034\n",
      "Epoch: 69/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1034\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1037\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1063\n",
      "Epoch: 70/100... Training loss: 0.1037\n",
      "Epoch: 70/100... Training loss: 0.1051\n",
      "Epoch: 70/100... Training loss: 0.1053\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1037\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.0992\n",
      "Epoch: 70/100... Training loss: 0.0972\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1056\n",
      "Epoch: 70/100... Training loss: 0.0968\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1063\n",
      "Epoch: 70/100... Training loss: 0.1048\n",
      "Epoch: 70/100... Training loss: 0.1044\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.0995\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1059\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1054\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1055\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1059\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1054\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1003\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.0991\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1034\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1037\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.1055\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.1039\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.0994\n",
      "Epoch: 70/100... Training loss: 0.1047\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1040\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1039\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1051\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1035\n",
      "Epoch: 70/100... Training loss: 0.0989\n",
      "Epoch: 70/100... Training loss: 0.0984\n",
      "Epoch: 70/100... Training loss: 0.1046\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1004\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1048\n",
      "Epoch: 70/100... Training loss: 0.1016\n",
      "Epoch: 70/100... Training loss: 0.1066\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.1055\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1039\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1040\n",
      "Epoch: 70/100... Training loss: 0.1035\n",
      "Epoch: 70/100... Training loss: 0.1027\n",
      "Epoch: 70/100... Training loss: 0.1019\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1043\n",
      "Epoch: 70/100... Training loss: 0.1040\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.0971\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1051\n",
      "Epoch: 70/100... Training loss: 0.0976\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1061\n",
      "Epoch: 70/100... Training loss: 0.1037\n",
      "Epoch: 70/100... Training loss: 0.1045\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1014\n",
      "Epoch: 70/100... Training loss: 0.1060\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.1029\n",
      "Epoch: 70/100... Training loss: 0.1050\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.1062\n",
      "Epoch: 70/100... Training loss: 0.1048\n",
      "Epoch: 70/100... Training loss: 0.1048\n",
      "Epoch: 70/100... Training loss: 0.1039\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1021\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1045\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.0993\n",
      "Epoch: 70/100... Training loss: 0.1033\n",
      "Epoch: 70/100... Training loss: 0.1060\n",
      "Epoch: 70/100... Training loss: 0.1039\n",
      "Epoch: 70/100... Training loss: 0.1054\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.1051\n",
      "Epoch: 70/100... Training loss: 0.1055\n",
      "Epoch: 70/100... Training loss: 0.1039\n",
      "Epoch: 70/100... Training loss: 0.1006\n",
      "Epoch: 70/100... Training loss: 0.0983\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1077\n",
      "Epoch: 70/100... Training loss: 0.1018\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1033\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.0990\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1051\n",
      "Epoch: 70/100... Training loss: 0.1040\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.1023\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.1050\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1042\n",
      "Epoch: 70/100... Training loss: 0.0997\n",
      "Epoch: 70/100... Training loss: 0.1052\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1027\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1034\n",
      "Epoch: 70/100... Training loss: 0.1047\n",
      "Epoch: 70/100... Training loss: 0.0981\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1008\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.0987\n",
      "Epoch: 70/100... Training loss: 0.1050\n",
      "Epoch: 70/100... Training loss: 0.1033\n",
      "Epoch: 70/100... Training loss: 0.1025\n",
      "Epoch: 70/100... Training loss: 0.1002\n",
      "Epoch: 70/100... Training loss: 0.1035\n",
      "Epoch: 70/100... Training loss: 0.1010\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1061\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1007\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1024\n",
      "Epoch: 70/100... Training loss: 0.1046\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1032\n",
      "Epoch: 70/100... Training loss: 0.1067\n",
      "Epoch: 70/100... Training loss: 0.1058\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.1035\n",
      "Epoch: 70/100... Training loss: 0.0996\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1030\n",
      "Epoch: 70/100... Training loss: 0.1009\n",
      "Epoch: 70/100... Training loss: 0.1043\n",
      "Epoch: 70/100... Training loss: 0.1005\n",
      "Epoch: 70/100... Training loss: 0.1040\n",
      "Epoch: 70/100... Training loss: 0.0980\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1045\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1036\n",
      "Epoch: 70/100... Training loss: 0.1013\n",
      "Epoch: 70/100... Training loss: 0.1031\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 70/100... Training loss: 0.0982\n",
      "Epoch: 70/100... Training loss: 0.1044\n",
      "Epoch: 70/100... Training loss: 0.1020\n",
      "Epoch: 70/100... Training loss: 0.1017\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.1011\n",
      "Epoch: 70/100... Training loss: 0.1041\n",
      "Epoch: 70/100... Training loss: 0.1028\n",
      "Epoch: 70/100... Training loss: 0.0964\n",
      "Epoch: 70/100... Training loss: 0.1022\n",
      "Epoch: 70/100... Training loss: 0.1026\n",
      "Epoch: 70/100... Training loss: 0.1012\n",
      "Epoch: 70/100... Training loss: 0.1033\n",
      "Epoch: 70/100... Training loss: 0.1044\n",
      "Epoch: 70/100... Training loss: 0.1001\n",
      "Epoch: 70/100... Training loss: 0.1035\n",
      "Epoch: 70/100... Training loss: 0.0999\n",
      "Epoch: 70/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.1052\n",
      "Epoch: 71/100... Training loss: 0.1048\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.1037\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1056\n",
      "Epoch: 71/100... Training loss: 0.0999\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.1039\n",
      "Epoch: 71/100... Training loss: 0.1048\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.1040\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1044\n",
      "Epoch: 71/100... Training loss: 0.1028\n",
      "Epoch: 71/100... Training loss: 0.1036\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.1049\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1050\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1043\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.1057\n",
      "Epoch: 71/100... Training loss: 0.1037\n",
      "Epoch: 71/100... Training loss: 0.1050\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1039\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.0967\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1047\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.1036\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.1041\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.0986\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.1047\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1044\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1049\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1001\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1036\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.1041\n",
      "Epoch: 71/100... Training loss: 0.1053\n",
      "Epoch: 71/100... Training loss: 0.1045\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1040\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.1040\n",
      "Epoch: 71/100... Training loss: 0.1074\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.0996\n",
      "Epoch: 71/100... Training loss: 0.1020\n",
      "Epoch: 71/100... Training loss: 0.1050\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1033\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1039\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.1048\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1081\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.1015\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1009\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1040\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1059\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1046\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1022\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.1051\n",
      "Epoch: 71/100... Training loss: 0.1003\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1043\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1071\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.0983\n",
      "Epoch: 71/100... Training loss: 0.1007\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.1070\n",
      "Epoch: 71/100... Training loss: 0.1045\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.1035\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.1043\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.0980\n",
      "Epoch: 71/100... Training loss: 0.1002\n",
      "Epoch: 71/100... Training loss: 0.1037\n",
      "Epoch: 71/100... Training loss: 0.1043\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1040\n",
      "Epoch: 71/100... Training loss: 0.1044\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1045\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0998\n",
      "Epoch: 71/100... Training loss: 0.1037\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.0988\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1028\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1019\n",
      "Epoch: 71/100... Training loss: 0.1038\n",
      "Epoch: 71/100... Training loss: 0.1027\n",
      "Epoch: 71/100... Training loss: 0.0977\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.0997\n",
      "Epoch: 71/100... Training loss: 0.1048\n",
      "Epoch: 71/100... Training loss: 0.1045\n",
      "Epoch: 71/100... Training loss: 0.1049\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1032\n",
      "Epoch: 71/100... Training loss: 0.1059\n",
      "Epoch: 71/100... Training loss: 0.1016\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1000\n",
      "Epoch: 71/100... Training loss: 0.1028\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1008\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1047\n",
      "Epoch: 71/100... Training loss: 0.1026\n",
      "Epoch: 71/100... Training loss: 0.1040\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.1013\n",
      "Epoch: 71/100... Training loss: 0.1059\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.0993\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1050\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1018\n",
      "Epoch: 71/100... Training loss: 0.1025\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1011\n",
      "Epoch: 71/100... Training loss: 0.1072\n",
      "Epoch: 71/100... Training loss: 0.1023\n",
      "Epoch: 71/100... Training loss: 0.1024\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1046\n",
      "Epoch: 71/100... Training loss: 0.1039\n",
      "Epoch: 71/100... Training loss: 0.1060\n",
      "Epoch: 71/100... Training loss: 0.1039\n",
      "Epoch: 71/100... Training loss: 0.1014\n",
      "Epoch: 71/100... Training loss: 0.1058\n",
      "Epoch: 71/100... Training loss: 0.1046\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.1054\n",
      "Epoch: 71/100... Training loss: 0.0984\n",
      "Epoch: 71/100... Training loss: 0.0979\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1056\n",
      "Epoch: 71/100... Training loss: 0.1030\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.1029\n",
      "Epoch: 71/100... Training loss: 0.1004\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1040\n",
      "Epoch: 71/100... Training loss: 0.1070\n",
      "Epoch: 71/100... Training loss: 0.1050\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1006\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.0991\n",
      "Epoch: 71/100... Training loss: 0.0995\n",
      "Epoch: 71/100... Training loss: 0.1021\n",
      "Epoch: 71/100... Training loss: 0.1017\n",
      "Epoch: 71/100... Training loss: 0.1010\n",
      "Epoch: 71/100... Training loss: 0.0981\n",
      "Epoch: 71/100... Training loss: 0.1005\n",
      "Epoch: 71/100... Training loss: 0.1057\n",
      "Epoch: 71/100... Training loss: 0.1031\n",
      "Epoch: 71/100... Training loss: 0.1034\n",
      "Epoch: 71/100... Training loss: 0.1012\n",
      "Epoch: 71/100... Training loss: 0.0992\n",
      "Epoch: 71/100... Training loss: 0.1047\n",
      "Epoch: 71/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.0981\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1044\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1072\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1036\n",
      "Epoch: 72/100... Training loss: 0.1059\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.1059\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1044\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1067\n",
      "Epoch: 72/100... Training loss: 0.0986\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.0990\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1000\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.1040\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1052\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1096\n",
      "Epoch: 72/100... Training loss: 0.1035\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1053\n",
      "Epoch: 72/100... Training loss: 0.1032\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1053\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1034\n",
      "Epoch: 72/100... Training loss: 0.1038\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1045\n",
      "Epoch: 72/100... Training loss: 0.1047\n",
      "Epoch: 72/100... Training loss: 0.1039\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1058\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1035\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1046\n",
      "Epoch: 72/100... Training loss: 0.1055\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1050\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1031\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.1017\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.1018\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1038\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1039\n",
      "Epoch: 72/100... Training loss: 0.1059\n",
      "Epoch: 72/100... Training loss: 0.1053\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1034\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1078\n",
      "Epoch: 72/100... Training loss: 0.1046\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1065\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1054\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.1053\n",
      "Epoch: 72/100... Training loss: 0.1080\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1077\n",
      "Epoch: 72/100... Training loss: 0.0989\n",
      "Epoch: 72/100... Training loss: 0.1052\n",
      "Epoch: 72/100... Training loss: 0.1035\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1068\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.1032\n",
      "Epoch: 72/100... Training loss: 0.1035\n",
      "Epoch: 72/100... Training loss: 0.1041\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1038\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1054\n",
      "Epoch: 72/100... Training loss: 0.0992\n",
      "Epoch: 72/100... Training loss: 0.1044\n",
      "Epoch: 72/100... Training loss: 0.1029\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1034\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1048\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1072\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.1048\n",
      "Epoch: 72/100... Training loss: 0.1049\n",
      "Epoch: 72/100... Training loss: 0.1066\n",
      "Epoch: 72/100... Training loss: 0.1029\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.1056\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1036\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.0987\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1032\n",
      "Epoch: 72/100... Training loss: 0.1055\n",
      "Epoch: 72/100... Training loss: 0.1029\n",
      "Epoch: 72/100... Training loss: 0.1034\n",
      "Epoch: 72/100... Training loss: 0.0993\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1029\n",
      "Epoch: 72/100... Training loss: 0.0974\n",
      "Epoch: 72/100... Training loss: 0.0997\n",
      "Epoch: 72/100... Training loss: 0.0999\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.1001\n",
      "Epoch: 72/100... Training loss: 0.1037\n",
      "Epoch: 72/100... Training loss: 0.0988\n",
      "Epoch: 72/100... Training loss: 0.1035\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1053\n",
      "Epoch: 72/100... Training loss: 0.1014\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.1013\n",
      "Epoch: 72/100... Training loss: 0.0996\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1041\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.0978\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.0983\n",
      "Epoch: 72/100... Training loss: 0.1047\n",
      "Epoch: 72/100... Training loss: 0.1053\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.0991\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1031\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.0998\n",
      "Epoch: 72/100... Training loss: 0.1031\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.1047\n",
      "Epoch: 72/100... Training loss: 0.1041\n",
      "Epoch: 72/100... Training loss: 0.1057\n",
      "Epoch: 72/100... Training loss: 0.1034\n",
      "Epoch: 72/100... Training loss: 0.1044\n",
      "Epoch: 72/100... Training loss: 0.1004\n",
      "Epoch: 72/100... Training loss: 0.1034\n",
      "Epoch: 72/100... Training loss: 0.1036\n",
      "Epoch: 72/100... Training loss: 0.1029\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.1015\n",
      "Epoch: 72/100... Training loss: 0.1016\n",
      "Epoch: 72/100... Training loss: 0.1032\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1038\n",
      "Epoch: 72/100... Training loss: 0.1039\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1042\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1029\n",
      "Epoch: 72/100... Training loss: 0.1002\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.0995\n",
      "Epoch: 72/100... Training loss: 0.1022\n",
      "Epoch: 72/100... Training loss: 0.0985\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.1039\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.1037\n",
      "Epoch: 72/100... Training loss: 0.1012\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1054\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.1042\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.1021\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1025\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.1028\n",
      "Epoch: 72/100... Training loss: 0.1019\n",
      "Epoch: 72/100... Training loss: 0.1009\n",
      "Epoch: 72/100... Training loss: 0.1043\n",
      "Epoch: 72/100... Training loss: 0.0979\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1026\n",
      "Epoch: 72/100... Training loss: 0.1030\n",
      "Epoch: 72/100... Training loss: 0.1050\n",
      "Epoch: 72/100... Training loss: 0.1036\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.1003\n",
      "Epoch: 72/100... Training loss: 0.1032\n",
      "Epoch: 72/100... Training loss: 0.1049\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 72/100... Training loss: 0.1033\n",
      "Epoch: 72/100... Training loss: 0.1061\n",
      "Epoch: 72/100... Training loss: 0.1046\n",
      "Epoch: 72/100... Training loss: 0.1053\n",
      "Epoch: 72/100... Training loss: 0.1007\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1027\n",
      "Epoch: 72/100... Training loss: 0.0994\n",
      "Epoch: 72/100... Training loss: 0.1008\n",
      "Epoch: 72/100... Training loss: 0.1039\n",
      "Epoch: 72/100... Training loss: 0.1011\n",
      "Epoch: 72/100... Training loss: 0.1031\n",
      "Epoch: 72/100... Training loss: 0.1024\n",
      "Epoch: 72/100... Training loss: 0.1077\n",
      "Epoch: 72/100... Training loss: 0.1020\n",
      "Epoch: 72/100... Training loss: 0.1006\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1005\n",
      "Epoch: 72/100... Training loss: 0.1010\n",
      "Epoch: 72/100... Training loss: 0.1035\n",
      "Epoch: 72/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.1046\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1053\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1038\n",
      "Epoch: 73/100... Training loss: 0.0988\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.1035\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.0980\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.0975\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.1050\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1052\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1057\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1029\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1075\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1042\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1041\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.1049\n",
      "Epoch: 73/100... Training loss: 0.1025\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1053\n",
      "Epoch: 73/100... Training loss: 0.1060\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1034\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1029\n",
      "Epoch: 73/100... Training loss: 0.1054\n",
      "Epoch: 73/100... Training loss: 0.1061\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1039\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1042\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.0982\n",
      "Epoch: 73/100... Training loss: 0.1046\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.0999\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1037\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1039\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.1057\n",
      "Epoch: 73/100... Training loss: 0.1049\n",
      "Epoch: 73/100... Training loss: 0.1060\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1049\n",
      "Epoch: 73/100... Training loss: 0.1052\n",
      "Epoch: 73/100... Training loss: 0.1054\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.1052\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1077\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.1058\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1059\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1030\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1047\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.1039\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1037\n",
      "Epoch: 73/100... Training loss: 0.1047\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.1043\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.1053\n",
      "Epoch: 73/100... Training loss: 0.1035\n",
      "Epoch: 73/100... Training loss: 0.0994\n",
      "Epoch: 73/100... Training loss: 0.1035\n",
      "Epoch: 73/100... Training loss: 0.1032\n",
      "Epoch: 73/100... Training loss: 0.1024\n",
      "Epoch: 73/100... Training loss: 0.1053\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.1043\n",
      "Epoch: 73/100... Training loss: 0.1021\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1060\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.0993\n",
      "Epoch: 73/100... Training loss: 0.1029\n",
      "Epoch: 73/100... Training loss: 0.1039\n",
      "Epoch: 73/100... Training loss: 0.1047\n",
      "Epoch: 73/100... Training loss: 0.0995\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.0996\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1048\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0986\n",
      "Epoch: 73/100... Training loss: 0.1052\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1048\n",
      "Epoch: 73/100... Training loss: 0.1035\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.1026\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1052\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.1059\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.1060\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.0985\n",
      "Epoch: 73/100... Training loss: 0.1009\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1058\n",
      "Epoch: 73/100... Training loss: 0.1051\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1013\n",
      "Epoch: 73/100... Training loss: 0.0991\n",
      "Epoch: 73/100... Training loss: 0.1040\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.1002\n",
      "Epoch: 73/100... Training loss: 0.1001\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.1012\n",
      "Epoch: 73/100... Training loss: 0.1022\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.0998\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1050\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1033\n",
      "Epoch: 73/100... Training loss: 0.1054\n",
      "Epoch: 73/100... Training loss: 0.1045\n",
      "Epoch: 73/100... Training loss: 0.1008\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1023\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1019\n",
      "Epoch: 73/100... Training loss: 0.1041\n",
      "Epoch: 73/100... Training loss: 0.1055\n",
      "Epoch: 73/100... Training loss: 0.1067\n",
      "Epoch: 73/100... Training loss: 0.1004\n",
      "Epoch: 73/100... Training loss: 0.0997\n",
      "Epoch: 73/100... Training loss: 0.1006\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.1011\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1000\n",
      "Epoch: 73/100... Training loss: 0.0964\n",
      "Epoch: 73/100... Training loss: 0.1015\n",
      "Epoch: 73/100... Training loss: 0.1029\n",
      "Epoch: 73/100... Training loss: 0.0990\n",
      "Epoch: 73/100... Training loss: 0.1051\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.1031\n",
      "Epoch: 73/100... Training loss: 0.1065\n",
      "Epoch: 73/100... Training loss: 0.1014\n",
      "Epoch: 73/100... Training loss: 0.0989\n",
      "Epoch: 73/100... Training loss: 0.0992\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1036\n",
      "Epoch: 73/100... Training loss: 0.1068\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1027\n",
      "Epoch: 73/100... Training loss: 0.1017\n",
      "Epoch: 73/100... Training loss: 0.1037\n",
      "Epoch: 73/100... Training loss: 0.1040\n",
      "Epoch: 73/100... Training loss: 0.1007\n",
      "Epoch: 73/100... Training loss: 0.1010\n",
      "Epoch: 73/100... Training loss: 0.1018\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1044\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1003\n",
      "Epoch: 73/100... Training loss: 0.1005\n",
      "Epoch: 73/100... Training loss: 0.1020\n",
      "Epoch: 73/100... Training loss: 0.1047\n",
      "Epoch: 73/100... Training loss: 0.1016\n",
      "Epoch: 73/100... Training loss: 0.1028\n",
      "Epoch: 73/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.1034\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1043\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1052\n",
      "Epoch: 74/100... Training loss: 0.1053\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1043\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.1047\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1036\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.0980\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1039\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.1036\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.1040\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.1041\n",
      "Epoch: 74/100... Training loss: 0.1041\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.1036\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1034\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.1061\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1056\n",
      "Epoch: 74/100... Training loss: 0.1057\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.1023\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.0997\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.1045\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1054\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.1035\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1034\n",
      "Epoch: 74/100... Training loss: 0.1052\n",
      "Epoch: 74/100... Training loss: 0.1043\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1051\n",
      "Epoch: 74/100... Training loss: 0.1052\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1051\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.0991\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.0996\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1063\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1047\n",
      "Epoch: 74/100... Training loss: 0.1039\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.0985\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.1036\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1057\n",
      "Epoch: 74/100... Training loss: 0.1044\n",
      "Epoch: 74/100... Training loss: 0.1056\n",
      "Epoch: 74/100... Training loss: 0.1052\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.1016\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1039\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.1037\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.1023\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.1053\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1032\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1045\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1046\n",
      "Epoch: 74/100... Training loss: 0.1050\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.0990\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.0980\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.0989\n",
      "Epoch: 74/100... Training loss: 0.1044\n",
      "Epoch: 74/100... Training loss: 0.1032\n",
      "Epoch: 74/100... Training loss: 0.1037\n",
      "Epoch: 74/100... Training loss: 0.1040\n",
      "Epoch: 74/100... Training loss: 0.1059\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1036\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.0967\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.1044\n",
      "Epoch: 74/100... Training loss: 0.1070\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.0953\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.1036\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.1042\n",
      "Epoch: 74/100... Training loss: 0.0992\n",
      "Epoch: 74/100... Training loss: 0.1041\n",
      "Epoch: 74/100... Training loss: 0.1041\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1032\n",
      "Epoch: 74/100... Training loss: 0.1030\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.0998\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1073\n",
      "Epoch: 74/100... Training loss: 0.1052\n",
      "Epoch: 74/100... Training loss: 0.0994\n",
      "Epoch: 74/100... Training loss: 0.0979\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1031\n",
      "Epoch: 74/100... Training loss: 0.1002\n",
      "Epoch: 74/100... Training loss: 0.1003\n",
      "Epoch: 74/100... Training loss: 0.1044\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.0986\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1023\n",
      "Epoch: 74/100... Training loss: 0.0980\n",
      "Epoch: 74/100... Training loss: 0.1012\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1037\n",
      "Epoch: 74/100... Training loss: 0.1019\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1018\n",
      "Epoch: 74/100... Training loss: 0.0984\n",
      "Epoch: 74/100... Training loss: 0.1006\n",
      "Epoch: 74/100... Training loss: 0.0976\n",
      "Epoch: 74/100... Training loss: 0.1032\n",
      "Epoch: 74/100... Training loss: 0.1010\n",
      "Epoch: 74/100... Training loss: 0.1044\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.0995\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.0982\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1032\n",
      "Epoch: 74/100... Training loss: 0.1026\n",
      "Epoch: 74/100... Training loss: 0.1038\n",
      "Epoch: 74/100... Training loss: 0.1024\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.1007\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.1004\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1044\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1050\n",
      "Epoch: 74/100... Training loss: 0.1041\n",
      "Epoch: 74/100... Training loss: 0.0999\n",
      "Epoch: 74/100... Training loss: 0.1045\n",
      "Epoch: 74/100... Training loss: 0.1013\n",
      "Epoch: 74/100... Training loss: 0.1021\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1049\n",
      "Epoch: 74/100... Training loss: 0.1032\n",
      "Epoch: 74/100... Training loss: 0.0987\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 74/100... Training loss: 0.1011\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.1047\n",
      "Epoch: 74/100... Training loss: 0.1027\n",
      "Epoch: 74/100... Training loss: 0.1008\n",
      "Epoch: 74/100... Training loss: 0.1042\n",
      "Epoch: 74/100... Training loss: 0.0993\n",
      "Epoch: 74/100... Training loss: 0.1017\n",
      "Epoch: 74/100... Training loss: 0.0988\n",
      "Epoch: 74/100... Training loss: 0.1020\n",
      "Epoch: 74/100... Training loss: 0.1022\n",
      "Epoch: 74/100... Training loss: 0.0968\n",
      "Epoch: 74/100... Training loss: 0.1041\n",
      "Epoch: 74/100... Training loss: 0.1062\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.1029\n",
      "Epoch: 74/100... Training loss: 0.1028\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1009\n",
      "Epoch: 74/100... Training loss: 0.1014\n",
      "Epoch: 74/100... Training loss: 0.1000\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.1025\n",
      "Epoch: 74/100... Training loss: 0.0970\n",
      "Epoch: 74/100... Training loss: 0.1033\n",
      "Epoch: 74/100... Training loss: 0.1015\n",
      "Epoch: 74/100... Training loss: 0.1047\n",
      "Epoch: 74/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.1037\n",
      "Epoch: 75/100... Training loss: 0.1046\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1040\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.1025\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.1051\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.1037\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.1030\n",
      "Epoch: 75/100... Training loss: 0.1029\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1030\n",
      "Epoch: 75/100... Training loss: 0.1046\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.1048\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1038\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1053\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1065\n",
      "Epoch: 75/100... Training loss: 0.1043\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.1042\n",
      "Epoch: 75/100... Training loss: 0.1030\n",
      "Epoch: 75/100... Training loss: 0.1030\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1059\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.1040\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.1034\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1038\n",
      "Epoch: 75/100... Training loss: 0.1041\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.1035\n",
      "Epoch: 75/100... Training loss: 0.1005\n",
      "Epoch: 75/100... Training loss: 0.1030\n",
      "Epoch: 75/100... Training loss: 0.1044\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1057\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.1029\n",
      "Epoch: 75/100... Training loss: 0.1029\n",
      "Epoch: 75/100... Training loss: 0.1029\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1006\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.1043\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1056\n",
      "Epoch: 75/100... Training loss: 0.1030\n",
      "Epoch: 75/100... Training loss: 0.1038\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.0984\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0974\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.1030\n",
      "Epoch: 75/100... Training loss: 0.1025\n",
      "Epoch: 75/100... Training loss: 0.1025\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1025\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.1059\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.1044\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.0973\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.0978\n",
      "Epoch: 75/100... Training loss: 0.1049\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1035\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1065\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.0981\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1011\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1036\n",
      "Epoch: 75/100... Training loss: 0.1035\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1052\n",
      "Epoch: 75/100... Training loss: 0.1064\n",
      "Epoch: 75/100... Training loss: 0.1043\n",
      "Epoch: 75/100... Training loss: 0.1043\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1050\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.0986\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.0987\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.1048\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.0998\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.1032\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.1010\n",
      "Epoch: 75/100... Training loss: 0.0983\n",
      "Epoch: 75/100... Training loss: 0.1034\n",
      "Epoch: 75/100... Training loss: 0.1029\n",
      "Epoch: 75/100... Training loss: 0.1044\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.1044\n",
      "Epoch: 75/100... Training loss: 0.1017\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1030\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.0982\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1009\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.1048\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1039\n",
      "Epoch: 75/100... Training loss: 0.0989\n",
      "Epoch: 75/100... Training loss: 0.0993\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1007\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.0996\n",
      "Epoch: 75/100... Training loss: 0.1049\n",
      "Epoch: 75/100... Training loss: 0.0994\n",
      "Epoch: 75/100... Training loss: 0.1022\n",
      "Epoch: 75/100... Training loss: 0.1012\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.0990\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1000\n",
      "Epoch: 75/100... Training loss: 0.0980\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1029\n",
      "Epoch: 75/100... Training loss: 0.0997\n",
      "Epoch: 75/100... Training loss: 0.0991\n",
      "Epoch: 75/100... Training loss: 0.1042\n",
      "Epoch: 75/100... Training loss: 0.1027\n",
      "Epoch: 75/100... Training loss: 0.1050\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.0995\n",
      "Epoch: 75/100... Training loss: 0.1016\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.1030\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1045\n",
      "Epoch: 75/100... Training loss: 0.1024\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.1044\n",
      "Epoch: 75/100... Training loss: 0.0999\n",
      "Epoch: 75/100... Training loss: 0.1029\n",
      "Epoch: 75/100... Training loss: 0.1050\n",
      "Epoch: 75/100... Training loss: 0.1026\n",
      "Epoch: 75/100... Training loss: 0.1008\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.1028\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.1044\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1014\n",
      "Epoch: 75/100... Training loss: 0.0969\n",
      "Epoch: 75/100... Training loss: 0.1055\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.1051\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.1002\n",
      "Epoch: 75/100... Training loss: 0.1038\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.1057\n",
      "Epoch: 75/100... Training loss: 0.1034\n",
      "Epoch: 75/100... Training loss: 0.1048\n",
      "Epoch: 75/100... Training loss: 0.1085\n",
      "Epoch: 75/100... Training loss: 0.1031\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.0992\n",
      "Epoch: 75/100... Training loss: 0.1019\n",
      "Epoch: 75/100... Training loss: 0.1021\n",
      "Epoch: 75/100... Training loss: 0.1033\n",
      "Epoch: 75/100... Training loss: 0.1003\n",
      "Epoch: 75/100... Training loss: 0.1018\n",
      "Epoch: 75/100... Training loss: 0.1013\n",
      "Epoch: 75/100... Training loss: 0.1020\n",
      "Epoch: 75/100... Training loss: 0.1041\n",
      "Epoch: 75/100... Training loss: 0.1054\n",
      "Epoch: 75/100... Training loss: 0.1004\n",
      "Epoch: 75/100... Training loss: 0.1058\n",
      "Epoch: 75/100... Training loss: 0.1025\n",
      "Epoch: 75/100... Training loss: 0.1046\n",
      "Epoch: 75/100... Training loss: 0.1023\n",
      "Epoch: 75/100... Training loss: 0.1037\n",
      "Epoch: 75/100... Training loss: 0.1015\n",
      "Epoch: 75/100... Training loss: 0.1051\n",
      "Epoch: 75/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1001\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1040\n",
      "Epoch: 76/100... Training loss: 0.0984\n",
      "Epoch: 76/100... Training loss: 0.1040\n",
      "Epoch: 76/100... Training loss: 0.1050\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1040\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.1054\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.1027\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1047\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.1027\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1036\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1060\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.1080\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.1064\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.0988\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1030\n",
      "Epoch: 76/100... Training loss: 0.1032\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1054\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1037\n",
      "Epoch: 76/100... Training loss: 0.1075\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1055\n",
      "Epoch: 76/100... Training loss: 0.1027\n",
      "Epoch: 76/100... Training loss: 0.1037\n",
      "Epoch: 76/100... Training loss: 0.1050\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.1041\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1055\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1051\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.1044\n",
      "Epoch: 76/100... Training loss: 0.1053\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.1070\n",
      "Epoch: 76/100... Training loss: 0.1036\n",
      "Epoch: 76/100... Training loss: 0.1040\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1045\n",
      "Epoch: 76/100... Training loss: 0.1040\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.1046\n",
      "Epoch: 76/100... Training loss: 0.1056\n",
      "Epoch: 76/100... Training loss: 0.1037\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1064\n",
      "Epoch: 76/100... Training loss: 0.1043\n",
      "Epoch: 76/100... Training loss: 0.1036\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.1032\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.0989\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1032\n",
      "Epoch: 76/100... Training loss: 0.1048\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.0976\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1054\n",
      "Epoch: 76/100... Training loss: 0.1059\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0985\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0961\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1048\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1048\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.0965\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.1041\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.0995\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1040\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1021\n",
      "Epoch: 76/100... Training loss: 0.1040\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.0990\n",
      "Epoch: 76/100... Training loss: 0.0992\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1038\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1045\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1035\n",
      "Epoch: 76/100... Training loss: 0.1044\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1040\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.1047\n",
      "Epoch: 76/100... Training loss: 0.1056\n",
      "Epoch: 76/100... Training loss: 0.1036\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1046\n",
      "Epoch: 76/100... Training loss: 0.1036\n",
      "Epoch: 76/100... Training loss: 0.1036\n",
      "Epoch: 76/100... Training loss: 0.1038\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1048\n",
      "Epoch: 76/100... Training loss: 0.1045\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.1010\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1054\n",
      "Epoch: 76/100... Training loss: 0.1014\n",
      "Epoch: 76/100... Training loss: 0.1032\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1031\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.1042\n",
      "Epoch: 76/100... Training loss: 0.1000\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1040\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.0997\n",
      "Epoch: 76/100... Training loss: 0.1008\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1018\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.1053\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.1045\n",
      "Epoch: 76/100... Training loss: 0.1046\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.1026\n",
      "Epoch: 76/100... Training loss: 0.1037\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1007\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1043\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.0998\n",
      "Epoch: 76/100... Training loss: 0.0993\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.1023\n",
      "Epoch: 76/100... Training loss: 0.1039\n",
      "Epoch: 76/100... Training loss: 0.1057\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.1043\n",
      "Epoch: 76/100... Training loss: 0.1032\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.0987\n",
      "Epoch: 76/100... Training loss: 0.1017\n",
      "Epoch: 76/100... Training loss: 0.1020\n",
      "Epoch: 76/100... Training loss: 0.1028\n",
      "Epoch: 76/100... Training loss: 0.1033\n",
      "Epoch: 76/100... Training loss: 0.1002\n",
      "Epoch: 76/100... Training loss: 0.1016\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1044\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.0999\n",
      "Epoch: 76/100... Training loss: 0.1025\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.0983\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.0982\n",
      "Epoch: 76/100... Training loss: 0.0971\n",
      "Epoch: 76/100... Training loss: 0.1019\n",
      "Epoch: 76/100... Training loss: 0.1003\n",
      "Epoch: 76/100... Training loss: 0.1009\n",
      "Epoch: 76/100... Training loss: 0.1011\n",
      "Epoch: 76/100... Training loss: 0.1006\n",
      "Epoch: 76/100... Training loss: 0.1015\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.1005\n",
      "Epoch: 76/100... Training loss: 0.1024\n",
      "Epoch: 76/100... Training loss: 0.1004\n",
      "Epoch: 76/100... Training loss: 0.1012\n",
      "Epoch: 76/100... Training loss: 0.1027\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1029\n",
      "Epoch: 76/100... Training loss: 0.1034\n",
      "Epoch: 76/100... Training loss: 0.1045\n",
      "Epoch: 76/100... Training loss: 0.1013\n",
      "Epoch: 76/100... Training loss: 0.1027\n",
      "Epoch: 76/100... Training loss: 0.1059\n",
      "Epoch: 76/100... Training loss: 0.1022\n",
      "Epoch: 76/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1043\n",
      "Epoch: 77/100... Training loss: 0.1046\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.1038\n",
      "Epoch: 77/100... Training loss: 0.1001\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1045\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1043\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1037\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.1044\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1031\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1059\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1029\n",
      "Epoch: 77/100... Training loss: 0.1044\n",
      "Epoch: 77/100... Training loss: 0.1029\n",
      "Epoch: 77/100... Training loss: 0.1037\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1041\n",
      "Epoch: 77/100... Training loss: 0.1029\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.1053\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1052\n",
      "Epoch: 77/100... Training loss: 0.1050\n",
      "Epoch: 77/100... Training loss: 0.1031\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1031\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1042\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.0999\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.0970\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1029\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1071\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.0982\n",
      "Epoch: 77/100... Training loss: 0.0978\n",
      "Epoch: 77/100... Training loss: 0.1048\n",
      "Epoch: 77/100... Training loss: 0.1037\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1035\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1035\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.0995\n",
      "Epoch: 77/100... Training loss: 0.1055\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.0979\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1029\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.1048\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.1086\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.1046\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.0980\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.1044\n",
      "Epoch: 77/100... Training loss: 0.1018\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1043\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1038\n",
      "Epoch: 77/100... Training loss: 0.1039\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1040\n",
      "Epoch: 77/100... Training loss: 0.1024\n",
      "Epoch: 77/100... Training loss: 0.1046\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1034\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.1041\n",
      "Epoch: 77/100... Training loss: 0.1036\n",
      "Epoch: 77/100... Training loss: 0.0985\n",
      "Epoch: 77/100... Training loss: 0.1047\n",
      "Epoch: 77/100... Training loss: 0.0973\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.0976\n",
      "Epoch: 77/100... Training loss: 0.0984\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.0988\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.1056\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1043\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1037\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.1035\n",
      "Epoch: 77/100... Training loss: 0.0998\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1002\n",
      "Epoch: 77/100... Training loss: 0.1055\n",
      "Epoch: 77/100... Training loss: 0.1074\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.1029\n",
      "Epoch: 77/100... Training loss: 0.1051\n",
      "Epoch: 77/100... Training loss: 0.1031\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.1036\n",
      "Epoch: 77/100... Training loss: 0.1029\n",
      "Epoch: 77/100... Training loss: 0.1007\n",
      "Epoch: 77/100... Training loss: 0.1043\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1010\n",
      "Epoch: 77/100... Training loss: 0.1003\n",
      "Epoch: 77/100... Training loss: 0.1008\n",
      "Epoch: 77/100... Training loss: 0.1041\n",
      "Epoch: 77/100... Training loss: 0.1026\n",
      "Epoch: 77/100... Training loss: 0.1023\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.1049\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1044\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1005\n",
      "Epoch: 77/100... Training loss: 0.1050\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1037\n",
      "Epoch: 77/100... Training loss: 0.0989\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.0996\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1036\n",
      "Epoch: 77/100... Training loss: 0.1035\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1039\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1014\n",
      "Epoch: 77/100... Training loss: 0.1013\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1012\n",
      "Epoch: 77/100... Training loss: 0.1025\n",
      "Epoch: 77/100... Training loss: 0.1045\n",
      "Epoch: 77/100... Training loss: 0.1022\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.0983\n",
      "Epoch: 77/100... Training loss: 0.0997\n",
      "Epoch: 77/100... Training loss: 0.1037\n",
      "Epoch: 77/100... Training loss: 0.1029\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1053\n",
      "Epoch: 77/100... Training loss: 0.1044\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.1036\n",
      "Epoch: 77/100... Training loss: 0.0987\n",
      "Epoch: 77/100... Training loss: 0.1019\n",
      "Epoch: 77/100... Training loss: 0.1004\n",
      "Epoch: 77/100... Training loss: 0.0994\n",
      "Epoch: 77/100... Training loss: 0.1006\n",
      "Epoch: 77/100... Training loss: 0.0991\n",
      "Epoch: 77/100... Training loss: 0.1035\n",
      "Epoch: 77/100... Training loss: 0.1044\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1011\n",
      "Epoch: 77/100... Training loss: 0.0992\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1020\n",
      "Epoch: 77/100... Training loss: 0.1039\n",
      "Epoch: 77/100... Training loss: 0.1021\n",
      "Epoch: 77/100... Training loss: 0.1016\n",
      "Epoch: 77/100... Training loss: 0.1009\n",
      "Epoch: 77/100... Training loss: 0.1053\n",
      "Epoch: 77/100... Training loss: 0.1052\n",
      "Epoch: 77/100... Training loss: 0.0977\n",
      "Epoch: 77/100... Training loss: 0.1039\n",
      "Epoch: 77/100... Training loss: 0.1000\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.1027\n",
      "Epoch: 77/100... Training loss: 0.0986\n",
      "Epoch: 77/100... Training loss: 0.1030\n",
      "Epoch: 77/100... Training loss: 0.1017\n",
      "Epoch: 77/100... Training loss: 0.1059\n",
      "Epoch: 77/100... Training loss: 0.1032\n",
      "Epoch: 77/100... Training loss: 0.1028\n",
      "Epoch: 77/100... Training loss: 0.1042\n",
      "Epoch: 77/100... Training loss: 0.1036\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1033\n",
      "Epoch: 77/100... Training loss: 0.1015\n",
      "Epoch: 77/100... Training loss: 0.1060\n",
      "Epoch: 77/100... Training loss: 0.1035\n",
      "Epoch: 77/100... Training loss: 0.0968\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1056\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.1054\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.1053\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1039\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1044\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1052\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1055\n",
      "Epoch: 78/100... Training loss: 0.1030\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.1030\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1054\n",
      "Epoch: 78/100... Training loss: 0.1050\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1057\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1057\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1034\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1030\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.0993\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.1050\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.1060\n",
      "Epoch: 78/100... Training loss: 0.1048\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1054\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1044\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1089\n",
      "Epoch: 78/100... Training loss: 0.1000\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1047\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0988\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1055\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1055\n",
      "Epoch: 78/100... Training loss: 0.1030\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1051\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1039\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1045\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.0969\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.1041\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.1041\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1055\n",
      "Epoch: 78/100... Training loss: 0.0985\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.0942\n",
      "Epoch: 78/100... Training loss: 0.1001\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1061\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.1014\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.1047\n",
      "Epoch: 78/100... Training loss: 0.1045\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1031\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.1033\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1065\n",
      "Epoch: 78/100... Training loss: 0.0955\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1037\n",
      "Epoch: 78/100... Training loss: 0.1010\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1013\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1026\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.1033\n",
      "Epoch: 78/100... Training loss: 0.1037\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1018\n",
      "Epoch: 78/100... Training loss: 0.1009\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.0991\n",
      "Epoch: 78/100... Training loss: 0.0977\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1019\n",
      "Epoch: 78/100... Training loss: 0.1034\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.1024\n",
      "Epoch: 78/100... Training loss: 0.1034\n",
      "Epoch: 78/100... Training loss: 0.0998\n",
      "Epoch: 78/100... Training loss: 0.0994\n",
      "Epoch: 78/100... Training loss: 0.1020\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.0992\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.1007\n",
      "Epoch: 78/100... Training loss: 0.0995\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 78/100... Training loss: 0.1016\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.0987\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0989\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1051\n",
      "Epoch: 78/100... Training loss: 0.1029\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1037\n",
      "Epoch: 78/100... Training loss: 0.1048\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.1004\n",
      "Epoch: 78/100... Training loss: 0.0999\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.1025\n",
      "Epoch: 78/100... Training loss: 0.1067\n",
      "Epoch: 78/100... Training loss: 0.1015\n",
      "Epoch: 78/100... Training loss: 0.1028\n",
      "Epoch: 78/100... Training loss: 0.1011\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1038\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.0979\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.1076\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.0996\n",
      "Epoch: 78/100... Training loss: 0.1053\n",
      "Epoch: 78/100... Training loss: 0.1032\n",
      "Epoch: 78/100... Training loss: 0.0986\n",
      "Epoch: 78/100... Training loss: 0.1079\n",
      "Epoch: 78/100... Training loss: 0.1022\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.1027\n",
      "Epoch: 78/100... Training loss: 0.1023\n",
      "Epoch: 78/100... Training loss: 0.1046\n",
      "Epoch: 78/100... Training loss: 0.1021\n",
      "Epoch: 78/100... Training loss: 0.0997\n",
      "Epoch: 78/100... Training loss: 0.1008\n",
      "Epoch: 78/100... Training loss: 0.1003\n",
      "Epoch: 78/100... Training loss: 0.1005\n",
      "Epoch: 78/100... Training loss: 0.1036\n",
      "Epoch: 78/100... Training loss: 0.1002\n",
      "Epoch: 78/100... Training loss: 0.1017\n",
      "Epoch: 78/100... Training loss: 0.1012\n",
      "Epoch: 78/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.0975\n",
      "Epoch: 79/100... Training loss: 0.0974\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1039\n",
      "Epoch: 79/100... Training loss: 0.1036\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1037\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1034\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1041\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1036\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1036\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.1057\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.1037\n",
      "Epoch: 79/100... Training loss: 0.1046\n",
      "Epoch: 79/100... Training loss: 0.1034\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0973\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.1055\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1046\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1032\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.1049\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.0986\n",
      "Epoch: 79/100... Training loss: 0.1047\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.0983\n",
      "Epoch: 79/100... Training loss: 0.1051\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.1040\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.1034\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1046\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1048\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1038\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.1040\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.0977\n",
      "Epoch: 79/100... Training loss: 0.1041\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1043\n",
      "Epoch: 79/100... Training loss: 0.1008\n",
      "Epoch: 79/100... Training loss: 0.1041\n",
      "Epoch: 79/100... Training loss: 0.1034\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.1048\n",
      "Epoch: 79/100... Training loss: 0.1043\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.1035\n",
      "Epoch: 79/100... Training loss: 0.1035\n",
      "Epoch: 79/100... Training loss: 0.1038\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.1033\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1033\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.1003\n",
      "Epoch: 79/100... Training loss: 0.1032\n",
      "Epoch: 79/100... Training loss: 0.1045\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.1037\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.1039\n",
      "Epoch: 79/100... Training loss: 0.1031\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1032\n",
      "Epoch: 79/100... Training loss: 0.1042\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.1075\n",
      "Epoch: 79/100... Training loss: 0.1036\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.1045\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.0982\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1039\n",
      "Epoch: 79/100... Training loss: 0.0992\n",
      "Epoch: 79/100... Training loss: 0.1006\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1035\n",
      "Epoch: 79/100... Training loss: 0.1025\n",
      "Epoch: 79/100... Training loss: 0.1057\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1037\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1052\n",
      "Epoch: 79/100... Training loss: 0.1040\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1041\n",
      "Epoch: 79/100... Training loss: 0.1025\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1054\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1007\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.1002\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.1036\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1042\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1004\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1037\n",
      "Epoch: 79/100... Training loss: 0.0994\n",
      "Epoch: 79/100... Training loss: 0.1015\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.1014\n",
      "Epoch: 79/100... Training loss: 0.1021\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1035\n",
      "Epoch: 79/100... Training loss: 0.1025\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1057\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1062\n",
      "Epoch: 79/100... Training loss: 0.1037\n",
      "Epoch: 79/100... Training loss: 0.1035\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.0998\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.0984\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1026\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.1057\n",
      "Epoch: 79/100... Training loss: 0.0979\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.1044\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.1041\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.0997\n",
      "Epoch: 79/100... Training loss: 0.1040\n",
      "Epoch: 79/100... Training loss: 0.1027\n",
      "Epoch: 79/100... Training loss: 0.0988\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.1018\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.0993\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.1063\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1013\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.1034\n",
      "Epoch: 79/100... Training loss: 0.1037\n",
      "Epoch: 79/100... Training loss: 0.0981\n",
      "Epoch: 79/100... Training loss: 0.1057\n",
      "Epoch: 79/100... Training loss: 0.1030\n",
      "Epoch: 79/100... Training loss: 0.0991\n",
      "Epoch: 79/100... Training loss: 0.1009\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1016\n",
      "Epoch: 79/100... Training loss: 0.1001\n",
      "Epoch: 79/100... Training loss: 0.1068\n",
      "Epoch: 79/100... Training loss: 0.0999\n",
      "Epoch: 79/100... Training loss: 0.1012\n",
      "Epoch: 79/100... Training loss: 0.1039\n",
      "Epoch: 79/100... Training loss: 0.1019\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1020\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1010\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1052\n",
      "Epoch: 79/100... Training loss: 0.1042\n",
      "Epoch: 79/100... Training loss: 0.1047\n",
      "Epoch: 79/100... Training loss: 0.0995\n",
      "Epoch: 79/100... Training loss: 0.1000\n",
      "Epoch: 79/100... Training loss: 0.1028\n",
      "Epoch: 79/100... Training loss: 0.1034\n",
      "Epoch: 79/100... Training loss: 0.1022\n",
      "Epoch: 79/100... Training loss: 0.1011\n",
      "Epoch: 79/100... Training loss: 0.1037\n",
      "Epoch: 79/100... Training loss: 0.1040\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1054\n",
      "Epoch: 79/100... Training loss: 0.1044\n",
      "Epoch: 79/100... Training loss: 0.1029\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.0980\n",
      "Epoch: 79/100... Training loss: 0.0987\n",
      "Epoch: 79/100... Training loss: 0.1047\n",
      "Epoch: 79/100... Training loss: 0.0990\n",
      "Epoch: 79/100... Training loss: 0.1023\n",
      "Epoch: 79/100... Training loss: 0.1043\n",
      "Epoch: 79/100... Training loss: 0.1017\n",
      "Epoch: 79/100... Training loss: 0.1024\n",
      "Epoch: 79/100... Training loss: 0.1005\n",
      "Epoch: 79/100... Training loss: 0.1074\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.1035\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1024\n",
      "Epoch: 80/100... Training loss: 0.1044\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1030\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1038\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.1044\n",
      "Epoch: 80/100... Training loss: 0.1046\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1028\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.1024\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.1024\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.0982\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1053\n",
      "Epoch: 80/100... Training loss: 0.1026\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.1042\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1042\n",
      "Epoch: 80/100... Training loss: 0.1044\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1026\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1061\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1043\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1047\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.1045\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.1045\n",
      "Epoch: 80/100... Training loss: 0.1037\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.1039\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1040\n",
      "Epoch: 80/100... Training loss: 0.1026\n",
      "Epoch: 80/100... Training loss: 0.1044\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1034\n",
      "Epoch: 80/100... Training loss: 0.1001\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1034\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1030\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1045\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.0993\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.1040\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1041\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.0949\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.1044\n",
      "Epoch: 80/100... Training loss: 0.1057\n",
      "Epoch: 80/100... Training loss: 0.1024\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.1016\n",
      "Epoch: 80/100... Training loss: 0.0955\n",
      "Epoch: 80/100... Training loss: 0.0998\n",
      "Epoch: 80/100... Training loss: 0.1030\n",
      "Epoch: 80/100... Training loss: 0.1049\n",
      "Epoch: 80/100... Training loss: 0.0989\n",
      "Epoch: 80/100... Training loss: 0.1037\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1039\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.0972\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.0988\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1046\n",
      "Epoch: 80/100... Training loss: 0.1034\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.0986\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1043\n",
      "Epoch: 80/100... Training loss: 0.1014\n",
      "Epoch: 80/100... Training loss: 0.1049\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1079\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1028\n",
      "Epoch: 80/100... Training loss: 0.1026\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.1026\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.1063\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1045\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1006\n",
      "Epoch: 80/100... Training loss: 0.0979\n",
      "Epoch: 80/100... Training loss: 0.1053\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1024\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1002\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1030\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1012\n",
      "Epoch: 80/100... Training loss: 0.1049\n",
      "Epoch: 80/100... Training loss: 0.1064\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.0987\n",
      "Epoch: 80/100... Training loss: 0.1041\n",
      "Epoch: 80/100... Training loss: 0.1023\n",
      "Epoch: 80/100... Training loss: 0.1044\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.0983\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1053\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.1008\n",
      "Epoch: 80/100... Training loss: 0.0981\n",
      "Epoch: 80/100... Training loss: 0.1042\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.1020\n",
      "Epoch: 80/100... Training loss: 0.1029\n",
      "Epoch: 80/100... Training loss: 0.1000\n",
      "Epoch: 80/100... Training loss: 0.1027\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.1019\n",
      "Epoch: 80/100... Training loss: 0.1053\n",
      "Epoch: 80/100... Training loss: 0.1043\n",
      "Epoch: 80/100... Training loss: 0.1035\n",
      "Epoch: 80/100... Training loss: 0.1004\n",
      "Epoch: 80/100... Training loss: 0.1043\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 80/100... Training loss: 0.1025\n",
      "Epoch: 80/100... Training loss: 0.1033\n",
      "Epoch: 80/100... Training loss: 0.0985\n",
      "Epoch: 80/100... Training loss: 0.1031\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.1010\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1047\n",
      "Epoch: 80/100... Training loss: 0.0990\n",
      "Epoch: 80/100... Training loss: 0.1011\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1025\n",
      "Epoch: 80/100... Training loss: 0.1043\n",
      "Epoch: 80/100... Training loss: 0.1047\n",
      "Epoch: 80/100... Training loss: 0.0997\n",
      "Epoch: 80/100... Training loss: 0.1003\n",
      "Epoch: 80/100... Training loss: 0.0995\n",
      "Epoch: 80/100... Training loss: 0.0978\n",
      "Epoch: 80/100... Training loss: 0.0999\n",
      "Epoch: 80/100... Training loss: 0.1024\n",
      "Epoch: 80/100... Training loss: 0.1009\n",
      "Epoch: 80/100... Training loss: 0.1007\n",
      "Epoch: 80/100... Training loss: 0.0980\n",
      "Epoch: 80/100... Training loss: 0.1018\n",
      "Epoch: 80/100... Training loss: 0.1026\n",
      "Epoch: 80/100... Training loss: 0.0996\n",
      "Epoch: 80/100... Training loss: 0.1050\n",
      "Epoch: 80/100... Training loss: 0.0967\n",
      "Epoch: 80/100... Training loss: 0.1017\n",
      "Epoch: 80/100... Training loss: 0.0991\n",
      "Epoch: 80/100... Training loss: 0.1074\n",
      "Epoch: 80/100... Training loss: 0.0994\n",
      "Epoch: 80/100... Training loss: 0.1032\n",
      "Epoch: 80/100... Training loss: 0.1005\n",
      "Epoch: 80/100... Training loss: 0.1050\n",
      "Epoch: 80/100... Training loss: 0.1036\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.0984\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1013\n",
      "Epoch: 80/100... Training loss: 0.1058\n",
      "Epoch: 80/100... Training loss: 0.1021\n",
      "Epoch: 80/100... Training loss: 0.1022\n",
      "Epoch: 80/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1037\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.1045\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.0988\n",
      "Epoch: 81/100... Training loss: 0.1032\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1037\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.0998\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.1039\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.1037\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1053\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1044\n",
      "Epoch: 81/100... Training loss: 0.1040\n",
      "Epoch: 81/100... Training loss: 0.1024\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.0989\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.0979\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1032\n",
      "Epoch: 81/100... Training loss: 0.1041\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1049\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.0980\n",
      "Epoch: 81/100... Training loss: 0.1056\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.0975\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1037\n",
      "Epoch: 81/100... Training loss: 0.1043\n",
      "Epoch: 81/100... Training loss: 0.1046\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1031\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1040\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1046\n",
      "Epoch: 81/100... Training loss: 0.0968\n",
      "Epoch: 81/100... Training loss: 0.1039\n",
      "Epoch: 81/100... Training loss: 0.1055\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.1044\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.1047\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.1036\n",
      "Epoch: 81/100... Training loss: 0.1043\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1042\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1031\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.1035\n",
      "Epoch: 81/100... Training loss: 0.1031\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1073\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.1015\n",
      "Epoch: 81/100... Training loss: 0.1059\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.0972\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1024\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.1037\n",
      "Epoch: 81/100... Training loss: 0.1004\n",
      "Epoch: 81/100... Training loss: 0.1035\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1040\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1058\n",
      "Epoch: 81/100... Training loss: 0.1008\n",
      "Epoch: 81/100... Training loss: 0.1028\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1054\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.0997\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1038\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.0994\n",
      "Epoch: 81/100... Training loss: 0.0973\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.1047\n",
      "Epoch: 81/100... Training loss: 0.1035\n",
      "Epoch: 81/100... Training loss: 0.0977\n",
      "Epoch: 81/100... Training loss: 0.1074\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1006\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.0973\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1046\n",
      "Epoch: 81/100... Training loss: 0.1036\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.1049\n",
      "Epoch: 81/100... Training loss: 0.0992\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1034\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1022\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.0996\n",
      "Epoch: 81/100... Training loss: 0.1024\n",
      "Epoch: 81/100... Training loss: 0.1032\n",
      "Epoch: 81/100... Training loss: 0.1056\n",
      "Epoch: 81/100... Training loss: 0.0984\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1044\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1024\n",
      "Epoch: 81/100... Training loss: 0.1048\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.1023\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.1021\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1029\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.1032\n",
      "Epoch: 81/100... Training loss: 0.1007\n",
      "Epoch: 81/100... Training loss: 0.0993\n",
      "Epoch: 81/100... Training loss: 0.1054\n",
      "Epoch: 81/100... Training loss: 0.1039\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1053\n",
      "Epoch: 81/100... Training loss: 0.0976\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1012\n",
      "Epoch: 81/100... Training loss: 0.1051\n",
      "Epoch: 81/100... Training loss: 0.1041\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.1019\n",
      "Epoch: 81/100... Training loss: 0.1026\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1017\n",
      "Epoch: 81/100... Training loss: 0.1053\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1047\n",
      "Epoch: 81/100... Training loss: 0.1001\n",
      "Epoch: 81/100... Training loss: 0.1034\n",
      "Epoch: 81/100... Training loss: 0.1038\n",
      "Epoch: 81/100... Training loss: 0.1036\n",
      "Epoch: 81/100... Training loss: 0.1020\n",
      "Epoch: 81/100... Training loss: 0.0987\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.0990\n",
      "Epoch: 81/100... Training loss: 0.1010\n",
      "Epoch: 81/100... Training loss: 0.1055\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.1011\n",
      "Epoch: 81/100... Training loss: 0.1009\n",
      "Epoch: 81/100... Training loss: 0.1016\n",
      "Epoch: 81/100... Training loss: 0.0981\n",
      "Epoch: 81/100... Training loss: 0.1066\n",
      "Epoch: 81/100... Training loss: 0.0995\n",
      "Epoch: 81/100... Training loss: 0.1014\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.1003\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.1033\n",
      "Epoch: 81/100... Training loss: 0.1024\n",
      "Epoch: 81/100... Training loss: 0.1013\n",
      "Epoch: 81/100... Training loss: 0.1044\n",
      "Epoch: 81/100... Training loss: 0.1030\n",
      "Epoch: 81/100... Training loss: 0.1000\n",
      "Epoch: 81/100... Training loss: 0.1069\n",
      "Epoch: 81/100... Training loss: 0.1041\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 81/100... Training loss: 0.1034\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1002\n",
      "Epoch: 81/100... Training loss: 0.0991\n",
      "Epoch: 81/100... Training loss: 0.1025\n",
      "Epoch: 81/100... Training loss: 0.1053\n",
      "Epoch: 81/100... Training loss: 0.1028\n",
      "Epoch: 81/100... Training loss: 0.1027\n",
      "Epoch: 81/100... Training loss: 0.1005\n",
      "Epoch: 81/100... Training loss: 0.0999\n",
      "Epoch: 81/100... Training loss: 0.1018\n",
      "Epoch: 81/100... Training loss: 0.0975\n",
      "Epoch: 81/100... Training loss: 0.1039\n",
      "Epoch: 81/100... Training loss: 0.1049\n",
      "Epoch: 81/100... Training loss: 0.1048\n",
      "Epoch: 81/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1031\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.1065\n",
      "Epoch: 82/100... Training loss: 0.1040\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1045\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1035\n",
      "Epoch: 82/100... Training loss: 0.1034\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1039\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.1037\n",
      "Epoch: 82/100... Training loss: 0.1031\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.1037\n",
      "Epoch: 82/100... Training loss: 0.1039\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1055\n",
      "Epoch: 82/100... Training loss: 0.1027\n",
      "Epoch: 82/100... Training loss: 0.1030\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.1047\n",
      "Epoch: 82/100... Training loss: 0.1045\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1039\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1047\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.1048\n",
      "Epoch: 82/100... Training loss: 0.1047\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1036\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.1027\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1016\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1033\n",
      "Epoch: 82/100... Training loss: 0.1027\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1049\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1039\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.1059\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.1062\n",
      "Epoch: 82/100... Training loss: 0.1027\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1030\n",
      "Epoch: 82/100... Training loss: 0.1040\n",
      "Epoch: 82/100... Training loss: 0.1024\n",
      "Epoch: 82/100... Training loss: 0.1041\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1030\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1036\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1035\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1056\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.1048\n",
      "Epoch: 82/100... Training loss: 0.1027\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.1045\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0992\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1091\n",
      "Epoch: 82/100... Training loss: 0.1039\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1050\n",
      "Epoch: 82/100... Training loss: 0.1049\n",
      "Epoch: 82/100... Training loss: 0.0985\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.1034\n",
      "Epoch: 82/100... Training loss: 0.1032\n",
      "Epoch: 82/100... Training loss: 0.1032\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0981\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1033\n",
      "Epoch: 82/100... Training loss: 0.0965\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1027\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1038\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.0982\n",
      "Epoch: 82/100... Training loss: 0.1052\n",
      "Epoch: 82/100... Training loss: 0.1036\n",
      "Epoch: 82/100... Training loss: 0.1054\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0986\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1017\n",
      "Epoch: 82/100... Training loss: 0.1047\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.1044\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.0971\n",
      "Epoch: 82/100... Training loss: 0.1031\n",
      "Epoch: 82/100... Training loss: 0.1004\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.1075\n",
      "Epoch: 82/100... Training loss: 0.0977\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1034\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1018\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1038\n",
      "Epoch: 82/100... Training loss: 0.1046\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1033\n",
      "Epoch: 82/100... Training loss: 0.1033\n",
      "Epoch: 82/100... Training loss: 0.1040\n",
      "Epoch: 82/100... Training loss: 0.1046\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1012\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1048\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1031\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1008\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1042\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.1020\n",
      "Epoch: 82/100... Training loss: 0.1031\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.0983\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.1015\n",
      "Epoch: 82/100... Training loss: 0.0993\n",
      "Epoch: 82/100... Training loss: 0.0990\n",
      "Epoch: 82/100... Training loss: 0.1007\n",
      "Epoch: 82/100... Training loss: 0.1032\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.1025\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.0991\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.0994\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.1031\n",
      "Epoch: 82/100... Training loss: 0.1055\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1042\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.0995\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1036\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1021\n",
      "Epoch: 82/100... Training loss: 0.1027\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1030\n",
      "Epoch: 82/100... Training loss: 0.1032\n",
      "Epoch: 82/100... Training loss: 0.1005\n",
      "Epoch: 82/100... Training loss: 0.1022\n",
      "Epoch: 82/100... Training loss: 0.0989\n",
      "Epoch: 82/100... Training loss: 0.0970\n",
      "Epoch: 82/100... Training loss: 0.0976\n",
      "Epoch: 82/100... Training loss: 0.0996\n",
      "Epoch: 82/100... Training loss: 0.1000\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1001\n",
      "Epoch: 82/100... Training loss: 0.1019\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1039\n",
      "Epoch: 82/100... Training loss: 0.1039\n",
      "Epoch: 82/100... Training loss: 0.0997\n",
      "Epoch: 82/100... Training loss: 0.1011\n",
      "Epoch: 82/100... Training loss: 0.1041\n",
      "Epoch: 82/100... Training loss: 0.0987\n",
      "Epoch: 82/100... Training loss: 0.1065\n",
      "Epoch: 82/100... Training loss: 0.1023\n",
      "Epoch: 82/100... Training loss: 0.1066\n",
      "Epoch: 82/100... Training loss: 0.1038\n",
      "Epoch: 82/100... Training loss: 0.0988\n",
      "Epoch: 82/100... Training loss: 0.1028\n",
      "Epoch: 82/100... Training loss: 0.0999\n",
      "Epoch: 82/100... Training loss: 0.0998\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.1064\n",
      "Epoch: 82/100... Training loss: 0.1014\n",
      "Epoch: 82/100... Training loss: 0.1003\n",
      "Epoch: 82/100... Training loss: 0.1039\n",
      "Epoch: 82/100... Training loss: 0.1042\n",
      "Epoch: 82/100... Training loss: 0.1037\n",
      "Epoch: 82/100... Training loss: 0.1010\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1050\n",
      "Epoch: 82/100... Training loss: 0.1006\n",
      "Epoch: 82/100... Training loss: 0.0984\n",
      "Epoch: 82/100... Training loss: 0.1030\n",
      "Epoch: 82/100... Training loss: 0.1009\n",
      "Epoch: 82/100... Training loss: 0.1002\n",
      "Epoch: 82/100... Training loss: 0.1013\n",
      "Epoch: 82/100... Training loss: 0.1040\n",
      "Epoch: 82/100... Training loss: 0.1029\n",
      "Epoch: 82/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.1062\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.0987\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.0954\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.1051\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1043\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.0960\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.1028\n",
      "Epoch: 83/100... Training loss: 0.1027\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0998\n",
      "Epoch: 83/100... Training loss: 0.1041\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1041\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.1032\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1056\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.0945\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1038\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.0984\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1046\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1033\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1033\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.0979\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.1043\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.1027\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.1044\n",
      "Epoch: 83/100... Training loss: 0.1041\n",
      "Epoch: 83/100... Training loss: 0.1034\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1044\n",
      "Epoch: 83/100... Training loss: 0.1032\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.0970\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1039\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1048\n",
      "Epoch: 83/100... Training loss: 0.1059\n",
      "Epoch: 83/100... Training loss: 0.1033\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 83/100... Training loss: 0.1027\n",
      "Epoch: 83/100... Training loss: 0.1041\n",
      "Epoch: 83/100... Training loss: 0.1042\n",
      "Epoch: 83/100... Training loss: 0.1039\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.0976\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1036\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.1040\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1039\n",
      "Epoch: 83/100... Training loss: 0.1048\n",
      "Epoch: 83/100... Training loss: 0.0978\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.0974\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1001\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.0975\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.1027\n",
      "Epoch: 83/100... Training loss: 0.0996\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.1057\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1034\n",
      "Epoch: 83/100... Training loss: 0.1039\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1038\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1076\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.1050\n",
      "Epoch: 83/100... Training loss: 0.1041\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.1032\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.0989\n",
      "Epoch: 83/100... Training loss: 0.1059\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.0985\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.1046\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.1025\n",
      "Epoch: 83/100... Training loss: 0.1008\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.1053\n",
      "Epoch: 83/100... Training loss: 0.1049\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.1035\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.1039\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1047\n",
      "Epoch: 83/100... Training loss: 0.1028\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.1046\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.0986\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1003\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.1033\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.1014\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.1034\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.1038\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.1037\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1016\n",
      "Epoch: 83/100... Training loss: 0.1042\n",
      "Epoch: 83/100... Training loss: 0.1045\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.1040\n",
      "Epoch: 83/100... Training loss: 0.1027\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.1006\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1033\n",
      "Epoch: 83/100... Training loss: 0.1053\n",
      "Epoch: 83/100... Training loss: 0.1031\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.1013\n",
      "Epoch: 83/100... Training loss: 0.1000\n",
      "Epoch: 83/100... Training loss: 0.1029\n",
      "Epoch: 83/100... Training loss: 0.1017\n",
      "Epoch: 83/100... Training loss: 0.1035\n",
      "Epoch: 83/100... Training loss: 0.1012\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.1028\n",
      "Epoch: 83/100... Training loss: 0.1041\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1004\n",
      "Epoch: 83/100... Training loss: 0.0999\n",
      "Epoch: 83/100... Training loss: 0.0995\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1015\n",
      "Epoch: 83/100... Training loss: 0.1005\n",
      "Epoch: 83/100... Training loss: 0.1046\n",
      "Epoch: 83/100... Training loss: 0.1028\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.0994\n",
      "Epoch: 83/100... Training loss: 0.1036\n",
      "Epoch: 83/100... Training loss: 0.1056\n",
      "Epoch: 83/100... Training loss: 0.1032\n",
      "Epoch: 83/100... Training loss: 0.1011\n",
      "Epoch: 83/100... Training loss: 0.1021\n",
      "Epoch: 83/100... Training loss: 0.1018\n",
      "Epoch: 83/100... Training loss: 0.1027\n",
      "Epoch: 83/100... Training loss: 0.1033\n",
      "Epoch: 83/100... Training loss: 0.1010\n",
      "Epoch: 83/100... Training loss: 0.1019\n",
      "Epoch: 83/100... Training loss: 0.1007\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.1024\n",
      "Epoch: 83/100... Training loss: 0.1026\n",
      "Epoch: 83/100... Training loss: 0.1009\n",
      "Epoch: 83/100... Training loss: 0.1030\n",
      "Epoch: 83/100... Training loss: 0.1002\n",
      "Epoch: 83/100... Training loss: 0.1022\n",
      "Epoch: 83/100... Training loss: 0.0993\n",
      "Epoch: 83/100... Training loss: 0.1020\n",
      "Epoch: 83/100... Training loss: 0.1053\n",
      "Epoch: 83/100... Training loss: 0.1023\n",
      "Epoch: 83/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1002\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1060\n",
      "Epoch: 84/100... Training loss: 0.0979\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1028\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1051\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.1030\n",
      "Epoch: 84/100... Training loss: 0.1028\n",
      "Epoch: 84/100... Training loss: 0.1065\n",
      "Epoch: 84/100... Training loss: 0.1069\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1053\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.0981\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1050\n",
      "Epoch: 84/100... Training loss: 0.1027\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1029\n",
      "Epoch: 84/100... Training loss: 0.0971\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1032\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1037\n",
      "Epoch: 84/100... Training loss: 0.1029\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.1028\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1001\n",
      "Epoch: 84/100... Training loss: 0.0972\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.1045\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.1035\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.1030\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1051\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1041\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1027\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1045\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.0969\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1050\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1052\n",
      "Epoch: 84/100... Training loss: 0.1038\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.0974\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1038\n",
      "Epoch: 84/100... Training loss: 0.1044\n",
      "Epoch: 84/100... Training loss: 0.1040\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1031\n",
      "Epoch: 84/100... Training loss: 0.1055\n",
      "Epoch: 84/100... Training loss: 0.0987\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1029\n",
      "Epoch: 84/100... Training loss: 0.0984\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.1031\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1045\n",
      "Epoch: 84/100... Training loss: 0.1055\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1047\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1030\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.1036\n",
      "Epoch: 84/100... Training loss: 0.1028\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.1052\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1035\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1038\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1047\n",
      "Epoch: 84/100... Training loss: 0.1009\n",
      "Epoch: 84/100... Training loss: 0.1056\n",
      "Epoch: 84/100... Training loss: 0.1029\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0996\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1030\n",
      "Epoch: 84/100... Training loss: 0.1035\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.1035\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.0995\n",
      "Epoch: 84/100... Training loss: 0.1024\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1030\n",
      "Epoch: 84/100... Training loss: 0.0986\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.1000\n",
      "Epoch: 84/100... Training loss: 0.1042\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.1041\n",
      "Epoch: 84/100... Training loss: 0.1028\n",
      "Epoch: 84/100... Training loss: 0.1027\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1037\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.1040\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.1040\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.0969\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1033\n",
      "Epoch: 84/100... Training loss: 0.0999\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.0985\n",
      "Epoch: 84/100... Training loss: 0.1008\n",
      "Epoch: 84/100... Training loss: 0.1035\n",
      "Epoch: 84/100... Training loss: 0.1041\n",
      "Epoch: 84/100... Training loss: 0.0997\n",
      "Epoch: 84/100... Training loss: 0.1005\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1035\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1035\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.1034\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.1036\n",
      "Epoch: 84/100... Training loss: 0.1038\n",
      "Epoch: 84/100... Training loss: 0.1013\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1006\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.1023\n",
      "Epoch: 84/100... Training loss: 0.1042\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1007\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.1015\n",
      "Epoch: 84/100... Training loss: 0.0998\n",
      "Epoch: 84/100... Training loss: 0.1036\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1003\n",
      "Epoch: 84/100... Training loss: 0.0992\n",
      "Epoch: 84/100... Training loss: 0.0988\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.0982\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1010\n",
      "Epoch: 84/100... Training loss: 0.1037\n",
      "Epoch: 84/100... Training loss: 0.0989\n",
      "Epoch: 84/100... Training loss: 0.1037\n",
      "Epoch: 84/100... Training loss: 0.1022\n",
      "Epoch: 84/100... Training loss: 0.1014\n",
      "Epoch: 84/100... Training loss: 0.1017\n",
      "Epoch: 84/100... Training loss: 0.1018\n",
      "Epoch: 84/100... Training loss: 0.1004\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1021\n",
      "Epoch: 84/100... Training loss: 0.1020\n",
      "Epoch: 84/100... Training loss: 0.1026\n",
      "Epoch: 84/100... Training loss: 0.1039\n",
      "Epoch: 84/100... Training loss: 0.1042\n",
      "Epoch: 84/100... Training loss: 0.0991\n",
      "Epoch: 84/100... Training loss: 0.1016\n",
      "Epoch: 84/100... Training loss: 0.1045\n",
      "Epoch: 84/100... Training loss: 0.1011\n",
      "Epoch: 84/100... Training loss: 0.1019\n",
      "Epoch: 84/100... Training loss: 0.0980\n",
      "Epoch: 84/100... Training loss: 0.1012\n",
      "Epoch: 84/100... Training loss: 0.1053\n",
      "Epoch: 84/100... Training loss: 0.1025\n",
      "Epoch: 84/100... Training loss: 0.0994\n",
      "Epoch: 84/100... Training loss: 0.0983\n",
      "Epoch: 84/100... Training loss: 0.1046\n",
      "Epoch: 84/100... Training loss: 0.0976\n",
      "Epoch: 84/100... Training loss: 0.1038\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.1024\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.1050\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.0969\n",
      "Epoch: 85/100... Training loss: 0.1028\n",
      "Epoch: 85/100... Training loss: 0.1009\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1033\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.1039\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.1041\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.1033\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1024\n",
      "Epoch: 85/100... Training loss: 0.1022\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1050\n",
      "Epoch: 85/100... Training loss: 0.1040\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.1039\n",
      "Epoch: 85/100... Training loss: 0.0976\n",
      "Epoch: 85/100... Training loss: 0.1035\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.0964\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1038\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1025\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.1050\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.1048\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1036\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1035\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1030\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.1029\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1029\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.1030\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1028\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1045\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.1048\n",
      "Epoch: 85/100... Training loss: 0.1036\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1044\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1028\n",
      "Epoch: 85/100... Training loss: 0.0978\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.0980\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.0981\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.1045\n",
      "Epoch: 85/100... Training loss: 0.1048\n",
      "Epoch: 85/100... Training loss: 0.1025\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.1043\n",
      "Epoch: 85/100... Training loss: 0.1024\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.1012\n",
      "Epoch: 85/100... Training loss: 0.1007\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.1006\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.1050\n",
      "Epoch: 85/100... Training loss: 0.1028\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.1024\n",
      "Epoch: 85/100... Training loss: 0.1005\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.0995\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1044\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1036\n",
      "Epoch: 85/100... Training loss: 0.1043\n",
      "Epoch: 85/100... Training loss: 0.1057\n",
      "Epoch: 85/100... Training loss: 0.1026\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.0984\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1030\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1035\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.0994\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.1034\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1041\n",
      "Epoch: 85/100... Training loss: 0.1053\n",
      "Epoch: 85/100... Training loss: 0.0996\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1041\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1010\n",
      "Epoch: 85/100... Training loss: 0.0993\n",
      "Epoch: 85/100... Training loss: 0.1030\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.1047\n",
      "Epoch: 85/100... Training loss: 0.0982\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1029\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.0991\n",
      "Epoch: 85/100... Training loss: 0.1040\n",
      "Epoch: 85/100... Training loss: 0.0968\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.0990\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1049\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1035\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1035\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.0985\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.0983\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1029\n",
      "Epoch: 85/100... Training loss: 0.0986\n",
      "Epoch: 85/100... Training loss: 0.1004\n",
      "Epoch: 85/100... Training loss: 0.1025\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1013\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1015\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1022\n",
      "Epoch: 85/100... Training loss: 0.1046\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.1037\n",
      "Epoch: 85/100... Training loss: 0.1044\n",
      "Epoch: 85/100... Training loss: 0.1001\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.1044\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.1022\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.1055\n",
      "Epoch: 85/100... Training loss: 0.0966\n",
      "Epoch: 85/100... Training loss: 0.1038\n",
      "Epoch: 85/100... Training loss: 0.0987\n",
      "Epoch: 85/100... Training loss: 0.1029\n",
      "Epoch: 85/100... Training loss: 0.1017\n",
      "Epoch: 85/100... Training loss: 0.1008\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1045\n",
      "Epoch: 85/100... Training loss: 0.0998\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.1000\n",
      "Epoch: 85/100... Training loss: 0.1045\n",
      "Epoch: 85/100... Training loss: 0.1032\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1033\n",
      "Epoch: 85/100... Training loss: 0.1014\n",
      "Epoch: 85/100... Training loss: 0.1029\n",
      "Epoch: 85/100... Training loss: 0.0979\n",
      "Epoch: 85/100... Training loss: 0.1028\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1035\n",
      "Epoch: 85/100... Training loss: 0.1059\n",
      "Epoch: 85/100... Training loss: 0.1018\n",
      "Epoch: 85/100... Training loss: 0.1033\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.1031\n",
      "Epoch: 85/100... Training loss: 0.1019\n",
      "Epoch: 85/100... Training loss: 0.1021\n",
      "Epoch: 85/100... Training loss: 0.1073\n",
      "Epoch: 85/100... Training loss: 0.1020\n",
      "Epoch: 85/100... Training loss: 0.0999\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 85/100... Training loss: 0.1024\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0988\n",
      "Epoch: 85/100... Training loss: 0.1023\n",
      "Epoch: 85/100... Training loss: 0.1016\n",
      "Epoch: 85/100... Training loss: 0.1027\n",
      "Epoch: 85/100... Training loss: 0.0997\n",
      "Epoch: 85/100... Training loss: 0.0989\n",
      "Epoch: 85/100... Training loss: 0.1003\n",
      "Epoch: 85/100... Training loss: 0.0975\n",
      "Epoch: 85/100... Training loss: 0.1028\n",
      "Epoch: 85/100... Training loss: 0.1002\n",
      "Epoch: 85/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0972\n",
      "Epoch: 86/100... Training loss: 0.1040\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.1056\n",
      "Epoch: 86/100... Training loss: 0.1047\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.1042\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1033\n",
      "Epoch: 86/100... Training loss: 0.0976\n",
      "Epoch: 86/100... Training loss: 0.1034\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.1051\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0971\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.1043\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.1030\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.1027\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.1046\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.1024\n",
      "Epoch: 86/100... Training loss: 0.1026\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1031\n",
      "Epoch: 86/100... Training loss: 0.1032\n",
      "Epoch: 86/100... Training loss: 0.1051\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.0977\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1037\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1039\n",
      "Epoch: 86/100... Training loss: 0.1031\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1038\n",
      "Epoch: 86/100... Training loss: 0.1032\n",
      "Epoch: 86/100... Training loss: 0.1034\n",
      "Epoch: 86/100... Training loss: 0.1038\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.1037\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0941\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1074\n",
      "Epoch: 86/100... Training loss: 0.1041\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.0989\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1037\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.1030\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.1049\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.0999\n",
      "Epoch: 86/100... Training loss: 0.1036\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1042\n",
      "Epoch: 86/100... Training loss: 0.1038\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1034\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1030\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.1060\n",
      "Epoch: 86/100... Training loss: 0.0973\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.1027\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.1031\n",
      "Epoch: 86/100... Training loss: 0.1030\n",
      "Epoch: 86/100... Training loss: 0.1041\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1030\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.1029\n",
      "Epoch: 86/100... Training loss: 0.1056\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.1047\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.1045\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1067\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1033\n",
      "Epoch: 86/100... Training loss: 0.1030\n",
      "Epoch: 86/100... Training loss: 0.0980\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1046\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1039\n",
      "Epoch: 86/100... Training loss: 0.0974\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.1055\n",
      "Epoch: 86/100... Training loss: 0.1037\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.0975\n",
      "Epoch: 86/100... Training loss: 0.1007\n",
      "Epoch: 86/100... Training loss: 0.1033\n",
      "Epoch: 86/100... Training loss: 0.1035\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.1054\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1027\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1044\n",
      "Epoch: 86/100... Training loss: 0.1033\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1029\n",
      "Epoch: 86/100... Training loss: 0.1026\n",
      "Epoch: 86/100... Training loss: 0.0967\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1033\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.1041\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1057\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.1033\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1030\n",
      "Epoch: 86/100... Training loss: 0.1046\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.1050\n",
      "Epoch: 86/100... Training loss: 0.1001\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.1048\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.1069\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.1031\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.0992\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.0967\n",
      "Epoch: 86/100... Training loss: 0.1012\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1011\n",
      "Epoch: 86/100... Training loss: 0.0979\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1031\n",
      "Epoch: 86/100... Training loss: 0.0990\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1031\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.1031\n",
      "Epoch: 86/100... Training loss: 0.1045\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.0993\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1006\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1031\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.1042\n",
      "Epoch: 86/100... Training loss: 0.1031\n",
      "Epoch: 86/100... Training loss: 0.0988\n",
      "Epoch: 86/100... Training loss: 0.0985\n",
      "Epoch: 86/100... Training loss: 0.1032\n",
      "Epoch: 86/100... Training loss: 0.1042\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.0995\n",
      "Epoch: 86/100... Training loss: 0.0969\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.1037\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.0970\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.1039\n",
      "Epoch: 86/100... Training loss: 0.1023\n",
      "Epoch: 86/100... Training loss: 0.1031\n",
      "Epoch: 86/100... Training loss: 0.1019\n",
      "Epoch: 86/100... Training loss: 0.1037\n",
      "Epoch: 86/100... Training loss: 0.1021\n",
      "Epoch: 86/100... Training loss: 0.0998\n",
      "Epoch: 86/100... Training loss: 0.0962\n",
      "Epoch: 86/100... Training loss: 0.1027\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.0991\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.1010\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1022\n",
      "Epoch: 86/100... Training loss: 0.1035\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.1041\n",
      "Epoch: 86/100... Training loss: 0.0986\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1003\n",
      "Epoch: 86/100... Training loss: 0.1002\n",
      "Epoch: 86/100... Training loss: 0.0997\n",
      "Epoch: 86/100... Training loss: 0.1013\n",
      "Epoch: 86/100... Training loss: 0.1016\n",
      "Epoch: 86/100... Training loss: 0.1020\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.0987\n",
      "Epoch: 86/100... Training loss: 0.1027\n",
      "Epoch: 86/100... Training loss: 0.1009\n",
      "Epoch: 86/100... Training loss: 0.0969\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.1017\n",
      "Epoch: 86/100... Training loss: 0.1005\n",
      "Epoch: 86/100... Training loss: 0.1025\n",
      "Epoch: 86/100... Training loss: 0.0996\n",
      "Epoch: 86/100... Training loss: 0.1014\n",
      "Epoch: 86/100... Training loss: 0.1000\n",
      "Epoch: 86/100... Training loss: 0.0994\n",
      "Epoch: 86/100... Training loss: 0.1015\n",
      "Epoch: 86/100... Training loss: 0.1028\n",
      "Epoch: 86/100... Training loss: 0.1049\n",
      "Epoch: 86/100... Training loss: 0.1018\n",
      "Epoch: 86/100... Training loss: 0.1043\n",
      "Epoch: 86/100... Training loss: 0.1004\n",
      "Epoch: 86/100... Training loss: 0.1008\n",
      "Epoch: 86/100... Training loss: 0.1029\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1047\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1033\n",
      "Epoch: 87/100... Training loss: 0.1050\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1049\n",
      "Epoch: 87/100... Training loss: 0.1041\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1032\n",
      "Epoch: 87/100... Training loss: 0.1047\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.1035\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1034\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1046\n",
      "Epoch: 87/100... Training loss: 0.0976\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1036\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1053\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.0961\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1034\n",
      "Epoch: 87/100... Training loss: 0.1062\n",
      "Epoch: 87/100... Training loss: 0.0973\n",
      "Epoch: 87/100... Training loss: 0.1034\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1040\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.0969\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1050\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1031\n",
      "Epoch: 87/100... Training loss: 0.1036\n",
      "Epoch: 87/100... Training loss: 0.1030\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.1035\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0983\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1042\n",
      "Epoch: 87/100... Training loss: 0.1030\n",
      "Epoch: 87/100... Training loss: 0.1033\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.1028\n",
      "Epoch: 87/100... Training loss: 0.1047\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.1028\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1030\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.1057\n",
      "Epoch: 87/100... Training loss: 0.1030\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.0985\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.1030\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1047\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.1055\n",
      "Epoch: 87/100... Training loss: 0.1038\n",
      "Epoch: 87/100... Training loss: 0.1039\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.1033\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.1050\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.1062\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.0993\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.0979\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.1033\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1061\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.1032\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.0981\n",
      "Epoch: 87/100... Training loss: 0.1057\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1037\n",
      "Epoch: 87/100... Training loss: 0.1046\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.0970\n",
      "Epoch: 87/100... Training loss: 0.1028\n",
      "Epoch: 87/100... Training loss: 0.1015\n",
      "Epoch: 87/100... Training loss: 0.1040\n",
      "Epoch: 87/100... Training loss: 0.1036\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1033\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.1062\n",
      "Epoch: 87/100... Training loss: 0.1045\n",
      "Epoch: 87/100... Training loss: 0.1034\n",
      "Epoch: 87/100... Training loss: 0.1036\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1046\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.0994\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1049\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.0984\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.1024\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.1032\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.1030\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0989\n",
      "Epoch: 87/100... Training loss: 0.1023\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1070\n",
      "Epoch: 87/100... Training loss: 0.1014\n",
      "Epoch: 87/100... Training loss: 0.1029\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.0997\n",
      "Epoch: 87/100... Training loss: 0.1044\n",
      "Epoch: 87/100... Training loss: 0.0990\n",
      "Epoch: 87/100... Training loss: 0.0986\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.0992\n",
      "Epoch: 87/100... Training loss: 0.1025\n",
      "Epoch: 87/100... Training loss: 0.1009\n",
      "Epoch: 87/100... Training loss: 0.0980\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.1029\n",
      "Epoch: 87/100... Training loss: 0.1016\n",
      "Epoch: 87/100... Training loss: 0.1034\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1030\n",
      "Epoch: 87/100... Training loss: 0.1072\n",
      "Epoch: 87/100... Training loss: 0.1030\n",
      "Epoch: 87/100... Training loss: 0.1070\n",
      "Epoch: 87/100... Training loss: 0.0996\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1012\n",
      "Epoch: 87/100... Training loss: 0.1040\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.1050\n",
      "Epoch: 87/100... Training loss: 0.0975\n",
      "Epoch: 87/100... Training loss: 0.1027\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1000\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1030\n",
      "Epoch: 87/100... Training loss: 0.1028\n",
      "Epoch: 87/100... Training loss: 0.1043\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1019\n",
      "Epoch: 87/100... Training loss: 0.0991\n",
      "Epoch: 87/100... Training loss: 0.1020\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.0999\n",
      "Epoch: 87/100... Training loss: 0.0995\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1002\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.1011\n",
      "Epoch: 87/100... Training loss: 0.1022\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1035\n",
      "Epoch: 87/100... Training loss: 0.1026\n",
      "Epoch: 87/100... Training loss: 0.1027\n",
      "Epoch: 87/100... Training loss: 0.0987\n",
      "Epoch: 87/100... Training loss: 0.1021\n",
      "Epoch: 87/100... Training loss: 0.0988\n",
      "Epoch: 87/100... Training loss: 0.0974\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.1010\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1038\n",
      "Epoch: 87/100... Training loss: 0.1038\n",
      "Epoch: 87/100... Training loss: 0.1006\n",
      "Epoch: 87/100... Training loss: 0.1005\n",
      "Epoch: 87/100... Training loss: 0.1007\n",
      "Epoch: 87/100... Training loss: 0.1004\n",
      "Epoch: 87/100... Training loss: 0.1001\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1008\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 87/100... Training loss: 0.0998\n",
      "Epoch: 87/100... Training loss: 0.1018\n",
      "Epoch: 87/100... Training loss: 0.1017\n",
      "Epoch: 87/100... Training loss: 0.1003\n",
      "Epoch: 87/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1048\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0977\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.1027\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.1027\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.1026\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1037\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1036\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.1026\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0999\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1033\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1021\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1046\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.0974\n",
      "Epoch: 88/100... Training loss: 0.1044\n",
      "Epoch: 88/100... Training loss: 0.1026\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1021\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1023\n",
      "Epoch: 88/100... Training loss: 0.0965\n",
      "Epoch: 88/100... Training loss: 0.1027\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.1038\n",
      "Epoch: 88/100... Training loss: 0.1060\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1043\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.0984\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1033\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.1039\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1000\n",
      "Epoch: 88/100... Training loss: 0.1023\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1031\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0965\n",
      "Epoch: 88/100... Training loss: 0.0985\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1046\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1028\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1041\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.1023\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1052\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.1053\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.1052\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.0994\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.0989\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1030\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.0981\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.0987\n",
      "Epoch: 88/100... Training loss: 0.1009\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.1034\n",
      "Epoch: 88/100... Training loss: 0.0996\n",
      "Epoch: 88/100... Training loss: 0.1002\n",
      "Epoch: 88/100... Training loss: 0.1034\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.1048\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1027\n",
      "Epoch: 88/100... Training loss: 0.1033\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.1054\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0983\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1029\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1046\n",
      "Epoch: 88/100... Training loss: 0.1045\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.1026\n",
      "Epoch: 88/100... Training loss: 0.1020\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.0988\n",
      "Epoch: 88/100... Training loss: 0.1027\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1041\n",
      "Epoch: 88/100... Training loss: 0.1045\n",
      "Epoch: 88/100... Training loss: 0.0990\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.1035\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1031\n",
      "Epoch: 88/100... Training loss: 0.1021\n",
      "Epoch: 88/100... Training loss: 0.1026\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.0976\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1060\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.0962\n",
      "Epoch: 88/100... Training loss: 0.1029\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1045\n",
      "Epoch: 88/100... Training loss: 0.1056\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.0975\n",
      "Epoch: 88/100... Training loss: 0.1034\n",
      "Epoch: 88/100... Training loss: 0.1006\n",
      "Epoch: 88/100... Training loss: 0.1040\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1039\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1054\n",
      "Epoch: 88/100... Training loss: 0.1031\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1018\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.1041\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1033\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1070\n",
      "Epoch: 88/100... Training loss: 0.1013\n",
      "Epoch: 88/100... Training loss: 0.0965\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.1054\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1038\n",
      "Epoch: 88/100... Training loss: 0.1041\n",
      "Epoch: 88/100... Training loss: 0.1021\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.0995\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1005\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1025\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1044\n",
      "Epoch: 88/100... Training loss: 0.1064\n",
      "Epoch: 88/100... Training loss: 0.1010\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.1033\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1022\n",
      "Epoch: 88/100... Training loss: 0.0998\n",
      "Epoch: 88/100... Training loss: 0.1032\n",
      "Epoch: 88/100... Training loss: 0.0986\n",
      "Epoch: 88/100... Training loss: 0.1060\n",
      "Epoch: 88/100... Training loss: 0.1031\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.0980\n",
      "Epoch: 88/100... Training loss: 0.0997\n",
      "Epoch: 88/100... Training loss: 0.1049\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1016\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1026\n",
      "Epoch: 88/100... Training loss: 0.1024\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1004\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.0993\n",
      "Epoch: 88/100... Training loss: 0.1073\n",
      "Epoch: 88/100... Training loss: 0.1033\n",
      "Epoch: 88/100... Training loss: 0.1001\n",
      "Epoch: 88/100... Training loss: 0.1064\n",
      "Epoch: 88/100... Training loss: 0.1050\n",
      "Epoch: 88/100... Training loss: 0.1017\n",
      "Epoch: 88/100... Training loss: 0.1012\n",
      "Epoch: 88/100... Training loss: 0.1008\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.1061\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1036\n",
      "Epoch: 88/100... Training loss: 0.1028\n",
      "Epoch: 88/100... Training loss: 0.1014\n",
      "Epoch: 88/100... Training loss: 0.1029\n",
      "Epoch: 88/100... Training loss: 0.1007\n",
      "Epoch: 88/100... Training loss: 0.1059\n",
      "Epoch: 88/100... Training loss: 0.1027\n",
      "Epoch: 88/100... Training loss: 0.0992\n",
      "Epoch: 88/100... Training loss: 0.1015\n",
      "Epoch: 88/100... Training loss: 0.1003\n",
      "Epoch: 88/100... Training loss: 0.1011\n",
      "Epoch: 88/100... Training loss: 0.1050\n",
      "Epoch: 88/100... Training loss: 0.0991\n",
      "Epoch: 88/100... Training loss: 0.1050\n",
      "Epoch: 88/100... Training loss: 0.1019\n",
      "Epoch: 88/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.1032\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0972\n",
      "Epoch: 89/100... Training loss: 0.1038\n",
      "Epoch: 89/100... Training loss: 0.1027\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.1026\n",
      "Epoch: 89/100... Training loss: 0.1026\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.1047\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.1035\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.1022\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1036\n",
      "Epoch: 89/100... Training loss: 0.1020\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1052\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1022\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.1035\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.1048\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1020\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.1036\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1037\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.1052\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1020\n",
      "Epoch: 89/100... Training loss: 0.1075\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1032\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.1027\n",
      "Epoch: 89/100... Training loss: 0.1039\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1031\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.1025\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1036\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1047\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1038\n",
      "Epoch: 89/100... Training loss: 0.1048\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.1039\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.0975\n",
      "Epoch: 89/100... Training loss: 0.0993\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1038\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.1020\n",
      "Epoch: 89/100... Training loss: 0.1061\n",
      "Epoch: 89/100... Training loss: 0.1047\n",
      "Epoch: 89/100... Training loss: 0.1061\n",
      "Epoch: 89/100... Training loss: 0.1026\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1035\n",
      "Epoch: 89/100... Training loss: 0.1030\n",
      "Epoch: 89/100... Training loss: 0.0989\n",
      "Epoch: 89/100... Training loss: 0.1045\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.1047\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1043\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.1032\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0981\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1024\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1020\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1035\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.0997\n",
      "Epoch: 89/100... Training loss: 0.0986\n",
      "Epoch: 89/100... Training loss: 0.1011\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1060\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1007\n",
      "Epoch: 89/100... Training loss: 0.0984\n",
      "Epoch: 89/100... Training loss: 0.1054\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.1005\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1049\n",
      "Epoch: 89/100... Training loss: 0.1039\n",
      "Epoch: 89/100... Training loss: 0.1001\n",
      "Epoch: 89/100... Training loss: 0.1054\n",
      "Epoch: 89/100... Training loss: 0.0988\n",
      "Epoch: 89/100... Training loss: 0.1043\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1019\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.0994\n",
      "Epoch: 89/100... Training loss: 0.0991\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1032\n",
      "Epoch: 89/100... Training loss: 0.0982\n",
      "Epoch: 89/100... Training loss: 0.1047\n",
      "Epoch: 89/100... Training loss: 0.1043\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.0999\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1036\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1030\n",
      "Epoch: 89/100... Training loss: 0.1030\n",
      "Epoch: 89/100... Training loss: 0.1040\n",
      "Epoch: 89/100... Training loss: 0.1040\n",
      "Epoch: 89/100... Training loss: 0.1068\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.0973\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.1047\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1020\n",
      "Epoch: 89/100... Training loss: 0.1030\n",
      "Epoch: 89/100... Training loss: 0.1032\n",
      "Epoch: 89/100... Training loss: 0.1003\n",
      "Epoch: 89/100... Training loss: 0.1035\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.1051\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.0992\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.1025\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1057\n",
      "Epoch: 89/100... Training loss: 0.1047\n",
      "Epoch: 89/100... Training loss: 0.1042\n",
      "Epoch: 89/100... Training loss: 0.0983\n",
      "Epoch: 89/100... Training loss: 0.1064\n",
      "Epoch: 89/100... Training loss: 0.0981\n",
      "Epoch: 89/100... Training loss: 0.1014\n",
      "Epoch: 89/100... Training loss: 0.1048\n",
      "Epoch: 89/100... Training loss: 0.1022\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.1004\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1033\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.1018\n",
      "Epoch: 89/100... Training loss: 0.1038\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.1026\n",
      "Epoch: 89/100... Training loss: 0.1020\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1012\n",
      "Epoch: 89/100... Training loss: 0.0996\n",
      "Epoch: 89/100... Training loss: 0.1006\n",
      "Epoch: 89/100... Training loss: 0.1021\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1000\n",
      "Epoch: 89/100... Training loss: 0.1002\n",
      "Epoch: 89/100... Training loss: 0.1008\n",
      "Epoch: 89/100... Training loss: 0.1009\n",
      "Epoch: 89/100... Training loss: 0.1056\n",
      "Epoch: 89/100... Training loss: 0.1051\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.0985\n",
      "Epoch: 89/100... Training loss: 0.1043\n",
      "Epoch: 89/100... Training loss: 0.0998\n",
      "Epoch: 89/100... Training loss: 0.1036\n",
      "Epoch: 89/100... Training loss: 0.0980\n",
      "Epoch: 89/100... Training loss: 0.0995\n",
      "Epoch: 89/100... Training loss: 0.1027\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.1010\n",
      "Epoch: 89/100... Training loss: 0.0978\n",
      "Epoch: 89/100... Training loss: 0.0987\n",
      "Epoch: 89/100... Training loss: 0.1029\n",
      "Epoch: 89/100... Training loss: 0.1028\n",
      "Epoch: 89/100... Training loss: 0.1040\n",
      "Epoch: 89/100... Training loss: 0.1050\n",
      "Epoch: 89/100... Training loss: 0.1013\n",
      "Epoch: 89/100... Training loss: 0.1026\n",
      "Epoch: 89/100... Training loss: 0.1015\n",
      "Epoch: 89/100... Training loss: 0.0990\n",
      "Epoch: 89/100... Training loss: 0.1023\n",
      "Epoch: 89/100... Training loss: 0.1016\n",
      "Epoch: 89/100... Training loss: 0.1041\n",
      "Epoch: 89/100... Training loss: 0.0974\n",
      "Epoch: 89/100... Training loss: 0.1017\n",
      "Epoch: 89/100... Training loss: 0.1031\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1037\n",
      "Epoch: 90/100... Training loss: 0.1030\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1027\n",
      "Epoch: 90/100... Training loss: 0.1040\n",
      "Epoch: 90/100... Training loss: 0.1027\n",
      "Epoch: 90/100... Training loss: 0.1037\n",
      "Epoch: 90/100... Training loss: 0.1032\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.1036\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1032\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.1055\n",
      "Epoch: 90/100... Training loss: 0.0975\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1045\n",
      "Epoch: 90/100... Training loss: 0.1037\n",
      "Epoch: 90/100... Training loss: 0.1039\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1042\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1045\n",
      "Epoch: 90/100... Training loss: 0.1037\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1037\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0967\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.1058\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.1023\n",
      "Epoch: 90/100... Training loss: 0.0965\n",
      "Epoch: 90/100... Training loss: 0.0979\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.1035\n",
      "Epoch: 90/100... Training loss: 0.1041\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1032\n",
      "Epoch: 90/100... Training loss: 0.1022\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1048\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.0973\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.1040\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1044\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1033\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.1048\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0995\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.1043\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.1039\n",
      "Epoch: 90/100... Training loss: 0.1067\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.1023\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.1022\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1034\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.0976\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.1036\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.1023\n",
      "Epoch: 90/100... Training loss: 0.1033\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1040\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1033\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.0986\n",
      "Epoch: 90/100... Training loss: 0.0981\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0971\n",
      "Epoch: 90/100... Training loss: 0.1045\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.1001\n",
      "Epoch: 90/100... Training loss: 0.1038\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.1022\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1022\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1040\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.1036\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.1036\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.0953\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.1044\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.1011\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.0963\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.0972\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1036\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1045\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.0989\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.1022\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.1032\n",
      "Epoch: 90/100... Training loss: 0.1030\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.1034\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.1027\n",
      "Epoch: 90/100... Training loss: 0.1031\n",
      "Epoch: 90/100... Training loss: 0.1040\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.1015\n",
      "Epoch: 90/100... Training loss: 0.1052\n",
      "Epoch: 90/100... Training loss: 0.1040\n",
      "Epoch: 90/100... Training loss: 0.1063\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0946\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1040\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.0996\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.1034\n",
      "Epoch: 90/100... Training loss: 0.1034\n",
      "Epoch: 90/100... Training loss: 0.1034\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1027\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.1040\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.1079\n",
      "Epoch: 90/100... Training loss: 0.1004\n",
      "Epoch: 90/100... Training loss: 0.1014\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1016\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.1042\n",
      "Epoch: 90/100... Training loss: 0.1061\n",
      "Epoch: 90/100... Training loss: 0.1046\n",
      "Epoch: 90/100... Training loss: 0.0985\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 90/100... Training loss: 0.0974\n",
      "Epoch: 90/100... Training loss: 0.1055\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.0988\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.0991\n",
      "Epoch: 90/100... Training loss: 0.1035\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1047\n",
      "Epoch: 90/100... Training loss: 0.1002\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.0997\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1008\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.0998\n",
      "Epoch: 90/100... Training loss: 0.0984\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.0993\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.1000\n",
      "Epoch: 90/100... Training loss: 0.1026\n",
      "Epoch: 90/100... Training loss: 0.1009\n",
      "Epoch: 90/100... Training loss: 0.1006\n",
      "Epoch: 90/100... Training loss: 0.1017\n",
      "Epoch: 90/100... Training loss: 0.1018\n",
      "Epoch: 90/100... Training loss: 0.1032\n",
      "Epoch: 90/100... Training loss: 0.0992\n",
      "Epoch: 90/100... Training loss: 0.1007\n",
      "Epoch: 90/100... Training loss: 0.0990\n",
      "Epoch: 90/100... Training loss: 0.1025\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.1021\n",
      "Epoch: 90/100... Training loss: 0.1031\n",
      "Epoch: 90/100... Training loss: 0.0970\n",
      "Epoch: 90/100... Training loss: 0.0999\n",
      "Epoch: 90/100... Training loss: 0.1020\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1012\n",
      "Epoch: 90/100... Training loss: 0.1031\n",
      "Epoch: 90/100... Training loss: 0.0987\n",
      "Epoch: 90/100... Training loss: 0.1019\n",
      "Epoch: 90/100... Training loss: 0.1040\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.1024\n",
      "Epoch: 90/100... Training loss: 0.1010\n",
      "Epoch: 90/100... Training loss: 0.1003\n",
      "Epoch: 90/100... Training loss: 0.1029\n",
      "Epoch: 90/100... Training loss: 0.0978\n",
      "Epoch: 90/100... Training loss: 0.1005\n",
      "Epoch: 90/100... Training loss: 0.1013\n",
      "Epoch: 90/100... Training loss: 0.0980\n",
      "Epoch: 90/100... Training loss: 0.1028\n",
      "Epoch: 90/100... Training loss: 0.0994\n",
      "Epoch: 90/100... Training loss: 0.1022\n",
      "Epoch: 90/100... Training loss: 0.1023\n",
      "Epoch: 90/100... Training loss: 0.1033\n",
      "Epoch: 90/100... Training loss: 0.1039\n",
      "Epoch: 90/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1034\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.1028\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0970\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1031\n",
      "Epoch: 91/100... Training loss: 0.1032\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.1038\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.1020\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.1053\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1031\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.1027\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.1022\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1031\n",
      "Epoch: 91/100... Training loss: 0.1044\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.1045\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.0978\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.1028\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1058\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.1034\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1039\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.1037\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.1057\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.1042\n",
      "Epoch: 91/100... Training loss: 0.1038\n",
      "Epoch: 91/100... Training loss: 0.1022\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.1037\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.0994\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.1038\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.1043\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1032\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.1046\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.1046\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1037\n",
      "Epoch: 91/100... Training loss: 0.0982\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.1022\n",
      "Epoch: 91/100... Training loss: 0.1035\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.0987\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1033\n",
      "Epoch: 91/100... Training loss: 0.1034\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1024\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.0999\n",
      "Epoch: 91/100... Training loss: 0.0967\n",
      "Epoch: 91/100... Training loss: 0.1039\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.0988\n",
      "Epoch: 91/100... Training loss: 0.1042\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1021\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.0973\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1028\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.1030\n",
      "Epoch: 91/100... Training loss: 0.1027\n",
      "Epoch: 91/100... Training loss: 0.0962\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1039\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.0995\n",
      "Epoch: 91/100... Training loss: 0.1032\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.0986\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.1031\n",
      "Epoch: 91/100... Training loss: 0.1043\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.1021\n",
      "Epoch: 91/100... Training loss: 0.0990\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.1050\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.1002\n",
      "Epoch: 91/100... Training loss: 0.1034\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.1053\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.1053\n",
      "Epoch: 91/100... Training loss: 0.1024\n",
      "Epoch: 91/100... Training loss: 0.1058\n",
      "Epoch: 91/100... Training loss: 0.1006\n",
      "Epoch: 91/100... Training loss: 0.0981\n",
      "Epoch: 91/100... Training loss: 0.1005\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.1042\n",
      "Epoch: 91/100... Training loss: 0.1016\n",
      "Epoch: 91/100... Training loss: 0.1061\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.1043\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.1062\n",
      "Epoch: 91/100... Training loss: 0.0980\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1052\n",
      "Epoch: 91/100... Training loss: 0.1047\n",
      "Epoch: 91/100... Training loss: 0.0971\n",
      "Epoch: 91/100... Training loss: 0.1036\n",
      "Epoch: 91/100... Training loss: 0.1044\n",
      "Epoch: 91/100... Training loss: 0.1008\n",
      "Epoch: 91/100... Training loss: 0.1027\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.1021\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.1053\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1027\n",
      "Epoch: 91/100... Training loss: 0.1045\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.1023\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.0991\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.1028\n",
      "Epoch: 91/100... Training loss: 0.1004\n",
      "Epoch: 91/100... Training loss: 0.1032\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1038\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0989\n",
      "Epoch: 91/100... Training loss: 0.1012\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.1000\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.1047\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1033\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1021\n",
      "Epoch: 91/100... Training loss: 0.1013\n",
      "Epoch: 91/100... Training loss: 0.1038\n",
      "Epoch: 91/100... Training loss: 0.1047\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 91/100... Training loss: 0.1042\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.0993\n",
      "Epoch: 91/100... Training loss: 0.1052\n",
      "Epoch: 91/100... Training loss: 0.0976\n",
      "Epoch: 91/100... Training loss: 0.1043\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1057\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1022\n",
      "Epoch: 91/100... Training loss: 0.1027\n",
      "Epoch: 91/100... Training loss: 0.1018\n",
      "Epoch: 91/100... Training loss: 0.0992\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1030\n",
      "Epoch: 91/100... Training loss: 0.1015\n",
      "Epoch: 91/100... Training loss: 0.1034\n",
      "Epoch: 91/100... Training loss: 0.1017\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.1021\n",
      "Epoch: 91/100... Training loss: 0.1026\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.1009\n",
      "Epoch: 91/100... Training loss: 0.0997\n",
      "Epoch: 91/100... Training loss: 0.0983\n",
      "Epoch: 91/100... Training loss: 0.1032\n",
      "Epoch: 91/100... Training loss: 0.1022\n",
      "Epoch: 91/100... Training loss: 0.1028\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.1028\n",
      "Epoch: 91/100... Training loss: 0.0977\n",
      "Epoch: 91/100... Training loss: 0.1029\n",
      "Epoch: 91/100... Training loss: 0.1010\n",
      "Epoch: 91/100... Training loss: 0.1011\n",
      "Epoch: 91/100... Training loss: 0.0996\n",
      "Epoch: 91/100... Training loss: 0.0998\n",
      "Epoch: 91/100... Training loss: 0.1044\n",
      "Epoch: 91/100... Training loss: 0.1045\n",
      "Epoch: 91/100... Training loss: 0.1043\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.1025\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1037\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1007\n",
      "Epoch: 91/100... Training loss: 0.1003\n",
      "Epoch: 91/100... Training loss: 0.1001\n",
      "Epoch: 91/100... Training loss: 0.1059\n",
      "Epoch: 91/100... Training loss: 0.1020\n",
      "Epoch: 91/100... Training loss: 0.1019\n",
      "Epoch: 91/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1038\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.0967\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1024\n",
      "Epoch: 92/100... Training loss: 0.1029\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1028\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.0988\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.0978\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.1033\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0972\n",
      "Epoch: 92/100... Training loss: 0.0975\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1034\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.1001\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1033\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1026\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.1037\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.1026\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.1038\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1050\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.1028\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.1040\n",
      "Epoch: 92/100... Training loss: 0.1045\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1050\n",
      "Epoch: 92/100... Training loss: 0.0990\n",
      "Epoch: 92/100... Training loss: 0.1031\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.0981\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1047\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1024\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.1024\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.0982\n",
      "Epoch: 92/100... Training loss: 0.1046\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.1043\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1040\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.0986\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1040\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1043\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1033\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1036\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.1035\n",
      "Epoch: 92/100... Training loss: 0.1031\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.1031\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1068\n",
      "Epoch: 92/100... Training loss: 0.1029\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.1042\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.1031\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0970\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1046\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.1032\n",
      "Epoch: 92/100... Training loss: 0.0984\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.1007\n",
      "Epoch: 92/100... Training loss: 0.1026\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.1036\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1036\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.1017\n",
      "Epoch: 92/100... Training loss: 0.1008\n",
      "Epoch: 92/100... Training loss: 0.1032\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1002\n",
      "Epoch: 92/100... Training loss: 0.1031\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.0997\n",
      "Epoch: 92/100... Training loss: 0.1003\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.0977\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1032\n",
      "Epoch: 92/100... Training loss: 0.0974\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1005\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1028\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.0983\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1010\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.1035\n",
      "Epoch: 92/100... Training loss: 0.1032\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1011\n",
      "Epoch: 92/100... Training loss: 0.1032\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.1045\n",
      "Epoch: 92/100... Training loss: 0.0992\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.1029\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.1028\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.0994\n",
      "Epoch: 92/100... Training loss: 0.1027\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1006\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.1013\n",
      "Epoch: 92/100... Training loss: 0.1030\n",
      "Epoch: 92/100... Training loss: 0.1041\n",
      "Epoch: 92/100... Training loss: 0.0980\n",
      "Epoch: 92/100... Training loss: 0.1036\n",
      "Epoch: 92/100... Training loss: 0.1018\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.0993\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.1051\n",
      "Epoch: 92/100... Training loss: 0.0985\n",
      "Epoch: 92/100... Training loss: 0.0956\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.1029\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1028\n",
      "Epoch: 92/100... Training loss: 0.1016\n",
      "Epoch: 92/100... Training loss: 0.0989\n",
      "Epoch: 92/100... Training loss: 0.1000\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.1019\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 92/100... Training loss: 0.1009\n",
      "Epoch: 92/100... Training loss: 0.0999\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1004\n",
      "Epoch: 92/100... Training loss: 0.0987\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1029\n",
      "Epoch: 92/100... Training loss: 0.1034\n",
      "Epoch: 92/100... Training loss: 0.1020\n",
      "Epoch: 92/100... Training loss: 0.1031\n",
      "Epoch: 92/100... Training loss: 0.1012\n",
      "Epoch: 92/100... Training loss: 0.1049\n",
      "Epoch: 92/100... Training loss: 0.1015\n",
      "Epoch: 92/100... Training loss: 0.1023\n",
      "Epoch: 92/100... Training loss: 0.0996\n",
      "Epoch: 92/100... Training loss: 0.0976\n",
      "Epoch: 92/100... Training loss: 0.1034\n",
      "Epoch: 92/100... Training loss: 0.1021\n",
      "Epoch: 92/100... Training loss: 0.1022\n",
      "Epoch: 92/100... Training loss: 0.0998\n",
      "Epoch: 92/100... Training loss: 0.1060\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1025\n",
      "Epoch: 92/100... Training loss: 0.1050\n",
      "Epoch: 92/100... Training loss: 0.0995\n",
      "Epoch: 92/100... Training loss: 0.1014\n",
      "Epoch: 92/100... Training loss: 0.1048\n",
      "Epoch: 92/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.1043\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.1024\n",
      "Epoch: 93/100... Training loss: 0.1023\n",
      "Epoch: 93/100... Training loss: 0.1055\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1056\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.1042\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.1037\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1038\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.1037\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.0973\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1024\n",
      "Epoch: 93/100... Training loss: 0.1064\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.1038\n",
      "Epoch: 93/100... Training loss: 0.1038\n",
      "Epoch: 93/100... Training loss: 0.1047\n",
      "Epoch: 93/100... Training loss: 0.1058\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.1041\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1036\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1030\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.0991\n",
      "Epoch: 93/100... Training loss: 0.1031\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0977\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.0990\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1033\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0964\n",
      "Epoch: 93/100... Training loss: 0.1031\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1038\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.1042\n",
      "Epoch: 93/100... Training loss: 0.0975\n",
      "Epoch: 93/100... Training loss: 0.1030\n",
      "Epoch: 93/100... Training loss: 0.1054\n",
      "Epoch: 93/100... Training loss: 0.1052\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1040\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.0987\n",
      "Epoch: 93/100... Training loss: 0.0992\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0952\n",
      "Epoch: 93/100... Training loss: 0.1033\n",
      "Epoch: 93/100... Training loss: 0.1037\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1037\n",
      "Epoch: 93/100... Training loss: 0.1033\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.1030\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1040\n",
      "Epoch: 93/100... Training loss: 0.1059\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.1036\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.1042\n",
      "Epoch: 93/100... Training loss: 0.1047\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0979\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.1032\n",
      "Epoch: 93/100... Training loss: 0.1037\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1049\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1047\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.1040\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.1033\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1039\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1040\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1042\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1032\n",
      "Epoch: 93/100... Training loss: 0.1053\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.0995\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1007\n",
      "Epoch: 93/100... Training loss: 0.1027\n",
      "Epoch: 93/100... Training loss: 0.1024\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.1085\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.1036\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.1050\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1028\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1036\n",
      "Epoch: 93/100... Training loss: 0.0999\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.1030\n",
      "Epoch: 93/100... Training loss: 0.1032\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.1066\n",
      "Epoch: 93/100... Training loss: 0.1028\n",
      "Epoch: 93/100... Training loss: 0.1052\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1046\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1013\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.1048\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.0964\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1003\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.1028\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.0969\n",
      "Epoch: 93/100... Training loss: 0.1030\n",
      "Epoch: 93/100... Training loss: 0.0981\n",
      "Epoch: 93/100... Training loss: 0.1026\n",
      "Epoch: 93/100... Training loss: 0.1068\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.0993\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.1039\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.0970\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.0989\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0997\n",
      "Epoch: 93/100... Training loss: 0.1030\n",
      "Epoch: 93/100... Training loss: 0.1024\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.1020\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.0984\n",
      "Epoch: 93/100... Training loss: 0.1033\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.0985\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.1028\n",
      "Epoch: 93/100... Training loss: 0.1027\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.0979\n",
      "Epoch: 93/100... Training loss: 0.1017\n",
      "Epoch: 93/100... Training loss: 0.1043\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1039\n",
      "Epoch: 93/100... Training loss: 0.0954\n",
      "Epoch: 93/100... Training loss: 0.0976\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1004\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.1002\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.1000\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.1021\n",
      "Epoch: 93/100... Training loss: 0.1069\n",
      "Epoch: 93/100... Training loss: 0.0988\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.0996\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1014\n",
      "Epoch: 93/100... Training loss: 0.1055\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.0982\n",
      "Epoch: 93/100... Training loss: 0.1012\n",
      "Epoch: 93/100... Training loss: 0.1006\n",
      "Epoch: 93/100... Training loss: 0.1022\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.0998\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.0972\n",
      "Epoch: 93/100... Training loss: 0.1001\n",
      "Epoch: 93/100... Training loss: 0.1011\n",
      "Epoch: 93/100... Training loss: 0.1009\n",
      "Epoch: 93/100... Training loss: 0.0971\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.0986\n",
      "Epoch: 93/100... Training loss: 0.1054\n",
      "Epoch: 93/100... Training loss: 0.1010\n",
      "Epoch: 93/100... Training loss: 0.1018\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1029\n",
      "Epoch: 93/100... Training loss: 0.1025\n",
      "Epoch: 93/100... Training loss: 0.1028\n",
      "Epoch: 93/100... Training loss: 0.1016\n",
      "Epoch: 93/100... Training loss: 0.1008\n",
      "Epoch: 93/100... Training loss: 0.1032\n",
      "Epoch: 93/100... Training loss: 0.0980\n",
      "Epoch: 93/100... Training loss: 0.1019\n",
      "Epoch: 93/100... Training loss: 0.0960\n",
      "Epoch: 93/100... Training loss: 0.0994\n",
      "Epoch: 93/100... Training loss: 0.1015\n",
      "Epoch: 93/100... Training loss: 0.1005\n",
      "Epoch: 93/100... Training loss: 0.1031\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.0970\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.0991\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.1017\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1032\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1054\n",
      "Epoch: 94/100... Training loss: 0.1021\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.1028\n",
      "Epoch: 94/100... Training loss: 0.1040\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.1056\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.1017\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0987\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.0980\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1044\n",
      "Epoch: 94/100... Training loss: 0.1030\n",
      "Epoch: 94/100... Training loss: 0.1064\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.1027\n",
      "Epoch: 94/100... Training loss: 0.1021\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1029\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.1021\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.1037\n",
      "Epoch: 94/100... Training loss: 0.1039\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1033\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1034\n",
      "Epoch: 94/100... Training loss: 0.1054\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.0997\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1036\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1043\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1030\n",
      "Epoch: 94/100... Training loss: 0.1027\n",
      "Epoch: 94/100... Training loss: 0.1054\n",
      "Epoch: 94/100... Training loss: 0.1040\n",
      "Epoch: 94/100... Training loss: 0.0967\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.0983\n",
      "Epoch: 94/100... Training loss: 0.1030\n",
      "Epoch: 94/100... Training loss: 0.0973\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.1046\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.1021\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1034\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1033\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0967\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1033\n",
      "Epoch: 94/100... Training loss: 0.1050\n",
      "Epoch: 94/100... Training loss: 0.1026\n",
      "Epoch: 94/100... Training loss: 0.1039\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1042\n",
      "Epoch: 94/100... Training loss: 0.1033\n",
      "Epoch: 94/100... Training loss: 0.1037\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.0978\n",
      "Epoch: 94/100... Training loss: 0.0998\n",
      "Epoch: 94/100... Training loss: 0.1031\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.1028\n",
      "Epoch: 94/100... Training loss: 0.1039\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1040\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.1025\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.1031\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.1048\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.1042\n",
      "Epoch: 94/100... Training loss: 0.0981\n",
      "Epoch: 94/100... Training loss: 0.1028\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1015\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.1009\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1029\n",
      "Epoch: 94/100... Training loss: 0.0994\n",
      "Epoch: 94/100... Training loss: 0.0999\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.1047\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1002\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1030\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1029\n",
      "Epoch: 94/100... Training loss: 0.1022\n",
      "Epoch: 94/100... Training loss: 0.0992\n",
      "Epoch: 94/100... Training loss: 0.0979\n",
      "Epoch: 94/100... Training loss: 0.1029\n",
      "Epoch: 94/100... Training loss: 0.1043\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.1011\n",
      "Epoch: 94/100... Training loss: 0.1007\n",
      "Epoch: 94/100... Training loss: 0.1021\n",
      "Epoch: 94/100... Training loss: 0.1034\n",
      "Epoch: 94/100... Training loss: 0.1041\n",
      "Epoch: 94/100... Training loss: 0.1053\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.1042\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.1017\n",
      "Epoch: 94/100... Training loss: 0.1004\n",
      "Epoch: 94/100... Training loss: 0.1005\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1006\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1053\n",
      "Epoch: 94/100... Training loss: 0.1018\n",
      "Epoch: 94/100... Training loss: 0.0995\n",
      "Epoch: 94/100... Training loss: 0.1021\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1024\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.1035\n",
      "Epoch: 94/100... Training loss: 0.1033\n",
      "Epoch: 94/100... Training loss: 0.0984\n",
      "Epoch: 94/100... Training loss: 0.1041\n",
      "Epoch: 94/100... Training loss: 0.1029\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.0996\n",
      "Epoch: 94/100... Training loss: 0.1075\n",
      "Epoch: 94/100... Training loss: 0.0989\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.1030\n",
      "Epoch: 94/100... Training loss: 0.1040\n",
      "Epoch: 94/100... Training loss: 0.1013\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1023\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1050\n",
      "Epoch: 94/100... Training loss: 0.1019\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1038\n",
      "Epoch: 94/100... Training loss: 0.1017\n",
      "Epoch: 94/100... Training loss: 0.0985\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1020\n",
      "Epoch: 94/100... Training loss: 0.1033\n",
      "Epoch: 94/100... Training loss: 0.1021\n",
      "Epoch: 94/100... Training loss: 0.1042\n",
      "Epoch: 94/100... Training loss: 0.1003\n",
      "Epoch: 94/100... Training loss: 0.1010\n",
      "Epoch: 94/100... Training loss: 0.0993\n",
      "Epoch: 94/100... Training loss: 0.0990\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 94/100... Training loss: 0.0988\n",
      "Epoch: 94/100... Training loss: 0.1017\n",
      "Epoch: 94/100... Training loss: 0.0982\n",
      "Epoch: 94/100... Training loss: 0.1000\n",
      "Epoch: 94/100... Training loss: 0.1043\n",
      "Epoch: 94/100... Training loss: 0.1041\n",
      "Epoch: 94/100... Training loss: 0.1016\n",
      "Epoch: 94/100... Training loss: 0.1012\n",
      "Epoch: 94/100... Training loss: 0.1001\n",
      "Epoch: 94/100... Training loss: 0.1034\n",
      "Epoch: 94/100... Training loss: 0.1014\n",
      "Epoch: 94/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.1029\n",
      "Epoch: 95/100... Training loss: 0.1044\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1037\n",
      "Epoch: 95/100... Training loss: 0.1031\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1033\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.1043\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.0979\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1032\n",
      "Epoch: 95/100... Training loss: 0.1024\n",
      "Epoch: 95/100... Training loss: 0.1055\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1030\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1034\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.1023\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0962\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1052\n",
      "Epoch: 95/100... Training loss: 0.1032\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1038\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.0999\n",
      "Epoch: 95/100... Training loss: 0.0991\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1036\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0983\n",
      "Epoch: 95/100... Training loss: 0.1038\n",
      "Epoch: 95/100... Training loss: 0.1029\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1024\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.1023\n",
      "Epoch: 95/100... Training loss: 0.0974\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1049\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.1037\n",
      "Epoch: 95/100... Training loss: 0.1035\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.0976\n",
      "Epoch: 95/100... Training loss: 0.1035\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1029\n",
      "Epoch: 95/100... Training loss: 0.1031\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1033\n",
      "Epoch: 95/100... Training loss: 0.1024\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1024\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1056\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.0982\n",
      "Epoch: 95/100... Training loss: 0.1045\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.0995\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.1047\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.1030\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.0966\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1021\n",
      "Epoch: 95/100... Training loss: 0.1050\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.1023\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1044\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1037\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.0968\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1024\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.1030\n",
      "Epoch: 95/100... Training loss: 0.0990\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.0977\n",
      "Epoch: 95/100... Training loss: 0.0980\n",
      "Epoch: 95/100... Training loss: 0.1030\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1031\n",
      "Epoch: 95/100... Training loss: 0.1044\n",
      "Epoch: 95/100... Training loss: 0.1035\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.1032\n",
      "Epoch: 95/100... Training loss: 0.1033\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1039\n",
      "Epoch: 95/100... Training loss: 0.1033\n",
      "Epoch: 95/100... Training loss: 0.1019\n",
      "Epoch: 95/100... Training loss: 0.1047\n",
      "Epoch: 95/100... Training loss: 0.1047\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.1057\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.1042\n",
      "Epoch: 95/100... Training loss: 0.1033\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1044\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.1050\n",
      "Epoch: 95/100... Training loss: 0.1005\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.1061\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.1042\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.1017\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1001\n",
      "Epoch: 95/100... Training loss: 0.0996\n",
      "Epoch: 95/100... Training loss: 0.0988\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.1029\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1008\n",
      "Epoch: 95/100... Training loss: 0.1032\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1027\n",
      "Epoch: 95/100... Training loss: 0.1028\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1020\n",
      "Epoch: 95/100... Training loss: 0.1016\n",
      "Epoch: 95/100... Training loss: 0.1018\n",
      "Epoch: 95/100... Training loss: 0.1046\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1009\n",
      "Epoch: 95/100... Training loss: 0.1032\n",
      "Epoch: 95/100... Training loss: 0.1004\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.1010\n",
      "Epoch: 95/100... Training loss: 0.1024\n",
      "Epoch: 95/100... Training loss: 0.1033\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.0993\n",
      "Epoch: 95/100... Training loss: 0.1014\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.0992\n",
      "Epoch: 95/100... Training loss: 0.1035\n",
      "Epoch: 95/100... Training loss: 0.0998\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1003\n",
      "Epoch: 95/100... Training loss: 0.1007\n",
      "Epoch: 95/100... Training loss: 0.0984\n",
      "Epoch: 95/100... Training loss: 0.1025\n",
      "Epoch: 95/100... Training loss: 0.1013\n",
      "Epoch: 95/100... Training loss: 0.1012\n",
      "Epoch: 95/100... Training loss: 0.1046\n",
      "Epoch: 95/100... Training loss: 0.0987\n",
      "Epoch: 95/100... Training loss: 0.0985\n",
      "Epoch: 95/100... Training loss: 0.1038\n",
      "Epoch: 95/100... Training loss: 0.1039\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0978\n",
      "Epoch: 95/100... Training loss: 0.0997\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1038\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.1031\n",
      "Epoch: 95/100... Training loss: 0.1002\n",
      "Epoch: 95/100... Training loss: 0.1024\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.1022\n",
      "Epoch: 95/100... Training loss: 0.0963\n",
      "Epoch: 95/100... Training loss: 0.1006\n",
      "Epoch: 95/100... Training loss: 0.1033\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.0986\n",
      "Epoch: 95/100... Training loss: 0.1046\n",
      "Epoch: 95/100... Training loss: 0.0994\n",
      "Epoch: 95/100... Training loss: 0.1015\n",
      "Epoch: 95/100... Training loss: 0.1026\n",
      "Epoch: 95/100... Training loss: 0.1011\n",
      "Epoch: 95/100... Training loss: 0.1000\n",
      "Epoch: 95/100... Training loss: 0.1031\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.0962\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1023\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.1026\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1039\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1037\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1020\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1040\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1046\n",
      "Epoch: 96/100... Training loss: 0.1039\n",
      "Epoch: 96/100... Training loss: 0.1024\n",
      "Epoch: 96/100... Training loss: 0.1034\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.1034\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1026\n",
      "Epoch: 96/100... Training loss: 0.1030\n",
      "Epoch: 96/100... Training loss: 0.1046\n",
      "Epoch: 96/100... Training loss: 0.1024\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.1040\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.1022\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.1044\n",
      "Epoch: 96/100... Training loss: 0.1023\n",
      "Epoch: 96/100... Training loss: 0.1048\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.0964\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1024\n",
      "Epoch: 96/100... Training loss: 0.1037\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1038\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1038\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.1030\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0983\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1020\n",
      "Epoch: 96/100... Training loss: 0.1030\n",
      "Epoch: 96/100... Training loss: 0.0995\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1031\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.1020\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.0993\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.1039\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.1026\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1038\n",
      "Epoch: 96/100... Training loss: 0.0965\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1035\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1023\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1060\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1032\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.1022\n",
      "Epoch: 96/100... Training loss: 0.1040\n",
      "Epoch: 96/100... Training loss: 0.1045\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.0981\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.0977\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.1056\n",
      "Epoch: 96/100... Training loss: 0.0975\n",
      "Epoch: 96/100... Training loss: 0.1034\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1037\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.1042\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.1034\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.1024\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.1033\n",
      "Epoch: 96/100... Training loss: 0.0984\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1030\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.0978\n",
      "Epoch: 96/100... Training loss: 0.1026\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.0982\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.1028\n",
      "Epoch: 96/100... Training loss: 0.1028\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.1024\n",
      "Epoch: 96/100... Training loss: 0.1030\n",
      "Epoch: 96/100... Training loss: 0.1026\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1014\n",
      "Epoch: 96/100... Training loss: 0.1034\n",
      "Epoch: 96/100... Training loss: 0.1008\n",
      "Epoch: 96/100... Training loss: 0.1033\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.1051\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1007\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1028\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.1046\n",
      "Epoch: 96/100... Training loss: 0.0980\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.1006\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.1036\n",
      "Epoch: 96/100... Training loss: 0.0997\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.1005\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.1036\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.0970\n",
      "Epoch: 96/100... Training loss: 0.1044\n",
      "Epoch: 96/100... Training loss: 0.1011\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1043\n",
      "Epoch: 96/100... Training loss: 0.1003\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1028\n",
      "Epoch: 96/100... Training loss: 0.0992\n",
      "Epoch: 96/100... Training loss: 0.0991\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.1034\n",
      "Epoch: 96/100... Training loss: 0.1021\n",
      "Epoch: 96/100... Training loss: 0.1059\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1018\n",
      "Epoch: 96/100... Training loss: 0.0999\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.0989\n",
      "Epoch: 96/100... Training loss: 0.1037\n",
      "Epoch: 96/100... Training loss: 0.1023\n",
      "Epoch: 96/100... Training loss: 0.1022\n",
      "Epoch: 96/100... Training loss: 0.1034\n",
      "Epoch: 96/100... Training loss: 0.1019\n",
      "Epoch: 96/100... Training loss: 0.1004\n",
      "Epoch: 96/100... Training loss: 0.1009\n",
      "Epoch: 96/100... Training loss: 0.1017\n",
      "Epoch: 96/100... Training loss: 0.0988\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1041\n",
      "Epoch: 96/100... Training loss: 0.1025\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.0986\n",
      "Epoch: 96/100... Training loss: 0.0996\n",
      "Epoch: 96/100... Training loss: 0.1016\n",
      "Epoch: 96/100... Training loss: 0.0990\n",
      "Epoch: 96/100... Training loss: 0.1012\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.1029\n",
      "Epoch: 96/100... Training loss: 0.1036\n",
      "Epoch: 96/100... Training loss: 0.0971\n",
      "Epoch: 96/100... Training loss: 0.0985\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.0998\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.1031\n",
      "Epoch: 96/100... Training loss: 0.0987\n",
      "Epoch: 96/100... Training loss: 0.1001\n",
      "Epoch: 96/100... Training loss: 0.1000\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.1013\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.1015\n",
      "Epoch: 96/100... Training loss: 0.1032\n",
      "Epoch: 96/100... Training loss: 0.1010\n",
      "Epoch: 96/100... Training loss: 0.1035\n",
      "Epoch: 96/100... Training loss: 0.1027\n",
      "Epoch: 96/100... Training loss: 0.0994\n",
      "Epoch: 96/100... Training loss: 0.1002\n",
      "Epoch: 96/100... Training loss: 0.1052\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1027\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1041\n",
      "Epoch: 97/100... Training loss: 0.1033\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.1027\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.1033\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1031\n",
      "Epoch: 97/100... Training loss: 0.1030\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1027\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.1035\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1036\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1033\n",
      "Epoch: 97/100... Training loss: 0.1026\n",
      "Epoch: 97/100... Training loss: 0.0971\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1041\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.1022\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0979\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.1020\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.1032\n",
      "Epoch: 97/100... Training loss: 0.1017\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1023\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.1052\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.1079\n",
      "Epoch: 97/100... Training loss: 0.1037\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1039\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.1020\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.1036\n",
      "Epoch: 97/100... Training loss: 0.1023\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1023\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1046\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1031\n",
      "Epoch: 97/100... Training loss: 0.1026\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0980\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.1035\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1034\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1046\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1020\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1023\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.1012\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.1029\n",
      "Epoch: 97/100... Training loss: 0.1055\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1027\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.1036\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1023\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1018\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.1027\n",
      "Epoch: 97/100... Training loss: 0.1038\n",
      "Epoch: 97/100... Training loss: 0.1033\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.1043\n",
      "Epoch: 97/100... Training loss: 0.0981\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1030\n",
      "Epoch: 97/100... Training loss: 0.0999\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.1022\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0959\n",
      "Epoch: 97/100... Training loss: 0.1018\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.0984\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0955\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.0973\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0978\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1047\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.1030\n",
      "Epoch: 97/100... Training loss: 0.1017\n",
      "Epoch: 97/100... Training loss: 0.1029\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0988\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0990\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.1027\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.1017\n",
      "Epoch: 97/100... Training loss: 0.1045\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 97/100... Training loss: 0.0986\n",
      "Epoch: 97/100... Training loss: 0.1017\n",
      "Epoch: 97/100... Training loss: 0.1037\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.0974\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.1038\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.0989\n",
      "Epoch: 97/100... Training loss: 0.1032\n",
      "Epoch: 97/100... Training loss: 0.0991\n",
      "Epoch: 97/100... Training loss: 0.1034\n",
      "Epoch: 97/100... Training loss: 0.1037\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1039\n",
      "Epoch: 97/100... Training loss: 0.0942\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0975\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.1025\n",
      "Epoch: 97/100... Training loss: 0.0972\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1028\n",
      "Epoch: 97/100... Training loss: 0.1041\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.0987\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1032\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1030\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.0993\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1052\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1025\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.1015\n",
      "Epoch: 97/100... Training loss: 0.1026\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.1019\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.1056\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0995\n",
      "Epoch: 97/100... Training loss: 0.1022\n",
      "Epoch: 97/100... Training loss: 0.1045\n",
      "Epoch: 97/100... Training loss: 0.1018\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.1048\n",
      "Epoch: 97/100... Training loss: 0.0982\n",
      "Epoch: 97/100... Training loss: 0.1047\n",
      "Epoch: 97/100... Training loss: 0.0985\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1006\n",
      "Epoch: 97/100... Training loss: 0.0983\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1011\n",
      "Epoch: 97/100... Training loss: 0.1036\n",
      "Epoch: 97/100... Training loss: 0.1048\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1053\n",
      "Epoch: 97/100... Training loss: 0.1016\n",
      "Epoch: 97/100... Training loss: 0.0996\n",
      "Epoch: 97/100... Training loss: 0.1022\n",
      "Epoch: 97/100... Training loss: 0.1031\n",
      "Epoch: 97/100... Training loss: 0.0976\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.1014\n",
      "Epoch: 97/100... Training loss: 0.0992\n",
      "Epoch: 97/100... Training loss: 0.0994\n",
      "Epoch: 97/100... Training loss: 0.1007\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.1041\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1065\n",
      "Epoch: 97/100... Training loss: 0.0977\n",
      "Epoch: 97/100... Training loss: 0.1071\n",
      "Epoch: 97/100... Training loss: 0.0997\n",
      "Epoch: 97/100... Training loss: 0.1004\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.1005\n",
      "Epoch: 97/100... Training loss: 0.1000\n",
      "Epoch: 97/100... Training loss: 0.1013\n",
      "Epoch: 97/100... Training loss: 0.1001\n",
      "Epoch: 97/100... Training loss: 0.1008\n",
      "Epoch: 97/100... Training loss: 0.1002\n",
      "Epoch: 97/100... Training loss: 0.1024\n",
      "Epoch: 97/100... Training loss: 0.1021\n",
      "Epoch: 97/100... Training loss: 0.1027\n",
      "Epoch: 97/100... Training loss: 0.1003\n",
      "Epoch: 97/100... Training loss: 0.1010\n",
      "Epoch: 97/100... Training loss: 0.1009\n",
      "Epoch: 97/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.1031\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1037\n",
      "Epoch: 98/100... Training loss: 0.1066\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0964\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1060\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1034\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1042\n",
      "Epoch: 98/100... Training loss: 0.1044\n",
      "Epoch: 98/100... Training loss: 0.1038\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1047\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.1026\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.1030\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1064\n",
      "Epoch: 98/100... Training loss: 0.1033\n",
      "Epoch: 98/100... Training loss: 0.1027\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0986\n",
      "Epoch: 98/100... Training loss: 0.1031\n",
      "Epoch: 98/100... Training loss: 0.1029\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1030\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.0959\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.1044\n",
      "Epoch: 98/100... Training loss: 0.1038\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0997\n",
      "Epoch: 98/100... Training loss: 0.1039\n",
      "Epoch: 98/100... Training loss: 0.1028\n",
      "Epoch: 98/100... Training loss: 0.1030\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1038\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.1028\n",
      "Epoch: 98/100... Training loss: 0.0965\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1035\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.1055\n",
      "Epoch: 98/100... Training loss: 0.0977\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1017\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1026\n",
      "Epoch: 98/100... Training loss: 0.1023\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.1041\n",
      "Epoch: 98/100... Training loss: 0.1046\n",
      "Epoch: 98/100... Training loss: 0.0984\n",
      "Epoch: 98/100... Training loss: 0.1027\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.1035\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.1033\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1036\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1030\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.1030\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.1041\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.1002\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1039\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1030\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0983\n",
      "Epoch: 98/100... Training loss: 0.1008\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.1022\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.1061\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.1033\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.1027\n",
      "Epoch: 98/100... Training loss: 0.1066\n",
      "Epoch: 98/100... Training loss: 0.1038\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.1026\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.1023\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1024\n",
      "Epoch: 98/100... Training loss: 0.1027\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.1017\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1039\n",
      "Epoch: 98/100... Training loss: 0.1023\n",
      "Epoch: 98/100... Training loss: 0.0960\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.0996\n",
      "Epoch: 98/100... Training loss: 0.0990\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.0975\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1027\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.1012\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.1000\n",
      "Epoch: 98/100... Training loss: 0.1058\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.0973\n",
      "Epoch: 98/100... Training loss: 0.1037\n",
      "Epoch: 98/100... Training loss: 0.1011\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.1032\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.1004\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.0987\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.1017\n",
      "Epoch: 98/100... Training loss: 0.1052\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.1027\n",
      "Epoch: 98/100... Training loss: 0.1063\n",
      "Epoch: 98/100... Training loss: 0.1021\n",
      "Epoch: 98/100... Training loss: 0.1049\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.1017\n",
      "Epoch: 98/100... Training loss: 0.1030\n",
      "Epoch: 98/100... Training loss: 0.1045\n",
      "Epoch: 98/100... Training loss: 0.1020\n",
      "Epoch: 98/100... Training loss: 0.0995\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1040\n",
      "Epoch: 98/100... Training loss: 0.1018\n",
      "Epoch: 98/100... Training loss: 0.0988\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1047\n",
      "Epoch: 98/100... Training loss: 0.0982\n",
      "Epoch: 98/100... Training loss: 0.1031\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1049\n",
      "Epoch: 98/100... Training loss: 0.1006\n",
      "Epoch: 98/100... Training loss: 0.1054\n",
      "Epoch: 98/100... Training loss: 0.0979\n",
      "Epoch: 98/100... Training loss: 0.0980\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1017\n",
      "Epoch: 98/100... Training loss: 0.0992\n",
      "Epoch: 98/100... Training loss: 0.1037\n",
      "Epoch: 98/100... Training loss: 0.1001\n",
      "Epoch: 98/100... Training loss: 0.0999\n",
      "Epoch: 98/100... Training loss: 0.0993\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.1013\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.0989\n",
      "Epoch: 98/100... Training loss: 0.1040\n",
      "Epoch: 98/100... Training loss: 0.1025\n",
      "Epoch: 98/100... Training loss: 0.0972\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.1023\n",
      "Epoch: 98/100... Training loss: 0.1015\n",
      "Epoch: 98/100... Training loss: 0.1038\n",
      "Epoch: 98/100... Training loss: 0.1010\n",
      "Epoch: 98/100... Training loss: 0.1014\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.1016\n",
      "Epoch: 98/100... Training loss: 0.1036\n",
      "Epoch: 98/100... Training loss: 0.1009\n",
      "Epoch: 98/100... Training loss: 0.1037\n",
      "Epoch: 98/100... Training loss: 0.0981\n",
      "Epoch: 98/100... Training loss: 0.0974\n",
      "Epoch: 98/100... Training loss: 0.1007\n",
      "Epoch: 98/100... Training loss: 0.0998\n",
      "Epoch: 98/100... Training loss: 0.0985\n",
      "Epoch: 98/100... Training loss: 0.1035\n",
      "Epoch: 98/100... Training loss: 0.1005\n",
      "Epoch: 98/100... Training loss: 0.1003\n",
      "Epoch: 98/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.1028\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.1021\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0987\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1021\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.1028\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1041\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1037\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.0990\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.1029\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.1048\n",
      "Epoch: 99/100... Training loss: 0.1033\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0980\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1033\n",
      "Epoch: 99/100... Training loss: 0.1049\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.1020\n",
      "Epoch: 99/100... Training loss: 0.1028\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.1021\n",
      "Epoch: 99/100... Training loss: 0.1029\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0973\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1020\n",
      "Epoch: 99/100... Training loss: 0.1043\n",
      "Epoch: 99/100... Training loss: 0.1027\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1020\n",
      "Epoch: 99/100... Training loss: 0.1034\n",
      "Epoch: 99/100... Training loss: 0.1037\n",
      "Epoch: 99/100... Training loss: 0.1035\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1032\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1054\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1052\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.1030\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.1043\n",
      "Epoch: 99/100... Training loss: 0.1042\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.1031\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1031\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.1033\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.1037\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1042\n",
      "Epoch: 99/100... Training loss: 0.1030\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.1025\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.1037\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1037\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0983\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1032\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0974\n",
      "Epoch: 99/100... Training loss: 0.1032\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.1007\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.1032\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.1040\n",
      "Epoch: 99/100... Training loss: 0.0971\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.0999\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0963\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.0992\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1006\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.1021\n",
      "Epoch: 99/100... Training loss: 0.1020\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.0982\n",
      "Epoch: 99/100... Training loss: 0.1025\n",
      "Epoch: 99/100... Training loss: 0.1018\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1027\n",
      "Epoch: 99/100... Training loss: 0.0977\n",
      "Epoch: 99/100... Training loss: 0.1029\n",
      "Epoch: 99/100... Training loss: 0.1034\n",
      "Epoch: 99/100... Training loss: 0.1025\n",
      "Epoch: 99/100... Training loss: 0.1042\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1037\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.1010\n",
      "Epoch: 99/100... Training loss: 0.1030\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.1061\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1018\n",
      "Epoch: 99/100... Training loss: 0.1018\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.1035\n",
      "Epoch: 99/100... Training loss: 0.1002\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.1032\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0996\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1013\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.0956\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.1018\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.0984\n",
      "Epoch: 99/100... Training loss: 0.1004\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.1028\n",
      "Epoch: 99/100... Training loss: 0.1019\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1029\n",
      "Epoch: 99/100... Training loss: 0.1021\n",
      "Epoch: 99/100... Training loss: 0.1069\n",
      "Epoch: 99/100... Training loss: 0.1079\n",
      "Epoch: 99/100... Training loss: 0.1061\n",
      "Epoch: 99/100... Training loss: 0.0997\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1067\n",
      "Epoch: 99/100... Training loss: 0.1031\n",
      "Epoch: 99/100... Training loss: 0.1015\n",
      "Epoch: 99/100... Training loss: 0.0981\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 99/100... Training loss: 0.1016\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.1022\n",
      "Epoch: 99/100... Training loss: 0.1011\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1051\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0988\n",
      "Epoch: 99/100... Training loss: 0.1001\n",
      "Epoch: 99/100... Training loss: 0.1020\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.0989\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.1025\n",
      "Epoch: 99/100... Training loss: 0.1065\n",
      "Epoch: 99/100... Training loss: 0.0965\n",
      "Epoch: 99/100... Training loss: 0.1063\n",
      "Epoch: 99/100... Training loss: 0.1024\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.1042\n",
      "Epoch: 99/100... Training loss: 0.0964\n",
      "Epoch: 99/100... Training loss: 0.0985\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1035\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1026\n",
      "Epoch: 99/100... Training loss: 0.1020\n",
      "Epoch: 99/100... Training loss: 0.1029\n",
      "Epoch: 99/100... Training loss: 0.1023\n",
      "Epoch: 99/100... Training loss: 0.1039\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1046\n",
      "Epoch: 99/100... Training loss: 0.1059\n",
      "Epoch: 99/100... Training loss: 0.1000\n",
      "Epoch: 99/100... Training loss: 0.0998\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.1008\n",
      "Epoch: 99/100... Training loss: 0.1003\n",
      "Epoch: 99/100... Training loss: 0.0979\n",
      "Epoch: 99/100... Training loss: 0.1017\n",
      "Epoch: 99/100... Training loss: 0.1014\n",
      "Epoch: 99/100... Training loss: 0.0991\n",
      "Epoch: 99/100... Training loss: 0.0993\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.1068\n",
      "Epoch: 99/100... Training loss: 0.0978\n",
      "Epoch: 99/100... Training loss: 0.1012\n",
      "Epoch: 99/100... Training loss: 0.0976\n",
      "Epoch: 99/100... Training loss: 0.0995\n",
      "Epoch: 99/100... Training loss: 0.1009\n",
      "Epoch: 99/100... Training loss: 0.0970\n",
      "Epoch: 99/100... Training loss: 0.1027\n",
      "Epoch: 99/100... Training loss: 0.1005\n",
      "Epoch: 99/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.0988\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.1043\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.0985\n",
      "Epoch: 100/100... Training loss: 0.1036\n",
      "Epoch: 100/100... Training loss: 0.1033\n",
      "Epoch: 100/100... Training loss: 0.1041\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1033\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.1025\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0976\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.0967\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1049\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.1031\n",
      "Epoch: 100/100... Training loss: 0.1032\n",
      "Epoch: 100/100... Training loss: 0.1032\n",
      "Epoch: 100/100... Training loss: 0.1025\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1048\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1053\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.0992\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.0972\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1027\n",
      "Epoch: 100/100... Training loss: 0.1039\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1044\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1039\n",
      "Epoch: 100/100... Training loss: 0.1027\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.1048\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1028\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.0980\n",
      "Epoch: 100/100... Training loss: 0.1033\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.0959\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0977\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.1025\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.1028\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.1026\n",
      "Epoch: 100/100... Training loss: 0.0962\n",
      "Epoch: 100/100... Training loss: 0.1025\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.1026\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.1029\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.1033\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.1025\n",
      "Epoch: 100/100... Training loss: 0.1040\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.1033\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1046\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1032\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1027\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.1034\n",
      "Epoch: 100/100... Training loss: 0.0996\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1035\n",
      "Epoch: 100/100... Training loss: 0.1036\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.1031\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.1025\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.1036\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.1037\n",
      "Epoch: 100/100... Training loss: 0.0987\n",
      "Epoch: 100/100... Training loss: 0.1031\n",
      "Epoch: 100/100... Training loss: 0.1027\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1039\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.0981\n",
      "Epoch: 100/100... Training loss: 0.1014\n",
      "Epoch: 100/100... Training loss: 0.0979\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.1043\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1045\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.1025\n",
      "Epoch: 100/100... Training loss: 0.1043\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.1047\n",
      "Epoch: 100/100... Training loss: 0.1045\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.1030\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.0982\n",
      "Epoch: 100/100... Training loss: 0.1011\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.1019\n",
      "Epoch: 100/100... Training loss: 0.0973\n",
      "Epoch: 100/100... Training loss: 0.1027\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1021\n",
      "Epoch: 100/100... Training loss: 0.1029\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1020\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0969\n",
      "Epoch: 100/100... Training loss: 0.1028\n",
      "Epoch: 100/100... Training loss: 0.1033\n",
      "Epoch: 100/100... Training loss: 0.1003\n",
      "Epoch: 100/100... Training loss: 0.1015\n",
      "Epoch: 100/100... Training loss: 0.0995\n",
      "Epoch: 100/100... Training loss: 0.1032\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.0986\n",
      "Epoch: 100/100... Training loss: 0.1002\n",
      "Epoch: 100/100... Training loss: 0.1027\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.1034\n",
      "Epoch: 100/100... Training loss: 0.1033\n",
      "Epoch: 100/100... Training loss: 0.1029\n",
      "Epoch: 100/100... Training loss: 0.1043\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1027\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1027\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.1035\n",
      "Epoch: 100/100... Training loss: 0.0983\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.1049\n",
      "Epoch: 100/100... Training loss: 0.1005\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1008\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0989\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.0991\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.1065\n",
      "Epoch: 100/100... Training loss: 0.1031\n",
      "Epoch: 100/100... Training loss: 0.0994\n",
      "Epoch: 100/100... Training loss: 0.1013\n",
      "Epoch: 100/100... Training loss: 0.1009\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.1012\n",
      "Epoch: 100/100... Training loss: 0.1023\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1006\n",
      "Epoch: 100/100... Training loss: 0.0960\n",
      "Epoch: 100/100... Training loss: 0.1042\n",
      "Epoch: 100/100... Training loss: 0.1033\n",
      "Epoch: 100/100... Training loss: 0.1001\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0990\n",
      "Epoch: 100/100... Training loss: 0.1024\n",
      "Epoch: 100/100... Training loss: 0.1000\n",
      "Epoch: 100/100... Training loss: 0.1038\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.1043\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1007\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.0997\n",
      "Epoch: 100/100... Training loss: 0.0965\n",
      "Epoch: 100/100... Training loss: 0.1040\n",
      "Epoch: 100/100... Training loss: 0.1004\n",
      "Epoch: 100/100... Training loss: 0.1018\n",
      "Epoch: 100/100... Training loss: 0.0984\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.1017\n",
      "Epoch: 100/100... Training loss: 0.1010\n",
      "Epoch: 100/100... Training loss: 0.0998\n",
      "Epoch: 100/100... Training loss: 0.0999\n",
      "Epoch: 100/100... Training loss: 0.1016\n",
      "Epoch: 100/100... Training loss: 0.0974\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.1022\n",
      "Epoch: 100/100... Training loss: 0.0993\n",
      "Epoch: 100/100... Training loss: 0.1049\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 200\n",
    "noise_factor = 0.5\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for e in range(epochs):\n",
    "    for ii in range(mnist.train.num_examples//batch_size):\n",
    "        batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "        \n",
    "        # Add random noise to input\n",
    "        noisy_imgs = imgs + noise_factor * np.random.randn(*imgs.shape)\n",
    "        # Clip input to be between 0 and 1\n",
    "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "        \n",
    "        # Noisy images as inputs, original images as targets\n",
    "        batch_cost, _ = sess.run([cost, opt], feed_dict={inputs_: noisy_imgs,\n",
    "                                                         targets_: imgs})\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
    "              \"Training loss: {:.4f}\".format(batch_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABawAAAEsCAYAAAAvofT2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f837c8b5748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\n",
    "in_imgs = mnist.test.images[:10]\n",
    "noisy_imgs = in_imgs + noise_factor * np.random.randn(*in_imgs.shape)\n",
    "noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "\n",
    "reconstructed = sess.run(decoded, feed_dict={inputs_: noisy_imgs.reshape((10, 28, 28, 1))})\n",
    "\n",
    "for images, row in zip([noisy_imgs, reconstructed], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(img.reshape((28, 28)), cmap='Greys_r')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "fig.tight_layout(pad=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
